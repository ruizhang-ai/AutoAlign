{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-Cnf45GEK0Ow"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import datetime as dt\n",
    "import pickle as cPickle\n",
    "from functools import reduce\n",
    "from rdflib import URIRef\n",
    "import time\n",
    "\n",
    "import os\n",
    "#DEVICE = \"0\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=DEVICE\n",
    "\n",
    "from kitchen.text.converters import getwriter, to_bytes, to_unicode\n",
    "from kitchen.i18n import get_translation_object\n",
    "translations = get_translation_object('example')\n",
    "_ = translations.ugettext\n",
    "b_ = translations.lgettext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43379,
     "status": "ok",
     "timestamp": 1532297300333,
     "user": {
      "displayName": "Bayu Distiawan",
      "photoUrl": "//lh5.googleusercontent.com/-ZlEtcF5Few0/AAAAAAAAAAI/AAAAAAAAAAA/caTzimkqvdg/s50-c-k-no/photo.jpg",
      "userId": "113711532389286602961"
     },
     "user_tz": 0
    },
    "id": "05aOlHhgK0O3",
    "outputId": "ce8bae73-a395-44fd-ba3b-3273517e9d40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nb780380f65164ed4a7c3bc30a3b5f5bd (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Combine two KG\n",
    "dataset_name = 'wd'\n",
    "path = 'DW-NB/'\n",
    "lgd_filename = '../data/'+path+dataset_name+'.ttl'\n",
    "dbp_filename = '../data/'+path+'dbp_'+dataset_name+'.ttl'\n",
    "predicate_graph = cPickle.load(open('../data/'+path+dataset_name+'_pred_prox_graph.pickle', 'rb'))\n",
    "map_file = '../data/'+path+'mapping_'+dataset_name+'.ttl'\n",
    "\n",
    "graph = Graph()\n",
    "graph.parse(location=lgd_filename, format='nt')\n",
    "graph.parse(location=dbp_filename, format='nt')\n",
    "\n",
    "map_graph = Graph()\n",
    "map_graph.parse(location=map_file, format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847122"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicate_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dict(d):\n",
    "    return dict([(v, k) for k, v in d.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SWJb3cg5K0O-"
   },
   "outputs": [],
   "source": [
    "entity_label_dict = dict()\n",
    "\n",
    "for s,p,o in graph:\n",
    "    if str(p) == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "        entity_label_dict[s] = str(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149909"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7TufL-_7K0PB"
   },
   "outputs": [],
   "source": [
    "num_subj_triple = dict()\n",
    "for s,p,o in graph:\n",
    "    if num_subj_triple.get(s) == None:\n",
    "        num_subj_triple[s] = 1\n",
    "    else:\n",
    "        num_subj_triple[s] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# YAGO\n",
    "intersection_predicates = ['http://www.w3.org/2000/01/rdf-schema#label',\\\n",
    "'http://dbpedia.org/ontology/birthDate',\\\n",
    "'http://yago-knowledge.org/ontology/birthDate',\\\n",
    "'http://xmlns.com/foaf/0.1/gender',\\\n",
    "'http://xmlns.com/foaf/0.1/surname',\\\n",
    "'http://xmlns.com/foaf/0.1/givenName',\\\n",
    "'http://dbpedia.org/ontology/birthYear',\\\n",
    "'http://dbpedia.org/ontology/height',\\\n",
    "'http://dbpedia.org/ontology/Person/height',\\\n",
    "'http://yago-knowledge.org/ontology/birthYear',\\\n",
    "'http://yago-knowledge.org/ontology/height',\\\n",
    "'http://yago-knowledge.org/ontology/Person/height',\\\n",
    "'http://www.w3.org/2003/01/geo/wgs84_pos#long',\\\n",
    "'http://www.w3.org/2003/01/geo/wgs84_pos#lat',\\\n",
    "'http://dbpedia.org/ontology/populationTotal',\\\n",
    "'http://dbpedia.org/ontology/deathDate',\\\n",
    "'http://dbpedia.org/ontology/deathYear',\\\n",
    "'http://dbpedia.org/ontology/alias',\\\n",
    "'http://dbpedia.org/ontology/PopulatedPlace/populationDensity'\\\n",
    "'http://yago-knowledge.org/ontology/populationTotal',\\\n",
    "'http://yago-knowledge.org/ontology/deathDate',\\\n",
    "'http://yago-knowledge.org/ontology/deathYear',\\\n",
    "'http://yago-knowledge.org/ontology/alias',\\\n",
    "'http://yago-knowledge.org/ontology/PopulatedPlace/populationDensity']\n",
    "\n",
    "\n",
    "intersection_predicates_uri = ['http://dbpedia.org/ontology/deathPlace',\\\n",
    "'http://dbpedia.org/ontology/isPartOf',\\\n",
    "'http://yago-knowledge.org/ontology/deathPlace',\\\n",
    "'http://yago-knowledge.org/ontology/isPartOf',\\\n",
    "'http://linkedgeodata.org/ontology/isIn',\\\n",
    "'http://dbpedia.org/ontology/managerClub',\\\n",
    "'http://dbpedia.org/ontology/country',\\\n",
    "'http://yago-knowledge.org/ontology/managerClub',\\\n",
    "'http://yago-knowledge.org/ontology/country',\\\n",
    "'http://linkedgeodata.org/ontology/country',\\\n",
    "'http://dbpedia.org/ontology/team',\\\n",
    "'http://yago-knowledge.org/ontology/team',\\\n",
    "'http://www.w3.org/2003/01/geo/isIn',\\\n",
    "'http://www.w3.org/2003/01/geo/country',\\\n",
    "'http://dbpedia.org/ontology/birthPlace',\\\n",
    "'http://yago-knowledge.org/ontology/birthPlace']\n",
    "\n",
    "'''# LGD/GEO\n",
    "intersection_predicates = ['http://www.w3.org/2000/01/rdf-schema#label',\\\n",
    "                           'http://www.w3.org/2003/01/geo/wgs84_pos#long', \\\n",
    "                           'http://www.w3.org/2003/01/geo/wgs84_pos#lat']\n",
    "intersection_predicates_uri = ['http://dbpedia.org/ontology/isPartOf',\\\n",
    "                              'http://linkedgeodata.org/ontology/isIn',\\\n",
    "                              'http://dbpedia.org/ontology/country',\\\n",
    "                              'http://linkedgeodata.org/ontology/country',\\\n",
    "                              'http://www.w3.org/2003/01/geo/country',\\\n",
    "                              'http://www.w3.org/2003/01/geo/isIn',\n",
    "                              ]'''\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "intersection_predicates = ['http://www.wikidata.org/entity/P36',\\\n",
    " 'http://www.wikidata.org/entity/P185',\\\n",
    " 'http://www.wikidata.org/entity/P345',\\\n",
    " 'http://www.wikidata.org/entity/P214',\\\n",
    " 'http://www.wikidata.org/entity/P40',\\\n",
    " 'http://www.wikidata.org/entity/P569',\\\n",
    " 'http://www.wikidata.org/entity/P102',\\\n",
    " 'http://www.wikidata.org/entity/P175',\\\n",
    " 'http://www.wikidata.org/entity/P131',\\\n",
    " 'http://www.wikidata.org/entity/P577',\\\n",
    " 'http://www.wikidata.org/entity/P140',\\\n",
    " 'http://www.wikidata.org/entity/P400',\\\n",
    " 'http://www.wikidata.org/entity/P736',\\\n",
    " 'http://www.wikidata.org/entity/P1432',\\\n",
    " 'http://www.wikidata.org/entity/P159',\\\n",
    " 'http://www.wikidata.org/entity/P136',\\\n",
    " 'http://www.wikidata.org/entity/P1477',\\\n",
    " 'http://www.wikidata.org/entity/P227',\\\n",
    " 'http://www.wikidata.org/entity/P6',\\\n",
    " 'http://www.wikidata.org/entity/P108',\\\n",
    " 'http://www.wikidata.org/entity/P585',\\\n",
    " 'http://www.wikidata.org/entity/P239',\\\n",
    " 'http://www.wikidata.org/entity/P98',\\\n",
    " 'http://www.wikidata.org/entity/P54',\\\n",
    " 'http://www.wikidata.org/entity/P17',\\\n",
    " 'http://www.wikidata.org/entity/P244',\\\n",
    " 'http://www.wikidata.org/entity/P238',\\\n",
    " 'http://www.wikidata.org/entity/P287',\\\n",
    " 'http://www.wikidata.org/entity/P570',\\\n",
    " 'http://www.wikidata.org/entity/P176',\\\n",
    " 'http://www.wikidata.org/entity/P119',\\\n",
    " 'http://www.wikidata.org/entity/P230',\\\n",
    " 'http://www.wikidata.org/entity/P50',\\\n",
    " 'http://www.wikidata.org/entity/P57',\\\n",
    " 'http://www.wikidata.org/entity/P969',\\\n",
    " 'http://www.wikidata.org/entity/P20',\\\n",
    " 'http://www.wikidata.org/entity/P374',\\\n",
    " 'http://www.wikidata.org/entity/P19',\\\n",
    " 'http://www.wikidata.org/entity/P84',\\\n",
    " 'http://www.wikidata.org/entity/P166',\\\n",
    " 'http://www.wikidata.org/entity/P571',\\\n",
    " 'http://www.wikidata.org/entity/P184',\\\n",
    " 'http://www.wikidata.org/entity/P473',\\\n",
    " 'http://www.wikidata.org/entity/P219',\\\n",
    " 'http://www.wikidata.org/entity/P170',\\\n",
    " 'http://www.wikidata.org/entity/P26',\\\n",
    " 'http://www.wikidata.org/entity/P580',\\\n",
    " 'http://www.wikidata.org/entity/P1015',\\\n",
    " 'http://www.wikidata.org/entity/P408',\\\n",
    " 'http://www.wikidata.org/entity/P172',\\\n",
    " 'http://www.wikidata.org/entity/P220',\\\n",
    " 'http://www.wikidata.org/entity/P177',\\\n",
    " 'http://www.wikidata.org/entity/P178',\\\n",
    " 'http://www.wikidata.org/entity/P161',\\\n",
    " 'http://www.wikidata.org/entity/P27',\\\n",
    " 'http://www.wikidata.org/entity/P742',\\\n",
    " 'http://www.wikidata.org/entity/P607',\\\n",
    " 'http://www.wikidata.org/entity/P286',\\\n",
    " 'http://www.wikidata.org/entity/P361',\\\n",
    " 'http://www.wikidata.org/entity/P1082',\\\n",
    " 'http://www.wikidata.org/entity/P344',\\\n",
    " 'http://www.wikidata.org/entity/P106',\\\n",
    " 'http://www.wikidata.org/entity/P112',\\\n",
    " 'http://www.wikidata.org/entity/P1036',\\\n",
    " 'http://www.wikidata.org/entity/P229',\\\n",
    " 'http://www.w3.org/2000/01/rdf-schema#label',\\\n",
    " 'http://www.wikidata.org/entity/P126',\\\n",
    " 'http://www.wikidata.org/entity/P750',\\\n",
    " 'http://www.wikidata.org/entity/P144',\\\n",
    " 'http://www.wikidata.org/entity/P69',\\\n",
    " 'http://www.wikidata.org/entity/P264',\\\n",
    " 'http://www.wikidata.org/entity/P218',\\\n",
    " 'http://www.wikidata.org/entity/P110',\\\n",
    " 'http://www.wikidata.org/entity/P86',\\\n",
    " 'http://www.wikidata.org/entity/P957',\\\n",
    " 'http://www.wikidata.org/entity/P1040',\\\n",
    " 'http://www.wikidata.org/entity/P200',\\\n",
    " 'http://www.wikidata.org/entity/P605',\\\n",
    " 'http://www.wikidata.org/entity/P118',\\\n",
    " 'http://www.wikidata.org/entity/P127',\\\n",
    " 'http://dbpedia.org/resource/P36',\\\n",
    " 'http://dbpedia.org/resource/P185',\\\n",
    " 'http://dbpedia.org/resource/P345',\\\n",
    " 'http://dbpedia.org/resource/P214',\\\n",
    " 'http://dbpedia.org/resource/P40',\\\n",
    " 'http://dbpedia.org/resource/P569',\\\n",
    " 'http://dbpedia.org/resource/P102',\\\n",
    " 'http://dbpedia.org/resource/P175',\\\n",
    " 'http://dbpedia.org/resource/P131',\\\n",
    " 'http://dbpedia.org/resource/P577',\\\n",
    " 'http://dbpedia.org/resource/P140',\\\n",
    " 'http://dbpedia.org/resource/P400',\\\n",
    " 'http://dbpedia.org/resource/P736',\\\n",
    " 'http://dbpedia.org/resource/P1432',\\\n",
    " 'http://dbpedia.org/resource/P159',\\\n",
    " 'http://dbpedia.org/resource/P136',\\\n",
    " 'http://dbpedia.org/resource/P1477',\\\n",
    " 'http://dbpedia.org/resource/P227',\\\n",
    " 'http://dbpedia.org/resource/P6',\\\n",
    " 'http://dbpedia.org/resource/P108',\\\n",
    " 'http://dbpedia.org/resource/P585',\\\n",
    " 'http://dbpedia.org/resource/P239',\\\n",
    " 'http://dbpedia.org/resource/P98',\\\n",
    " 'http://dbpedia.org/resource/P54',\\\n",
    " 'http://dbpedia.org/resource/P17',\\\n",
    " 'http://dbpedia.org/resource/P244',\\\n",
    " 'http://dbpedia.org/resource/P238',\\\n",
    " 'http://dbpedia.org/resource/P287',\\\n",
    " 'http://dbpedia.org/resource/P570',\\\n",
    " 'http://dbpedia.org/resource/P176',\\\n",
    " 'http://dbpedia.org/resource/P119',\\\n",
    " 'http://dbpedia.org/resource/P230',\\\n",
    " 'http://dbpedia.org/resource/P50',\\\n",
    " 'http://dbpedia.org/resource/P57',\\\n",
    " 'http://dbpedia.org/resource/P969',\\\n",
    " 'http://dbpedia.org/resource/P20',\\\n",
    " 'http://dbpedia.org/resource/P374',\\\n",
    " 'http://dbpedia.org/resource/P19',\\\n",
    " 'http://dbpedia.org/resource/P84',\\\n",
    " 'http://dbpedia.org/resource/P166',\\\n",
    " 'http://dbpedia.org/resource/P571',\\\n",
    " 'http://dbpedia.org/resource/P184',\\\n",
    " 'http://dbpedia.org/resource/P473',\\\n",
    " 'http://dbpedia.org/resource/P219',\\\n",
    " 'http://dbpedia.org/resource/P170',\\\n",
    " 'http://dbpedia.org/resource/P26',\\\n",
    " 'http://dbpedia.org/resource/P580',\\\n",
    " 'http://dbpedia.org/resource/P1015',\\\n",
    " 'http://dbpedia.org/resource/P408',\\\n",
    " 'http://dbpedia.org/resource/P172',\\\n",
    " 'http://dbpedia.org/resource/P220',\\\n",
    " 'http://dbpedia.org/resource/P177',\\\n",
    " 'http://dbpedia.org/resource/P178',\\\n",
    " 'http://dbpedia.org/resource/P161',\\\n",
    " 'http://dbpedia.org/resource/P27',\\\n",
    " 'http://dbpedia.org/resource/P742',\\\n",
    " 'http://dbpedia.org/resource/P607',\\\n",
    " 'http://dbpedia.org/resource/P286',\\\n",
    " 'http://dbpedia.org/resource/P361',\\\n",
    " 'http://dbpedia.org/resource/P1082',\\\n",
    " 'http://dbpedia.org/resource/P344',\\\n",
    " 'http://dbpedia.org/resource/P106',\\\n",
    " 'http://dbpedia.org/resource/P112',\\\n",
    " 'http://dbpedia.org/resource/P1036',\\\n",
    " 'http://dbpedia.org/resource/P229',\\\n",
    " 'http://dbpedia.org/resource/P126',\\\n",
    " 'http://dbpedia.org/resource/P750',\\\n",
    " 'http://dbpedia.org/resource/P144',\\\n",
    " 'http://dbpedia.org/resource/P69',\\\n",
    " 'http://dbpedia.org/resource/P264',\\\n",
    " 'http://dbpedia.org/resource/P218',\\\n",
    " 'http://dbpedia.org/resource/P110',\\\n",
    " 'http://dbpedia.org/resource/P86',\\\n",
    " 'http://dbpedia.org/resource/P957',\\\n",
    " 'http://dbpedia.org/resource/P1040',\\\n",
    " 'http://dbpedia.org/resource/P200',\\\n",
    " 'http://dbpedia.org/resource/P605',\\\n",
    " 'http://dbpedia.org/resource/P118',\\\n",
    " 'http://dbpedia.org/resource/P127']\n",
    "\n",
    "intersection_predicates_uri = intersection_predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37334,
     "status": "ok",
     "timestamp": 1532297345055,
     "user": {
      "displayName": "Bayu Distiawan",
      "photoUrl": "//lh5.googleusercontent.com/-ZlEtcF5Few0/AAAAAAAAAAI/AAAAAAAAAAA/caTzimkqvdg/s50-c-k-no/photo.jpg",
      "userId": "113711532389286602961"
     },
     "user_tz": 0
    },
    "id": "bWXb0oFFK0PE",
    "outputId": "2b00b71e-ed1d-4e64-ff41-4d8e457a4043",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273161 1248 786 75000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import rdflib\n",
    "import re\n",
    "import collections\n",
    "\n",
    "literal_len = 10\n",
    "\n",
    "def dataType(string):\n",
    "    odp='string'\n",
    "    patternBIT=re.compile('[01]')\n",
    "    patternINT=re.compile('[0-9]+')\n",
    "    patternFLOAT=re.compile('[0-9]+\\.[0-9]+')\n",
    "    patternTEXT=re.compile('[a-zA-Z0-9]+')\n",
    "    if patternTEXT.match(string):\n",
    "        odp= \"string\"\n",
    "    if patternINT.match(string):\n",
    "        odp= \"integer\"\n",
    "    if patternFLOAT.match(string):\n",
    "        odp= \"float\"\n",
    "    return odp\n",
    "\n",
    "### Return: data, data_type\n",
    "def getRDFData(o):\n",
    "    if isinstance(o, rdflib.term.URIRef):\n",
    "        data_type = \"uri\"\n",
    "    else:\n",
    "        data_type = o.datatype\n",
    "        if data_type == None:\n",
    "            data_type = dataType(o)\n",
    "        else:\n",
    "            if \"#\" in o.datatype:\n",
    "                data_type = o.datatype.split('#')[1].lower()\n",
    "            else:\n",
    "                data_type = dataType(o)\n",
    "        if data_type == 'gmonthday' or data_type=='gyear':\n",
    "            data_type = 'date'\n",
    "        if data_type == 'positiveinteger' or data_type == 'int' or data_type == 'nonnegativeinteger':\n",
    "            data_type = 'integer'\n",
    "    return o, data_type\n",
    "    \n",
    "\n",
    "def getLiteralArray(o, literal_len, char_vocab):\n",
    "    literal_object = list()\n",
    "    for i in range(literal_len):\n",
    "        literal_object.append(0)\n",
    "    if o[1] != 'uri':\n",
    "        max_len = min(literal_len, len(o[0]))\n",
    "        for i in range(max_len):\n",
    "            if char_vocab.get(o[0][i]) == None:\n",
    "                char_vocab[o[0][i]] = len(char_vocab)\n",
    "            literal_object[i] = char_vocab[o[0][i]]\n",
    "    elif entity_label_dict.get(o[0]) != None:\n",
    "        label = entity_label_dict.get(o[0])\n",
    "        max_len = min(literal_len, len(label))\n",
    "        for i in range(max_len):\n",
    "            if char_vocab.get(label[i]) == None:\n",
    "                char_vocab[label[i]] = len(char_vocab)\n",
    "            literal_object[i] = char_vocab[label[i]]\n",
    "        \n",
    "    return literal_object\n",
    "\n",
    "entity_vocab = dict()\n",
    "entity_dbp_vocab = set()\n",
    "entity_dbp_vocab_neg = list()\n",
    "entity_lgd_vocab_neg = list()\n",
    "predicate_vocab = dict()\n",
    "predicate_vocab['<NONE>'] = 0\n",
    "entity_literal_vocab = dict()\n",
    "entity_literal_dbp_vocab_neg = list()\n",
    "entity_literal_lgd_vocab_neg = list()\n",
    "data_uri = [] ###[ [[s,p,o,p_trans],[chars],predicate_weight], ... ]\n",
    "data_uri_0 = []\n",
    "data_literal_0 = []\n",
    "data_literal = []\n",
    "data_uri_trans = []\n",
    "data_literal_trans = []\n",
    "char_vocab = dict()\n",
    "char_vocab['<pad>'] = 0\n",
    "#tmp_data = []\n",
    "\n",
    "pred_weight = dict()\n",
    "num_triples = 0\n",
    "for s, p, o in graph:\n",
    "\n",
    "    num_triples += 1\n",
    "    s = getRDFData(s)\n",
    "    p = getRDFData(p)\n",
    "    o = getRDFData(o)\n",
    "    \n",
    "    if pred_weight.get(p[0]) == None:\n",
    "        pred_weight[p[0]] = 1\n",
    "    else:\n",
    "        pred_weight[p[0]] += 1\n",
    "\n",
    "    ## all vocab for finding neg sample\n",
    "    if entity_literal_vocab.get(s[0]) == None:\n",
    "        entity_literal_vocab[s[0]] = len(entity_literal_vocab)\n",
    "        if str(s[0]).startswith('http://dbpedia.org/resource/'):\n",
    "            entity_literal_dbp_vocab_neg.append(s[0])\n",
    "        else:\n",
    "            entity_literal_lgd_vocab_neg.append(s[0])\n",
    "    if entity_literal_vocab.get(o[0]) == None:\n",
    "        entity_literal_vocab[o[0]] = len(entity_literal_vocab)\n",
    "        if str(s[0]).startswith('http://dbpedia.org/resource/'):\n",
    "            entity_literal_dbp_vocab_neg.append(o[0])\n",
    "        else:\n",
    "            entity_literal_lgd_vocab_neg.append(o[0])\n",
    "        \n",
    "    if entity_vocab.get(s[0]) == None:\n",
    "        idx = len(entity_vocab)\n",
    "        entity_vocab[s[0]] = idx\n",
    "        if str(s[0]).startswith('http://dbpedia.org/resource/'):\n",
    "            #entity_dbp_vocab.append(idx)\n",
    "            entity_dbp_vocab_neg.append(s[0])\n",
    "        else:\n",
    "            entity_lgd_vocab_neg.append(s[0])\n",
    "    \n",
    "    if str(s[0]).startswith('http://dbpedia.org/resource/'):\n",
    "        entity_dbp_vocab.add(entity_vocab[s[0]])            # replace here to fix dbp vocab set\n",
    "    \n",
    "    if predicate_vocab.get(p[0]) == None:\n",
    "        predicate_vocab[p[0]] = len(predicate_vocab)\n",
    "    if o[1] == 'uri':\n",
    "        if entity_vocab.get(o[0]) == None:\n",
    "            entity_vocab[o[0]] = len(entity_vocab)\n",
    "            if str(s[0]).startswith('http://dbpedia.org/resource/'):\n",
    "                entity_dbp_vocab_neg.append(o[0])\n",
    "            else:\n",
    "                entity_lgd_vocab_neg.append(o[0])\n",
    "        literal_object = getLiteralArray(o, literal_len, char_vocab)\n",
    "        if str(p[0]) not in intersection_predicates_uri:\n",
    "            data_uri_0.append([[entity_vocab[s[0]], predicate_vocab[p[0]], entity_vocab[o[0]], 0], literal_object])\n",
    "        else:\n",
    "            data_uri.append([[entity_vocab[s[0]], predicate_vocab[p[0]], entity_vocab[o[0]], 0], literal_object])\n",
    "            ### DATA TRANS\n",
    "            duplicate_preds = [item for item, count in collections.Counter(graph.predicates(o[0],None)).items() if count > 1]\n",
    "            if True:\n",
    "              for g1 in graph.triples((o[0],None,None)):\n",
    "                  if len(g1) > 0:\n",
    "                      s1,p1,o1 = g1\n",
    "\n",
    "                      s1 = getRDFData(s1)\n",
    "                      p1 = getRDFData(p1)\n",
    "                      o1 = getRDFData(o1)\n",
    "\n",
    "                      if entity_vocab.get(o1[0]) == None:\n",
    "                          entity_vocab[o1[0]] = len(entity_vocab)\n",
    "                      if str(s1[0]).startswith('http://dbpedia.org/resource/'):\n",
    "                          entity_dbp_vocab_neg.append(o1[0])\n",
    "                      else:\n",
    "                          entity_lgd_vocab_neg.append(o1[0])\n",
    "                      if entity_vocab.get(o1[1]) == None:\n",
    "                          entity_vocab[o1[1]] = len(entity_vocab)\n",
    "                      if predicate_vocab.get(p1[0]) == None:\n",
    "                          predicate_vocab[p1[0]] = len(predicate_vocab)\n",
    "\n",
    "                      if p[0] != p1[0] \\\n",
    "                          and len(set(str(x) for x in (graph.predicates(s[0]))).intersection(set(intersection_predicates_uri))) != 0:\n",
    "                          if isinstance(o1[0], rdflib.term.URIRef) and str(p1[0]) in intersection_predicates_uri:\n",
    "                              data_uri_trans.append([[entity_vocab[s[0]], predicate_vocab[p[0]], entity_vocab[o1[0]], predicate_vocab[p1[0]]], getLiteralArray(o1, literal_len, char_vocab)])\n",
    "                          elif isinstance(o1[0], rdflib.term.Literal) and str(p1[0]) == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "                              data_literal_trans.append([[entity_vocab[s[0]], predicate_vocab[p[0]], entity_vocab[o1[1]], predicate_vocab[p1[0]]], getLiteralArray(o1, literal_len, char_vocab)])\n",
    "                              #tmp_data.append((s[0], p[0], o[0], p1[0], o1[0]))\n",
    "              ##############\n",
    "    else:\n",
    "        if entity_vocab.get(o[1]) == None:\n",
    "            entity_vocab[o[1]] = len(entity_vocab)\n",
    "        literal_object = getLiteralArray(o, literal_len, char_vocab)\n",
    "        if str(p[0]) not in intersection_predicates:\n",
    "            data_literal_0.append([[entity_vocab[s[0]], predicate_vocab[p[0]], entity_vocab[o[1]], 0], literal_object])\n",
    "        else:\n",
    "            data_literal.append([[entity_vocab[s[0]], predicate_vocab[p[0]], entity_vocab[o[1]], 0], literal_object])\n",
    "            \n",
    "reverse_entity_vocab = invert_dict(entity_vocab)\n",
    "reverse_predicate_vocab = invert_dict(predicate_vocab)\n",
    "reverse_char_vocab = invert_dict(char_vocab)\n",
    "reverse_entity_literal_vocab = invert_dict(entity_literal_vocab)\n",
    "\n",
    "#Add predicate weight\n",
    "for i in range(0, len(data_uri)):\n",
    "    s = reverse_entity_vocab.get(data_uri[i][0][0])\n",
    "    p = reverse_predicate_vocab.get(data_uri[i][0][1])\n",
    "    data_uri[i].append([(pred_weight.get(p)/float(num_triples))])\n",
    "\n",
    "for i in range(0, len(data_uri_0)):\n",
    "    s = reverse_entity_vocab.get(data_uri_0[i][0][0])\n",
    "    p = reverse_predicate_vocab.get(data_uri_0[i][0][1])\n",
    "    data_uri_0[i].append([(pred_weight.get(p)/float(num_triples))])\n",
    "\n",
    "for i in range(0, len(data_uri_trans)):\n",
    "    s = reverse_entity_vocab.get(data_uri_trans[i][0][0])\n",
    "    p = reverse_predicate_vocab.get(data_uri_trans[i][0][1])\n",
    "    data_uri_trans[i].append([(pred_weight.get(p)/float(num_triples))])\n",
    "    \n",
    "for i in range(0, len(data_literal)):\n",
    "    s = reverse_entity_vocab.get(data_literal[i][0][0])\n",
    "    p = reverse_predicate_vocab.get(data_literal[i][0][1])\n",
    "    data_literal[i].append([(pred_weight.get(p)/float(num_triples))])\n",
    "\n",
    "for i in range(0, len(data_literal_0)):\n",
    "    s = reverse_entity_vocab.get(data_literal_0[i][0][0])\n",
    "    p = reverse_predicate_vocab.get(data_literal_0[i][0][1])\n",
    "    data_literal_0[i].append([(pred_weight.get(p)/float(num_triples))])\n",
    "    \n",
    "for i in range(0, len(data_literal_trans)):\n",
    "    s = reverse_entity_vocab.get(data_literal_trans[i][0][0])\n",
    "    p = reverse_predicate_vocab.get(data_literal_trans[i][0][1])\n",
    "    data_literal_trans[i].append([(pred_weight.get(p)/float(num_triples))])\n",
    "    \n",
    "if len(data_uri_trans) < 100:\n",
    "    data_uri_trans = data_uri_trans+data_uri_trans\n",
    "    \n",
    "print (len(entity_vocab), len(predicate_vocab), len(char_vocab), len(entity_dbp_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dbp_vocab = list(entity_dbp_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t in predicate_graph:\n",
    "    p = URIRef(t[1].replace('<','').replace('>',''))\n",
    "    if p not in predicate_vocab:\n",
    "        print(p)\n",
    "        i += 1\n",
    "    if i >= 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate proximity triples\n",
    "\n",
    "ent_type_vocab = dict()\n",
    "data_predicate = list()\n",
    "domain_vocab = dict()\n",
    "range_vocab = dict()\n",
    "for t in  predicate_graph:\n",
    "    s,p,o = t\n",
    "    p = URIRef(p.replace('<','').replace('>',''))\n",
    "    if s not in ent_type_vocab:\n",
    "        ent_type_vocab[s] = len(ent_type_vocab)\n",
    "    if o not in ent_type_vocab:\n",
    "        ent_type_vocab[o] = len(ent_type_vocab)\n",
    "    data_predicate.append([[ent_type_vocab[s],predicate_vocab[p],ent_type_vocab[o], 0], [0]*10, [0]])\n",
    "    \n",
    "    if predicate_vocab[p] in domain_vocab:\n",
    "        domain_vocab[predicate_vocab[p]].add(ent_type_vocab[s])\n",
    "    else:\n",
    "        domain_vocab[predicate_vocab[p]] = set()\n",
    "        domain_vocab[predicate_vocab[p]].add(ent_type_vocab[s])\n",
    "        \n",
    "    if predicate_vocab[p] in range_vocab:\n",
    "        range_vocab[predicate_vocab[p]].add(ent_type_vocab[o])\n",
    "    else:\n",
    "        range_vocab[predicate_vocab[p]] = set()\n",
    "        range_vocab[predicate_vocab[p]].add(ent_type_vocab[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211904\n",
      "188827\n",
      "253206\n",
      "322156\n",
      "149093\n",
      "122667\n",
      "847122\n"
     ]
    }
   ],
   "source": [
    "print (len(data_uri_trans))\n",
    "print (len(data_literal_trans))\n",
    "print (len(data_uri))\n",
    "print (len(data_literal))\n",
    "print (len(data_uri_0))\n",
    "print (len(data_literal_0))\n",
    "print (len(data_predicate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 183, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0]]\n"
     ]
    }
   ],
   "source": [
    "print(data_predicate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_JrNO09iK0PI"
   },
   "outputs": [],
   "source": [
    "def getBatch(data, batchSize, current, entityVocab, literal_len, char_vocab):\n",
    "    hasNext = current+batchSize < len(data)\n",
    "    \n",
    "    if (len(data) - current) < batchSize:\n",
    "        current = current - (batchSize - (len(data) - current))\n",
    "    \n",
    "    dataPos_all = data[current:current+batchSize]\n",
    "    dataPos = list()\n",
    "    charPos = list()\n",
    "    pred_weight_pos = list()\n",
    "    dataNeg = list()\n",
    "    predNeg = list()\n",
    "    predTransNeg = list()\n",
    "    charNeg = list()\n",
    "    pred_weight_neg = list()\n",
    "    for triples,chars, pred_weight in dataPos_all:\n",
    "        s,p,o,p_trans = triples\n",
    "        dataPos.append([s,p,o,p_trans])\n",
    "        charPos.append(chars)\n",
    "        pred_weight_pos.append(pred_weight)\n",
    "        lr = round(random.random())\n",
    "        \n",
    "        if lr == 0:\n",
    "            try:\n",
    "                o_type = getRDFData(reverse_entity_vocab[o])\n",
    "            except:\n",
    "                o_type = 'not_uri'\n",
    "            \n",
    "            literal_array = []\n",
    "            rerun = True\n",
    "            while rerun or negElm[0] == (reverse_entity_vocab[o] and literal_array == chars):\n",
    "                if o_type[1] == 'uri':\n",
    "                    if str(s).startswith('http://dbpedia.org/resource/'):\n",
    "                        negElm = entity_dbp_vocab_neg[random.randint(0, len(entity_dbp_vocab_neg)-1)]\n",
    "                        negElm = reverse_entity_vocab[entity_vocab[negElm]]\n",
    "                    else:\n",
    "                        negElm = entity_lgd_vocab_neg[random.randint(0, len(entity_lgd_vocab_neg)-1)]\n",
    "                        negElm = reverse_entity_vocab[entity_vocab[negElm]]\n",
    "                else:\n",
    "                    if str(s).startswith('http://dbpedia.org/resource/'):\n",
    "                        negElm = entity_literal_dbp_vocab_neg[random.randint(0, len(entity_literal_dbp_vocab_neg)-1)]\n",
    "                        negElm = reverse_entity_literal_vocab[entity_literal_vocab[negElm]]\n",
    "                    else:\n",
    "                        negElm = entity_literal_lgd_vocab_neg[random.randint(0, len(entity_literal_lgd_vocab_neg)-1)]\n",
    "                        negElm = reverse_entity_literal_vocab[entity_literal_vocab[negElm]]\n",
    "                if o_type == 'uri' and negElm[1] == 'uri':\n",
    "                    rerun = False\n",
    "                elif o_type != 'uri':\n",
    "                    rerun = False\n",
    "                if (isinstance(negElm, rdflib.term.URIRef)) or (isinstance(negElm, rdflib.term.Literal)):\n",
    "                    negElm = getRDFData(negElm)\n",
    "                    literal_array = getLiteralArray(negElm, literal_len, char_vocab)\n",
    "                else:\n",
    "                    rerun = True    \n",
    "            if negElm[1] == 'uri':\n",
    "                dataNeg.append([s, p, entity_vocab[negElm[0]], p_trans])\n",
    "            else:\n",
    "                dataNeg.append([s, p, entity_vocab[negElm[1]], p_trans])\n",
    "            charNeg.append(literal_array)\n",
    "            predNeg.append(p)\n",
    "            pred_weight_neg.append(pred_weight)\n",
    "        else:\n",
    "            ### SUBJECTS only contains URI\n",
    "            negElm = random.randint(0, len(entity_vocab)-1)\n",
    "            while negElm == s:\n",
    "                negElm = random.randint(0, len(entity_vocab)-1)\n",
    "            dataNeg.append([negElm, p, o, p_trans])\n",
    "            charNeg.append(chars)\n",
    "            predNeg.append(p)\n",
    "            pred_weight_neg.append(pred_weight)\n",
    "            \n",
    "    dataPos = np.array(dataPos)\n",
    "    charPos = np.array(charPos)\n",
    "    pred_weight_pos = np.array(pred_weight_pos)\n",
    "    dataNeg = np.array(dataNeg)\n",
    "    predNeg = np.array(predNeg)\n",
    "    predTransNeg = np.array(predTransNeg)\n",
    "    charNeg = np.array(charNeg)\n",
    "    pred_weight_neg = np.array(pred_weight_neg)\n",
    "    \n",
    "    return hasNext, current+batchSize, dataPos[:,0], dataPos[:,1], dataPos[:,2], dataPos[:,3], pred_weight_pos, charPos, dataNeg[:,0], dataNeg[:,1], dataNeg[:,2], dataNeg[:,3], pred_weight_neg, charNeg\n",
    "    #return charNeg   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatchPP(data, batchSize, current, entityVocab, literal_len, char_vocab):\n",
    "    hasNext = current+batchSize < len(data)\n",
    "    \n",
    "    if (len(data) - current) < batchSize:\n",
    "        current = current - (batchSize - (len(data) - current))\n",
    "    \n",
    "    dataPos_all = data[current:current+batchSize]\n",
    "    dataPos = list()\n",
    "    charPos = list()\n",
    "    pred_weight_pos = list()\n",
    "    dataNeg = list()\n",
    "    charNeg = list()\n",
    "    pred_weight_neg = list()\n",
    "    for triples,chars, pred_weight in dataPos_all:\n",
    "        s,p,o,p_trans = triples\n",
    "        print (s,p,o)\n",
    "        print()\n",
    "        dataPos.append([s,p,o,p_trans])\n",
    "        charPos.append(chars)\n",
    "        pred_weight_pos.append(pred_weight)\n",
    "        charNeg.append(chars)\n",
    "        pred_weight_neg.append(pred_weight)\n",
    "        lr = round(random.random())\n",
    "        \n",
    "        if lr == 0: #randomize object\n",
    "            candidate = set(ent_type_vocab.values()) - range_vocab[p]\n",
    "            o_rand = random.choice(list(candidate))\n",
    "            dataNeg.append([s,p,o_rand,p_trans])\n",
    "        else: #randomize object\n",
    "            candidate = set(ent_type_vocab.values()) - domain_vocab[p]\n",
    "            s_rand = random.choice(list(candidate))\n",
    "            dataNeg.append([s_rand,p,o,p_trans])\n",
    "            \n",
    "    dataPos = np.array(dataPos)\n",
    "    charPos = np.array(charPos)\n",
    "    pred_weight_pos = np.array(pred_weight_pos)\n",
    "    dataNeg = np.array(dataNeg)\n",
    "    charNeg = np.array(charNeg)\n",
    "    pred_weight_neg = np.array(pred_weight_neg)\n",
    "    \n",
    "    return hasNext, current+batchSize, dataPos[:,0], dataPos[:,1], dataPos[:,2], dataPos[:,3], pred_weight_pos, charPos, dataNeg[:,0], dataNeg[:,1], dataNeg[:,2], dataNeg[:,3], pred_weight_neg, charNeg\n",
    "    #return charNeg   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HpyMnQCsK0PL"
   },
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "hidden_size = 100\n",
    "totalEpoch = 400\n",
    "verbose = 1000\n",
    "margin = 1.0\n",
    "literal_len = literal_len\n",
    "entitySize = len(entity_vocab)\n",
    "charSize = len(char_vocab)\n",
    "predSize = len(predicate_vocab)\n",
    "ppEntSize = len(ent_type_vocab)\n",
    "valid_size = 100 #100 entity validation sample\n",
    "top_k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "M8DdUZv5K0PP"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import ast\n",
    "from rdflib import URIRef\n",
    "\n",
    "file_lgd = open(map_file, 'r')\n",
    "\n",
    "valid_dataset_list = list()\n",
    "for line in file_lgd:\n",
    "    elements = line.split(' ')\n",
    "    s = elements[0].replace('\\\\\\\\u', '\\\\u')\n",
    "    p = elements[1]\n",
    "    o = elements[2].replace('\\\\\\\\u', '\\\\u')\n",
    "    s = ast.literal_eval(f'\"{s}\"')\n",
    "    o = ast.literal_eval(f'\"{o}\"')\n",
    "    if (entity_vocab[URIRef(s.replace('<','').replace('>',''))] in entity_dbp_vocab) and (URIRef(o.replace('<','').replace('>','')) in entity_vocab):\n",
    "        valid_dataset_list.append((o, s))\n",
    "#valid_dataset_list = random.sample(valid_dataset_list, valid_size)\n",
    "file_lgd.close()\n",
    "\n",
    "valid_examples = [entity_vocab[URIRef(k.replace('<','').replace('>',''))] for k,_ in valid_dataset_list] #LGD\n",
    "valid_answer = [entity_dbp_vocab.index(entity_vocab[URIRef(k.replace('<','').replace('>',''))]) for _,k in valid_dataset_list] #DBpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4950,
     "status": "ok",
     "timestamp": 1532297359735,
     "user": {
      "displayName": "Bayu Distiawan",
      "photoUrl": "//lh5.googleusercontent.com/-ZlEtcF5Few0/AAAAAAAAAAI/AAAAAAAAAAA/caTzimkqvdg/s50-c-k-no/photo.jpg",
      "userId": "113711532389286602961"
     },
     "user_tz": 0
    },
    "id": "PHGBLgFlK0PU",
    "outputId": "4c34477f-958b-4d07-c7d2-c60b1901c4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-cfe3686a2746>:62: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "\n",
    "tfgraph = tf.Graph()\n",
    "\n",
    "with tfgraph.as_default():\n",
    "    \n",
    "    # input placeholder #\n",
    "    pos_h = tf.placeholder(tf.int32, [None])\n",
    "    pos_t = tf.placeholder(tf.int32, [None])\n",
    "    pos_r = tf.placeholder(tf.int32, [None])\n",
    "    pos_r_trans = tf.placeholder(tf.int32, [None])\n",
    "    pos_c = tf.placeholder(tf.int32, [None, literal_len])\n",
    "    pos_pred_weight = tf.placeholder(tf.float32, [None,1], name='pos_pred_weight')\n",
    "\n",
    "    neg_h = tf.placeholder(tf.int32, [None])\n",
    "    neg_t = tf.placeholder(tf.int32, [None])\n",
    "    neg_r = tf.placeholder(tf.int32, [None])\n",
    "    neg_r_trans = tf.placeholder(tf.int32, [None])\n",
    "    neg_c = tf.placeholder(tf.int32, [None, literal_len])\n",
    "    neg_pred_weight = tf.placeholder(tf.float32, [None,1], name='neg_pred_weight')\n",
    "    \n",
    "    type_data = tf.placeholder(tf.int32, [1])\n",
    "    type_trans = tf.placeholder(tf.int32, [1])\n",
    "    ######################\n",
    "    \n",
    "    # embedding variables #\n",
    "    ent_embeddings_ori = tf.get_variable(name = \"relationship_triple_ent_embedding\", shape = [entitySize, hidden_size], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n",
    "    atr_embeddings_ori = tf.get_variable(name = \"attribute_triple_ent_embedding\", shape = [entitySize, hidden_size], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n",
    "    ent_rel_embeddings = tf.get_variable(name = \"proximity_triple_pred_embedding\", shape = [predSize, hidden_size], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n",
    "    pp_ent_embeddings = tf.get_variable(name = \"proximity_triple_ent_embedding\", shape = [ppEntSize, hidden_size], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n",
    "    #atr_rel_embeddings = tf.get_variable(name = \"attribute_triple_pred_embedding\", shape = [predSize, hidden_size], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n",
    "    char_embeddings = tf.get_variable(name = \"attribute_triple_char_embedding\", shape = [charSize, hidden_size], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n",
    "    \n",
    "    ent_indices = tf.concat([pos_h, pos_t, neg_h, neg_t], 0)\n",
    "    ent_indices = tf.reshape(ent_indices,[-1,1])\n",
    "    ent_value = tf.concat([tf.nn.embedding_lookup(ent_embeddings_ori, pos_h),\\\n",
    "                          tf.nn.embedding_lookup(ent_embeddings_ori, pos_t),\\\n",
    "                          tf.nn.embedding_lookup(ent_embeddings_ori, neg_h),\\\n",
    "                          tf.nn.embedding_lookup(ent_embeddings_ori, neg_t)], 0)\n",
    "    part_ent_embeddings = tf.scatter_nd([ent_indices], [ent_value], ent_embeddings_ori.shape)\n",
    "    ent_embeddings = part_ent_embeddings + tf.stop_gradient(-part_ent_embeddings + ent_embeddings_ori)\n",
    "    \n",
    "    atr_indices = tf.concat([pos_h, pos_t, neg_h, neg_t], 0)\n",
    "    atr_indices = tf.reshape(atr_indices,[-1,1])\n",
    "    atr_value = tf.concat([tf.nn.embedding_lookup(atr_embeddings_ori, pos_h),\\\n",
    "                          tf.nn.embedding_lookup(atr_embeddings_ori, pos_t),\\\n",
    "                          tf.nn.embedding_lookup(atr_embeddings_ori, neg_h),\\\n",
    "                          tf.nn.embedding_lookup(atr_embeddings_ori, neg_t)], 0)\n",
    "    part_atr_embeddings = tf.scatter_nd([atr_indices], [atr_value], atr_embeddings_ori.shape)\n",
    "    atr_embeddings = part_atr_embeddings + tf.stop_gradient(-part_atr_embeddings + atr_embeddings_ori)\n",
    "    ########################\n",
    "    \n",
    "    \n",
    "    # PREDICATE PROXIMITY TRIPLES #\n",
    "    pp_pos_h_e = tf.nn.embedding_lookup(pp_ent_embeddings, pos_h)\n",
    "    pp_pos_t_e = tf.nn.embedding_lookup(pp_ent_embeddings, pos_t)\n",
    "    pp_pos_r_e = tf.nn.embedding_lookup(ent_rel_embeddings, pos_r)\n",
    "    pp_neg_h_e = tf.nn.embedding_lookup(pp_ent_embeddings, neg_h)\n",
    "    pp_neg_t_e = tf.nn.embedding_lookup(pp_ent_embeddings, neg_t)\n",
    "    pp_neg_r_e = tf.nn.embedding_lookup(ent_rel_embeddings, neg_r)\n",
    "    \n",
    "    pp_pos = tf.reduce_sum(abs(pp_pos_h_e + pp_pos_r_e - pp_pos_t_e), 1, keep_dims = True)\n",
    "    pp_neg = tf.reduce_sum(abs(pp_neg_h_e + pp_neg_r_e - pp_neg_t_e), 1, keep_dims = True)\n",
    "    #pp_learning_rate = 0.0001 # LGD/GEO\n",
    "    pp_learning_rate = 0.0001 # YAGO\n",
    "    pp_opt_vars_ent = [v for v in tf.trainable_variables() if v.name.startswith(\"proximity_triple\")]\n",
    "    #pp_loss = tf.reduce_sum(tf.maximum(pp_pos - pp_neg + 1, 0)) # LGD/GEO\n",
    "    pp_loss = tf.reduce_sum(tf.maximum(pp_pos - pp_neg + 10, 0)) # YAGO\n",
    "    pp_optimizer = tf.train.AdamOptimizer(pp_learning_rate).minimize(pp_loss, var_list=pp_opt_vars_ent)\n",
    "    ########################\n",
    "    \n",
    "    \n",
    "    # RELATIONSHIP TRIPLES #\n",
    "    rt_pos_h_e = tf.nn.embedding_lookup(ent_embeddings, pos_h)\n",
    "    rt_pos_t_e = tf.nn.embedding_lookup(ent_embeddings, pos_t)\n",
    "    #rt_pos_r_e = tf.nn.embedding_lookup(ent_rel_embeddings, pos_r) # LGD/GEO\n",
    "    rt_pos_r_e = tf.stop_gradient(tf.nn.embedding_lookup(ent_rel_embeddings, pos_r)) # YAGO\n",
    "    rt_neg_h_e = tf.nn.embedding_lookup(ent_embeddings, neg_h)\n",
    "    rt_neg_t_e = tf.nn.embedding_lookup(ent_embeddings, neg_t)\n",
    "    #rt_neg_r_e = tf.nn.embedding_lookup(ent_rel_embeddings, neg_r) # LGD/GEO\n",
    "    rt_neg_r_e = tf.stop_gradient(tf.nn.embedding_lookup(ent_rel_embeddings, neg_r)) # YAGO\n",
    "    \n",
    "    ent_emb = tf.nn.embedding_lookup(ent_embeddings, pos_h)\n",
    "    atr_emb = tf.nn.embedding_lookup(atr_embeddings, pos_h)\n",
    "    norm_ent_emb = tf.nn.l2_normalize(ent_emb,1)\n",
    "    norm_atr_emb = tf.nn.l2_normalize(atr_emb,1)\n",
    "    cos_sim = tf.reduce_sum(tf.multiply(norm_ent_emb, norm_atr_emb), 1, keep_dims=True)\n",
    "    \n",
    "    rt_pos = tf.reduce_sum(abs(rt_pos_h_e + rt_pos_r_e - rt_pos_t_e), 1, keep_dims = True)\n",
    "    rt_neg = tf.reduce_sum(abs(rt_neg_h_e + rt_neg_r_e - rt_neg_t_e), 1, keep_dims = True)\n",
    "    #rt_learning_rate = tf.reduce_min(pos_pred_weight)*0.001 # LGD/GEO\n",
    "    rt_learning_rate = 0.0001 # YAGO\n",
    "    rt_opt_vars_ent = [v for v in tf.trainable_variables() if v.name.startswith(\"relationship_triple\")]\n",
    "    #rt_loss = tf.reduce_sum(tf.maximum(rt_pos - rt_neg + 1, 0)) # LGD/GEO\n",
    "    rt_loss = tf.reduce_sum(tf.maximum(rt_pos - rt_neg + 10, 0)) # YAGO\n",
    "    rt_optimizer = tf.train.AdamOptimizer(rt_learning_rate).minimize(rt_loss, var_list=rt_opt_vars_ent)\n",
    "    ########################\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "    # ATTRIBUTE TRIPLES #\n",
    "    at_pos_h_e = tf.nn.embedding_lookup(atr_embeddings, pos_h)\n",
    "    pos_c_e = tf.nn.embedding_lookup(char_embeddings, pos_c)\n",
    "    at_pos_r_e = tf.stop_gradient(tf.nn.embedding_lookup(ent_rel_embeddings, pos_r))\n",
    "    #at_pos_r_e = tf.nn.embedding_lookup(atr_rel_embeddings, pos_r)\n",
    "    at_neg_h_e = tf.nn.embedding_lookup(atr_embeddings, neg_h)\n",
    "    neg_c_e = tf.nn.embedding_lookup(char_embeddings, neg_c)\n",
    "    at_neg_r_e = tf.stop_gradient(tf.nn.embedding_lookup(ent_rel_embeddings, neg_r))\n",
    "    #at_neg_r_e = tf.nn.embedding_lookup(atr_rel_embeddings, neg_r)\n",
    "    \n",
    "    #Zero-Mask for char embedding\n",
    "    mask_constant_0 = np.zeros([1,hidden_size])\n",
    "    mask_constant_1 = np.ones([1,hidden_size])\n",
    "    mask_constant = np.concatenate([mask_constant_0, mask_constant_1])\n",
    "    mask_constant = tf.constant(mask_constant, tf.float32)\n",
    "    flag_pos_c_e = tf.sign(tf.abs(pos_c))\n",
    "    mask_pos_c_e = tf.nn.embedding_lookup(mask_constant, flag_pos_c_e)\n",
    "    pos_c_e = pos_c_e * mask_pos_c_e\n",
    "    flag_neg_c_e = tf.sign(tf.abs(neg_c))\n",
    "    mask_neg_c_e = tf.nn.embedding_lookup(mask_constant, flag_neg_c_e)\n",
    "    neg_c_e = neg_c_e * mask_neg_c_e\n",
    "    \n",
    "    \n",
    "    #N-GRAM\n",
    "    def calculate_ngram_weight(unstacked_tensor):\n",
    "        stacked_tensor = tf.stack(unstacked_tensor, 1)\n",
    "        stacked_tensor = tf.reverse(stacked_tensor, [1])\n",
    "        index = tf.constant(len(unstacked_tensor))\n",
    "        expected_result = tf.zeros([batchSize, hidden_size])\n",
    "        def condition(index, summation):\n",
    "            return tf.greater(index, 0)\n",
    "        def body(index, summation):\n",
    "            precessed = tf.slice(stacked_tensor,[0,index-1,0], [-1,-1,-1])\n",
    "            summand = tf.reduce_mean(precessed, 1)\n",
    "            return tf.subtract(index, 1), tf.add(summation, summand)\n",
    "        result = tf.while_loop(condition, body, [index, expected_result])\n",
    "        return result[1]\n",
    "    pos_c_e_in_lstm = tf.unstack(pos_c_e, literal_len, 1)\n",
    "    pos_c_e_lstm = calculate_ngram_weight(pos_c_e_in_lstm)\n",
    "    neg_c_e_in_lstm = tf.unstack(neg_c_e, literal_len, 1)\n",
    "    neg_c_e_lstm = calculate_ngram_weight(neg_c_e_in_lstm)\n",
    "    \n",
    "    at_pos = tf.reduce_sum(abs(at_pos_h_e + at_pos_r_e - pos_c_e_lstm), 1, keep_dims = True)\n",
    "    at_neg = tf.reduce_sum(abs(at_neg_h_e + at_neg_r_e - neg_c_e_lstm), 1, keep_dims = True)\n",
    "    at_pos_h_e = tf.multiply(at_pos, pos_pred_weight)\n",
    "    at_neg_h_e = tf.multiply(at_neg, neg_pred_weight)\n",
    "    #at_learning_rate = tf.reduce_min(pos_pred_weight)*0.001 # LGD/GEO\n",
    "    at_learning_rate = tf.reduce_min(pos_pred_weight)*0.01 # YAGO\n",
    "    at_opt_vars_atr = [v for v in tf.trainable_variables() if v.name.startswith(\"attribute_triple\") or v.name.startswith(\"rnn\")]\n",
    "    at_loss = tf.reduce_sum(tf.maximum(at_pos - at_neg + 1, 0))\n",
    "    at_optimizer = tf.train.AdamOptimizer(at_learning_rate).minimize(at_loss, var_list=at_opt_vars_atr)\n",
    "    ########################\n",
    "                            \n",
    "    \n",
    "    # TRANSITIVE TRIPLES #\n",
    "    pos_r_e_trans = tf.stop_gradient(tf.nn.embedding_lookup(ent_rel_embeddings, pos_r_trans))\n",
    "    neg_r_e_trans = tf.stop_gradient(tf.nn.embedding_lookup(ent_rel_embeddings, neg_r_trans))\n",
    "    tr_pos_r_e = tf.multiply(at_pos_r_e, pos_r_e_trans)\n",
    "    tr_neg_r_e = tf.multiply(at_neg_r_e, neg_r_e_trans)\n",
    "    tr_pos = tf.reduce_sum(abs(at_pos_h_e + tr_pos_r_e - pos_c_e_lstm), 1, keep_dims = True)\n",
    "    tr_neg = tf.reduce_sum(abs(at_neg_h_e + tr_neg_r_e - neg_c_e_lstm), 1, keep_dims = True)\n",
    "    tr_pos_h_e = tf.multiply(tr_pos, pos_pred_weight)\n",
    "    tr_neg_h_e = tf.multiply(tr_neg, neg_pred_weight)\n",
    "    #tr_learning_rate = tf.reduce_min(pos_pred_weight)*0.001 # LGD/GEO\n",
    "    tr_learning_rate = tf.reduce_min(pos_pred_weight)*0.01 # YAGO\n",
    "    tr_opt_vars_atr = [v for v in tf.trainable_variables() if v.name.startswith(\"attribute_triple\") or v.name.startswith(\"rnn\")]\n",
    "    tr_loss = tf.reduce_sum(tf.maximum(tr_pos - tr_neg + 1, 0))\n",
    "    tr_optimizer = tf.train.AdamOptimizer(tr_learning_rate).minimize(tr_loss, var_list=tr_opt_vars_atr)\n",
    "    ######################\n",
    "    \n",
    "    \n",
    "    #Entity Embeddings & Attribute Embeddings Similarity\n",
    "    sim_ent_emb = tf.nn.embedding_lookup(ent_embeddings, pos_h)\n",
    "    sim_atr_emb = tf.nn.embedding_lookup(atr_embeddings, pos_h)\n",
    "    norm_ent_emb = tf.nn.l2_normalize(sim_ent_emb,1)\n",
    "    norm_atr_emb = tf.nn.l2_normalize(sim_atr_emb,1)\n",
    "    cos_sim = tf.reduce_sum(tf.multiply(norm_ent_emb, norm_atr_emb), 1, keep_dims=True)\n",
    "    sim_loss = tf.reduce_sum(1-cos_sim)\n",
    "    opt_vars_sim = [v for v in tf.trainable_variables() if v.name.startswith(\"relationship_triple_ent_embedding\")]\n",
    "    sim_optimizer = tf.train.AdamOptimizer(0.01).minimize(sim_loss, var_list=opt_vars_sim)\n",
    "    ####################################################\n",
    "    \n",
    "    \n",
    "                            \n",
    "    # testing\n",
    "    with tf.device('/cpu:0'):\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(ent_embeddings_ori), 1, keep_dims=True))\n",
    "        normalized_embeddings = ent_embeddings_ori / norm\n",
    "\n",
    "        valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "        valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "        similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5Se9GHctK0PZ"
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred, answer_vocab, k=10):\n",
    "    file_result = open('correct_1.txt','w')\n",
    "    file_result_2 = open('correct_10.txt','w')\n",
    "    list_rank = list()\n",
    "    total_hits = 0\n",
    "    total_hits_1 = 0\n",
    "    for i in range(len(y_true)):\n",
    "        result = y_pred[i]\n",
    "        result = result[answer_vocab]\n",
    "        #sort result first\n",
    "        result = (-result).argsort()\n",
    "        \n",
    "        #Mean Rank\n",
    "        for j in range(len(result)):\n",
    "            if result[j] == y_true[i]:\n",
    "                rank = j\n",
    "                break\n",
    "        list_rank.append(j)\n",
    "        #Mean Rank\n",
    "        \n",
    "        #Hit @K\n",
    "        result = result[:k]\n",
    "        for j in range(len(result)):\n",
    "            if result[j] == y_true[i]:\n",
    "                total_hits += 1\n",
    "                if j == 0:\n",
    "                    total_hits_1 += 1\n",
    "                    file_result.write(str(result[j])+'\\n')\n",
    "                file_result_2.write(str(result[j])+'\\n')\n",
    "                break\n",
    "    \n",
    "    #RETURN: MeanRank, Hits@K\n",
    "    file_result.close()\n",
    "    file_result_2.close()\n",
    "    return reduce(lambda x, y: x + y, list_rank) / len(list_rank), float(total_hits)/len(y_true), float(total_hits_1)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(graph, totalEpoch):\n",
    "    writer = open('log.txt', 'w')\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        init.run()\n",
    "        \n",
    "        for epoch in range(totalEpoch):\n",
    "            if epoch % 2 == 0:\n",
    "                data = [data_predicate, data_uri_0, data_uri, data_literal_0, data_literal, []]\n",
    "            else:\n",
    "                data = [data_literal]\n",
    "            start_time_epoch = dt.datetime.now()\n",
    "            for i in range(0, len(data)):\n",
    "                random.shuffle(data[i])\n",
    "                hasNext = True\n",
    "                current = 0\n",
    "                step = 0\n",
    "                average_loss = 0\n",
    "                t_start = time.time()  \n",
    "                while(hasNext and len(data[i]) > 0):\n",
    "                    step += 1\n",
    "                    if epoch % 2 == 0 and i == 0:\n",
    "                        hasNext, current, ph, pr, pt, pr_trans, ppred, pc, nh, nr, nt, nr_trans, npred, nc = getBatch(data[i], batchSize, current, entity_vocab, literal_len, char_vocab)\n",
    "                    else:\n",
    "                        hasNext, current, ph, pr, pt, pr_trans, ppred, pc, nh, nr, nt, nr_trans, npred, nc = getBatch(data[i], batchSize, current, entity_vocab, literal_len, char_vocab)\n",
    "                    feed_dict = {\n",
    "                        pos_h: ph,\n",
    "                        pos_t: pt,\n",
    "                        pos_r: pr,\n",
    "                        pos_r_trans: pr_trans,\n",
    "                        pos_pred_weight : ppred,\n",
    "                        pos_c: pc,\n",
    "                        neg_h: nh,\n",
    "                        neg_t: nt,\n",
    "                        neg_r: nr,\n",
    "                        neg_r_trans: nr_trans,\n",
    "                        neg_c: nc,\n",
    "                        neg_pred_weight: npred,\n",
    "                    }\n",
    "                    # compute entity embedding and attribute embedding\n",
    "                    \n",
    "                    if epoch % 2 == 0:\n",
    "                        if i == 0: # predicate proximity triples\n",
    "                            __, loss_val = session.run([pp_optimizer, pp_loss], feed_dict=feed_dict)\n",
    "                            \n",
    "                            average_loss += loss_val\n",
    "                        elif i == 1 or i == 2: # relationship triples\n",
    "                            __, loss_val = session.run([rt_optimizer, rt_loss], feed_dict=feed_dict)\n",
    "                            \n",
    "                            average_loss += loss_val\n",
    "                        elif i == 3 or i == 4: # attribute triples\n",
    "                            __, loss_val = session.run([at_optimizer, at_loss], feed_dict=feed_dict)\n",
    "                            \n",
    "                            average_loss += loss_val\n",
    "                        elif i == 5: # transitive triples\n",
    "                            __, loss_val = session.run([tr_optimizer, tr_loss], feed_dict=feed_dict)\n",
    "                            \n",
    "                            average_loss += loss_val\n",
    "                    # compute entity embedding similarity\n",
    "                    else:\n",
    "                        __, loss_val = session.run([sim_optimizer, sim_loss], feed_dict=feed_dict)\n",
    "                        \n",
    "                        average_loss += loss_val\n",
    "\n",
    "                    if step % verbose == 0:\n",
    "                        average_loss /= verbose\n",
    "                        print('Epoch: ', epoch, ' Average loss at step ', step, ': ', average_loss)\n",
    "                        writer.write('Epoch: '+ str(epoch)+ ' Average loss at step '+ str(step)+ ': '+ str(average_loss)+'\\n')\n",
    "                        average_loss = 0\n",
    "                \n",
    "                if len(data[i]) > 0:\n",
    "                        average_loss /= ((len(data[i])%(verbose*batchSize))/batchSize)\n",
    "                        print('Epoch: ', epoch, ' Average loss at step ', step, ': ', average_loss)\n",
    "                        writer.write('Epoch: '+ str(epoch)+ ' Average loss at step '+ str(step)+ ': '+ str(average_loss)+ '\\n')\n",
    "                print(epoch, i, time.time()-t_start)\n",
    "            end_time_epoch = dt.datetime.now()\n",
    "            print(\"Training time took {} seconds to run 1 epoch\".format((end_time_epoch-start_time_epoch).total_seconds()))\n",
    "            writer.write(\"Training time took {} seconds to run 1 epoch\\n\".format((end_time_epoch-start_time_epoch).total_seconds()))\n",
    "            if (epoch) % 10 == 0:\n",
    "                start_time_epoch = dt.datetime.now()\n",
    "                sim = similarity.eval()\n",
    "                mean_rank, hits_at_10, hits_at_1 = metric(valid_answer, sim, entity_dbp_vocab, top_k)\n",
    "                print (\"Mean Rank: \", mean_rank, \" of \", len(entity_dbp_vocab))\n",
    "                writer.write(\"Mean Rank: \"+ str(mean_rank)+ \" of \"+ str(len(entity_dbp_vocab))+ \"\\n\")\n",
    "                print (\"Hits @ \"+str(top_k)+\": \", hits_at_10)\n",
    "                writer.write(\"Hits @ \"+str(top_k)+\": \"+ str(hits_at_10)+ \"\\n\")\n",
    "                print (\"Hits @ \"+str(1)+\": \", hits_at_1)\n",
    "                writer.write(\"Hits @ \"+str(1)+\": \"+ str(hits_at_1)+ \"\\n\")\n",
    "                end_time_epoch = dt.datetime.now()\n",
    "                print(\"Testing time took {} seconds.\".format((end_time_epoch-start_time_epoch).total_seconds()))\n",
    "                writer.write(\"Testing time took {} seconds.\\n\\n\".format((end_time_epoch-start_time_epoch).total_seconds()))\n",
    "                print()\n",
    "            #break\n",
    "        final_embeddings_normalized = normalized_embeddings.eval()\n",
    "        final_embeddings_entity = ent_embeddings_ori.eval()\n",
    "        final_embeddings_predicate = ent_rel_embeddings.eval()\n",
    "        np.savetxt('TextKE_final_embedding_normalize.txt',final_embeddings_normalized)\n",
    "        np.savetxt('TextKE_final_embedding_entity.txt',final_embeddings_entity)\n",
    "        np.savetxt('TextKE_final_embedding_predicate.txt',final_embeddings_predicate)\n",
    "        cPickle.dump( reverse_entity_vocab, open( \"TextKE_dictionary_entity.pickle\", \"wb\" ) )\n",
    "        cPickle.dump( reverse_predicate_vocab, open( \"TextKE_dictionary_predicate.pickle\", \"wb\" ) )\n",
    "        #cPickle.dump( predicate_info_vocab, open( \"TextKE_predicate_info_vocab.pickle\", \"wb\" ) )\n",
    "        #cPickle.dump( rev_predicate_info_vocab, open( \"TextKE_rev_predicate_info_vocab.pickle\", \"wb\" ) )\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1248,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: proximity_triple_pred_embedding/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[\"loc:@proximity_triple_pred_embedding\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](proximity_triple_pred_embedding/Initializer/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'proximity_triple_pred_embedding/Initializer/truncated_normal/TruncatedNormal', defined at:\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-cfe3686a2746>\", line 29, in <module>\n    ent_rel_embeddings = tf.get_variable(name = \"proximity_triple_pred_embedding\", shape = [predSize, hidden_size], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1262, in get_variable\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1097, in get_variable\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 435, in get_variable\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 404, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 806, in _get_single_variable\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 323, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 780, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/initializers.py\", line 150, in _initializer\n    seed=seed)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 172, in truncated_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 561, in _truncated_normal\n    name=name)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1248,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: proximity_triple_pred_embedding/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[\"loc:@proximity_triple_pred_embedding\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](proximity_triple_pred_embedding/Initializer/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1248,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: proximity_triple_pred_embedding/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[\"loc:@proximity_triple_pred_embedding\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](proximity_triple_pred_embedding/Initializer/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6ba66d054ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time took {} seconds to run {} epoch\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalEpoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-aa32ea1a7a66>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(graph, totalEpoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalEpoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2211\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m     \"\"\"\n\u001b[0;32m-> 2213\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4791\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4792\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4793\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1248,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: proximity_triple_pred_embedding/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[\"loc:@proximity_triple_pred_embedding\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](proximity_triple_pred_embedding/Initializer/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'proximity_triple_pred_embedding/Initializer/truncated_normal/TruncatedNormal', defined at:\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-cfe3686a2746>\", line 29, in <module>\n    ent_rel_embeddings = tf.get_variable(name = \"proximity_triple_pred_embedding\", shape = [predSize, hidden_size], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1262, in get_variable\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1097, in get_variable\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 435, in get_variable\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 404, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 806, in _get_single_variable\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 323, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 780, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/initializers.py\", line 150, in _initializer\n    seed=seed)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 172, in truncated_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 561, in _truncated_normal\n    name=name)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/suyixin/miniconda3/envs/EA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1248,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: proximity_triple_pred_embedding/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[\"loc:@proximity_triple_pred_embedding\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](proximity_triple_pred_embedding/Initializer/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "start_time = dt.datetime.now()\n",
    "run(tfgraph, 800) \n",
    "end_time = dt.datetime.now()\n",
    "print(\"Training time took {} seconds to run {} epoch\".format((end_time-start_time).total_seconds(), totalEpoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Average loss at step  1000 :  726.3579352111816\n",
      "Epoch:  0  Average loss at step  2000 :  268.79928493499756\n",
      "Epoch:  0  Average loss at step  3000 :  135.68605353164673\n",
      "Epoch:  0  Average loss at step  4000 :  97.48497088623047\n",
      "Epoch:  0  Average loss at step  5000 :  74.94069411849975\n",
      "Epoch:  0  Average loss at step  6000 :  57.67762372207642\n",
      "Epoch:  0  Average loss at step  7000 :  45.682580664634706\n",
      "Epoch:  0  Average loss at step  8000 :  37.35403254890442\n",
      "Epoch:  0  Average loss at step  8472 :  32.41626042106612\n",
      "0 0 19.967023134231567\n",
      "Epoch:  0  Average loss at step  1000 :  898.3544458007813\n",
      "Epoch:  0  Average loss at step  1491 :  752.07992876025\n",
      "0 1 10.038846969604492\n",
      "Epoch:  0  Average loss at step  1000 :  737.8869542846679\n",
      "Epoch:  0  Average loss at step  2000 :  717.8686304931641\n",
      "Epoch:  0  Average loss at step  2533 :  709.9767667657608\n",
      "0 2 17.015730619430542\n",
      "Epoch:  0  Average loss at step  1000 :  223.50382203674317\n",
      "Epoch:  0  Average loss at step  1227 :  223.70972710986962\n",
      "0 3 10.837360382080078\n",
      "Epoch:  0  Average loss at step  1000 :  145.92534142303467\n",
      "Epoch:  0  Average loss at step  2000 :  128.61964757537842\n",
      "Epoch:  0  Average loss at step  3000 :  119.30678500366211\n",
      "Epoch:  0  Average loss at step  3222 :  117.98479087431522\n",
      "0 4 28.49004030227661\n",
      "0 5 1.6689300537109375e-06\n",
      "Training time took 86.990666 seconds to run 1 epoch\n",
      "Mean Rank:  32757.41672  of  75000\n",
      "Hits @ 10:  8e-05\n",
      "Hits @ 1:  0.0\n",
      "Testing time took 302.647092 seconds.\n",
      "\n",
      "Epoch:  1  Average loss at step  1000 :  81.74087303161622\n",
      "Epoch:  1  Average loss at step  2000 :  53.77907769012451\n",
      "Epoch:  1  Average loss at step  3000 :  36.048492492675784\n",
      "Epoch:  1  Average loss at step  3222 :  28.578351580896495\n",
      "1 0 25.973998546600342\n",
      "Training time took 26.094076 seconds to run 1 epoch\n",
      "Epoch:  2  Average loss at step  1000 :  29.506490461826324\n",
      "Epoch:  2  Average loss at step  2000 :  26.143644425868988\n",
      "Epoch:  2  Average loss at step  3000 :  25.546409576416014\n",
      "Epoch:  2  Average loss at step  4000 :  23.141971163272856\n",
      "Epoch:  2  Average loss at step  5000 :  21.72216084623337\n",
      "Epoch:  2  Average loss at step  6000 :  20.646657899856567\n",
      "Epoch:  2  Average loss at step  7000 :  19.33870749473572\n",
      "Epoch:  2  Average loss at step  8000 :  18.625845348358155\n",
      "Epoch:  2  Average loss at step  8472 :  18.38832861053271\n",
      "2 0 19.959336757659912\n",
      "Epoch:  2  Average loss at step  1000 :  1203.2295294799806\n",
      "Epoch:  2  Average loss at step  1491 :  1112.8810951957573\n",
      "2 1 10.047066688537598\n",
      "Epoch:  2  Average loss at step  1000 :  968.8513143920899\n",
      "Epoch:  2  Average loss at step  2000 :  917.7127572021484\n",
      "Epoch:  2  Average loss at step  2533 :  904.113647704133\n",
      "2 2 17.10659694671631\n",
      "Epoch:  2  Average loss at step  1000 :  189.47567245483398\n",
      "Epoch:  2  Average loss at step  1227 :  191.1789413669583\n",
      "2 3 10.878355503082275\n",
      "Epoch:  2  Average loss at step  1000 :  109.17384210205078\n",
      "Epoch:  2  Average loss at step  2000 :  103.78125357437133\n",
      "Epoch:  2  Average loss at step  3000 :  101.64874645233154\n",
      "Epoch:  2  Average loss at step  3222 :  100.15782550647168\n",
      "2 4 33.1643226146698\n",
      "2 5 1.430511474609375e-06\n",
      "Training time took 91.824068 seconds to run 1 epoch\n",
      "Epoch:  3  Average loss at step  1000 :  12.219349449157715\n",
      "Epoch:  3  Average loss at step  2000 :  11.007394034385682\n",
      "Epoch:  3  Average loss at step  3000 :  9.826394852638245\n",
      "Epoch:  3  Average loss at step  3222 :  9.126912241142177\n",
      "3 0 29.308104753494263\n",
      "Training time took 29.42841 seconds to run 1 epoch\n",
      "Epoch:  4  Average loss at step  1000 :  17.86954238033295\n",
      "Epoch:  4  Average loss at step  2000 :  17.07238721370697\n",
      "Epoch:  4  Average loss at step  3000 :  16.54271117401123\n",
      "Epoch:  4  Average loss at step  4000 :  16.648154863357544\n",
      "Epoch:  4  Average loss at step  5000 :  15.741932641983032\n",
      "Epoch:  4  Average loss at step  6000 :  15.104049026489259\n",
      "Epoch:  4  Average loss at step  7000 :  15.845986290454864\n",
      "Epoch:  4  Average loss at step  8000 :  14.674459527492523\n",
      "Epoch:  4  Average loss at step  8472 :  14.53409816164258\n",
      "4 0 21.089228868484497\n",
      "Epoch:  4  Average loss at step  1000 :  918.4311767578125\n",
      "Epoch:  4  Average loss at step  1491 :  916.0227713585774\n",
      "4 1 11.740897417068481\n",
      "Epoch:  4  Average loss at step  1000 :  893.3513314819336\n",
      "Epoch:  4  Average loss at step  2000 :  883.1319034423828\n",
      "Epoch:  4  Average loss at step  2533 :  881.4691373872896\n",
      "4 2 19.99626898765564\n",
      "Epoch:  4  Average loss at step  1000 :  181.25351068878174\n",
      "Epoch:  4  Average loss at step  1227 :  184.88678858351392\n",
      "4 3 12.556692600250244\n",
      "Epoch:  4  Average loss at step  1000 :  94.90696705245972\n",
      "Epoch:  4  Average loss at step  2000 :  92.99194351196289\n",
      "Epoch:  4  Average loss at step  3000 :  92.57723205566407\n",
      "Epoch:  4  Average loss at step  3222 :  90.01741020187485\n",
      "4 4 33.209012269973755\n",
      "4 5 1.1920928955078125e-06\n",
      "Training time took 99.23102 seconds to run 1 epoch\n",
      "Epoch:  5  Average loss at step  1000 :  6.423128931999207\n",
      "Epoch:  5  Average loss at step  2000 :  6.356153284072876\n",
      "Epoch:  5  Average loss at step  3000 :  6.521144614696503\n",
      "Epoch:  5  Average loss at step  3222 :  6.535802881389259\n",
      "5 0 29.51447057723999\n",
      "Training time took 29.631972 seconds to run 1 epoch\n",
      "Epoch:  6  Average loss at step  1000 :  15.185781651973725\n",
      "Epoch:  6  Average loss at step  2000 :  14.45699994659424\n",
      "Epoch:  6  Average loss at step  3000 :  13.809316329956054\n",
      "Epoch:  6  Average loss at step  4000 :  13.703503071308136\n",
      "Epoch:  6  Average loss at step  5000 :  13.18164360666275\n",
      "Epoch:  6  Average loss at step  6000 :  13.382561501026153\n",
      "Epoch:  6  Average loss at step  7000 :  12.436930632591247\n",
      "Epoch:  6  Average loss at step  8000 :  13.137028574466706\n",
      "Epoch:  6  Average loss at step  8472 :  12.872537517834992\n",
      "6 0 20.331876039505005\n",
      "Epoch:  6  Average loss at step  1000 :  919.2759569702148\n",
      "Epoch:  6  Average loss at step  1491 :  914.5722246771275\n",
      "6 1 11.784473896026611\n",
      "Epoch:  6  Average loss at step  1000 :  928.3308231811524\n",
      "Epoch:  6  Average loss at step  2000 :  928.9739916381836\n",
      "Epoch:  6  Average loss at step  2533 :  920.8586081774511\n",
      "6 2 19.934865474700928\n",
      "Epoch:  6  Average loss at step  1000 :  173.92808560943604\n",
      "Epoch:  6  Average loss at step  1227 :  172.09669582612483\n",
      "6 3 12.598453998565674\n",
      "Epoch:  6  Average loss at step  1000 :  86.68728903579712\n",
      "Epoch:  6  Average loss at step  2000 :  85.7084680480957\n",
      "Epoch:  6  Average loss at step  3000 :  84.74412146759033\n",
      "Epoch:  6  Average loss at step  3222 :  85.17992002780224\n",
      "6 4 33.25462818145752\n",
      "6 5 1.6689300537109375e-06\n",
      "Training time took 98.546905 seconds to run 1 epoch\n",
      "Epoch:  7  Average loss at step  1000 :  4.514492171764374\n",
      "Epoch:  7  Average loss at step  2000 :  4.760609521150589\n",
      "Epoch:  7  Average loss at step  3000 :  5.141554978370666\n",
      "Epoch:  7  Average loss at step  3222 :  5.290058269722837\n",
      "7 0 29.427303075790405\n",
      "Training time took 29.552972 seconds to run 1 epoch\n",
      "Epoch:  8  Average loss at step  1000 :  12.358438117027283\n",
      "Epoch:  8  Average loss at step  2000 :  12.171753807544707\n",
      "Epoch:  8  Average loss at step  3000 :  11.673365772724152\n",
      "Epoch:  8  Average loss at step  4000 :  11.0910535902977\n",
      "Epoch:  8  Average loss at step  5000 :  11.812898914337158\n",
      "Epoch:  8  Average loss at step  6000 :  11.815712732315063\n",
      "Epoch:  8  Average loss at step  7000 :  11.379942918300628\n",
      "Epoch:  8  Average loss at step  8000 :  11.511531620502472\n",
      "Epoch:  8  Average loss at step  8472 :  11.655771582060133\n",
      "8 0 21.01557230949402\n",
      "Epoch:  8  Average loss at step  1000 :  997.9466879882813\n",
      "Epoch:  8  Average loss at step  1491 :  986.4358084808822\n",
      "8 1 11.740391492843628\n",
      "Epoch:  8  Average loss at step  1000 :  1038.2582321777343\n",
      "Epoch:  8  Average loss at step  2000 :  1039.8644368286132\n",
      "Epoch:  8  Average loss at step  2533 :  1039.1254136110929\n",
      "8 2 19.94966459274292\n",
      "Epoch:  8  Average loss at step  1000 :  168.0739928665161\n",
      "Epoch:  8  Average loss at step  1227 :  166.91380924597286\n",
      "8 3 12.644396781921387\n",
      "Epoch:  8  Average loss at step  1000 :  81.61258359146119\n",
      "Epoch:  8  Average loss at step  2000 :  80.73661922454833\n",
      "Epoch:  8  Average loss at step  3000 :  80.65274951171875\n",
      "Epoch:  8  Average loss at step  3222 :  80.33620591928951\n",
      "8 4 33.219255208969116\n",
      "8 5 1.430511474609375e-06\n",
      "Training time took 99.21654 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9  Average loss at step  1000 :  3.883576215028763\n",
      "Epoch:  9  Average loss at step  2000 :  4.01723359465599\n",
      "Epoch:  9  Average loss at step  3000 :  4.2745316269397735\n",
      "Epoch:  9  Average loss at step  3222 :  4.411512399154528\n",
      "9 0 29.458870887756348\n",
      "Training time took 29.58329 seconds to run 1 epoch\n",
      "Epoch:  10  Average loss at step  1000 :  11.848275244235992\n",
      "Epoch:  10  Average loss at step  2000 :  11.329192256450654\n",
      "Epoch:  10  Average loss at step  3000 :  10.981157053470612\n",
      "Epoch:  10  Average loss at step  4000 :  11.44351900959015\n",
      "Epoch:  10  Average loss at step  5000 :  11.268786325454712\n",
      "Epoch:  10  Average loss at step  6000 :  10.643434291839599\n",
      "Epoch:  10  Average loss at step  7000 :  11.25511008119583\n",
      "Epoch:  10  Average loss at step  8000 :  11.174227107524873\n",
      "Epoch:  10  Average loss at step  8472 :  10.946072346538482\n",
      "10 0 21.02592658996582\n",
      "Epoch:  10  Average loss at step  1000 :  1103.3674215698243\n",
      "Epoch:  10  Average loss at step  1491 :  1086.0260658123516\n",
      "10 1 11.708210706710815\n",
      "Epoch:  10  Average loss at step  1000 :  1155.478840637207\n",
      "Epoch:  10  Average loss at step  2000 :  1144.4224307861327\n",
      "Epoch:  10  Average loss at step  2533 :  1150.068425771926\n",
      "10 2 19.901404857635498\n",
      "Epoch:  10  Average loss at step  1000 :  165.37281538391113\n",
      "Epoch:  10  Average loss at step  1227 :  164.8247356518295\n",
      "10 3 12.684216737747192\n",
      "Epoch:  10  Average loss at step  1000 :  77.83109148406983\n",
      "Epoch:  10  Average loss at step  2000 :  78.12383690261841\n",
      "Epoch:  10  Average loss at step  3000 :  76.77862338638306\n",
      "Epoch:  10  Average loss at step  3222 :  75.94318174674507\n",
      "10 4 33.60485315322876\n",
      "10 5 1.430511474609375e-06\n",
      "Training time took 99.584121 seconds to run 1 epoch\n",
      "Mean Rank:  28463.10508  of  75000\n",
      "Hits @ 10:  0.00084\n",
      "Hits @ 1:  8e-05\n",
      "Testing time took 254.950178 seconds.\n",
      "\n",
      "Epoch:  11  Average loss at step  1000 :  3.0902218444347382\n",
      "Epoch:  11  Average loss at step  2000 :  3.169596153020859\n",
      "Epoch:  11  Average loss at step  3000 :  3.3373202147483827\n",
      "Epoch:  11  Average loss at step  3222 :  3.4333974031533416\n",
      "11 0 29.509581327438354\n",
      "Training time took 29.648416 seconds to run 1 epoch\n",
      "Epoch:  12  Average loss at step  1000 :  11.068821804046632\n",
      "Epoch:  12  Average loss at step  2000 :  10.148562991142272\n",
      "Epoch:  12  Average loss at step  3000 :  10.804539381504059\n",
      "Epoch:  12  Average loss at step  4000 :  10.06371404695511\n",
      "Epoch:  12  Average loss at step  5000 :  10.538015353679658\n",
      "Epoch:  12  Average loss at step  6000 :  10.406140461921693\n",
      "Epoch:  12  Average loss at step  7000 :  10.825667114257813\n",
      "Epoch:  12  Average loss at step  8000 :  10.04776491880417\n",
      "Epoch:  12  Average loss at step  8472 :  9.67545558214137\n",
      "12 0 20.92567467689514\n",
      "Epoch:  12  Average loss at step  1000 :  1164.711130493164\n",
      "Epoch:  12  Average loss at step  1491 :  1166.8218107326275\n",
      "12 1 11.747899293899536\n",
      "Epoch:  12  Average loss at step  1000 :  1230.9018289794922\n",
      "Epoch:  12  Average loss at step  2000 :  1226.6702102661134\n",
      "Epoch:  12  Average loss at step  2533 :  1220.8306639964244\n",
      "12 2 19.955886840820312\n",
      "Epoch:  12  Average loss at step  1000 :  162.43087048339845\n",
      "Epoch:  12  Average loss at step  1227 :  164.48832159454255\n",
      "12 3 12.723022222518921\n",
      "Epoch:  12  Average loss at step  1000 :  75.35139903259277\n",
      "Epoch:  12  Average loss at step  2000 :  74.39095268249511\n",
      "Epoch:  12  Average loss at step  3000 :  74.11653101348877\n",
      "Epoch:  12  Average loss at step  3222 :  73.77404453823725\n",
      "12 4 33.17516589164734\n",
      "12 5 1.430511474609375e-06\n",
      "Training time took 99.176623 seconds to run 1 epoch\n",
      "Epoch:  13  Average loss at step  1000 :  2.506774019360542\n",
      "Epoch:  13  Average loss at step  2000 :  2.4936986980438234\n",
      "Epoch:  13  Average loss at step  3000 :  2.6337240867614744\n",
      "Epoch:  13  Average loss at step  3222 :  2.685300275982018\n",
      "13 0 29.463876962661743\n",
      "Training time took 29.586852 seconds to run 1 epoch\n",
      "Epoch:  14  Average loss at step  1000 :  10.063838811397552\n",
      "Epoch:  14  Average loss at step  2000 :  10.241545279979706\n",
      "Epoch:  14  Average loss at step  3000 :  10.307599348068237\n",
      "Epoch:  14  Average loss at step  4000 :  10.150744146823882\n",
      "Epoch:  14  Average loss at step  5000 :  10.251575532913208\n",
      "Epoch:  14  Average loss at step  6000 :  10.330880870819092\n",
      "Epoch:  14  Average loss at step  7000 :  10.383709654808044\n",
      "Epoch:  14  Average loss at step  8000 :  9.831512461185456\n",
      "Epoch:  14  Average loss at step  8472 :  9.957464229756495\n",
      "14 0 20.530821084976196\n",
      "Epoch:  14  Average loss at step  1000 :  1232.5902856445311\n",
      "Epoch:  14  Average loss at step  1491 :  1214.6250763508242\n",
      "14 1 11.737258911132812\n",
      "Epoch:  14  Average loss at step  1000 :  1300.7688173828126\n",
      "Epoch:  14  Average loss at step  2000 :  1297.5060114135742\n",
      "Epoch:  14  Average loss at step  2533 :  1287.5263892219189\n",
      "14 2 19.956989288330078\n",
      "Epoch:  14  Average loss at step  1000 :  160.90823794555664\n",
      "Epoch:  14  Average loss at step  1227 :  159.9170485050671\n",
      "14 3 12.644246578216553\n",
      "Epoch:  14  Average loss at step  1000 :  73.02124415206909\n",
      "Epoch:  14  Average loss at step  2000 :  72.387131690979\n",
      "Epoch:  14  Average loss at step  3000 :  72.0553838043213\n",
      "Epoch:  14  Average loss at step  3222 :  71.48041579671275\n",
      "14 4 33.148332595825195\n",
      "14 5 1.6689300537109375e-06\n",
      "Training time took 98.659885 seconds to run 1 epoch\n",
      "Epoch:  15  Average loss at step  1000 :  2.1289604300260545\n",
      "Epoch:  15  Average loss at step  2000 :  2.0952762813568113\n",
      "Epoch:  15  Average loss at step  3000 :  2.1845303955078124\n",
      "Epoch:  15  Average loss at step  3222 :  2.2474609023505847\n",
      "15 0 29.47836422920227\n",
      "Training time took 29.599503 seconds to run 1 epoch\n",
      "Epoch:  16  Average loss at step  1000 :  9.922046340465545\n",
      "Epoch:  16  Average loss at step  2000 :  10.145686246871948\n",
      "Epoch:  16  Average loss at step  3000 :  10.182927790164948\n",
      "Epoch:  16  Average loss at step  4000 :  9.962270375728608\n",
      "Epoch:  16  Average loss at step  5000 :  10.17299871635437\n",
      "Epoch:  16  Average loss at step  6000 :  10.221769351959228\n",
      "Epoch:  16  Average loss at step  7000 :  9.450178919792176\n",
      "Epoch:  16  Average loss at step  8000 :  10.130890763282776\n",
      "Epoch:  16  Average loss at step  8472 :  10.114967385372966\n",
      "16 0 21.17766046524048\n",
      "Epoch:  16  Average loss at step  1000 :  1262.0763348388673\n",
      "Epoch:  16  Average loss at step  1491 :  1263.152731044069\n",
      "16 1 11.740986347198486\n",
      "Epoch:  16  Average loss at step  1000 :  1363.1745618286134\n",
      "Epoch:  16  Average loss at step  2000 :  1365.5143009643555\n",
      "Epoch:  16  Average loss at step  2533 :  1366.3021815368495\n",
      "16 2 19.93379807472229\n",
      "Epoch:  16  Average loss at step  1000 :  158.02141446685792\n",
      "Epoch:  16  Average loss at step  1227 :  161.16883699509089\n",
      "16 3 12.629404067993164\n",
      "Epoch:  16  Average loss at step  1000 :  70.51398972320557\n",
      "Epoch:  16  Average loss at step  2000 :  70.59344262313843\n",
      "Epoch:  16  Average loss at step  3000 :  70.54135428619385\n",
      "Epoch:  16  Average loss at step  3222 :  69.65882937859533\n",
      "16 4 33.251638889312744\n",
      "16 5 1.430511474609375e-06\n",
      "Training time took 99.370932 seconds to run 1 epoch\n",
      "Epoch:  17  Average loss at step  1000 :  1.8363579733371735\n",
      "Epoch:  17  Average loss at step  2000 :  1.8184485327005386\n",
      "Epoch:  17  Average loss at step  3000 :  1.8931578496694565\n",
      "Epoch:  17  Average loss at step  3222 :  1.9374942855943431\n",
      "17 0 29.452126502990723\n",
      "Training time took 29.571989 seconds to run 1 epoch\n",
      "Epoch:  18  Average loss at step  1000 :  9.377670032978058\n",
      "Epoch:  18  Average loss at step  2000 :  9.879560685157776\n",
      "Epoch:  18  Average loss at step  3000 :  9.88875895690918\n",
      "Epoch:  18  Average loss at step  4000 :  9.39903167963028\n",
      "Epoch:  18  Average loss at step  5000 :  9.613030677318573\n",
      "Epoch:  18  Average loss at step  6000 :  9.28021270942688\n",
      "Epoch:  18  Average loss at step  7000 :  9.670564734458923\n",
      "Epoch:  18  Average loss at step  8000 :  9.52428257226944\n",
      "Epoch:  18  Average loss at step  8472 :  10.077676315278474\n",
      "18 0 20.81632900238037\n",
      "Epoch:  18  Average loss at step  1000 :  1308.1071682128907\n",
      "Epoch:  18  Average loss at step  1491 :  1327.5232968977168\n",
      "18 1 11.75033164024353\n",
      "Epoch:  18  Average loss at step  1000 :  1422.109265625\n",
      "Epoch:  18  Average loss at step  2000 :  1417.4185495605468\n",
      "Epoch:  18  Average loss at step  2533 :  1413.141644039096\n",
      "18 2 19.95383930206299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18  Average loss at step  1000 :  154.79119645690918\n",
      "Epoch:  18  Average loss at step  1227 :  156.58445970442128\n",
      "18 3 12.491914510726929\n",
      "Epoch:  18  Average loss at step  1000 :  68.92640078353882\n",
      "Epoch:  18  Average loss at step  2000 :  68.31738941955567\n",
      "Epoch:  18  Average loss at step  3000 :  68.56788800811768\n",
      "Epoch:  18  Average loss at step  3222 :  68.87688508509815\n",
      "18 4 33.287484884262085\n",
      "18 5 1.1920928955078125e-06\n",
      "Training time took 98.957843 seconds to run 1 epoch\n",
      "Epoch:  19  Average loss at step  1000 :  1.6131745409965514\n",
      "Epoch:  19  Average loss at step  2000 :  1.5784433835744858\n",
      "Epoch:  19  Average loss at step  3000 :  1.6381398657560349\n",
      "Epoch:  19  Average loss at step  3222 :  1.6719715090343767\n",
      "19 0 29.372706174850464\n",
      "Training time took 29.492083 seconds to run 1 epoch\n",
      "Epoch:  20  Average loss at step  1000 :  9.899177315235137\n",
      "Epoch:  20  Average loss at step  2000 :  9.918154740810394\n",
      "Epoch:  20  Average loss at step  3000 :  9.382657944202423\n",
      "Epoch:  20  Average loss at step  4000 :  9.23565732574463\n",
      "Epoch:  20  Average loss at step  5000 :  9.721942345619201\n",
      "Epoch:  20  Average loss at step  6000 :  9.837608185291291\n",
      "Epoch:  20  Average loss at step  7000 :  9.450907262802124\n",
      "Epoch:  20  Average loss at step  8000 :  9.641960659503937\n",
      "Epoch:  20  Average loss at step  8472 :  9.614788307550022\n",
      "20 0 20.630439281463623\n",
      "Epoch:  20  Average loss at step  1000 :  1346.6030029296876\n",
      "Epoch:  20  Average loss at step  1491 :  1337.492720488728\n",
      "20 1 11.745595216751099\n",
      "Epoch:  20  Average loss at step  1000 :  1478.653558898926\n",
      "Epoch:  20  Average loss at step  2000 :  1460.013150756836\n",
      "Epoch:  20  Average loss at step  2533 :  1460.5009020116463\n",
      "20 2 19.924672842025757\n",
      "Epoch:  20  Average loss at step  1000 :  153.08339542388916\n",
      "Epoch:  20  Average loss at step  1227 :  152.59939217202458\n",
      "20 3 12.658162117004395\n",
      "Epoch:  20  Average loss at step  1000 :  67.86161371612549\n",
      "Epoch:  20  Average loss at step  2000 :  67.89204880905152\n",
      "Epoch:  20  Average loss at step  3000 :  67.41397709274293\n",
      "Epoch:  20  Average loss at step  3222 :  66.726620538632\n",
      "20 4 33.24247455596924\n",
      "20 5 1.1920928955078125e-06\n",
      "Training time took 98.846679 seconds to run 1 epoch\n",
      "Mean Rank:  13202.05076  of  75000\n",
      "Hits @ 10:  0.016\n",
      "Hits @ 1:  0.0032\n",
      "Testing time took 206.318784 seconds.\n",
      "\n",
      "Epoch:  21  Average loss at step  1000 :  1.4271069879531861\n",
      "Epoch:  21  Average loss at step  2000 :  1.3879828068017959\n",
      "Epoch:  21  Average loss at step  3000 :  1.4353515751361847\n",
      "Epoch:  21  Average loss at step  3222 :  1.46762018094835\n",
      "21 0 29.45538091659546\n",
      "Training time took 29.575548 seconds to run 1 epoch\n",
      "Epoch:  22  Average loss at step  1000 :  9.26949398136139\n",
      "Epoch:  22  Average loss at step  2000 :  9.414253727436066\n",
      "Epoch:  22  Average loss at step  3000 :  10.021413803100586\n",
      "Epoch:  22  Average loss at step  4000 :  9.524396344184876\n",
      "Epoch:  22  Average loss at step  5000 :  9.093613449573517\n",
      "Epoch:  22  Average loss at step  6000 :  9.399202688694\n",
      "Epoch:  22  Average loss at step  7000 :  9.330917753219605\n",
      "Epoch:  22  Average loss at step  8000 :  9.456447124004365\n",
      "Epoch:  22  Average loss at step  8472 :  9.70904522529862\n",
      "22 0 21.496224403381348\n",
      "Epoch:  22  Average loss at step  1000 :  1371.856046508789\n",
      "Epoch:  22  Average loss at step  1491 :  1378.5122796473338\n",
      "22 1 11.715866088867188\n",
      "Epoch:  22  Average loss at step  1000 :  1524.0796376953126\n",
      "Epoch:  22  Average loss at step  2000 :  1520.3792329101564\n",
      "Epoch:  22  Average loss at step  2533 :  1525.7721962491603\n",
      "22 2 19.919189453125\n",
      "Epoch:  22  Average loss at step  1000 :  151.65703426361085\n",
      "Epoch:  22  Average loss at step  1227 :  148.63141755304207\n",
      "22 3 12.565494060516357\n",
      "Epoch:  22  Average loss at step  1000 :  66.43017845153808\n",
      "Epoch:  22  Average loss at step  2000 :  66.44078405380249\n",
      "Epoch:  22  Average loss at step  3000 :  66.16962971496582\n",
      "Epoch:  22  Average loss at step  3222 :  66.61508521957934\n",
      "22 4 33.1773145198822\n",
      "22 5 1.1920928955078125e-06\n",
      "Training time took 99.512945 seconds to run 1 epoch\n",
      "Epoch:  23  Average loss at step  1000 :  1.2973524640202523\n",
      "Epoch:  23  Average loss at step  2000 :  1.2618320347070695\n",
      "Epoch:  23  Average loss at step  3000 :  1.302721454501152\n",
      "Epoch:  23  Average loss at step  3222 :  1.3282447531456163\n",
      "23 0 29.497563362121582\n",
      "Training time took 29.616769 seconds to run 1 epoch\n",
      "Epoch:  24  Average loss at step  1000 :  9.506267331123352\n",
      "Epoch:  24  Average loss at step  2000 :  9.635757763385772\n",
      "Epoch:  24  Average loss at step  3000 :  9.691413893699647\n",
      "Epoch:  24  Average loss at step  4000 :  9.451852405548095\n",
      "Epoch:  24  Average loss at step  5000 :  8.845262162685394\n",
      "Epoch:  24  Average loss at step  6000 :  9.449241304397583\n",
      "Epoch:  24  Average loss at step  7000 :  8.954274065494538\n",
      "Epoch:  24  Average loss at step  8000 :  8.75354812192917\n",
      "Epoch:  24  Average loss at step  8472 :  8.777073728861659\n",
      "24 0 21.052891492843628\n",
      "Epoch:  24  Average loss at step  1000 :  1416.6059732666015\n",
      "Epoch:  24  Average loss at step  1491 :  1419.2623284277179\n",
      "24 1 11.545984029769897\n",
      "Epoch:  24  Average loss at step  1000 :  1565.6024221191406\n",
      "Epoch:  24  Average loss at step  2000 :  1565.4436201171875\n",
      "Epoch:  24  Average loss at step  2533 :  1573.3511417811785\n",
      "24 2 19.943394660949707\n",
      "Epoch:  24  Average loss at step  1000 :  147.8187398223877\n",
      "Epoch:  24  Average loss at step  1227 :  148.29118836092772\n",
      "24 3 12.604244709014893\n",
      "Epoch:  24  Average loss at step  1000 :  65.37088122177124\n",
      "Epoch:  24  Average loss at step  2000 :  65.38400361251831\n",
      "Epoch:  24  Average loss at step  3000 :  65.28146869659423\n",
      "Epoch:  24  Average loss at step  3222 :  65.99703494511178\n",
      "24 4 33.09321880340576\n",
      "24 5 1.430511474609375e-06\n",
      "Training time took 98.876256 seconds to run 1 epoch\n",
      "Epoch:  25  Average loss at step  1000 :  1.1951432805657387\n",
      "Epoch:  25  Average loss at step  2000 :  1.1485097442269325\n",
      "Epoch:  25  Average loss at step  3000 :  1.1837995664477348\n",
      "Epoch:  25  Average loss at step  3222 :  1.2095043175077154\n",
      "25 0 29.3763165473938\n",
      "Training time took 29.499504 seconds to run 1 epoch\n",
      "Epoch:  26  Average loss at step  1000 :  9.182855144023895\n",
      "Epoch:  26  Average loss at step  2000 :  9.060033953666688\n",
      "Epoch:  26  Average loss at step  3000 :  8.672109930038452\n",
      "Epoch:  26  Average loss at step  4000 :  9.350703119754792\n",
      "Epoch:  26  Average loss at step  5000 :  9.673853426456452\n",
      "Epoch:  26  Average loss at step  6000 :  9.337018994808197\n",
      "Epoch:  26  Average loss at step  7000 :  9.407080359458924\n",
      "Epoch:  26  Average loss at step  8000 :  9.085962079524993\n",
      "Epoch:  26  Average loss at step  8472 :  9.372355291239398\n",
      "26 0 20.62467861175537\n",
      "Epoch:  26  Average loss at step  1000 :  1422.693420654297\n",
      "Epoch:  26  Average loss at step  1491 :  1433.81881174605\n",
      "26 1 11.719691514968872\n",
      "Epoch:  26  Average loss at step  1000 :  1615.0154395751954\n",
      "Epoch:  26  Average loss at step  2000 :  1611.8373483276366\n",
      "Epoch:  26  Average loss at step  2533 :  1618.2540463947764\n",
      "26 2 19.95999240875244\n",
      "Epoch:  26  Average loss at step  1000 :  145.33790745544434\n",
      "Epoch:  26  Average loss at step  1227 :  145.17462744670547\n",
      "26 3 12.695984601974487\n",
      "Epoch:  26  Average loss at step  1000 :  64.4207776222229\n",
      "Epoch:  26  Average loss at step  2000 :  64.50754251098633\n",
      "Epoch:  26  Average loss at step  3000 :  63.95317058181762\n",
      "Epoch:  26  Average loss at step  3222 :  64.08063458458011\n",
      "26 4 33.272446632385254\n",
      "26 5 1.430511474609375e-06\n",
      "Training time took 98.916284 seconds to run 1 epoch\n",
      "Epoch:  27  Average loss at step  1000 :  1.0876704018115997\n",
      "Epoch:  27  Average loss at step  2000 :  1.052059962749481\n",
      "Epoch:  27  Average loss at step  3000 :  1.0843367855548858\n",
      "Epoch:  27  Average loss at step  3222 :  1.1004649211641984\n",
      "27 0 29.38001036643982\n",
      "Training time took 29.500368 seconds to run 1 epoch\n",
      "Epoch:  28  Average loss at step  1000 :  9.354499097824096\n",
      "Epoch:  28  Average loss at step  2000 :  8.991268340587617\n",
      "Epoch:  28  Average loss at step  3000 :  9.524284275054931\n",
      "Epoch:  28  Average loss at step  4000 :  9.360216814994812\n",
      "Epoch:  28  Average loss at step  5000 :  9.251611032485961\n",
      "Epoch:  28  Average loss at step  6000 :  9.407548878192902\n",
      "Epoch:  28  Average loss at step  7000 :  9.054187846660614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28  Average loss at step  8000 :  9.497172188282013\n",
      "Epoch:  28  Average loss at step  8472 :  8.928556587167751\n",
      "28 0 20.744532823562622\n",
      "Epoch:  28  Average loss at step  1000 :  1447.3398260498047\n",
      "Epoch:  28  Average loss at step  1491 :  1450.028388253942\n",
      "28 1 11.715065002441406\n",
      "Epoch:  28  Average loss at step  1000 :  1651.3443112792968\n",
      "Epoch:  28  Average loss at step  2000 :  1644.293635131836\n",
      "Epoch:  28  Average loss at step  2533 :  1658.5498119374754\n",
      "28 2 19.962103843688965\n",
      "Epoch:  28  Average loss at step  1000 :  143.03297998809813\n",
      "Epoch:  28  Average loss at step  1227 :  146.07858084378543\n",
      "28 3 12.634826421737671\n",
      "Epoch:  28  Average loss at step  1000 :  63.18520207977295\n",
      "Epoch:  28  Average loss at step  2000 :  63.25820369720459\n",
      "Epoch:  28  Average loss at step  3000 :  62.70619049453735\n",
      "Epoch:  28  Average loss at step  3222 :  62.87175204526175\n",
      "28 4 33.04908227920532\n",
      "28 5 1.6689300537109375e-06\n",
      "Training time took 98.746854 seconds to run 1 epoch\n",
      "Epoch:  29  Average loss at step  1000 :  1.009618867456913\n",
      "Epoch:  29  Average loss at step  2000 :  0.9725984519720078\n",
      "Epoch:  29  Average loss at step  3000 :  1.0005806563496589\n",
      "Epoch:  29  Average loss at step  3222 :  1.0112797545168584\n",
      "29 0 29.436792135238647\n",
      "Training time took 29.556455 seconds to run 1 epoch\n",
      "Epoch:  30  Average loss at step  1000 :  8.782998821258545\n",
      "Epoch:  30  Average loss at step  2000 :  9.176057036876678\n",
      "Epoch:  30  Average loss at step  3000 :  8.787684155464172\n",
      "Epoch:  30  Average loss at step  4000 :  8.85095714187622\n",
      "Epoch:  30  Average loss at step  5000 :  9.029453352928162\n",
      "Epoch:  30  Average loss at step  6000 :  9.40576178073883\n",
      "Epoch:  30  Average loss at step  7000 :  9.812606657028198\n",
      "Epoch:  30  Average loss at step  8000 :  8.91627789068222\n",
      "Epoch:  30  Average loss at step  8472 :  8.368570797208928\n",
      "30 0 20.645988702774048\n",
      "Epoch:  30  Average loss at step  1000 :  1467.5016420288086\n",
      "Epoch:  30  Average loss at step  1491 :  1469.07261704368\n",
      "30 1 11.723519325256348\n",
      "Epoch:  30  Average loss at step  1000 :  1696.976841064453\n",
      "Epoch:  30  Average loss at step  2000 :  1689.3626032104492\n",
      "Epoch:  30  Average loss at step  2533 :  1687.9735360390953\n",
      "30 2 19.989562273025513\n",
      "Epoch:  30  Average loss at step  1000 :  141.3811375579834\n",
      "Epoch:  30  Average loss at step  1227 :  138.89209210291514\n",
      "30 3 12.617828369140625\n",
      "Epoch:  30  Average loss at step  1000 :  62.77060587692261\n",
      "Epoch:  30  Average loss at step  2000 :  62.601612663269044\n",
      "Epoch:  30  Average loss at step  3000 :  62.39040190887451\n",
      "Epoch:  30  Average loss at step  3222 :  62.324421946850464\n",
      "30 4 33.1182165145874\n",
      "30 5 1.430511474609375e-06\n",
      "Training time took 98.730043 seconds to run 1 epoch\n",
      "Mean Rank:  4925.9016  of  75000\n",
      "Hits @ 10:  0.0856\n",
      "Hits @ 1:  0.02344\n",
      "Testing time took 180.634863 seconds.\n",
      "\n",
      "Epoch:  31  Average loss at step  1000 :  0.9371554988622666\n",
      "Epoch:  31  Average loss at step  2000 :  0.9033734869360924\n",
      "Epoch:  31  Average loss at step  3000 :  0.9306793650984764\n",
      "Epoch:  31  Average loss at step  3222 :  0.9536078401174888\n",
      "31 0 29.40703511238098\n",
      "Training time took 29.520672 seconds to run 1 epoch\n",
      "Epoch:  32  Average loss at step  1000 :  8.783504682540894\n",
      "Epoch:  32  Average loss at step  2000 :  9.441003979206085\n",
      "Epoch:  32  Average loss at step  3000 :  8.988154511928558\n",
      "Epoch:  32  Average loss at step  4000 :  9.38701875925064\n",
      "Epoch:  32  Average loss at step  5000 :  9.176788744449615\n",
      "Epoch:  32  Average loss at step  6000 :  8.911739039421082\n",
      "Epoch:  32  Average loss at step  7000 :  9.115670485019685\n",
      "Epoch:  32  Average loss at step  8000 :  9.222871777534484\n",
      "Epoch:  32  Average loss at step  8472 :  8.43995947226832\n",
      "32 0 21.280502319335938\n",
      "Epoch:  32  Average loss at step  1000 :  1489.4525910034179\n",
      "Epoch:  32  Average loss at step  1491 :  1493.4120445367244\n",
      "32 1 11.724022388458252\n",
      "Epoch:  32  Average loss at step  1000 :  1729.6648530273437\n",
      "Epoch:  32  Average loss at step  2000 :  1723.2816020507812\n",
      "Epoch:  32  Average loss at step  2533 :  1719.5975602015928\n",
      "32 2 19.976321697235107\n",
      "Epoch:  32  Average loss at step  1000 :  140.00031771087646\n",
      "Epoch:  32  Average loss at step  1227 :  139.80445170132208\n",
      "32 3 12.594679355621338\n",
      "Epoch:  32  Average loss at step  1000 :  61.74561522293091\n",
      "Epoch:  32  Average loss at step  2000 :  61.398495567321774\n",
      "Epoch:  32  Average loss at step  3000 :  61.50779037094116\n",
      "Epoch:  32  Average loss at step  3222 :  61.92496914922987\n",
      "32 4 33.08843541145325\n",
      "32 5 1.430511474609375e-06\n",
      "Training time took 99.30399 seconds to run 1 epoch\n",
      "Epoch:  33  Average loss at step  1000 :  0.8635621200799942\n",
      "Epoch:  33  Average loss at step  2000 :  0.8350037815570831\n",
      "Epoch:  33  Average loss at step  3000 :  0.8677556869387627\n",
      "Epoch:  33  Average loss at step  3222 :  0.8988910094562647\n",
      "33 0 29.44804883003235\n",
      "Training time took 29.566668 seconds to run 1 epoch\n",
      "Epoch:  34  Average loss at step  1000 :  8.40541762495041\n",
      "Epoch:  34  Average loss at step  2000 :  9.162910288333892\n",
      "Epoch:  34  Average loss at step  3000 :  8.899172457218171\n",
      "Epoch:  34  Average loss at step  4000 :  8.479323579311371\n",
      "Epoch:  34  Average loss at step  5000 :  9.09759030342102\n",
      "Epoch:  34  Average loss at step  6000 :  8.714057173252106\n",
      "Epoch:  34  Average loss at step  7000 :  9.08796408367157\n",
      "Epoch:  34  Average loss at step  8000 :  9.18043293952942\n",
      "Epoch:  34  Average loss at step  8472 :  8.490883811747327\n",
      "34 0 20.766611337661743\n",
      "Epoch:  34  Average loss at step  1000 :  1507.5835036621095\n",
      "Epoch:  34  Average loss at step  1491 :  1498.6864608520038\n",
      "34 1 11.752194881439209\n",
      "Epoch:  34  Average loss at step  1000 :  1761.5507946777343\n",
      "Epoch:  34  Average loss at step  2000 :  1763.9312768554687\n",
      "Epoch:  34  Average loss at step  2533 :  1751.8036708882694\n",
      "34 2 19.983458757400513\n",
      "Epoch:  34  Average loss at step  1000 :  139.93636847686767\n",
      "Epoch:  34  Average loss at step  1227 :  139.19898898294292\n",
      "34 3 12.710431337356567\n",
      "Epoch:  34  Average loss at step  1000 :  60.61205430984497\n",
      "Epoch:  34  Average loss at step  2000 :  60.28843198394775\n",
      "Epoch:  34  Average loss at step  3000 :  60.180807415008545\n",
      "Epoch:  34  Average loss at step  3222 :  60.64724909267091\n",
      "34 4 33.25014042854309\n",
      "34 5 1.430511474609375e-06\n",
      "Training time took 99.10504 seconds to run 1 epoch\n",
      "Epoch:  35  Average loss at step  1000 :  0.8242220482230187\n",
      "Epoch:  35  Average loss at step  2000 :  0.797286227941513\n",
      "Epoch:  35  Average loss at step  3000 :  0.8183586908578873\n",
      "Epoch:  35  Average loss at step  3222 :  0.8428352791967322\n",
      "35 0 29.434661388397217\n",
      "Training time took 29.55936 seconds to run 1 epoch\n",
      "Epoch:  36  Average loss at step  1000 :  8.980676385879516\n",
      "Epoch:  36  Average loss at step  2000 :  9.104984457492828\n",
      "Epoch:  36  Average loss at step  3000 :  8.93325147676468\n",
      "Epoch:  36  Average loss at step  4000 :  9.058688910007477\n",
      "Epoch:  36  Average loss at step  5000 :  9.345715245246888\n",
      "Epoch:  36  Average loss at step  6000 :  8.618103711128235\n",
      "Epoch:  36  Average loss at step  7000 :  9.701323165416717\n",
      "Epoch:  36  Average loss at step  8000 :  8.766364580154418\n",
      "Epoch:  36  Average loss at step  8472 :  9.152875665664915\n",
      "36 0 20.731216430664062\n",
      "Epoch:  36  Average loss at step  1000 :  1530.2215294799805\n",
      "Epoch:  36  Average loss at step  1491 :  1505.9229345871213\n",
      "36 1 11.713455200195312\n",
      "Epoch:  36  Average loss at step  1000 :  1797.5442769165038\n",
      "Epoch:  36  Average loss at step  2000 :  1783.7485880126953\n",
      "Epoch:  36  Average loss at step  2533 :  1775.2981442228968\n",
      "36 2 19.941014528274536\n",
      "Epoch:  36  Average loss at step  1000 :  137.7171647338867\n",
      "Epoch:  36  Average loss at step  1227 :  134.23405916252108\n",
      "36 3 12.750131130218506\n",
      "Epoch:  36  Average loss at step  1000 :  60.001071342468265\n",
      "Epoch:  36  Average loss at step  2000 :  59.392629131317136\n",
      "Epoch:  36  Average loss at step  3000 :  59.5829817237854\n",
      "Epoch:  36  Average loss at step  3222 :  59.27215117499122\n",
      "36 4 33.26517963409424\n",
      "36 5 1.6689300537109375e-06\n",
      "Training time took 99.044398 seconds to run 1 epoch\n",
      "Epoch:  37  Average loss at step  1000 :  0.7752330777645111\n",
      "Epoch:  37  Average loss at step  2000 :  0.7495756821632386\n",
      "Epoch:  37  Average loss at step  3000 :  0.7680652377605438\n",
      "Epoch:  37  Average loss at step  3222 :  0.7900996414477439\n",
      "37 0 29.39798903465271\n",
      "Training time took 29.516915 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  38  Average loss at step  1000 :  8.809695385456084\n",
      "Epoch:  38  Average loss at step  2000 :  8.539212289333344\n",
      "Epoch:  38  Average loss at step  3000 :  8.778821928977965\n",
      "Epoch:  38  Average loss at step  4000 :  9.431914747714996\n",
      "Epoch:  38  Average loss at step  5000 :  8.579692118644715\n",
      "Epoch:  38  Average loss at step  6000 :  8.515799231529236\n",
      "Epoch:  38  Average loss at step  7000 :  9.021663582324981\n",
      "Epoch:  38  Average loss at step  8000 :  8.49814612197876\n",
      "Epoch:  38  Average loss at step  8472 :  7.925196752640909\n",
      "38 0 21.101500511169434\n",
      "Epoch:  38  Average loss at step  1000 :  1538.2394196166993\n",
      "Epoch:  38  Average loss at step  1491 :  1533.2950627706916\n",
      "38 1 11.712183952331543\n",
      "Epoch:  38  Average loss at step  1000 :  1823.4464356689452\n",
      "Epoch:  38  Average loss at step  2000 :  1818.4477596435547\n",
      "Epoch:  38  Average loss at step  2533 :  1825.5423784551733\n",
      "38 2 19.955082178115845\n",
      "Epoch:  38  Average loss at step  1000 :  135.28008493041992\n",
      "Epoch:  38  Average loss at step  1227 :  133.5525042484691\n",
      "38 3 12.630924701690674\n",
      "Epoch:  38  Average loss at step  1000 :  59.054998695373534\n",
      "Epoch:  38  Average loss at step  2000 :  58.517293327331544\n",
      "Epoch:  38  Average loss at step  3000 :  58.7563821182251\n",
      "Epoch:  38  Average loss at step  3222 :  59.392345491826994\n",
      "38 4 33.06657528877258\n",
      "38 5 1.1920928955078125e-06\n",
      "Training time took 99.10071 seconds to run 1 epoch\n",
      "Epoch:  39  Average loss at step  1000 :  0.7300777476429939\n",
      "Epoch:  39  Average loss at step  2000 :  0.7036002663969994\n",
      "Epoch:  39  Average loss at step  3000 :  0.7293937335014343\n",
      "Epoch:  39  Average loss at step  3222 :  0.7452020341253686\n",
      "39 0 29.39231038093567\n",
      "Training time took 29.509735 seconds to run 1 epoch\n",
      "Epoch:  40  Average loss at step  1000 :  8.799670475006103\n",
      "Epoch:  40  Average loss at step  2000 :  8.898421260356903\n",
      "Epoch:  40  Average loss at step  3000 :  8.717534707069397\n",
      "Epoch:  40  Average loss at step  4000 :  8.870249032020569\n",
      "Epoch:  40  Average loss at step  5000 :  8.836247965335845\n",
      "Epoch:  40  Average loss at step  6000 :  8.719328876018524\n",
      "Epoch:  40  Average loss at step  7000 :  8.97287750673294\n",
      "Epoch:  40  Average loss at step  8000 :  8.424786928653717\n",
      "Epoch:  40  Average loss at step  8472 :  8.992503135719685\n",
      "40 0 20.415777921676636\n",
      "Epoch:  40  Average loss at step  1000 :  1551.0062307739258\n",
      "Epoch:  40  Average loss at step  1491 :  1555.7840278561305\n",
      "40 1 11.72371220588684\n",
      "Epoch:  40  Average loss at step  1000 :  1851.941061279297\n",
      "Epoch:  40  Average loss at step  2000 :  1845.710640991211\n",
      "Epoch:  40  Average loss at step  2533 :  1853.7097226702729\n",
      "40 2 19.91988229751587\n",
      "Epoch:  40  Average loss at step  1000 :  132.8226983642578\n",
      "Epoch:  40  Average loss at step  1227 :  134.14827591583915\n",
      "40 3 12.622129917144775\n",
      "Epoch:  40  Average loss at step  1000 :  58.095660778045655\n",
      "Epoch:  40  Average loss at step  2000 :  58.05315299606323\n",
      "Epoch:  40  Average loss at step  3000 :  57.569351085662845\n",
      "Epoch:  40  Average loss at step  3222 :  58.14863787938766\n",
      "40 4 33.10151386260986\n",
      "40 5 1.1920928955078125e-06\n",
      "Training time took 98.43866 seconds to run 1 epoch\n",
      "Mean Rank:  1936.76208  of  75000\n",
      "Hits @ 10:  0.2156\n",
      "Hits @ 1:  0.07144\n",
      "Testing time took 169.378355 seconds.\n",
      "\n",
      "Epoch:  41  Average loss at step  1000 :  0.6863205541372299\n",
      "Epoch:  41  Average loss at step  2000 :  0.6702391337752343\n",
      "Epoch:  41  Average loss at step  3000 :  0.6906412488818169\n",
      "Epoch:  41  Average loss at step  3222 :  0.7087073056657814\n",
      "41 0 29.517507553100586\n",
      "Training time took 29.628316 seconds to run 1 epoch\n",
      "Epoch:  42  Average loss at step  1000 :  9.23349987077713\n",
      "Epoch:  42  Average loss at step  2000 :  8.602316057682037\n",
      "Epoch:  42  Average loss at step  3000 :  9.041481033325196\n",
      "Epoch:  42  Average loss at step  4000 :  8.33872689294815\n",
      "Epoch:  42  Average loss at step  5000 :  8.262526976108552\n",
      "Epoch:  42  Average loss at step  6000 :  8.787558225154877\n",
      "Epoch:  42  Average loss at step  7000 :  8.737498130321503\n",
      "Epoch:  42  Average loss at step  8000 :  8.878922650814056\n",
      "Epoch:  42  Average loss at step  8472 :  8.976871739329994\n",
      "42 0 21.44322419166565\n",
      "Epoch:  42  Average loss at step  1000 :  1558.8896364135742\n",
      "Epoch:  42  Average loss at step  1491 :  1557.901095526165\n",
      "42 1 11.713557481765747\n",
      "Epoch:  42  Average loss at step  1000 :  1875.763627319336\n",
      "Epoch:  42  Average loss at step  2000 :  1868.6096500244141\n",
      "Epoch:  42  Average loss at step  2533 :  1879.7352296160798\n",
      "42 2 19.9027156829834\n",
      "Epoch:  42  Average loss at step  1000 :  131.71732418060301\n",
      "Epoch:  42  Average loss at step  1227 :  132.07854039826708\n",
      "42 3 12.626912832260132\n",
      "Epoch:  42  Average loss at step  1000 :  57.37796739196777\n",
      "Epoch:  42  Average loss at step  2000 :  57.38031262207031\n",
      "Epoch:  42  Average loss at step  3000 :  57.216718200683594\n",
      "Epoch:  42  Average loss at step  3222 :  57.15924335485935\n",
      "42 4 33.16898822784424\n",
      "42 5 1.6689300537109375e-06\n",
      "Training time took 99.484542 seconds to run 1 epoch\n",
      "Epoch:  43  Average loss at step  1000 :  0.6554239119291305\n",
      "Epoch:  43  Average loss at step  2000 :  0.638950903058052\n",
      "Epoch:  43  Average loss at step  3000 :  0.6604123851060867\n",
      "Epoch:  43  Average loss at step  3222 :  0.6720166058182221\n",
      "43 0 29.45163917541504\n",
      "Training time took 29.579133 seconds to run 1 epoch\n",
      "Epoch:  44  Average loss at step  1000 :  8.547139090538025\n",
      "Epoch:  44  Average loss at step  2000 :  8.248888570785523\n",
      "Epoch:  44  Average loss at step  3000 :  8.600191815853119\n",
      "Epoch:  44  Average loss at step  4000 :  9.02943998336792\n",
      "Epoch:  44  Average loss at step  5000 :  8.760552555084228\n",
      "Epoch:  44  Average loss at step  6000 :  8.786875144481659\n",
      "Epoch:  44  Average loss at step  7000 :  9.101449956893921\n",
      "Epoch:  44  Average loss at step  8000 :  8.491825213909149\n",
      "Epoch:  44  Average loss at step  8472 :  9.083582870138859\n",
      "44 0 20.354715585708618\n",
      "Epoch:  44  Average loss at step  1000 :  1561.7071643066406\n",
      "Epoch:  44  Average loss at step  1491 :  1571.6592511100582\n",
      "44 1 11.712916851043701\n",
      "Epoch:  44  Average loss at step  1000 :  1902.0880018310547\n",
      "Epoch:  44  Average loss at step  2000 :  1891.4841524658202\n",
      "Epoch:  44  Average loss at step  2533 :  1895.9392826220994\n",
      "44 2 19.858155965805054\n",
      "Epoch:  44  Average loss at step  1000 :  129.5552159500122\n",
      "Epoch:  44  Average loss at step  1227 :  129.7351931570572\n",
      "44 3 12.59461259841919\n",
      "Epoch:  44  Average loss at step  1000 :  56.35437045288086\n",
      "Epoch:  44  Average loss at step  2000 :  56.6103242263794\n",
      "Epoch:  44  Average loss at step  3000 :  56.11788139724732\n",
      "Epoch:  44  Average loss at step  3222 :  56.757453495596565\n",
      "44 4 33.207759380340576\n",
      "44 5 1.1920928955078125e-06\n",
      "Training time took 98.368894 seconds to run 1 epoch\n",
      "Epoch:  45  Average loss at step  1000 :  0.6262840560078621\n",
      "Epoch:  45  Average loss at step  2000 :  0.6076007879376412\n",
      "Epoch:  45  Average loss at step  3000 :  0.6308862105607986\n",
      "Epoch:  45  Average loss at step  3222 :  0.6451513289350704\n",
      "45 0 29.43553853034973\n",
      "Training time took 29.554623 seconds to run 1 epoch\n",
      "Epoch:  46  Average loss at step  1000 :  8.586919953346252\n",
      "Epoch:  46  Average loss at step  2000 :  8.507797398090363\n",
      "Epoch:  46  Average loss at step  3000 :  8.547667653083801\n",
      "Epoch:  46  Average loss at step  4000 :  8.672640278339387\n",
      "Epoch:  46  Average loss at step  5000 :  8.711475229263305\n",
      "Epoch:  46  Average loss at step  6000 :  8.520185799598694\n",
      "Epoch:  46  Average loss at step  7000 :  8.479103184700012\n",
      "Epoch:  46  Average loss at step  8000 :  8.633237082958221\n",
      "Epoch:  46  Average loss at step  8472 :  10.498601350743419\n",
      "46 0 20.42542815208435\n",
      "Epoch:  46  Average loss at step  1000 :  1580.3714844970702\n",
      "Epoch:  46  Average loss at step  1491 :  1586.868242059395\n",
      "46 1 11.717575788497925\n",
      "Epoch:  46  Average loss at step  1000 :  1923.428068725586\n",
      "Epoch:  46  Average loss at step  2000 :  1921.9473270263672\n",
      "Epoch:  46  Average loss at step  2533 :  1925.7005446970709\n",
      "46 2 19.876380920410156\n",
      "Epoch:  46  Average loss at step  1000 :  129.1626782913208\n",
      "Epoch:  46  Average loss at step  1227 :  126.46953754254233\n",
      "46 3 12.49679708480835\n",
      "Epoch:  46  Average loss at step  1000 :  55.66680836868286\n",
      "Epoch:  46  Average loss at step  2000 :  55.63983410644531\n",
      "Epoch:  46  Average loss at step  3000 :  55.55564431762695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  46  Average loss at step  3222 :  55.592415388320454\n",
      "46 4 33.290075063705444\n",
      "46 5 1.430511474609375e-06\n",
      "Training time took 98.439358 seconds to run 1 epoch\n",
      "Epoch:  47  Average loss at step  1000 :  0.5935002366304397\n",
      "Epoch:  47  Average loss at step  2000 :  0.5801432700157165\n",
      "Epoch:  47  Average loss at step  3000 :  0.6020944755673409\n",
      "Epoch:  47  Average loss at step  3222 :  0.6208399725339111\n",
      "47 0 29.419316053390503\n",
      "Training time took 29.539892 seconds to run 1 epoch\n",
      "Epoch:  48  Average loss at step  1000 :  8.596993027210235\n",
      "Epoch:  48  Average loss at step  2000 :  8.48110394334793\n",
      "Epoch:  48  Average loss at step  3000 :  8.450727175712585\n",
      "Epoch:  48  Average loss at step  4000 :  8.9041729054451\n",
      "Epoch:  48  Average loss at step  5000 :  8.514864889621734\n",
      "Epoch:  48  Average loss at step  6000 :  8.880272573947906\n",
      "Epoch:  48  Average loss at step  7000 :  8.628994662284851\n",
      "Epoch:  48  Average loss at step  8000 :  8.874586542129517\n",
      "Epoch:  48  Average loss at step  8472 :  8.765514617125929\n",
      "48 0 20.93515920639038\n",
      "Epoch:  48  Average loss at step  1000 :  1587.336153869629\n",
      "Epoch:  48  Average loss at step  1491 :  1597.1986689623998\n",
      "48 1 11.642228364944458\n",
      "Epoch:  48  Average loss at step  1000 :  1951.580126220703\n",
      "Epoch:  48  Average loss at step  2000 :  1945.4840336914062\n",
      "Epoch:  48  Average loss at step  2533 :  1923.6151331139524\n",
      "48 2 19.901190042495728\n",
      "Epoch:  48  Average loss at step  1000 :  127.0833823928833\n",
      "Epoch:  48  Average loss at step  1227 :  125.46753143083015\n",
      "48 3 12.648945569992065\n",
      "Epoch:  48  Average loss at step  1000 :  54.91105450439453\n",
      "Epoch:  48  Average loss at step  2000 :  55.05300490951538\n",
      "Epoch:  48  Average loss at step  3000 :  54.727892219543456\n",
      "Epoch:  48  Average loss at step  3222 :  55.20816819507264\n",
      "48 4 33.09021043777466\n",
      "48 5 1.430511474609375e-06\n",
      "Training time took 98.862836 seconds to run 1 epoch\n",
      "Epoch:  49  Average loss at step  1000 :  0.5627209431529046\n",
      "Epoch:  49  Average loss at step  2000 :  0.5558780417442322\n",
      "Epoch:  49  Average loss at step  3000 :  0.5749766874909401\n",
      "Epoch:  49  Average loss at step  3222 :  0.596371494027806\n",
      "49 0 29.384015798568726\n",
      "Training time took 29.514142 seconds to run 1 epoch\n",
      "Epoch:  50  Average loss at step  1000 :  8.801241982460022\n",
      "Epoch:  50  Average loss at step  2000 :  8.8980736951828\n",
      "Epoch:  50  Average loss at step  3000 :  8.807298460006713\n",
      "Epoch:  50  Average loss at step  4000 :  9.063181182384492\n",
      "Epoch:  50  Average loss at step  5000 :  8.655471715927124\n",
      "Epoch:  50  Average loss at step  6000 :  8.72595877122879\n",
      "Epoch:  50  Average loss at step  7000 :  8.926722495555877\n",
      "Epoch:  50  Average loss at step  8000 :  8.270500035762787\n",
      "Epoch:  50  Average loss at step  8472 :  9.085278319592012\n",
      "50 0 20.112075567245483\n",
      "Epoch:  50  Average loss at step  1000 :  1604.8535618286132\n",
      "Epoch:  50  Average loss at step  1491 :  1602.0232356748288\n",
      "50 1 11.720687866210938\n",
      "Epoch:  50  Average loss at step  1000 :  1972.405707397461\n",
      "Epoch:  50  Average loss at step  2000 :  1944.6895083007812\n",
      "Epoch:  50  Average loss at step  2533 :  1947.1737501464681\n",
      "50 2 19.94520664215088\n",
      "Epoch:  50  Average loss at step  1000 :  125.41914237213135\n",
      "Epoch:  50  Average loss at step  1227 :  126.13916241002977\n",
      "50 3 12.631034135818481\n",
      "Epoch:  50  Average loss at step  1000 :  54.285772495269775\n",
      "Epoch:  50  Average loss at step  2000 :  53.962562049865724\n",
      "Epoch:  50  Average loss at step  3000 :  53.94669502258301\n",
      "Epoch:  50  Average loss at step  3222 :  54.31395935482831\n",
      "50 4 33.25270414352417\n",
      "50 5 1.430511474609375e-06\n",
      "Training time took 98.300877 seconds to run 1 epoch\n",
      "Mean Rank:  957.13228  of  75000\n",
      "Hits @ 10:  0.364\n",
      "Hits @ 1:  0.1416\n",
      "Testing time took 166.613897 seconds.\n",
      "\n",
      "Epoch:  51  Average loss at step  1000 :  0.5478646455407142\n",
      "Epoch:  51  Average loss at step  2000 :  0.5373542894124985\n",
      "Epoch:  51  Average loss at step  3000 :  0.5538467087745667\n",
      "Epoch:  51  Average loss at step  3222 :  0.5654719511746801\n",
      "51 0 29.48484992980957\n",
      "Training time took 29.590569 seconds to run 1 epoch\n",
      "Epoch:  52  Average loss at step  1000 :  8.552891020774842\n",
      "Epoch:  52  Average loss at step  2000 :  8.487782065868378\n",
      "Epoch:  52  Average loss at step  3000 :  8.291964650154114\n",
      "Epoch:  52  Average loss at step  4000 :  8.06373998260498\n",
      "Epoch:  52  Average loss at step  5000 :  9.110359102249145\n",
      "Epoch:  52  Average loss at step  6000 :  8.612535527229308\n",
      "Epoch:  52  Average loss at step  7000 :  8.43888333272934\n",
      "Epoch:  52  Average loss at step  8000 :  8.996199326515198\n",
      "Epoch:  52  Average loss at step  8472 :  9.365263350937544\n",
      "52 0 20.640138149261475\n",
      "Epoch:  52  Average loss at step  1000 :  1607.5224602661133\n",
      "Epoch:  52  Average loss at step  1491 :  1609.3478208123088\n",
      "52 1 11.711534976959229\n",
      "Epoch:  52  Average loss at step  1000 :  2005.6219586181642\n",
      "Epoch:  52  Average loss at step  2000 :  1974.099192993164\n",
      "Epoch:  52  Average loss at step  2533 :  1983.4096125569133\n",
      "52 2 19.937963485717773\n",
      "Epoch:  52  Average loss at step  1000 :  125.10811699676513\n",
      "Epoch:  52  Average loss at step  1227 :  125.1812743736722\n",
      "52 3 12.590878009796143\n",
      "Epoch:  52  Average loss at step  1000 :  53.5572038269043\n",
      "Epoch:  52  Average loss at step  2000 :  53.15738962936401\n",
      "Epoch:  52  Average loss at step  3000 :  53.27027480697632\n",
      "Epoch:  52  Average loss at step  3222 :  53.39099402289073\n",
      "52 4 33.07918357849121\n",
      "52 5 1.1920928955078125e-06\n",
      "Training time took 98.614645 seconds to run 1 epoch\n",
      "Epoch:  53  Average loss at step  1000 :  0.5243791571855545\n",
      "Epoch:  53  Average loss at step  2000 :  0.5161818973422051\n",
      "Epoch:  53  Average loss at step  3000 :  0.5338483016490936\n",
      "Epoch:  53  Average loss at step  3222 :  0.549053956959131\n",
      "53 0 29.448954582214355\n",
      "Training time took 29.573969 seconds to run 1 epoch\n",
      "Epoch:  54  Average loss at step  1000 :  8.476313926219941\n",
      "Epoch:  54  Average loss at step  2000 :  8.493695315361023\n",
      "Epoch:  54  Average loss at step  3000 :  8.897201575279237\n",
      "Epoch:  54  Average loss at step  4000 :  8.161311038970947\n",
      "Epoch:  54  Average loss at step  5000 :  8.33632676935196\n",
      "Epoch:  54  Average loss at step  6000 :  8.538447734355927\n",
      "Epoch:  54  Average loss at step  7000 :  8.26890210723877\n",
      "Epoch:  54  Average loss at step  8000 :  8.672273585796356\n",
      "Epoch:  54  Average loss at step  8472 :  9.506919636881607\n",
      "54 0 20.65450167655945\n",
      "Epoch:  54  Average loss at step  1000 :  1619.7469376831054\n",
      "Epoch:  54  Average loss at step  1491 :  1605.2393640860046\n",
      "54 1 11.743557691574097\n",
      "Epoch:  54  Average loss at step  1000 :  2011.4777745361328\n",
      "Epoch:  54  Average loss at step  2000 :  2009.5157368164062\n",
      "Epoch:  54  Average loss at step  2533 :  2014.7180101904921\n",
      "54 2 19.874747037887573\n",
      "Epoch:  54  Average loss at step  1000 :  123.47115537261963\n",
      "Epoch:  54  Average loss at step  1227 :  123.57660247214383\n",
      "54 3 12.658122301101685\n",
      "Epoch:  54  Average loss at step  1000 :  52.618870613098146\n",
      "Epoch:  54  Average loss at step  2000 :  52.69930601882935\n",
      "Epoch:  54  Average loss at step  3000 :  52.37828199386597\n",
      "Epoch:  54  Average loss at step  3222 :  52.309653224831436\n",
      "54 4 33.17600226402283\n",
      "54 5 1.6689300537109375e-06\n",
      "Training time took 98.741879 seconds to run 1 epoch\n",
      "Epoch:  55  Average loss at step  1000 :  0.5017457833886146\n",
      "Epoch:  55  Average loss at step  2000 :  0.49368902802467346\n",
      "Epoch:  55  Average loss at step  3000 :  0.5136500249505043\n",
      "Epoch:  55  Average loss at step  3222 :  0.5309964207174718\n",
      "55 0 29.401580095291138\n",
      "Training time took 29.51941 seconds to run 1 epoch\n",
      "Epoch:  56  Average loss at step  1000 :  8.822554135799408\n",
      "Epoch:  56  Average loss at step  2000 :  9.03055065536499\n",
      "Epoch:  56  Average loss at step  3000 :  8.953297924518585\n",
      "Epoch:  56  Average loss at step  4000 :  8.377022106647491\n",
      "Epoch:  56  Average loss at step  5000 :  8.657438287734985\n",
      "Epoch:  56  Average loss at step  6000 :  8.429909408569335\n",
      "Epoch:  56  Average loss at step  7000 :  8.92990593624115\n",
      "Epoch:  56  Average loss at step  8000 :  8.30642467880249\n",
      "Epoch:  56  Average loss at step  8472 :  9.14237765574525\n",
      "56 0 20.44865870475769\n",
      "Epoch:  56  Average loss at step  1000 :  1623.451032775879\n",
      "Epoch:  56  Average loss at step  1491 :  1606.414583692717\n",
      "56 1 11.712329387664795\n",
      "Epoch:  56  Average loss at step  1000 :  2032.0110338134766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  56  Average loss at step  2000 :  2016.1974401855468\n",
      "Epoch:  56  Average loss at step  2533 :  2039.7637529462434\n",
      "56 2 19.87502384185791\n",
      "Epoch:  56  Average loss at step  1000 :  122.41728410339356\n",
      "Epoch:  56  Average loss at step  1227 :  120.92580988404296\n",
      "56 3 12.619866371154785\n",
      "Epoch:  56  Average loss at step  1000 :  51.86591407012939\n",
      "Epoch:  56  Average loss at step  2000 :  52.04076872253418\n",
      "Epoch:  56  Average loss at step  3000 :  52.073952014923094\n",
      "Epoch:  56  Average loss at step  3222 :  51.9932280294429\n",
      "56 4 33.15220928192139\n",
      "56 5 1.430511474609375e-06\n",
      "Training time took 98.438807 seconds to run 1 epoch\n",
      "Epoch:  57  Average loss at step  1000 :  0.4871889790892601\n",
      "Epoch:  57  Average loss at step  2000 :  0.47999521934986117\n",
      "Epoch:  57  Average loss at step  3000 :  0.49774957466125486\n",
      "Epoch:  57  Average loss at step  3222 :  0.5060666080178886\n",
      "57 0 29.43402647972107\n",
      "Training time took 29.55328 seconds to run 1 epoch\n",
      "Epoch:  58  Average loss at step  1000 :  8.668357538700104\n",
      "Epoch:  58  Average loss at step  2000 :  8.680020558834077\n",
      "Epoch:  58  Average loss at step  3000 :  9.008210302829742\n",
      "Epoch:  58  Average loss at step  4000 :  8.655199865818023\n",
      "Epoch:  58  Average loss at step  5000 :  8.404068331718445\n",
      "Epoch:  58  Average loss at step  6000 :  8.687839745044709\n",
      "Epoch:  58  Average loss at step  7000 :  8.806543850898743\n",
      "Epoch:  58  Average loss at step  8000 :  8.258682755947113\n",
      "Epoch:  58  Average loss at step  8472 :  8.127005671681726\n",
      "58 0 20.831605911254883\n",
      "Epoch:  58  Average loss at step  1000 :  1628.989272705078\n",
      "Epoch:  58  Average loss at step  1491 :  1633.5335105274523\n",
      "58 1 11.712571620941162\n",
      "Epoch:  58  Average loss at step  1000 :  2061.143144897461\n",
      "Epoch:  58  Average loss at step  2000 :  2038.8841604003906\n",
      "Epoch:  58  Average loss at step  2533 :  2028.0215456051717\n",
      "58 2 19.89580750465393\n",
      "Epoch:  58  Average loss at step  1000 :  120.59738610076904\n",
      "Epoch:  58  Average loss at step  1227 :  119.87111194314569\n",
      "58 3 12.6620352268219\n",
      "Epoch:  58  Average loss at step  1000 :  51.21174113464355\n",
      "Epoch:  58  Average loss at step  2000 :  51.23842333221435\n",
      "Epoch:  58  Average loss at step  3000 :  51.27044610214234\n",
      "Epoch:  58  Average loss at step  3222 :  51.09744904423948\n",
      "58 4 33.021849632263184\n",
      "58 5 1.1920928955078125e-06\n",
      "Training time took 98.765965 seconds to run 1 epoch\n",
      "Epoch:  59  Average loss at step  1000 :  0.464929909825325\n",
      "Epoch:  59  Average loss at step  2000 :  0.4583624260425568\n",
      "Epoch:  59  Average loss at step  3000 :  0.4812255321741104\n",
      "Epoch:  59  Average loss at step  3222 :  0.4917912019743216\n",
      "59 0 29.440728902816772\n",
      "Training time took 29.562821 seconds to run 1 epoch\n",
      "Epoch:  60  Average loss at step  1000 :  8.738560513973237\n",
      "Epoch:  60  Average loss at step  2000 :  8.225856026649476\n",
      "Epoch:  60  Average loss at step  3000 :  8.591345404624938\n",
      "Epoch:  60  Average loss at step  4000 :  8.535523334026337\n",
      "Epoch:  60  Average loss at step  5000 :  8.405727885246277\n",
      "Epoch:  60  Average loss at step  6000 :  8.685555086135864\n",
      "Epoch:  60  Average loss at step  7000 :  8.575105237960816\n",
      "Epoch:  60  Average loss at step  8000 :  8.285832159519195\n",
      "Epoch:  60  Average loss at step  8472 :  9.196187200036661\n",
      "60 0 20.46349549293518\n",
      "Epoch:  60  Average loss at step  1000 :  1642.4511787719728\n",
      "Epoch:  60  Average loss at step  1491 :  1638.68772588963\n",
      "60 1 11.745174884796143\n",
      "Epoch:  60  Average loss at step  1000 :  2068.2647818603514\n",
      "Epoch:  60  Average loss at step  2000 :  2055.947985107422\n",
      "Epoch:  60  Average loss at step  2533 :  2052.968732746894\n",
      "60 2 19.9227032661438\n",
      "Epoch:  60  Average loss at step  1000 :  118.86748821258544\n",
      "Epoch:  60  Average loss at step  1227 :  119.65895708433904\n",
      "60 3 12.688881874084473\n",
      "Epoch:  60  Average loss at step  1000 :  50.66086727142334\n",
      "Epoch:  60  Average loss at step  2000 :  50.05772954940796\n",
      "Epoch:  60  Average loss at step  3000 :  50.491413204193115\n",
      "Epoch:  60  Average loss at step  3222 :  50.00529155810401\n",
      "60 4 32.70390963554382\n",
      "60 5 9.5367431640625e-07\n",
      "Training time took 98.15948 seconds to run 1 epoch\n",
      "Mean Rank:  608.6394  of  75000\n",
      "Hits @ 10:  0.48368\n",
      "Hits @ 1:  0.21136\n",
      "Testing time took 165.602106 seconds.\n",
      "\n",
      "Epoch:  61  Average loss at step  1000 :  0.4466889669895172\n",
      "Epoch:  61  Average loss at step  2000 :  0.4451587074995041\n",
      "Epoch:  61  Average loss at step  3000 :  0.4635047482252121\n",
      "Epoch:  61  Average loss at step  3222 :  0.47808226818727617\n",
      "61 0 29.21197509765625\n",
      "Training time took 29.323657 seconds to run 1 epoch\n",
      "Epoch:  62  Average loss at step  1000 :  8.540915145874024\n",
      "Epoch:  62  Average loss at step  2000 :  8.617715759277344\n",
      "Epoch:  62  Average loss at step  3000 :  8.655009906291962\n",
      "Epoch:  62  Average loss at step  4000 :  8.241638147830963\n",
      "Epoch:  62  Average loss at step  5000 :  8.472624361991882\n",
      "Epoch:  62  Average loss at step  6000 :  8.587376528739929\n",
      "Epoch:  62  Average loss at step  7000 :  8.446815769672394\n",
      "Epoch:  62  Average loss at step  8000 :  8.966314084053039\n",
      "Epoch:  62  Average loss at step  8472 :  8.477516117851245\n",
      "62 0 20.25365424156189\n",
      "Epoch:  62  Average loss at step  1000 :  1638.1097631835937\n",
      "Epoch:  62  Average loss at step  1491 :  1641.06945847279\n",
      "62 1 11.732990741729736\n",
      "Epoch:  62  Average loss at step  1000 :  2092.96705456543\n",
      "Epoch:  62  Average loss at step  2000 :  2083.6883725585935\n",
      "Epoch:  62  Average loss at step  2533 :  2072.4205799157994\n",
      "62 2 19.984774827957153\n",
      "Epoch:  62  Average loss at step  1000 :  117.78984588623047\n",
      "Epoch:  62  Average loss at step  1227 :  120.30045540514656\n",
      "62 3 12.594743967056274\n",
      "Epoch:  62  Average loss at step  1000 :  50.03631289291382\n",
      "Epoch:  62  Average loss at step  2000 :  49.871282585144044\n",
      "Epoch:  62  Average loss at step  3000 :  49.418434825897215\n",
      "Epoch:  62  Average loss at step  3222 :  49.18256388779775\n",
      "62 4 33.19442176818848\n",
      "62 5 1.1920928955078125e-06\n",
      "Training time took 98.402652 seconds to run 1 epoch\n",
      "Epoch:  63  Average loss at step  1000 :  0.43210836172103884\n",
      "Epoch:  63  Average loss at step  2000 :  0.42931086987257006\n",
      "Epoch:  63  Average loss at step  3000 :  0.45059751623868943\n",
      "Epoch:  63  Average loss at step  3222 :  0.4626480094102514\n",
      "63 0 29.50157594680786\n",
      "Training time took 29.618114 seconds to run 1 epoch\n",
      "Epoch:  64  Average loss at step  1000 :  8.802214061737061\n",
      "Epoch:  64  Average loss at step  2000 :  8.336772996902466\n",
      "Epoch:  64  Average loss at step  3000 :  8.04149007320404\n",
      "Epoch:  64  Average loss at step  4000 :  8.513745584964752\n",
      "Epoch:  64  Average loss at step  5000 :  8.670909028053284\n",
      "Epoch:  64  Average loss at step  6000 :  8.420115362167358\n",
      "Epoch:  64  Average loss at step  7000 :  8.211223618030548\n",
      "Epoch:  64  Average loss at step  8000 :  8.308665579319\n",
      "Epoch:  64  Average loss at step  8472 :  9.407408319119256\n",
      "64 0 20.74892520904541\n",
      "Epoch:  64  Average loss at step  1000 :  1648.1951913452149\n",
      "Epoch:  64  Average loss at step  1491 :  1654.5061569706506\n",
      "64 1 11.740234851837158\n",
      "Epoch:  64  Average loss at step  1000 :  2089.814341430664\n",
      "Epoch:  64  Average loss at step  2000 :  2105.7713402099607\n",
      "Epoch:  64  Average loss at step  2533 :  2064.110823609312\n",
      "64 2 19.957374572753906\n",
      "Epoch:  64  Average loss at step  1000 :  117.13132415008545\n",
      "Epoch:  64  Average loss at step  1227 :  115.85130604436698\n",
      "64 3 12.674386739730835\n",
      "Epoch:  64  Average loss at step  1000 :  49.02972626113892\n",
      "Epoch:  64  Average loss at step  2000 :  49.176869052886964\n",
      "Epoch:  64  Average loss at step  3000 :  49.108297588348385\n",
      "Epoch:  64  Average loss at step  3222 :  48.912296443236045\n",
      "64 4 33.32704019546509\n",
      "64 5 1.6689300537109375e-06\n",
      "Training time took 99.095449 seconds to run 1 epoch\n",
      "Epoch:  65  Average loss at step  1000 :  0.4158344019651413\n",
      "Epoch:  65  Average loss at step  2000 :  0.41423794108629225\n",
      "Epoch:  65  Average loss at step  3000 :  0.4377471051216125\n",
      "Epoch:  65  Average loss at step  3222 :  0.45072669682896166\n",
      "65 0 29.40134835243225\n",
      "Training time took 29.52259 seconds to run 1 epoch\n",
      "Epoch:  66  Average loss at step  1000 :  8.380965404033661\n",
      "Epoch:  66  Average loss at step  2000 :  8.729479983329773\n",
      "Epoch:  66  Average loss at step  3000 :  8.87158470773697\n",
      "Epoch:  66  Average loss at step  4000 :  8.460865057468414\n",
      "Epoch:  66  Average loss at step  5000 :  8.908151442527771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  66  Average loss at step  6000 :  8.583609366416932\n",
      "Epoch:  66  Average loss at step  7000 :  8.621389597415924\n",
      "Epoch:  66  Average loss at step  8000 :  8.405706001281738\n",
      "Epoch:  66  Average loss at step  8472 :  8.700919929472985\n",
      "66 0 20.735644817352295\n",
      "Epoch:  66  Average loss at step  1000 :  1640.1164624023438\n",
      "Epoch:  66  Average loss at step  1491 :  1648.544072134536\n",
      "66 1 11.706745862960815\n",
      "Epoch:  66  Average loss at step  1000 :  2119.860498779297\n",
      "Epoch:  66  Average loss at step  2000 :  2116.4007658691407\n",
      "Epoch:  66  Average loss at step  2533 :  2120.5641757813237\n",
      "66 2 19.9490966796875\n",
      "Epoch:  66  Average loss at step  1000 :  115.81630213928223\n",
      "Epoch:  66  Average loss at step  1227 :  115.54093909746402\n",
      "66 3 12.639225006103516\n",
      "Epoch:  66  Average loss at step  1000 :  48.282187530517575\n",
      "Epoch:  66  Average loss at step  2000 :  48.126136474609375\n",
      "Epoch:  66  Average loss at step  3000 :  48.35652505111695\n",
      "Epoch:  66  Average loss at step  3222 :  48.671455231787256\n",
      "66 4 33.16021227836609\n",
      "66 5 1.430511474609375e-06\n",
      "Training time took 98.820631 seconds to run 1 epoch\n",
      "Epoch:  67  Average loss at step  1000 :  0.4020615628957748\n",
      "Epoch:  67  Average loss at step  2000 :  0.40379634088277816\n",
      "Epoch:  67  Average loss at step  3000 :  0.4243813863992691\n",
      "Epoch:  67  Average loss at step  3222 :  0.4377854531649369\n",
      "67 0 29.44613027572632\n",
      "Training time took 29.565116 seconds to run 1 epoch\n",
      "Epoch:  68  Average loss at step  1000 :  8.930230017662048\n",
      "Epoch:  68  Average loss at step  2000 :  8.659766511917114\n",
      "Epoch:  68  Average loss at step  3000 :  8.459957750320434\n",
      "Epoch:  68  Average loss at step  4000 :  8.350580299377441\n",
      "Epoch:  68  Average loss at step  5000 :  8.366065643310547\n",
      "Epoch:  68  Average loss at step  6000 :  8.55556140756607\n",
      "Epoch:  68  Average loss at step  7000 :  8.823265047073365\n",
      "Epoch:  68  Average loss at step  8000 :  8.56224254846573\n",
      "Epoch:  68  Average loss at step  8472 :  8.613658066713912\n",
      "68 0 20.737709760665894\n",
      "Epoch:  68  Average loss at step  1000 :  1655.3904745483399\n",
      "Epoch:  68  Average loss at step  1491 :  1667.0031956596965\n",
      "68 1 11.730736494064331\n",
      "Epoch:  68  Average loss at step  1000 :  2141.8263126220704\n",
      "Epoch:  68  Average loss at step  2000 :  2145.2637462158204\n",
      "Epoch:  68  Average loss at step  2533 :  2150.3128520367773\n",
      "68 2 19.93531084060669\n",
      "Epoch:  68  Average loss at step  1000 :  115.33561805725098\n",
      "Epoch:  68  Average loss at step  1227 :  113.60539475762967\n",
      "68 3 12.656511068344116\n",
      "Epoch:  68  Average loss at step  1000 :  47.47872486114502\n",
      "Epoch:  68  Average loss at step  2000 :  47.88085279464722\n",
      "Epoch:  68  Average loss at step  3000 :  47.49531491088867\n",
      "Epoch:  68  Average loss at step  3222 :  47.55337013193665\n",
      "68 4 33.016371726989746\n",
      "68 5 1.6689300537109375e-06\n",
      "Training time took 98.709355 seconds to run 1 epoch\n",
      "Epoch:  69  Average loss at step  1000 :  0.39109282624721525\n",
      "Epoch:  69  Average loss at step  2000 :  0.3909644092321396\n",
      "Epoch:  69  Average loss at step  3000 :  0.4131493757367134\n",
      "Epoch:  69  Average loss at step  3222 :  0.4258047527710783\n",
      "69 0 29.457676887512207\n",
      "Training time took 29.577808 seconds to run 1 epoch\n",
      "Epoch:  70  Average loss at step  1000 :  8.353960927009583\n",
      "Epoch:  70  Average loss at step  2000 :  8.536328672409057\n",
      "Epoch:  70  Average loss at step  3000 :  8.776186419010163\n",
      "Epoch:  70  Average loss at step  4000 :  8.031254344940185\n",
      "Epoch:  70  Average loss at step  5000 :  8.523318818569184\n",
      "Epoch:  70  Average loss at step  6000 :  8.604928120613097\n",
      "Epoch:  70  Average loss at step  7000 :  8.79264697742462\n",
      "Epoch:  70  Average loss at step  8000 :  8.343524238586426\n",
      "Epoch:  70  Average loss at step  8472 :  8.372286073289557\n",
      "70 0 20.415077686309814\n",
      "Epoch:  70  Average loss at step  1000 :  1658.9446504516602\n",
      "Epoch:  70  Average loss at step  1491 :  1676.9583909342027\n",
      "70 1 11.68104600906372\n",
      "Epoch:  70  Average loss at step  1000 :  2169.846973754883\n",
      "Epoch:  70  Average loss at step  2000 :  2155.9738942871095\n",
      "Epoch:  70  Average loss at step  2533 :  2143.4273107103027\n",
      "70 2 19.95420002937317\n",
      "Epoch:  70  Average loss at step  1000 :  112.89329327392578\n",
      "Epoch:  70  Average loss at step  1227 :  113.88695876273448\n",
      "70 3 12.612268209457397\n",
      "Epoch:  70  Average loss at step  1000 :  47.137110467910766\n",
      "Epoch:  70  Average loss at step  2000 :  47.032666118621826\n",
      "Epoch:  70  Average loss at step  3000 :  47.000194637298584\n",
      "Epoch:  70  Average loss at step  3222 :  46.82691072724661\n",
      "70 4 33.18411111831665\n",
      "70 5 1.6689300537109375e-06\n",
      "Training time took 98.481716 seconds to run 1 epoch\n",
      "Mean Rank:  465.5908  of  75000\n",
      "Hits @ 10:  0.56748\n",
      "Hits @ 1:  0.26936\n",
      "Testing time took 164.844887 seconds.\n",
      "\n",
      "Epoch:  71  Average loss at step  1000 :  0.38201444065570833\n",
      "Epoch:  71  Average loss at step  2000 :  0.37898749351501465\n",
      "Epoch:  71  Average loss at step  3000 :  0.4007637214660644\n",
      "Epoch:  71  Average loss at step  3222 :  0.4183497607417433\n",
      "71 0 29.495074033737183\n",
      "Training time took 29.60453 seconds to run 1 epoch\n",
      "Epoch:  72  Average loss at step  1000 :  8.43488002872467\n",
      "Epoch:  72  Average loss at step  2000 :  8.363986760616303\n",
      "Epoch:  72  Average loss at step  3000 :  8.593293999671936\n",
      "Epoch:  72  Average loss at step  4000 :  8.232258864879608\n",
      "Epoch:  72  Average loss at step  5000 :  8.693722229480743\n",
      "Epoch:  72  Average loss at step  6000 :  8.708235596656799\n",
      "Epoch:  72  Average loss at step  7000 :  8.220477571964263\n",
      "Epoch:  72  Average loss at step  8000 :  8.694004829883575\n",
      "Epoch:  72  Average loss at step  8472 :  8.25673022439598\n",
      "72 0 20.679558992385864\n",
      "Epoch:  72  Average loss at step  1000 :  1657.6402627563477\n",
      "Epoch:  72  Average loss at step  1491 :  1666.4758723239565\n",
      "72 1 11.726200103759766\n",
      "Epoch:  72  Average loss at step  1000 :  2159.190732421875\n",
      "Epoch:  72  Average loss at step  2000 :  2154.2218548583983\n",
      "Epoch:  72  Average loss at step  2533 :  2175.9893263568874\n",
      "72 2 19.883176565170288\n",
      "Epoch:  72  Average loss at step  1000 :  113.05466008758545\n",
      "Epoch:  72  Average loss at step  1227 :  112.265155375038\n",
      "72 3 12.65296745300293\n",
      "Epoch:  72  Average loss at step  1000 :  46.34401441955566\n",
      "Epoch:  72  Average loss at step  2000 :  46.220408489227296\n",
      "Epoch:  72  Average loss at step  3000 :  46.07751329994202\n",
      "Epoch:  72  Average loss at step  3222 :  45.79810895608164\n",
      "72 4 33.22877359390259\n",
      "72 5 1.430511474609375e-06\n",
      "Training time took 98.803392 seconds to run 1 epoch\n",
      "Epoch:  73  Average loss at step  1000 :  0.3727156091332436\n",
      "Epoch:  73  Average loss at step  2000 :  0.37014874386787416\n",
      "Epoch:  73  Average loss at step  3000 :  0.3905231026411057\n",
      "Epoch:  73  Average loss at step  3222 :  0.4034963895276385\n",
      "73 0 29.50964665412903\n",
      "Training time took 29.633717 seconds to run 1 epoch\n",
      "Epoch:  74  Average loss at step  1000 :  8.026510746002197\n",
      "Epoch:  74  Average loss at step  2000 :  8.588526549816132\n",
      "Epoch:  74  Average loss at step  3000 :  8.548595027923584\n",
      "Epoch:  74  Average loss at step  4000 :  8.421830553531647\n",
      "Epoch:  74  Average loss at step  5000 :  8.630792949199677\n",
      "Epoch:  74  Average loss at step  6000 :  8.335744649887085\n",
      "Epoch:  74  Average loss at step  7000 :  8.443404850959778\n",
      "Epoch:  74  Average loss at step  8000 :  8.245104357719422\n",
      "Epoch:  74  Average loss at step  8472 :  8.276262252360429\n",
      "74 0 20.064497470855713\n",
      "Epoch:  74  Average loss at step  1000 :  1668.370287109375\n",
      "Epoch:  74  Average loss at step  1491 :  1674.2983797870718\n",
      "74 1 11.655469179153442\n",
      "Epoch:  74  Average loss at step  1000 :  2194.2127055664064\n",
      "Epoch:  74  Average loss at step  2000 :  2183.77096484375\n",
      "Epoch:  74  Average loss at step  2533 :  2184.108550329072\n",
      "74 2 19.905781984329224\n",
      "Epoch:  74  Average loss at step  1000 :  111.41090887451172\n",
      "Epoch:  74  Average loss at step  1227 :  111.05199675758374\n",
      "74 3 12.662364721298218\n",
      "Epoch:  74  Average loss at step  1000 :  45.42398345947266\n",
      "Epoch:  74  Average loss at step  2000 :  45.40379420852661\n",
      "Epoch:  74  Average loss at step  3000 :  45.37732525634765\n",
      "Epoch:  74  Average loss at step  3222 :  45.18397207788708\n",
      "74 4 33.11816716194153\n",
      "74 5 1.430511474609375e-06\n",
      "Training time took 98.044031 seconds to run 1 epoch\n",
      "Epoch:  75  Average loss at step  1000 :  0.3600075659155846\n",
      "Epoch:  75  Average loss at step  2000 :  0.36186417877674104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  75  Average loss at step  3000 :  0.3809708055257797\n",
      "Epoch:  75  Average loss at step  3222 :  0.3901428523358939\n",
      "75 0 29.438210248947144\n",
      "Training time took 29.559209 seconds to run 1 epoch\n",
      "Epoch:  76  Average loss at step  1000 :  8.561071801662445\n",
      "Epoch:  76  Average loss at step  2000 :  7.952173987865448\n",
      "Epoch:  76  Average loss at step  3000 :  8.755598742485047\n",
      "Epoch:  76  Average loss at step  4000 :  8.739900301456451\n",
      "Epoch:  76  Average loss at step  5000 :  8.563160046100617\n",
      "Epoch:  76  Average loss at step  6000 :  8.71587224149704\n",
      "Epoch:  76  Average loss at step  7000 :  7.793606078147888\n",
      "Epoch:  76  Average loss at step  8000 :  8.595711639881134\n",
      "Epoch:  76  Average loss at step  8472 :  8.384182551210609\n",
      "76 0 21.012876510620117\n",
      "Epoch:  76  Average loss at step  1000 :  1683.445833618164\n",
      "Epoch:  76  Average loss at step  1491 :  1669.663895943509\n",
      "76 1 11.754131317138672\n",
      "Epoch:  76  Average loss at step  1000 :  2190.2741088867188\n",
      "Epoch:  76  Average loss at step  2000 :  2190.595952270508\n",
      "Epoch:  76  Average loss at step  2533 :  2192.1859357489934\n",
      "76 2 20.011172771453857\n",
      "Epoch:  76  Average loss at step  1000 :  110.68644651031494\n",
      "Epoch:  76  Average loss at step  1227 :  108.47278018903789\n",
      "76 3 12.649219274520874\n",
      "Epoch:  76  Average loss at step  1000 :  44.98680447387695\n",
      "Epoch:  76  Average loss at step  2000 :  44.743483186721804\n",
      "Epoch:  76  Average loss at step  3000 :  44.824767244338986\n",
      "Epoch:  76  Average loss at step  3222 :  45.023523054520645\n",
      "76 4 33.15245771408081\n",
      "76 5 1.430511474609375e-06\n",
      "Training time took 99.220549 seconds to run 1 epoch\n",
      "Epoch:  77  Average loss at step  1000 :  0.348681715965271\n",
      "Epoch:  77  Average loss at step  2000 :  0.3512802976965904\n",
      "Epoch:  77  Average loss at step  3000 :  0.3710885056257248\n",
      "Epoch:  77  Average loss at step  3222 :  0.38309741383921175\n",
      "77 0 29.410287618637085\n",
      "Training time took 29.52839 seconds to run 1 epoch\n",
      "Epoch:  78  Average loss at step  1000 :  8.38902593231201\n",
      "Epoch:  78  Average loss at step  2000 :  8.768583149909974\n",
      "Epoch:  78  Average loss at step  3000 :  8.191618781089783\n",
      "Epoch:  78  Average loss at step  4000 :  8.121263432502747\n",
      "Epoch:  78  Average loss at step  5000 :  8.503501419067383\n",
      "Epoch:  78  Average loss at step  6000 :  8.444319626808166\n",
      "Epoch:  78  Average loss at step  7000 :  7.93848739862442\n",
      "Epoch:  78  Average loss at step  8000 :  8.2820035238266\n",
      "Epoch:  78  Average loss at step  8472 :  9.18362868428711\n",
      "78 0 20.24301028251648\n",
      "Epoch:  78  Average loss at step  1000 :  1690.6916823120116\n",
      "Epoch:  78  Average loss at step  1491 :  1666.9741805561875\n",
      "78 1 11.71709418296814\n",
      "Epoch:  78  Average loss at step  1000 :  2224.134826904297\n",
      "Epoch:  78  Average loss at step  2000 :  2213.9266162109375\n",
      "Epoch:  78  Average loss at step  2533 :  2219.369156841084\n",
      "78 2 19.97244882583618\n",
      "Epoch:  78  Average loss at step  1000 :  109.58783999633789\n",
      "Epoch:  78  Average loss at step  1227 :  109.11235603167256\n",
      "78 3 12.646225214004517\n",
      "Epoch:  78  Average loss at step  1000 :  44.341417385101316\n",
      "Epoch:  78  Average loss at step  2000 :  44.16999334716797\n",
      "Epoch:  78  Average loss at step  3000 :  43.94600485610962\n",
      "Epoch:  78  Average loss at step  3222 :  44.134282170488724\n",
      "78 4 33.27344799041748\n",
      "78 5 1.6689300537109375e-06\n",
      "Training time took 98.510649 seconds to run 1 epoch\n",
      "Epoch:  79  Average loss at step  1000 :  0.3407807504534721\n",
      "Epoch:  79  Average loss at step  2000 :  0.3435786850452423\n",
      "Epoch:  79  Average loss at step  3000 :  0.36224501305818557\n",
      "Epoch:  79  Average loss at step  3222 :  0.37745115859862766\n",
      "79 0 29.425858974456787\n",
      "Training time took 29.549612 seconds to run 1 epoch\n",
      "Epoch:  80  Average loss at step  1000 :  8.557512421131134\n",
      "Epoch:  80  Average loss at step  2000 :  8.815003367900848\n",
      "Epoch:  80  Average loss at step  3000 :  8.303157733917237\n",
      "Epoch:  80  Average loss at step  4000 :  8.8656476521492\n",
      "Epoch:  80  Average loss at step  5000 :  8.602172694206239\n",
      "Epoch:  80  Average loss at step  6000 :  8.19722964811325\n",
      "Epoch:  80  Average loss at step  7000 :  8.394981055736542\n",
      "Epoch:  80  Average loss at step  8000 :  8.211330051898956\n",
      "Epoch:  80  Average loss at step  8472 :  8.889200998978756\n",
      "80 0 20.39985942840576\n",
      "Epoch:  80  Average loss at step  1000 :  1694.5758172607423\n",
      "Epoch:  80  Average loss at step  1491 :  1678.7125169321491\n",
      "80 1 11.725804328918457\n",
      "Epoch:  80  Average loss at step  1000 :  2244.264469970703\n",
      "Epoch:  80  Average loss at step  2000 :  2217.911963623047\n",
      "Epoch:  80  Average loss at step  2533 :  2228.172446041095\n",
      "80 2 19.91709041595459\n",
      "Epoch:  80  Average loss at step  1000 :  109.15814219665528\n",
      "Epoch:  80  Average loss at step  1227 :  108.40700068503057\n",
      "80 3 12.63245439529419\n",
      "Epoch:  80  Average loss at step  1000 :  43.383176132202145\n",
      "Epoch:  80  Average loss at step  2000 :  43.24534844017029\n",
      "Epoch:  80  Average loss at step  3000 :  43.5085117225647\n",
      "Epoch:  80  Average loss at step  3222 :  43.09442709189155\n",
      "80 4 33.231212854385376\n",
      "80 5 1.430511474609375e-06\n",
      "Training time took 98.568579 seconds to run 1 epoch\n",
      "Mean Rank:  396.18676  of  75000\n",
      "Hits @ 10:  0.62276\n",
      "Hits @ 1:  0.31924\n",
      "Testing time took 164.838184 seconds.\n",
      "\n",
      "Epoch:  81  Average loss at step  1000 :  0.329871537566185\n",
      "Epoch:  81  Average loss at step  2000 :  0.33463917195796966\n",
      "Epoch:  81  Average loss at step  3000 :  0.3552614567279816\n",
      "Epoch:  81  Average loss at step  3222 :  0.36447288558938956\n",
      "81 0 29.48211932182312\n",
      "Training time took 29.592316 seconds to run 1 epoch\n",
      "Epoch:  82  Average loss at step  1000 :  8.78608627986908\n",
      "Epoch:  82  Average loss at step  2000 :  8.268200579166413\n",
      "Epoch:  82  Average loss at step  3000 :  8.041833003520965\n",
      "Epoch:  82  Average loss at step  4000 :  8.69615702342987\n",
      "Epoch:  82  Average loss at step  5000 :  8.212872000217438\n",
      "Epoch:  82  Average loss at step  6000 :  8.464850327968598\n",
      "Epoch:  82  Average loss at step  7000 :  8.061729848861694\n",
      "Epoch:  82  Average loss at step  8000 :  8.354049011707305\n",
      "Epoch:  82  Average loss at step  8472 :  7.843440969692295\n",
      "82 0 21.18662929534912\n",
      "Epoch:  82  Average loss at step  1000 :  1705.2251311645507\n",
      "Epoch:  82  Average loss at step  1491 :  1702.3506627508154\n",
      "82 1 11.765288591384888\n",
      "Epoch:  82  Average loss at step  1000 :  2236.6513278808593\n",
      "Epoch:  82  Average loss at step  2000 :  2223.9579444580077\n",
      "Epoch:  82  Average loss at step  2533 :  2247.766167656065\n",
      "82 2 19.970242738723755\n",
      "Epoch:  82  Average loss at step  1000 :  108.31460361480713\n",
      "Epoch:  82  Average loss at step  1227 :  108.51601735155148\n",
      "82 3 12.534692764282227\n",
      "Epoch:  82  Average loss at step  1000 :  42.8061063747406\n",
      "Epoch:  82  Average loss at step  2000 :  42.6419447517395\n",
      "Epoch:  82  Average loss at step  3000 :  42.72324441146851\n",
      "Epoch:  82  Average loss at step  3222 :  42.34712703668333\n",
      "82 4 33.24609684944153\n",
      "82 5 1.430511474609375e-06\n",
      "Training time took 99.34776 seconds to run 1 epoch\n",
      "Epoch:  83  Average loss at step  1000 :  0.3234728439450264\n",
      "Epoch:  83  Average loss at step  2000 :  0.3254325771331787\n",
      "Epoch:  83  Average loss at step  3000 :  0.345720585167408\n",
      "Epoch:  83  Average loss at step  3222 :  0.3569038341699212\n",
      "83 0 29.40716290473938\n",
      "Training time took 29.5299 seconds to run 1 epoch\n",
      "Epoch:  84  Average loss at step  1000 :  8.377039757728577\n",
      "Epoch:  84  Average loss at step  2000 :  8.343119659900665\n",
      "Epoch:  84  Average loss at step  3000 :  8.16735585975647\n",
      "Epoch:  84  Average loss at step  4000 :  8.316950655460358\n",
      "Epoch:  84  Average loss at step  5000 :  8.393817063808442\n",
      "Epoch:  84  Average loss at step  6000 :  8.529133275508881\n",
      "Epoch:  84  Average loss at step  7000 :  8.199089328765869\n",
      "Epoch:  84  Average loss at step  8000 :  8.426595170497894\n",
      "Epoch:  84  Average loss at step  8472 :  8.362537865059712\n",
      "84 0 21.184255838394165\n",
      "Epoch:  84  Average loss at step  1000 :  1700.2447353515624\n",
      "Epoch:  84  Average loss at step  1491 :  1712.805486346545\n",
      "84 1 11.762476205825806\n",
      "Epoch:  84  Average loss at step  1000 :  2263.202108642578\n",
      "Epoch:  84  Average loss at step  2000 :  2250.141498779297\n",
      "Epoch:  84  Average loss at step  2533 :  2244.6029176121615\n",
      "84 2 19.983598709106445\n",
      "Epoch:  84  Average loss at step  1000 :  106.69858924865723\n",
      "Epoch:  84  Average loss at step  1227 :  105.22417184687757\n",
      "84 3 12.60224175453186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  84  Average loss at step  1000 :  41.80238295936584\n",
      "Epoch:  84  Average loss at step  2000 :  41.899404941558835\n",
      "Epoch:  84  Average loss at step  3000 :  42.01173645210266\n",
      "Epoch:  84  Average loss at step  3222 :  41.77653154626954\n",
      "84 4 33.24375081062317\n",
      "84 5 1.430511474609375e-06\n",
      "Training time took 99.416337 seconds to run 1 epoch\n",
      "Epoch:  85  Average loss at step  1000 :  0.3129846752882004\n",
      "Epoch:  85  Average loss at step  2000 :  0.3163165882229805\n",
      "Epoch:  85  Average loss at step  3000 :  0.33780615985393525\n",
      "Epoch:  85  Average loss at step  3222 :  0.3480546145495966\n",
      "85 0 29.516364812850952\n",
      "Training time took 29.640609 seconds to run 1 epoch\n",
      "Epoch:  86  Average loss at step  1000 :  8.497514934062957\n",
      "Epoch:  86  Average loss at step  2000 :  8.991930854797364\n",
      "Epoch:  86  Average loss at step  3000 :  8.003538615226745\n",
      "Epoch:  86  Average loss at step  4000 :  8.794639449119568\n",
      "Epoch:  86  Average loss at step  5000 :  7.827446303367615\n",
      "Epoch:  86  Average loss at step  6000 :  8.182031919956207\n",
      "Epoch:  86  Average loss at step  7000 :  8.971235927581787\n",
      "Epoch:  86  Average loss at step  8000 :  7.955858305931091\n",
      "Epoch:  86  Average loss at step  8472 :  8.181456698661375\n",
      "86 0 20.44055938720703\n",
      "Epoch:  86  Average loss at step  1000 :  1726.4010497436523\n",
      "Epoch:  86  Average loss at step  1491 :  1702.6474450636101\n",
      "86 1 11.708585739135742\n",
      "Epoch:  86  Average loss at step  1000 :  2272.4090382080076\n",
      "Epoch:  86  Average loss at step  2000 :  2251.838120239258\n",
      "Epoch:  86  Average loss at step  2533 :  2254.5695816749553\n",
      "86 2 19.875983715057373\n",
      "Epoch:  86  Average loss at step  1000 :  106.20547257995605\n",
      "Epoch:  86  Average loss at step  1227 :  105.80378593962831\n",
      "86 3 12.562432527542114\n",
      "Epoch:  86  Average loss at step  1000 :  41.5350387802124\n",
      "Epoch:  86  Average loss at step  2000 :  41.01372139930725\n",
      "Epoch:  86  Average loss at step  3000 :  41.405445755004884\n",
      "Epoch:  86  Average loss at step  3222 :  40.94899184954771\n",
      "86 4 33.238919258117676\n",
      "86 5 9.5367431640625e-07\n",
      "Training time took 98.466752 seconds to run 1 epoch\n",
      "Epoch:  87  Average loss at step  1000 :  0.3077806559801102\n",
      "Epoch:  87  Average loss at step  2000 :  0.310305458843708\n",
      "Epoch:  87  Average loss at step  3000 :  0.329241230070591\n",
      "Epoch:  87  Average loss at step  3222 :  0.3411039688523054\n",
      "87 0 29.496201038360596\n",
      "Training time took 29.614742 seconds to run 1 epoch\n",
      "Epoch:  88  Average loss at step  1000 :  8.566962470054627\n",
      "Epoch:  88  Average loss at step  2000 :  8.235842361927032\n",
      "Epoch:  88  Average loss at step  3000 :  8.334688654899598\n",
      "Epoch:  88  Average loss at step  4000 :  8.118054696559906\n",
      "Epoch:  88  Average loss at step  5000 :  8.723129388809204\n",
      "Epoch:  88  Average loss at step  6000 :  8.599706801891326\n",
      "Epoch:  88  Average loss at step  7000 :  8.199908336162567\n",
      "Epoch:  88  Average loss at step  8000 :  8.511543880939483\n",
      "Epoch:  88  Average loss at step  8472 :  8.197064426231554\n",
      "88 0 20.91932773590088\n",
      "Epoch:  88  Average loss at step  1000 :  1712.667151977539\n",
      "Epoch:  88  Average loss at step  1491 :  1718.5631666287788\n",
      "88 1 11.727623224258423\n",
      "Epoch:  88  Average loss at step  1000 :  2283.4322880859377\n",
      "Epoch:  88  Average loss at step  2000 :  2282.830401489258\n",
      "Epoch:  88  Average loss at step  2533 :  2282.4143035938\n",
      "88 2 19.92301106452942\n",
      "Epoch:  88  Average loss at step  1000 :  105.21746865081788\n",
      "Epoch:  88  Average loss at step  1227 :  105.79350694021993\n",
      "88 3 12.714487075805664\n",
      "Epoch:  88  Average loss at step  1000 :  40.81183773612976\n",
      "Epoch:  88  Average loss at step  2000 :  40.66464021873474\n",
      "Epoch:  88  Average loss at step  3000 :  40.504236360549925\n",
      "Epoch:  88  Average loss at step  3222 :  40.48409636732171\n",
      "88 4 33.36540150642395\n",
      "88 5 1.6689300537109375e-06\n",
      "Training time took 99.295432 seconds to run 1 epoch\n",
      "Epoch:  89  Average loss at step  1000 :  0.30126186323165893\n",
      "Epoch:  89  Average loss at step  2000 :  0.3045278050899506\n",
      "Epoch:  89  Average loss at step  3000 :  0.32533734518289564\n",
      "Epoch:  89  Average loss at step  3222 :  0.33421872362244276\n",
      "89 0 29.450703382492065\n",
      "Training time took 29.568653 seconds to run 1 epoch\n",
      "Epoch:  90  Average loss at step  1000 :  7.623804828643799\n",
      "Epoch:  90  Average loss at step  2000 :  8.335334420680999\n",
      "Epoch:  90  Average loss at step  3000 :  8.758732548713684\n",
      "Epoch:  90  Average loss at step  4000 :  8.060535559654236\n",
      "Epoch:  90  Average loss at step  5000 :  8.528895622730255\n",
      "Epoch:  90  Average loss at step  6000 :  7.871614465713501\n",
      "Epoch:  90  Average loss at step  7000 :  8.075239158153535\n",
      "Epoch:  90  Average loss at step  8000 :  8.036791740417481\n",
      "Epoch:  90  Average loss at step  8472 :  8.499088289782124\n",
      "90 0 20.314011573791504\n",
      "Epoch:  90  Average loss at step  1000 :  1722.8136965942383\n",
      "Epoch:  90  Average loss at step  1491 :  1690.7979943181022\n",
      "90 1 11.722968339920044\n",
      "Epoch:  90  Average loss at step  1000 :  2283.9641337890625\n",
      "Epoch:  90  Average loss at step  2000 :  2274.5808270263674\n",
      "Epoch:  90  Average loss at step  2533 :  2297.0991022438143\n",
      "90 2 19.99451184272766\n",
      "Epoch:  90  Average loss at step  1000 :  104.29314785003662\n",
      "Epoch:  90  Average loss at step  1227 :  102.75956199855689\n",
      "90 3 12.667336463928223\n",
      "Epoch:  90  Average loss at step  1000 :  40.11937169075012\n",
      "Epoch:  90  Average loss at step  2000 :  40.01509340286255\n",
      "Epoch:  90  Average loss at step  3000 :  40.106803718566894\n",
      "Epoch:  90  Average loss at step  3222 :  40.260728478625396\n",
      "90 4 33.16355633735657\n",
      "90 5 1.6689300537109375e-06\n",
      "Training time took 98.498387 seconds to run 1 epoch\n",
      "Mean Rank:  346.86296  of  75000\n",
      "Hits @ 10:  0.66432\n",
      "Hits @ 1:  0.35784\n",
      "Testing time took 164.635107 seconds.\n",
      "\n",
      "Epoch:  91  Average loss at step  1000 :  0.29245837998390195\n",
      "Epoch:  91  Average loss at step  2000 :  0.2974952034950256\n",
      "Epoch:  91  Average loss at step  3000 :  0.31625782984495165\n",
      "Epoch:  91  Average loss at step  3222 :  0.3272490720172978\n",
      "91 0 29.533265829086304\n",
      "Training time took 29.641075 seconds to run 1 epoch\n",
      "Epoch:  92  Average loss at step  1000 :  8.427337295532226\n",
      "Epoch:  92  Average loss at step  2000 :  7.763866582870484\n",
      "Epoch:  92  Average loss at step  3000 :  8.861513292312623\n",
      "Epoch:  92  Average loss at step  4000 :  7.951816487312317\n",
      "Epoch:  92  Average loss at step  5000 :  8.378613985061646\n",
      "Epoch:  92  Average loss at step  6000 :  7.8767155122756956\n",
      "Epoch:  92  Average loss at step  7000 :  8.390816535949707\n",
      "Epoch:  92  Average loss at step  8000 :  8.162511204242707\n",
      "Epoch:  92  Average loss at step  8472 :  8.903546181727304\n",
      "92 0 20.467726469039917\n",
      "Epoch:  92  Average loss at step  1000 :  1736.8796696166992\n",
      "Epoch:  92  Average loss at step  1491 :  1728.350896095007\n",
      "92 1 11.732895374298096\n",
      "Epoch:  92  Average loss at step  1000 :  2301.18125769043\n",
      "Epoch:  92  Average loss at step  2000 :  2298.330223754883\n",
      "Epoch:  92  Average loss at step  2533 :  2288.763296959504\n",
      "92 2 19.98487877845764\n",
      "Epoch:  92  Average loss at step  1000 :  103.40457353973389\n",
      "Epoch:  92  Average loss at step  1227 :  103.01140626895653\n",
      "92 3 12.650614023208618\n",
      "Epoch:  92  Average loss at step  1000 :  39.38465219497681\n",
      "Epoch:  92  Average loss at step  2000 :  39.39382928085327\n",
      "Epoch:  92  Average loss at step  3000 :  39.24203815078735\n",
      "Epoch:  92  Average loss at step  3222 :  39.2679453025249\n",
      "92 4 33.28272771835327\n",
      "92 5 1.430511474609375e-06\n",
      "Training time took 98.761607 seconds to run 1 epoch\n",
      "Epoch:  93  Average loss at step  1000 :  0.28852725863456724\n",
      "Epoch:  93  Average loss at step  2000 :  0.29139174407720564\n",
      "Epoch:  93  Average loss at step  3000 :  0.31051139813661577\n",
      "Epoch:  93  Average loss at step  3222 :  0.3214180555600168\n",
      "93 0 29.4921555519104\n",
      "Training time took 29.61286 seconds to run 1 epoch\n",
      "Epoch:  94  Average loss at step  1000 :  8.748149077892304\n",
      "Epoch:  94  Average loss at step  2000 :  8.03174656677246\n",
      "Epoch:  94  Average loss at step  3000 :  8.142514528274535\n",
      "Epoch:  94  Average loss at step  4000 :  8.33190350818634\n",
      "Epoch:  94  Average loss at step  5000 :  8.453121091842652\n",
      "Epoch:  94  Average loss at step  6000 :  8.637411097049712\n",
      "Epoch:  94  Average loss at step  7000 :  8.239584290504455\n",
      "Epoch:  94  Average loss at step  8000 :  8.434412714004516\n",
      "Epoch:  94  Average loss at step  8472 :  8.337170328603555\n",
      "94 0 20.33168601989746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  94  Average loss at step  1000 :  1730.2767814941406\n",
      "Epoch:  94  Average loss at step  1491 :  1710.448374579322\n",
      "94 1 11.731946468353271\n",
      "Epoch:  94  Average loss at step  1000 :  2308.3221540527343\n",
      "Epoch:  94  Average loss at step  2000 :  2317.975369995117\n",
      "Epoch:  94  Average loss at step  2533 :  2304.7509228300883\n",
      "94 2 19.936076641082764\n",
      "Epoch:  94  Average loss at step  1000 :  103.46602263641357\n",
      "Epoch:  94  Average loss at step  1227 :  102.54002234225459\n",
      "94 3 12.71602988243103\n",
      "Epoch:  94  Average loss at step  1000 :  38.79054611778259\n",
      "Epoch:  94  Average loss at step  2000 :  38.61139418411255\n",
      "Epoch:  94  Average loss at step  3000 :  38.76966621398926\n",
      "Epoch:  94  Average loss at step  3222 :  38.52171653400455\n",
      "94 4 33.12938046455383\n",
      "94 5 1.6689300537109375e-06\n",
      "Training time took 98.483566 seconds to run 1 epoch\n",
      "Epoch:  95  Average loss at step  1000 :  0.2806371155977249\n",
      "Epoch:  95  Average loss at step  2000 :  0.2867062909603119\n",
      "Epoch:  95  Average loss at step  3000 :  0.3035516908764839\n",
      "Epoch:  95  Average loss at step  3222 :  0.31403991521362534\n",
      "95 0 29.48965573310852\n",
      "Training time took 29.61186 seconds to run 1 epoch\n",
      "Epoch:  96  Average loss at step  1000 :  8.264879302024841\n",
      "Epoch:  96  Average loss at step  2000 :  8.348561499595641\n",
      "Epoch:  96  Average loss at step  3000 :  8.456478565692901\n",
      "Epoch:  96  Average loss at step  4000 :  8.217174618721009\n",
      "Epoch:  96  Average loss at step  5000 :  8.201966290473939\n",
      "Epoch:  96  Average loss at step  6000 :  8.422824151039123\n",
      "Epoch:  96  Average loss at step  7000 :  8.69393147945404\n",
      "Epoch:  96  Average loss at step  8000 :  8.209178719520569\n",
      "Epoch:  96  Average loss at step  8472 :  8.37275833251961\n",
      "96 0 20.012892723083496\n",
      "Epoch:  96  Average loss at step  1000 :  1736.9211916503907\n",
      "Epoch:  96  Average loss at step  1491 :  1720.944512808041\n",
      "96 1 11.713634252548218\n",
      "Epoch:  96  Average loss at step  1000 :  2337.8367409667967\n",
      "Epoch:  96  Average loss at step  2000 :  2329.9899438476564\n",
      "Epoch:  96  Average loss at step  2533 :  2344.043727244255\n",
      "96 2 19.969719886779785\n",
      "Epoch:  96  Average loss at step  1000 :  102.26498394012451\n",
      "Epoch:  96  Average loss at step  1227 :  100.41273789143497\n",
      "96 3 12.69406270980835\n",
      "Epoch:  96  Average loss at step  1000 :  38.062921880722044\n",
      "Epoch:  96  Average loss at step  2000 :  37.857191312789915\n",
      "Epoch:  96  Average loss at step  3000 :  37.85150528526306\n",
      "Epoch:  96  Average loss at step  3222 :  38.28409720594906\n",
      "96 4 33.35322380065918\n",
      "96 5 1.430511474609375e-06\n",
      "Training time took 98.388643 seconds to run 1 epoch\n",
      "Epoch:  97  Average loss at step  1000 :  0.2762166638374329\n",
      "Epoch:  97  Average loss at step  2000 :  0.2814300019145012\n",
      "Epoch:  97  Average loss at step  3000 :  0.2979148501753807\n",
      "Epoch:  97  Average loss at step  3222 :  0.3137092135468638\n",
      "97 0 29.364985942840576\n",
      "Training time took 29.492777 seconds to run 1 epoch\n",
      "Epoch:  98  Average loss at step  1000 :  8.615649021148682\n",
      "Epoch:  98  Average loss at step  2000 :  8.47491635274887\n",
      "Epoch:  98  Average loss at step  3000 :  8.326518426895142\n",
      "Epoch:  98  Average loss at step  4000 :  8.704228998184204\n",
      "Epoch:  98  Average loss at step  5000 :  8.283374918460845\n",
      "Epoch:  98  Average loss at step  6000 :  7.968206618309021\n",
      "Epoch:  98  Average loss at step  7000 :  7.896377583026886\n",
      "Epoch:  98  Average loss at step  8000 :  7.738930437088013\n",
      "Epoch:  98  Average loss at step  8472 :  8.196460978597571\n",
      "98 0 20.90513300895691\n",
      "Epoch:  98  Average loss at step  1000 :  1744.4336682739258\n",
      "Epoch:  98  Average loss at step  1491 :  1716.94422119991\n",
      "98 1 11.734774351119995\n",
      "Epoch:  98  Average loss at step  1000 :  2357.5728365478517\n",
      "Epoch:  98  Average loss at step  2000 :  2328.865753051758\n",
      "Epoch:  98  Average loss at step  2533 :  2333.1479639297763\n",
      "98 2 19.946821212768555\n",
      "Epoch:  98  Average loss at step  1000 :  101.16948290252685\n",
      "Epoch:  98  Average loss at step  1227 :  99.82679133727196\n",
      "98 3 12.678514242172241\n",
      "Epoch:  98  Average loss at step  1000 :  37.533046447753904\n",
      "Epoch:  98  Average loss at step  2000 :  37.34806153869629\n",
      "Epoch:  98  Average loss at step  3000 :  37.053037450790406\n",
      "Epoch:  98  Average loss at step  3222 :  37.12995054489827\n",
      "98 4 33.16352987289429\n",
      "98 5 1.1920928955078125e-06\n",
      "Training time took 99.079773 seconds to run 1 epoch\n",
      "Epoch:  99  Average loss at step  1000 :  0.268642129778862\n",
      "Epoch:  99  Average loss at step  2000 :  0.27426065802574157\n",
      "Epoch:  99  Average loss at step  3000 :  0.29281717228889464\n",
      "Epoch:  99  Average loss at step  3222 :  0.30510599167903507\n",
      "99 0 29.45278835296631\n",
      "Training time took 29.570907 seconds to run 1 epoch\n",
      "Epoch:  100  Average loss at step  1000 :  8.591497467517852\n",
      "Epoch:  100  Average loss at step  2000 :  8.430428531169891\n",
      "Epoch:  100  Average loss at step  3000 :  8.627501459598541\n",
      "Epoch:  100  Average loss at step  4000 :  8.215420509815216\n",
      "Epoch:  100  Average loss at step  5000 :  8.215424842834473\n",
      "Epoch:  100  Average loss at step  6000 :  8.762959815502168\n",
      "Epoch:  100  Average loss at step  7000 :  8.701833641052247\n",
      "Epoch:  100  Average loss at step  8000 :  8.660435236930848\n",
      "Epoch:  100  Average loss at step  8472 :  8.92279904714733\n",
      "100 0 21.14499282836914\n",
      "Epoch:  100  Average loss at step  1000 :  1748.0124477539061\n",
      "Epoch:  100  Average loss at step  1491 :  1745.415128900163\n",
      "100 1 11.700101137161255\n",
      "Epoch:  100  Average loss at step  1000 :  2344.9685078125\n",
      "Epoch:  100  Average loss at step  2000 :  2357.8779353027344\n",
      "Epoch:  100  Average loss at step  2533 :  2354.8840612853082\n",
      "100 2 19.88871121406555\n",
      "Epoch:  100  Average loss at step  1000 :  99.43767004394532\n",
      "Epoch:  100  Average loss at step  1227 :  99.14947121345398\n",
      "100 3 12.593469858169556\n",
      "Epoch:  100  Average loss at step  1000 :  36.886938419342044\n",
      "Epoch:  100  Average loss at step  2000 :  36.50982433891296\n",
      "Epoch:  100  Average loss at step  3000 :  36.66139014625549\n",
      "Epoch:  100  Average loss at step  3222 :  36.3768895065382\n",
      "100 4 33.16493582725525\n",
      "100 5 1.6689300537109375e-06\n",
      "Training time took 99.147985 seconds to run 1 epoch\n",
      "Mean Rank:  319.78308  of  75000\n",
      "Hits @ 10:  0.6974\n",
      "Hits @ 1:  0.391\n",
      "Testing time took 164.646947 seconds.\n",
      "\n",
      "Epoch:  101  Average loss at step  1000 :  0.2642269425392151\n",
      "Epoch:  101  Average loss at step  2000 :  0.2694051119685173\n",
      "Epoch:  101  Average loss at step  3000 :  0.28656582564115524\n",
      "Epoch:  101  Average loss at step  3222 :  0.29939650267895257\n",
      "101 0 29.46752166748047\n",
      "Training time took 29.574695 seconds to run 1 epoch\n",
      "Epoch:  102  Average loss at step  1000 :  8.652038267612458\n",
      "Epoch:  102  Average loss at step  2000 :  7.886819302558899\n",
      "Epoch:  102  Average loss at step  3000 :  8.05498848772049\n",
      "Epoch:  102  Average loss at step  4000 :  8.328239649772645\n",
      "Epoch:  102  Average loss at step  5000 :  8.098775564193726\n",
      "Epoch:  102  Average loss at step  6000 :  8.578723798751831\n",
      "Epoch:  102  Average loss at step  7000 :  8.331213491916657\n",
      "Epoch:  102  Average loss at step  8000 :  8.945416722297669\n",
      "Epoch:  102  Average loss at step  8472 :  7.8077547669911604\n",
      "102 0 20.722110986709595\n",
      "Epoch:  102  Average loss at step  1000 :  1764.2173457641602\n",
      "Epoch:  102  Average loss at step  1491 :  1742.5307798305003\n",
      "102 1 11.7296781539917\n",
      "Epoch:  102  Average loss at step  1000 :  2375.3995286865234\n",
      "Epoch:  102  Average loss at step  2000 :  2350.3923697509767\n",
      "Epoch:  102  Average loss at step  2533 :  2347.805701358576\n",
      "102 2 19.968034029006958\n",
      "Epoch:  102  Average loss at step  1000 :  99.36369869995117\n",
      "Epoch:  102  Average loss at step  1227 :  100.03864239356818\n",
      "102 3 12.738670825958252\n",
      "Epoch:  102  Average loss at step  1000 :  36.30212759208679\n",
      "Epoch:  102  Average loss at step  2000 :  35.89001504135132\n",
      "Epoch:  102  Average loss at step  3000 :  36.082857973098754\n",
      "Epoch:  102  Average loss at step  3222 :  35.46852309644857\n",
      "102 4 33.253641843795776\n",
      "102 5 1.430511474609375e-06\n",
      "Training time took 99.059971 seconds to run 1 epoch\n",
      "Epoch:  103  Average loss at step  1000 :  0.2550234788656235\n",
      "Epoch:  103  Average loss at step  2000 :  0.26339379769563676\n",
      "Epoch:  103  Average loss at step  3000 :  0.28339460921287535\n",
      "Epoch:  103  Average loss at step  3222 :  0.2912146613838484\n",
      "103 0 29.524958848953247\n",
      "Training time took 29.648231 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  104  Average loss at step  1000 :  8.80745232772827\n",
      "Epoch:  104  Average loss at step  2000 :  8.677251848220825\n",
      "Epoch:  104  Average loss at step  3000 :  8.24478265428543\n",
      "Epoch:  104  Average loss at step  4000 :  8.519570631980896\n",
      "Epoch:  104  Average loss at step  5000 :  7.6235068106651305\n",
      "Epoch:  104  Average loss at step  6000 :  8.063487167358398\n",
      "Epoch:  104  Average loss at step  7000 :  8.464619517326355\n",
      "Epoch:  104  Average loss at step  8000 :  8.841248543739319\n",
      "Epoch:  104  Average loss at step  8472 :  8.215336882396675\n",
      "104 0 20.58220911026001\n",
      "Epoch:  104  Average loss at step  1000 :  1745.763771484375\n",
      "Epoch:  104  Average loss at step  1491 :  1760.5601808207127\n",
      "104 1 11.762540102005005\n",
      "Epoch:  104  Average loss at step  1000 :  2391.561363647461\n",
      "Epoch:  104  Average loss at step  2000 :  2359.68224609375\n",
      "Epoch:  104  Average loss at step  2533 :  2358.3609314962864\n",
      "104 2 19.980528354644775\n",
      "Epoch:  104  Average loss at step  1000 :  98.67541259765625\n",
      "Epoch:  104  Average loss at step  1227 :  97.48182430966592\n",
      "104 3 12.653501987457275\n",
      "Epoch:  104  Average loss at step  1000 :  35.44269128036499\n",
      "Epoch:  104  Average loss at step  2000 :  35.63472424888611\n",
      "Epoch:  104  Average loss at step  3000 :  35.31014323234558\n",
      "Epoch:  104  Average loss at step  3222 :  35.26408315501202\n",
      "104 4 33.298285245895386\n",
      "104 5 1.6689300537109375e-06\n",
      "Training time took 98.919383 seconds to run 1 epoch\n",
      "Epoch:  105  Average loss at step  1000 :  0.25199637669324876\n",
      "Epoch:  105  Average loss at step  2000 :  0.25721452420949936\n",
      "Epoch:  105  Average loss at step  3000 :  0.27834564661979677\n",
      "Epoch:  105  Average loss at step  3222 :  0.292093771247361\n",
      "105 0 29.46081042289734\n",
      "Training time took 29.580318 seconds to run 1 epoch\n",
      "Epoch:  106  Average loss at step  1000 :  8.513518405914306\n",
      "Epoch:  106  Average loss at step  2000 :  8.50726361131668\n",
      "Epoch:  106  Average loss at step  3000 :  8.771651119232178\n",
      "Epoch:  106  Average loss at step  4000 :  7.643555976867676\n",
      "Epoch:  106  Average loss at step  5000 :  8.66786494398117\n",
      "Epoch:  106  Average loss at step  6000 :  8.379243037223816\n",
      "Epoch:  106  Average loss at step  7000 :  7.939159739017486\n",
      "Epoch:  106  Average loss at step  8000 :  8.819696712017059\n",
      "Epoch:  106  Average loss at step  8472 :  7.723658672086826\n",
      "106 0 21.021865367889404\n",
      "Epoch:  106  Average loss at step  1000 :  1772.809949645996\n",
      "Epoch:  106  Average loss at step  1491 :  1760.5136281024504\n",
      "106 1 11.726349592208862\n",
      "Epoch:  106  Average loss at step  1000 :  2391.470529663086\n",
      "Epoch:  106  Average loss at step  2000 :  2394.2655247802736\n",
      "Epoch:  106  Average loss at step  2533 :  2368.557115324018\n",
      "106 2 19.972501754760742\n",
      "Epoch:  106  Average loss at step  1000 :  97.99469185638428\n",
      "Epoch:  106  Average loss at step  1227 :  96.54544650753643\n",
      "106 3 12.64136815071106\n",
      "Epoch:  106  Average loss at step  1000 :  34.97203610992432\n",
      "Epoch:  106  Average loss at step  2000 :  34.89336092185974\n",
      "Epoch:  106  Average loss at step  3000 :  34.77594622039795\n",
      "Epoch:  106  Average loss at step  3222 :  35.08074567257271\n",
      "106 4 33.146239042282104\n",
      "106 5 1.1920928955078125e-06\n",
      "Training time took 99.144401 seconds to run 1 epoch\n",
      "Epoch:  107  Average loss at step  1000 :  0.248677861392498\n",
      "Epoch:  107  Average loss at step  2000 :  0.25411993759870527\n",
      "Epoch:  107  Average loss at step  3000 :  0.2737961024045944\n",
      "Epoch:  107  Average loss at step  3222 :  0.2840875613493574\n",
      "107 0 29.41756248474121\n",
      "Training time took 29.543724 seconds to run 1 epoch\n",
      "Epoch:  108  Average loss at step  1000 :  8.466900627613068\n",
      "Epoch:  108  Average loss at step  2000 :  8.055986680030824\n",
      "Epoch:  108  Average loss at step  3000 :  8.56052320766449\n",
      "Epoch:  108  Average loss at step  4000 :  8.66558193874359\n",
      "Epoch:  108  Average loss at step  5000 :  8.232861621379852\n",
      "Epoch:  108  Average loss at step  6000 :  8.272505402565002\n",
      "Epoch:  108  Average loss at step  7000 :  8.78697659111023\n",
      "Epoch:  108  Average loss at step  8000 :  8.886950329780579\n",
      "Epoch:  108  Average loss at step  8472 :  8.419617642814337\n",
      "108 0 20.588156938552856\n",
      "Epoch:  108  Average loss at step  1000 :  1766.780900756836\n",
      "Epoch:  108  Average loss at step  1491 :  1763.2961979129534\n",
      "108 1 11.740966081619263\n",
      "Epoch:  108  Average loss at step  1000 :  2394.374811401367\n",
      "Epoch:  108  Average loss at step  2000 :  2400.7332412109376\n",
      "Epoch:  108  Average loss at step  2533 :  2390.306125895106\n",
      "108 2 19.92833685874939\n",
      "Epoch:  108  Average loss at step  1000 :  97.66715902709961\n",
      "Epoch:  108  Average loss at step  1227 :  98.2553887389337\n",
      "108 3 12.683435916900635\n",
      "Epoch:  108  Average loss at step  1000 :  34.538942346572874\n",
      "Epoch:  108  Average loss at step  2000 :  34.17792211151123\n",
      "Epoch:  108  Average loss at step  3000 :  34.48312389945984\n",
      "Epoch:  108  Average loss at step  3222 :  34.09991567370306\n",
      "108 4 33.28773498535156\n",
      "108 5 1.6689300537109375e-06\n",
      "Training time took 98.861149 seconds to run 1 epoch\n",
      "Epoch:  109  Average loss at step  1000 :  0.24360566997528077\n",
      "Epoch:  109  Average loss at step  2000 :  0.24996383392810823\n",
      "Epoch:  109  Average loss at step  3000 :  0.26744810539484026\n",
      "Epoch:  109  Average loss at step  3222 :  0.2790817146504435\n",
      "109 0 29.397023916244507\n",
      "Training time took 29.519572 seconds to run 1 epoch\n",
      "Epoch:  110  Average loss at step  1000 :  8.217411259174346\n",
      "Epoch:  110  Average loss at step  2000 :  8.464617986679077\n",
      "Epoch:  110  Average loss at step  3000 :  8.107771374225617\n",
      "Epoch:  110  Average loss at step  4000 :  8.20109694480896\n",
      "Epoch:  110  Average loss at step  5000 :  8.71963816165924\n",
      "Epoch:  110  Average loss at step  6000 :  8.300250104427338\n",
      "Epoch:  110  Average loss at step  7000 :  8.647984371185302\n",
      "Epoch:  110  Average loss at step  8000 :  7.8791248283386235\n",
      "Epoch:  110  Average loss at step  8472 :  8.3554747837174\n",
      "110 0 20.875314235687256\n",
      "Epoch:  110  Average loss at step  1000 :  1784.4519010009765\n",
      "Epoch:  110  Average loss at step  1491 :  1763.9070854430224\n",
      "110 1 11.71852731704712\n",
      "Epoch:  110  Average loss at step  1000 :  2426.6071311035157\n",
      "Epoch:  110  Average loss at step  2000 :  2390.501772949219\n",
      "Epoch:  110  Average loss at step  2533 :  2416.5646059801766\n",
      "110 2 19.952961444854736\n",
      "Epoch:  110  Average loss at step  1000 :  95.88926119232178\n",
      "Epoch:  110  Average loss at step  1227 :  96.2258106052794\n",
      "110 3 12.634474754333496\n",
      "Epoch:  110  Average loss at step  1000 :  33.783636905670164\n",
      "Epoch:  110  Average loss at step  2000 :  33.806624404907225\n",
      "Epoch:  110  Average loss at step  3000 :  33.75412750053406\n",
      "Epoch:  110  Average loss at step  3222 :  33.63816202235665\n",
      "110 4 33.1076819896698\n",
      "110 5 1.6689300537109375e-06\n",
      "Training time took 98.919181 seconds to run 1 epoch\n",
      "Mean Rank:  299.30484  of  75000\n",
      "Hits @ 10:  0.72072\n",
      "Hits @ 1:  0.42044\n",
      "Testing time took 164.149118 seconds.\n",
      "\n",
      "Epoch:  111  Average loss at step  1000 :  0.23853884482383728\n",
      "Epoch:  111  Average loss at step  2000 :  0.24575805991888047\n",
      "Epoch:  111  Average loss at step  3000 :  0.2623293678760529\n",
      "Epoch:  111  Average loss at step  3222 :  0.2735706758124666\n",
      "111 0 29.432365655899048\n",
      "Training time took 29.541403 seconds to run 1 epoch\n",
      "Epoch:  112  Average loss at step  1000 :  8.437735570907593\n",
      "Epoch:  112  Average loss at step  2000 :  8.705090715885163\n",
      "Epoch:  112  Average loss at step  3000 :  8.22384506702423\n",
      "Epoch:  112  Average loss at step  4000 :  8.228011036872864\n",
      "Epoch:  112  Average loss at step  5000 :  8.373873276233674\n",
      "Epoch:  112  Average loss at step  6000 :  8.536637302398681\n",
      "Epoch:  112  Average loss at step  7000 :  8.245471243858338\n",
      "Epoch:  112  Average loss at step  8000 :  8.346712232112884\n",
      "Epoch:  112  Average loss at step  8472 :  7.3212416881080244\n",
      "112 0 21.246829986572266\n",
      "Epoch:  112  Average loss at step  1000 :  1776.4068643798828\n",
      "Epoch:  112  Average loss at step  1491 :  1768.9322685089555\n",
      "112 1 11.732444524765015\n",
      "Epoch:  112  Average loss at step  1000 :  2440.2093436279297\n",
      "Epoch:  112  Average loss at step  2000 :  2403.8514057617185\n",
      "Epoch:  112  Average loss at step  2533 :  2449.441346267926\n",
      "112 2 19.94360589981079\n",
      "Epoch:  112  Average loss at step  1000 :  95.35333371734619\n",
      "Epoch:  112  Average loss at step  1227 :  95.14702328955296\n",
      "112 3 12.668331623077393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  112  Average loss at step  1000 :  33.396105039596556\n",
      "Epoch:  112  Average loss at step  2000 :  33.00960697746277\n",
      "Epoch:  112  Average loss at step  3000 :  33.12901344108582\n",
      "Epoch:  112  Average loss at step  3222 :  33.413499700267685\n",
      "112 4 33.3538613319397\n",
      "112 5 1.430511474609375e-06\n",
      "Training time took 99.560107 seconds to run 1 epoch\n",
      "Epoch:  113  Average loss at step  1000 :  0.2363579499721527\n",
      "Epoch:  113  Average loss at step  2000 :  0.2416180471777916\n",
      "Epoch:  113  Average loss at step  3000 :  0.2593323412537575\n",
      "Epoch:  113  Average loss at step  3222 :  0.2698414276536782\n",
      "113 0 29.421976566314697\n",
      "Training time took 29.538197 seconds to run 1 epoch\n",
      "Epoch:  114  Average loss at step  1000 :  8.570447140693664\n",
      "Epoch:  114  Average loss at step  2000 :  8.526467880249024\n",
      "Epoch:  114  Average loss at step  3000 :  8.021857045650481\n",
      "Epoch:  114  Average loss at step  4000 :  7.9887067131996155\n",
      "Epoch:  114  Average loss at step  5000 :  8.389758484363556\n",
      "Epoch:  114  Average loss at step  6000 :  8.547190111637116\n",
      "Epoch:  114  Average loss at step  7000 :  7.184687149524689\n",
      "Epoch:  114  Average loss at step  8000 :  8.417465096950531\n",
      "Epoch:  114  Average loss at step  8472 :  8.350539730621373\n",
      "114 0 21.34463906288147\n",
      "Epoch:  114  Average loss at step  1000 :  1776.534944885254\n",
      "Epoch:  114  Average loss at step  1491 :  1798.4692689150725\n",
      "114 1 11.727510690689087\n",
      "Epoch:  114  Average loss at step  1000 :  2438.954630004883\n",
      "Epoch:  114  Average loss at step  2000 :  2407.5061727294924\n",
      "Epoch:  114  Average loss at step  2533 :  2407.038303124736\n",
      "114 2 19.92124843597412\n",
      "Epoch:  114  Average loss at step  1000 :  94.82594692230225\n",
      "Epoch:  114  Average loss at step  1227 :  94.9060995851085\n",
      "114 3 12.856873273849487\n",
      "Epoch:  114  Average loss at step  1000 :  32.482476770401\n",
      "Epoch:  114  Average loss at step  2000 :  33.04957207298279\n",
      "Epoch:  114  Average loss at step  3000 :  32.72750803756714\n",
      "Epoch:  114  Average loss at step  3222 :  32.6943184714344\n",
      "114 4 33.27313709259033\n",
      "114 5 1.430511474609375e-06\n",
      "Training time took 99.770421 seconds to run 1 epoch\n",
      "Epoch:  115  Average loss at step  1000 :  0.22961764341592789\n",
      "Epoch:  115  Average loss at step  2000 :  0.2366449138522148\n",
      "Epoch:  115  Average loss at step  3000 :  0.25573840403556825\n",
      "Epoch:  115  Average loss at step  3222 :  0.26653672054498756\n",
      "115 0 29.432925701141357\n",
      "Training time took 29.553143 seconds to run 1 epoch\n",
      "Epoch:  116  Average loss at step  1000 :  8.29372056913376\n",
      "Epoch:  116  Average loss at step  2000 :  8.27800082874298\n",
      "Epoch:  116  Average loss at step  3000 :  8.133177918434143\n",
      "Epoch:  116  Average loss at step  4000 :  8.70432033109665\n",
      "Epoch:  116  Average loss at step  5000 :  8.189352006435394\n",
      "Epoch:  116  Average loss at step  6000 :  8.360468363761902\n",
      "Epoch:  116  Average loss at step  7000 :  8.170987732410431\n",
      "Epoch:  116  Average loss at step  8000 :  8.367459652900695\n",
      "Epoch:  116  Average loss at step  8472 :  8.2101186291936\n",
      "116 0 20.586066961288452\n",
      "Epoch:  116  Average loss at step  1000 :  1785.9303596801758\n",
      "Epoch:  116  Average loss at step  1491 :  1790.5673445102757\n",
      "116 1 11.718105554580688\n",
      "Epoch:  116  Average loss at step  1000 :  2456.4486892089844\n",
      "Epoch:  116  Average loss at step  2000 :  2425.8324613037107\n",
      "Epoch:  116  Average loss at step  2533 :  2420.363049076423\n",
      "116 2 19.91212034225464\n",
      "Epoch:  116  Average loss at step  1000 :  93.9360065689087\n",
      "Epoch:  116  Average loss at step  1227 :  94.24431768403811\n",
      "116 3 12.657081127166748\n",
      "Epoch:  116  Average loss at step  1000 :  32.28153381919861\n",
      "Epoch:  116  Average loss at step  2000 :  32.20832641601562\n",
      "Epoch:  116  Average loss at step  3000 :  32.12935990524292\n",
      "Epoch:  116  Average loss at step  3222 :  32.0072988285272\n",
      "116 4 33.36049818992615\n",
      "116 5 1.430511474609375e-06\n",
      "Training time took 98.873253 seconds to run 1 epoch\n",
      "Epoch:  117  Average loss at step  1000 :  0.22858720022439957\n",
      "Epoch:  117  Average loss at step  2000 :  0.23364620018005372\n",
      "Epoch:  117  Average loss at step  3000 :  0.25156400418281555\n",
      "Epoch:  117  Average loss at step  3222 :  0.26486282621744545\n",
      "117 0 29.404610633850098\n",
      "Training time took 29.526013 seconds to run 1 epoch\n",
      "Epoch:  118  Average loss at step  1000 :  8.487684692382812\n",
      "Epoch:  118  Average loss at step  2000 :  8.139535817146301\n",
      "Epoch:  118  Average loss at step  3000 :  8.147326902389526\n",
      "Epoch:  118  Average loss at step  4000 :  8.422381261825562\n",
      "Epoch:  118  Average loss at step  5000 :  8.364345541000366\n",
      "Epoch:  118  Average loss at step  6000 :  8.174172176361084\n",
      "Epoch:  118  Average loss at step  7000 :  8.408823674678802\n",
      "Epoch:  118  Average loss at step  8000 :  8.670061041355133\n",
      "Epoch:  118  Average loss at step  8472 :  8.932813868084077\n",
      "118 0 20.707401752471924\n",
      "Epoch:  118  Average loss at step  1000 :  1798.172167175293\n",
      "Epoch:  118  Average loss at step  1491 :  1799.8782014632145\n",
      "118 1 11.725084066390991\n",
      "Epoch:  118  Average loss at step  1000 :  2465.586983886719\n",
      "Epoch:  118  Average loss at step  2000 :  2466.810827758789\n",
      "Epoch:  118  Average loss at step  2533 :  2443.7063487244745\n",
      "118 2 19.888429164886475\n",
      "Epoch:  118  Average loss at step  1000 :  93.24294631195069\n",
      "Epoch:  118  Average loss at step  1227 :  92.04778716283025\n",
      "118 3 12.631662368774414\n",
      "Epoch:  118  Average loss at step  1000 :  31.75372359085083\n",
      "Epoch:  118  Average loss at step  2000 :  31.490669511795044\n",
      "Epoch:  118  Average loss at step  3000 :  31.517257360458373\n",
      "Epoch:  118  Average loss at step  3222 :  31.21915061587051\n",
      "118 4 33.232348680496216\n",
      "118 5 1.1920928955078125e-06\n",
      "Training time took 98.825444 seconds to run 1 epoch\n",
      "Epoch:  119  Average loss at step  1000 :  0.22366594696044922\n",
      "Epoch:  119  Average loss at step  2000 :  0.2302820613384247\n",
      "Epoch:  119  Average loss at step  3000 :  0.2468038830757141\n",
      "Epoch:  119  Average loss at step  3222 :  0.25745431295175547\n",
      "119 0 29.401660919189453\n",
      "Training time took 29.521838 seconds to run 1 epoch\n",
      "Epoch:  120  Average loss at step  1000 :  8.346464385986328\n",
      "Epoch:  120  Average loss at step  2000 :  8.37133060836792\n",
      "Epoch:  120  Average loss at step  3000 :  8.18268968820572\n",
      "Epoch:  120  Average loss at step  4000 :  8.528358264923096\n",
      "Epoch:  120  Average loss at step  5000 :  8.0897024102211\n",
      "Epoch:  120  Average loss at step  6000 :  8.367368050098419\n",
      "Epoch:  120  Average loss at step  7000 :  8.65358821105957\n",
      "Epoch:  120  Average loss at step  8000 :  8.01419106388092\n",
      "Epoch:  120  Average loss at step  8472 :  7.9635998656392415\n",
      "120 0 20.85948896408081\n",
      "Epoch:  120  Average loss at step  1000 :  1802.0869293823241\n",
      "Epoch:  120  Average loss at step  1491 :  1801.8300706505463\n",
      "120 1 11.72651219367981\n",
      "Epoch:  120  Average loss at step  1000 :  2455.69979296875\n",
      "Epoch:  120  Average loss at step  2000 :  2447.7375483398437\n",
      "Epoch:  120  Average loss at step  2533 :  2438.3850416563396\n",
      "120 2 19.971789121627808\n",
      "Epoch:  120  Average loss at step  1000 :  92.92251428222656\n",
      "Epoch:  120  Average loss at step  1227 :  92.65439811064\n",
      "120 3 12.608818054199219\n",
      "Epoch:  120  Average loss at step  1000 :  31.348586263656617\n",
      "Epoch:  120  Average loss at step  2000 :  31.164601402282713\n",
      "Epoch:  120  Average loss at step  3000 :  30.869217073440552\n",
      "Epoch:  120  Average loss at step  3222 :  31.091212012488437\n",
      "120 4 33.2401385307312\n",
      "120 5 1.430511474609375e-06\n",
      "Training time took 99.041228 seconds to run 1 epoch\n",
      "Mean Rank:  285.49148  of  75000\n",
      "Hits @ 10:  0.7412\n",
      "Hits @ 1:  0.44412\n",
      "Testing time took 164.862495 seconds.\n",
      "\n",
      "Epoch:  121  Average loss at step  1000 :  0.2183932322859764\n",
      "Epoch:  121  Average loss at step  2000 :  0.22593602502346039\n",
      "Epoch:  121  Average loss at step  3000 :  0.2439351664185524\n",
      "Epoch:  121  Average loss at step  3222 :  0.25392224167115984\n",
      "121 0 29.501952171325684\n",
      "Training time took 29.610899 seconds to run 1 epoch\n",
      "Epoch:  122  Average loss at step  1000 :  8.761743768692016\n",
      "Epoch:  122  Average loss at step  2000 :  8.082038900852204\n",
      "Epoch:  122  Average loss at step  3000 :  7.959258469581604\n",
      "Epoch:  122  Average loss at step  4000 :  7.872675856590271\n",
      "Epoch:  122  Average loss at step  5000 :  8.344558847427368\n",
      "Epoch:  122  Average loss at step  6000 :  7.872803050994873\n",
      "Epoch:  122  Average loss at step  7000 :  7.445157017707825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  122  Average loss at step  8000 :  8.478572371006011\n",
      "Epoch:  122  Average loss at step  8472 :  8.35844195712266\n",
      "122 0 20.508176565170288\n",
      "Epoch:  122  Average loss at step  1000 :  1813.7929674682616\n",
      "Epoch:  122  Average loss at step  1491 :  1794.2206195583192\n",
      "122 1 11.682126522064209\n",
      "Epoch:  122  Average loss at step  1000 :  2481.619700317383\n",
      "Epoch:  122  Average loss at step  2000 :  2467.1038834228516\n",
      "Epoch:  122  Average loss at step  2533 :  2488.070695803443\n",
      "122 2 19.941115856170654\n",
      "Epoch:  122  Average loss at step  1000 :  91.99378532028199\n",
      "Epoch:  122  Average loss at step  1227 :  93.54114058725929\n",
      "122 3 12.705919742584229\n",
      "Epoch:  122  Average loss at step  1000 :  30.46735675621033\n",
      "Epoch:  122  Average loss at step  2000 :  30.519255186080933\n",
      "Epoch:  122  Average loss at step  3000 :  30.143694597244263\n",
      "Epoch:  122  Average loss at step  3222 :  30.87120083700257\n",
      "122 4 33.2691376209259\n",
      "122 5 1.6689300537109375e-06\n",
      "Training time took 98.744833 seconds to run 1 epoch\n",
      "Epoch:  123  Average loss at step  1000 :  0.21796192634105682\n",
      "Epoch:  123  Average loss at step  2000 :  0.22391953003406526\n",
      "Epoch:  123  Average loss at step  3000 :  0.24062871116399764\n",
      "Epoch:  123  Average loss at step  3222 :  0.2505483790777461\n",
      "123 0 29.396665334701538\n",
      "Training time took 29.516255 seconds to run 1 epoch\n",
      "Epoch:  124  Average loss at step  1000 :  8.610946074008941\n",
      "Epoch:  124  Average loss at step  2000 :  8.101897561073303\n",
      "Epoch:  124  Average loss at step  3000 :  7.941438555717468\n",
      "Epoch:  124  Average loss at step  4000 :  8.494292616367341\n",
      "Epoch:  124  Average loss at step  5000 :  8.22569780778885\n",
      "Epoch:  124  Average loss at step  6000 :  8.301793328285218\n",
      "Epoch:  124  Average loss at step  7000 :  7.826385255813599\n",
      "Epoch:  124  Average loss at step  8000 :  8.086852162361145\n",
      "Epoch:  124  Average loss at step  8472 :  8.596197203137535\n",
      "124 0 20.54942035675049\n",
      "Epoch:  124  Average loss at step  1000 :  1818.044693359375\n",
      "Epoch:  124  Average loss at step  1491 :  1783.7393889610662\n",
      "124 1 11.730839490890503\n",
      "Epoch:  124  Average loss at step  1000 :  2457.9213162841797\n",
      "Epoch:  124  Average loss at step  2000 :  2470.6555599365233\n",
      "Epoch:  124  Average loss at step  2533 :  2494.793341426264\n",
      "124 2 19.933704376220703\n",
      "Epoch:  124  Average loss at step  1000 :  91.24928908538818\n",
      "Epoch:  124  Average loss at step  1227 :  91.29107266555378\n",
      "124 3 12.655223369598389\n",
      "Epoch:  124  Average loss at step  1000 :  30.068747142791747\n",
      "Epoch:  124  Average loss at step  2000 :  29.92315889930725\n",
      "Epoch:  124  Average loss at step  3000 :  30.436311611175537\n",
      "Epoch:  124  Average loss at step  3222 :  30.46106013779951\n",
      "124 4 33.09471416473389\n",
      "124 5 1.6689300537109375e-06\n",
      "Training time took 98.592089 seconds to run 1 epoch\n",
      "Epoch:  125  Average loss at step  1000 :  0.21205551999807357\n",
      "Epoch:  125  Average loss at step  2000 :  0.22013293528556824\n",
      "Epoch:  125  Average loss at step  3000 :  0.23644930523633956\n",
      "Epoch:  125  Average loss at step  3222 :  0.24579532295169546\n",
      "125 0 29.42806100845337\n",
      "Training time took 29.559935 seconds to run 1 epoch\n",
      "Epoch:  126  Average loss at step  1000 :  8.563288106918336\n",
      "Epoch:  126  Average loss at step  2000 :  8.031766068935394\n",
      "Epoch:  126  Average loss at step  3000 :  8.23864931869507\n",
      "Epoch:  126  Average loss at step  4000 :  8.439088810443879\n",
      "Epoch:  126  Average loss at step  5000 :  7.844427241802215\n",
      "Epoch:  126  Average loss at step  6000 :  8.14923718547821\n",
      "Epoch:  126  Average loss at step  7000 :  8.726745756149292\n",
      "Epoch:  126  Average loss at step  8000 :  8.044966669082642\n",
      "Epoch:  126  Average loss at step  8472 :  7.716687960867758\n",
      "126 0 20.8698787689209\n",
      "Epoch:  126  Average loss at step  1000 :  1810.8087665405274\n",
      "Epoch:  126  Average loss at step  1491 :  1805.7769219033662\n",
      "126 1 11.727402210235596\n",
      "Epoch:  126  Average loss at step  1000 :  2491.7622467041015\n",
      "Epoch:  126  Average loss at step  2000 :  2491.457578979492\n",
      "Epoch:  126  Average loss at step  2533 :  2498.005155292269\n",
      "126 2 19.924766540527344\n",
      "Epoch:  126  Average loss at step  1000 :  91.25688724517822\n",
      "Epoch:  126  Average loss at step  1227 :  90.03895011393948\n",
      "126 3 12.630993127822876\n",
      "Epoch:  126  Average loss at step  1000 :  29.473961055755616\n",
      "Epoch:  126  Average loss at step  2000 :  29.441788318634032\n",
      "Epoch:  126  Average loss at step  3000 :  29.350231439590456\n",
      "Epoch:  126  Average loss at step  3222 :  29.897712830452093\n",
      "126 4 33.30450963973999\n",
      "126 5 1.430511474609375e-06\n",
      "Training time took 99.101564 seconds to run 1 epoch\n",
      "Epoch:  127  Average loss at step  1000 :  0.21026902079582213\n",
      "Epoch:  127  Average loss at step  2000 :  0.21815279906988144\n",
      "Epoch:  127  Average loss at step  3000 :  0.23277305448055266\n",
      "Epoch:  127  Average loss at step  3222 :  0.24092033448945013\n",
      "127 0 29.42932939529419\n",
      "Training time took 29.552303 seconds to run 1 epoch\n",
      "Epoch:  128  Average loss at step  1000 :  8.329384380340576\n",
      "Epoch:  128  Average loss at step  2000 :  8.428165058135987\n",
      "Epoch:  128  Average loss at step  3000 :  8.137792964458466\n",
      "Epoch:  128  Average loss at step  4000 :  8.454860685825349\n",
      "Epoch:  128  Average loss at step  5000 :  8.029517990589142\n",
      "Epoch:  128  Average loss at step  6000 :  8.12005652141571\n",
      "Epoch:  128  Average loss at step  7000 :  8.18870719242096\n",
      "Epoch:  128  Average loss at step  8000 :  8.171290357589722\n",
      "Epoch:  128  Average loss at step  8472 :  8.292466556624683\n",
      "128 0 20.935936212539673\n",
      "Epoch:  128  Average loss at step  1000 :  1821.312039428711\n",
      "Epoch:  128  Average loss at step  1491 :  1814.8195835940523\n",
      "128 1 11.724762916564941\n",
      "Epoch:  128  Average loss at step  1000 :  2496.4874512939455\n",
      "Epoch:  128  Average loss at step  2000 :  2493.426750854492\n",
      "Epoch:  128  Average loss at step  2533 :  2491.4640607526644\n",
      "128 2 19.907087564468384\n",
      "Epoch:  128  Average loss at step  1000 :  90.1231268081665\n",
      "Epoch:  128  Average loss at step  1227 :  90.48118845431013\n",
      "128 3 12.658060073852539\n",
      "Epoch:  128  Average loss at step  1000 :  29.0217285861969\n",
      "Epoch:  128  Average loss at step  2000 :  29.288808280944824\n",
      "Epoch:  128  Average loss at step  3000 :  29.140322359085083\n",
      "Epoch:  128  Average loss at step  3222 :  29.1592781585484\n",
      "128 4 33.29951620101929\n",
      "128 5 1.430511474609375e-06\n",
      "Training time took 99.187372 seconds to run 1 epoch\n",
      "Epoch:  129  Average loss at step  1000 :  0.20647122567892073\n",
      "Epoch:  129  Average loss at step  2000 :  0.21343611687421798\n",
      "Epoch:  129  Average loss at step  3000 :  0.23050642716884612\n",
      "Epoch:  129  Average loss at step  3222 :  0.23829560430283622\n",
      "129 0 29.39331889152527\n",
      "Training time took 29.514314 seconds to run 1 epoch\n",
      "Epoch:  130  Average loss at step  1000 :  8.036639248371124\n",
      "Epoch:  130  Average loss at step  2000 :  8.59938900232315\n",
      "Epoch:  130  Average loss at step  3000 :  8.61527928161621\n",
      "Epoch:  130  Average loss at step  4000 :  8.518445223808289\n",
      "Epoch:  130  Average loss at step  5000 :  7.872110136985778\n",
      "Epoch:  130  Average loss at step  6000 :  8.006020318984985\n",
      "Epoch:  130  Average loss at step  7000 :  8.166957970619201\n",
      "Epoch:  130  Average loss at step  8000 :  8.693682650566101\n",
      "Epoch:  130  Average loss at step  8472 :  8.133821312162134\n",
      "130 0 21.05374574661255\n",
      "Epoch:  130  Average loss at step  1000 :  1818.5478977050782\n",
      "Epoch:  130  Average loss at step  1491 :  1830.119504903918\n",
      "130 1 11.711772441864014\n",
      "Epoch:  130  Average loss at step  1000 :  2499.892648803711\n",
      "Epoch:  130  Average loss at step  2000 :  2481.363955810547\n",
      "Epoch:  130  Average loss at step  2533 :  2495.6537434908073\n",
      "130 2 19.90229630470276\n",
      "Epoch:  130  Average loss at step  1000 :  90.11158364868164\n",
      "Epoch:  130  Average loss at step  1227 :  90.6809882176918\n",
      "130 3 12.67012071609497\n",
      "Epoch:  130  Average loss at step  1000 :  28.405766471862794\n",
      "Epoch:  130  Average loss at step  2000 :  28.227609743118286\n",
      "Epoch:  130  Average loss at step  3000 :  28.43630097103119\n",
      "Epoch:  130  Average loss at step  3222 :  28.448089862003247\n",
      "130 4 33.401758909225464\n",
      "130 5 1.6689300537109375e-06\n",
      "Training time took 99.374656 seconds to run 1 epoch\n",
      "Mean Rank:  270.60804  of  75000\n",
      "Hits @ 10:  0.75692\n",
      "Hits @ 1:  0.4632\n",
      "Testing time took 164.356435 seconds.\n",
      "\n",
      "Epoch:  131  Average loss at step  1000 :  0.20364188152551652\n",
      "Epoch:  131  Average loss at step  2000 :  0.20919737273454667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  131  Average loss at step  3000 :  0.22686496162414552\n",
      "Epoch:  131  Average loss at step  3222 :  0.23782971851617812\n",
      "131 0 29.40433120727539\n",
      "Training time took 29.513862 seconds to run 1 epoch\n",
      "Epoch:  132  Average loss at step  1000 :  8.108074831962586\n",
      "Epoch:  132  Average loss at step  2000 :  7.867465692520142\n",
      "Epoch:  132  Average loss at step  3000 :  8.24627782011032\n",
      "Epoch:  132  Average loss at step  4000 :  8.479448445320129\n",
      "Epoch:  132  Average loss at step  5000 :  8.065623150348664\n",
      "Epoch:  132  Average loss at step  6000 :  8.056485281944274\n",
      "Epoch:  132  Average loss at step  7000 :  8.248070348739624\n",
      "Epoch:  132  Average loss at step  8000 :  8.13884912776947\n",
      "Epoch:  132  Average loss at step  8472 :  8.919062317341071\n",
      "132 0 20.98645305633545\n",
      "Epoch:  132  Average loss at step  1000 :  1836.8332070922852\n",
      "Epoch:  132  Average loss at step  1491 :  1826.2465377315598\n",
      "132 1 11.733639001846313\n",
      "Epoch:  132  Average loss at step  1000 :  2524.448421142578\n",
      "Epoch:  132  Average loss at step  2000 :  2510.204421875\n",
      "Epoch:  132  Average loss at step  2533 :  2492.142543728915\n",
      "132 2 19.9686496257782\n",
      "Epoch:  132  Average loss at step  1000 :  89.05650227355957\n",
      "Epoch:  132  Average loss at step  1227 :  88.3184502067672\n",
      "132 3 12.555814266204834\n",
      "Epoch:  132  Average loss at step  1000 :  28.10277670097351\n",
      "Epoch:  132  Average loss at step  2000 :  28.15059671974182\n",
      "Epoch:  132  Average loss at step  3000 :  27.925336599349976\n",
      "Epoch:  132  Average loss at step  3222 :  28.273913489715525\n",
      "132 4 33.165555477142334\n",
      "132 5 1.6689300537109375e-06\n",
      "Training time took 99.050133 seconds to run 1 epoch\n",
      "Epoch:  133  Average loss at step  1000 :  0.20065480542182923\n",
      "Epoch:  133  Average loss at step  2000 :  0.20709349435567856\n",
      "Epoch:  133  Average loss at step  3000 :  0.22357707643508912\n",
      "Epoch:  133  Average loss at step  3222 :  0.23604806288632918\n",
      "133 0 29.455721139907837\n",
      "Training time took 29.576273 seconds to run 1 epoch\n",
      "Epoch:  134  Average loss at step  1000 :  8.554503007411956\n",
      "Epoch:  134  Average loss at step  2000 :  8.411013126850127\n",
      "Epoch:  134  Average loss at step  3000 :  8.257664350509643\n",
      "Epoch:  134  Average loss at step  4000 :  7.983664844989777\n",
      "Epoch:  134  Average loss at step  5000 :  8.06498930978775\n",
      "Epoch:  134  Average loss at step  6000 :  8.053263854026794\n",
      "Epoch:  134  Average loss at step  7000 :  8.208442489624023\n",
      "Epoch:  134  Average loss at step  8000 :  8.016202407836914\n",
      "Epoch:  134  Average loss at step  8472 :  8.103497251681675\n",
      "134 0 20.502061367034912\n",
      "Epoch:  134  Average loss at step  1000 :  1822.2039768066406\n",
      "Epoch:  134  Average loss at step  1491 :  1857.7020490317404\n",
      "134 1 11.750586032867432\n",
      "Epoch:  134  Average loss at step  1000 :  2532.6454732666016\n",
      "Epoch:  134  Average loss at step  2000 :  2534.7416538085936\n",
      "Epoch:  134  Average loss at step  2533 :  2508.1952518938774\n",
      "134 2 19.914093255996704\n",
      "Epoch:  134  Average loss at step  1000 :  88.69631184005738\n",
      "Epoch:  134  Average loss at step  1227 :  87.26043751659773\n",
      "134 3 12.617435693740845\n",
      "Epoch:  134  Average loss at step  1000 :  27.485592646598818\n",
      "Epoch:  134  Average loss at step  2000 :  27.518871355056763\n",
      "Epoch:  134  Average loss at step  3000 :  27.4282799282074\n",
      "Epoch:  134  Average loss at step  3222 :  27.19868668409693\n",
      "134 4 33.1834659576416\n",
      "134 5 1.430511474609375e-06\n",
      "Training time took 98.619937 seconds to run 1 epoch\n",
      "Epoch:  135  Average loss at step  1000 :  0.19730977177619935\n",
      "Epoch:  135  Average loss at step  2000 :  0.20394683474302291\n",
      "Epoch:  135  Average loss at step  3000 :  0.22056958770751953\n",
      "Epoch:  135  Average loss at step  3222 :  0.232835944743982\n",
      "135 0 29.402259826660156\n",
      "Training time took 29.522287 seconds to run 1 epoch\n",
      "Epoch:  136  Average loss at step  1000 :  8.722895230293274\n",
      "Epoch:  136  Average loss at step  2000 :  8.199336086273194\n",
      "Epoch:  136  Average loss at step  3000 :  8.144275104522706\n",
      "Epoch:  136  Average loss at step  4000 :  8.05427091741562\n",
      "Epoch:  136  Average loss at step  5000 :  8.42271036529541\n",
      "Epoch:  136  Average loss at step  6000 :  8.314077826976776\n",
      "Epoch:  136  Average loss at step  7000 :  8.785722315788268\n",
      "Epoch:  136  Average loss at step  8000 :  8.549938115119934\n",
      "Epoch:  136  Average loss at step  8472 :  8.41805429249353\n",
      "136 0 21.07016658782959\n",
      "Epoch:  136  Average loss at step  1000 :  1814.311279296875\n",
      "Epoch:  136  Average loss at step  1491 :  1827.2463856664583\n",
      "136 1 11.769155025482178\n",
      "Epoch:  136  Average loss at step  1000 :  2550.5156513671873\n",
      "Epoch:  136  Average loss at step  2000 :  2535.2755635986327\n",
      "Epoch:  136  Average loss at step  2533 :  2521.965075207757\n",
      "136 2 19.883206367492676\n",
      "Epoch:  136  Average loss at step  1000 :  88.56866371536255\n",
      "Epoch:  136  Average loss at step  1227 :  88.49186827646606\n",
      "136 3 12.444017887115479\n",
      "Epoch:  136  Average loss at step  1000 :  27.037041200637816\n",
      "Epoch:  136  Average loss at step  2000 :  27.162314847946167\n",
      "Epoch:  136  Average loss at step  3000 :  26.982327549934386\n",
      "Epoch:  136  Average loss at step  3222 :  27.106860295640235\n",
      "136 4 33.20355939865112\n",
      "136 5 1.430511474609375e-06\n",
      "Training time took 99.004328 seconds to run 1 epoch\n",
      "Epoch:  137  Average loss at step  1000 :  0.19571866899728774\n",
      "Epoch:  137  Average loss at step  2000 :  0.20150256192684174\n",
      "Epoch:  137  Average loss at step  3000 :  0.2177228792309761\n",
      "Epoch:  137  Average loss at step  3222 :  0.22596035796310265\n",
      "137 0 29.453652143478394\n",
      "Training time took 29.575763 seconds to run 1 epoch\n",
      "Epoch:  138  Average loss at step  1000 :  8.149714909553527\n",
      "Epoch:  138  Average loss at step  2000 :  8.129829682826996\n",
      "Epoch:  138  Average loss at step  3000 :  8.560238692760468\n",
      "Epoch:  138  Average loss at step  4000 :  8.912395525455475\n",
      "Epoch:  138  Average loss at step  5000 :  8.23465814781189\n",
      "Epoch:  138  Average loss at step  6000 :  7.997431668281555\n",
      "Epoch:  138  Average loss at step  7000 :  8.52258057641983\n",
      "Epoch:  138  Average loss at step  8000 :  7.91031867313385\n",
      "Epoch:  138  Average loss at step  8472 :  7.751553893762221\n",
      "138 0 20.728516578674316\n",
      "Epoch:  138  Average loss at step  1000 :  1845.148298461914\n",
      "Epoch:  138  Average loss at step  1491 :  1849.1489508850707\n",
      "138 1 11.729608297348022\n",
      "Epoch:  138  Average loss at step  1000 :  2552.003066040039\n",
      "Epoch:  138  Average loss at step  2000 :  2518.36465246582\n",
      "Epoch:  138  Average loss at step  2533 :  2516.176567340047\n",
      "138 2 19.953830003738403\n",
      "Epoch:  138  Average loss at step  1000 :  87.12448733139038\n",
      "Epoch:  138  Average loss at step  1227 :  86.38102031224258\n",
      "138 3 12.59113097190857\n",
      "Epoch:  138  Average loss at step  1000 :  26.58640984249115\n",
      "Epoch:  138  Average loss at step  2000 :  26.843013095855714\n",
      "Epoch:  138  Average loss at step  3000 :  26.751390830039977\n",
      "Epoch:  138  Average loss at step  3222 :  26.50523002364184\n",
      "138 4 33.19310116767883\n",
      "138 5 1.6689300537109375e-06\n",
      "Training time took 98.844672 seconds to run 1 epoch\n",
      "Epoch:  139  Average loss at step  1000 :  0.1917567299604416\n",
      "Epoch:  139  Average loss at step  2000 :  0.19944851505756378\n",
      "Epoch:  139  Average loss at step  3000 :  0.21575411355495452\n",
      "Epoch:  139  Average loss at step  3222 :  0.22479279589235493\n",
      "139 0 29.416419982910156\n",
      "Training time took 29.535899 seconds to run 1 epoch\n",
      "Epoch:  140  Average loss at step  1000 :  8.378701544761658\n",
      "Epoch:  140  Average loss at step  2000 :  8.079803847312927\n",
      "Epoch:  140  Average loss at step  3000 :  7.340970923423767\n",
      "Epoch:  140  Average loss at step  4000 :  8.177030847549439\n",
      "Epoch:  140  Average loss at step  5000 :  8.513556085586547\n",
      "Epoch:  140  Average loss at step  6000 :  8.00916950750351\n",
      "Epoch:  140  Average loss at step  7000 :  8.404312170028687\n",
      "Epoch:  140  Average loss at step  8000 :  7.764118310928345\n",
      "Epoch:  140  Average loss at step  8472 :  8.133433224475777\n",
      "140 0 20.310712337493896\n",
      "Epoch:  140  Average loss at step  1000 :  1860.6862911376952\n",
      "Epoch:  140  Average loss at step  1491 :  1828.6739368402589\n",
      "140 1 11.70992374420166\n",
      "Epoch:  140  Average loss at step  1000 :  2561.4176680908204\n",
      "Epoch:  140  Average loss at step  2000 :  2552.358196777344\n",
      "Epoch:  140  Average loss at step  2533 :  2525.489326990113\n",
      "140 2 19.903404474258423\n",
      "Epoch:  140  Average loss at step  1000 :  87.25081607055664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  140  Average loss at step  1227 :  85.86977529826581\n",
      "140 3 12.61327600479126\n",
      "Epoch:  140  Average loss at step  1000 :  26.417583713531496\n",
      "Epoch:  140  Average loss at step  2000 :  26.304876415252686\n",
      "Epoch:  140  Average loss at step  3000 :  26.091435933113097\n",
      "Epoch:  140  Average loss at step  3222 :  26.51836275946773\n",
      "140 4 33.06944513320923\n",
      "140 5 1.430511474609375e-06\n",
      "Training time took 98.250108 seconds to run 1 epoch\n",
      "Mean Rank:  259.4476  of  75000\n",
      "Hits @ 10:  0.76728\n",
      "Hits @ 1:  0.47956\n",
      "Testing time took 164.723402 seconds.\n",
      "\n",
      "Epoch:  141  Average loss at step  1000 :  0.18995323634147643\n",
      "Epoch:  141  Average loss at step  2000 :  0.1963728979229927\n",
      "Epoch:  141  Average loss at step  3000 :  0.21252084910869598\n",
      "Epoch:  141  Average loss at step  3222 :  0.22165571326145433\n",
      "141 0 29.518835067749023\n",
      "Training time took 29.626256 seconds to run 1 epoch\n",
      "Epoch:  142  Average loss at step  1000 :  8.088482316970826\n",
      "Epoch:  142  Average loss at step  2000 :  8.274343930244445\n",
      "Epoch:  142  Average loss at step  3000 :  8.252780970573426\n",
      "Epoch:  142  Average loss at step  4000 :  8.484202951908111\n",
      "Epoch:  142  Average loss at step  5000 :  8.258445816993714\n",
      "Epoch:  142  Average loss at step  6000 :  8.178215980529785\n",
      "Epoch:  142  Average loss at step  7000 :  8.5573008146286\n",
      "Epoch:  142  Average loss at step  8000 :  8.401730338573456\n",
      "Epoch:  142  Average loss at step  8472 :  8.58769204710554\n",
      "142 0 20.69014859199524\n",
      "Epoch:  142  Average loss at step  1000 :  1849.3905643920898\n",
      "Epoch:  142  Average loss at step  1491 :  1856.7878977234932\n",
      "142 1 11.708628416061401\n",
      "Epoch:  142  Average loss at step  1000 :  2567.0343079833983\n",
      "Epoch:  142  Average loss at step  2000 :  2541.990560913086\n",
      "Epoch:  142  Average loss at step  2533 :  2522.408010844642\n",
      "142 2 19.91165852546692\n",
      "Epoch:  142  Average loss at step  1000 :  86.75005254364014\n",
      "Epoch:  142  Average loss at step  1227 :  85.74885202031618\n",
      "142 3 12.668134689331055\n",
      "Epoch:  142  Average loss at step  1000 :  25.912095699310303\n",
      "Epoch:  142  Average loss at step  2000 :  25.969560781478883\n",
      "Epoch:  142  Average loss at step  3000 :  25.61472114467621\n",
      "Epoch:  142  Average loss at step  3222 :  25.986736538307312\n",
      "142 4 33.112929821014404\n",
      "142 5 1.6689300537109375e-06\n",
      "Training time took 98.742629 seconds to run 1 epoch\n",
      "Epoch:  143  Average loss at step  1000 :  0.18744880849123002\n",
      "Epoch:  143  Average loss at step  2000 :  0.19388154298067092\n",
      "Epoch:  143  Average loss at step  3000 :  0.21029939150810242\n",
      "Epoch:  143  Average loss at step  3222 :  0.2167023606712712\n",
      "143 0 29.475035429000854\n",
      "Training time took 29.588641 seconds to run 1 epoch\n",
      "Epoch:  144  Average loss at step  1000 :  8.645065051078797\n",
      "Epoch:  144  Average loss at step  2000 :  8.045530458927155\n",
      "Epoch:  144  Average loss at step  3000 :  8.340994859695435\n",
      "Epoch:  144  Average loss at step  4000 :  8.29825905752182\n",
      "Epoch:  144  Average loss at step  5000 :  7.923312890052795\n",
      "Epoch:  144  Average loss at step  6000 :  8.90174472618103\n",
      "Epoch:  144  Average loss at step  7000 :  7.981226881980896\n",
      "Epoch:  144  Average loss at step  8000 :  7.893564598560333\n",
      "Epoch:  144  Average loss at step  8472 :  8.039694677148658\n",
      "144 0 20.388145208358765\n",
      "Epoch:  144  Average loss at step  1000 :  1853.1832551879884\n",
      "Epoch:  144  Average loss at step  1491 :  1861.1773789928204\n",
      "144 1 11.718676090240479\n",
      "Epoch:  144  Average loss at step  1000 :  2579.719004638672\n",
      "Epoch:  144  Average loss at step  2000 :  2560.642137573242\n",
      "Epoch:  144  Average loss at step  2533 :  2578.7826854125215\n",
      "144 2 19.963168382644653\n",
      "Epoch:  144  Average loss at step  1000 :  86.54415578842163\n",
      "Epoch:  144  Average loss at step  1227 :  86.1849161283463\n",
      "144 3 12.656845331192017\n",
      "Epoch:  144  Average loss at step  1000 :  25.339626561164856\n",
      "Epoch:  144  Average loss at step  2000 :  25.297890648841857\n",
      "Epoch:  144  Average loss at step  3000 :  25.190147634506225\n",
      "Epoch:  144  Average loss at step  3222 :  25.583221439334714\n",
      "144 4 33.14886021614075\n",
      "144 5 1.6689300537109375e-06\n",
      "Training time took 98.516451 seconds to run 1 epoch\n",
      "Epoch:  145  Average loss at step  1000 :  0.18518250662088395\n",
      "Epoch:  145  Average loss at step  2000 :  0.19092543858289718\n",
      "Epoch:  145  Average loss at step  3000 :  0.20862182092666626\n",
      "Epoch:  145  Average loss at step  3222 :  0.21490356050086035\n",
      "145 0 29.422220945358276\n",
      "Training time took 29.539708 seconds to run 1 epoch\n",
      "Epoch:  146  Average loss at step  1000 :  8.478326630592345\n",
      "Epoch:  146  Average loss at step  2000 :  8.463686184883118\n",
      "Epoch:  146  Average loss at step  3000 :  8.003325158119202\n",
      "Epoch:  146  Average loss at step  4000 :  7.937114862442017\n",
      "Epoch:  146  Average loss at step  5000 :  8.18537680530548\n",
      "Epoch:  146  Average loss at step  6000 :  7.7502716088294985\n",
      "Epoch:  146  Average loss at step  7000 :  7.716761612892151\n",
      "Epoch:  146  Average loss at step  8000 :  8.346658726215363\n",
      "Epoch:  146  Average loss at step  8472 :  8.35721770944268\n",
      "146 0 20.318424463272095\n",
      "Epoch:  146  Average loss at step  1000 :  1869.596149658203\n",
      "Epoch:  146  Average loss at step  1491 :  1844.5896473404512\n",
      "146 1 11.80754804611206\n",
      "Epoch:  146  Average loss at step  1000 :  2586.813826538086\n",
      "Epoch:  146  Average loss at step  2000 :  2569.198634765625\n",
      "Epoch:  146  Average loss at step  2533 :  2584.9952812755496\n",
      "146 2 19.966628551483154\n",
      "Epoch:  146  Average loss at step  1000 :  86.73213243865966\n",
      "Epoch:  146  Average loss at step  1227 :  86.21865480069306\n",
      "146 3 12.628141164779663\n",
      "Epoch:  146  Average loss at step  1000 :  25.246006677627562\n",
      "Epoch:  146  Average loss at step  2000 :  25.05665029335022\n",
      "Epoch:  146  Average loss at step  3000 :  24.970317824363708\n",
      "Epoch:  146  Average loss at step  3222 :  24.487317824411058\n",
      "146 4 33.259618520736694\n",
      "146 5 1.6689300537109375e-06\n",
      "Training time took 98.639767 seconds to run 1 epoch\n",
      "Epoch:  147  Average loss at step  1000 :  0.18179926484823228\n",
      "Epoch:  147  Average loss at step  2000 :  0.19031917327642442\n",
      "Epoch:  147  Average loss at step  3000 :  0.2042073163986206\n",
      "Epoch:  147  Average loss at step  3222 :  0.21367530289873962\n",
      "147 0 29.37937068939209\n",
      "Training time took 29.4988 seconds to run 1 epoch\n",
      "Epoch:  148  Average loss at step  1000 :  7.735744630336762\n",
      "Epoch:  148  Average loss at step  2000 :  8.410894029140472\n",
      "Epoch:  148  Average loss at step  3000 :  8.281708894729615\n",
      "Epoch:  148  Average loss at step  4000 :  7.893187229156494\n",
      "Epoch:  148  Average loss at step  5000 :  8.158197053909301\n",
      "Epoch:  148  Average loss at step  6000 :  8.38941239643097\n",
      "Epoch:  148  Average loss at step  7000 :  8.047945815086365\n",
      "Epoch:  148  Average loss at step  8000 :  8.566796606063843\n",
      "Epoch:  148  Average loss at step  8472 :  8.501130195502073\n",
      "148 0 20.809903144836426\n",
      "Epoch:  148  Average loss at step  1000 :  1881.726322631836\n",
      "Epoch:  148  Average loss at step  1491 :  1855.699109383275\n",
      "148 1 11.751938819885254\n",
      "Epoch:  148  Average loss at step  1000 :  2600.270249267578\n",
      "Epoch:  148  Average loss at step  2000 :  2569.5496138916014\n",
      "Epoch:  148  Average loss at step  2533 :  2564.4855915825697\n",
      "148 2 19.931064128875732\n",
      "Epoch:  148  Average loss at step  1000 :  85.83402010345459\n",
      "Epoch:  148  Average loss at step  1227 :  84.73402681256886\n",
      "148 3 12.674278497695923\n",
      "Epoch:  148  Average loss at step  1000 :  24.523572222709657\n",
      "Epoch:  148  Average loss at step  2000 :  24.62001093387604\n",
      "Epoch:  148  Average loss at step  3000 :  24.42633181285858\n",
      "Epoch:  148  Average loss at step  3222 :  24.501781305222547\n",
      "148 4 33.30725693702698\n",
      "148 5 1.430511474609375e-06\n",
      "Training time took 99.113647 seconds to run 1 epoch\n",
      "Epoch:  149  Average loss at step  1000 :  0.1808530644774437\n",
      "Epoch:  149  Average loss at step  2000 :  0.18648596042394638\n",
      "Epoch:  149  Average loss at step  3000 :  0.2020535027384758\n",
      "Epoch:  149  Average loss at step  3222 :  0.21129286440943829\n",
      "149 0 29.492064714431763\n",
      "Training time took 29.611095 seconds to run 1 epoch\n",
      "Epoch:  150  Average loss at step  1000 :  8.436063584327698\n",
      "Epoch:  150  Average loss at step  2000 :  8.446226305007935\n",
      "Epoch:  150  Average loss at step  3000 :  8.143596081733703\n",
      "Epoch:  150  Average loss at step  4000 :  8.600209820270539\n",
      "Epoch:  150  Average loss at step  5000 :  8.688536907672882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  150  Average loss at step  6000 :  8.594626463413238\n",
      "Epoch:  150  Average loss at step  7000 :  8.060806317806243\n",
      "Epoch:  150  Average loss at step  8000 :  8.744569375991821\n",
      "Epoch:  150  Average loss at step  8472 :  9.045107082025156\n",
      "150 0 20.80167865753174\n",
      "Epoch:  150  Average loss at step  1000 :  1869.8293723754882\n",
      "Epoch:  150  Average loss at step  1491 :  1844.1885185696265\n",
      "150 1 11.729585647583008\n",
      "Epoch:  150  Average loss at step  1000 :  2606.837528198242\n",
      "Epoch:  150  Average loss at step  2000 :  2586.273930175781\n",
      "Epoch:  150  Average loss at step  2533 :  2599.5701900304803\n",
      "150 2 19.958012580871582\n",
      "Epoch:  150  Average loss at step  1000 :  84.81170166397095\n",
      "Epoch:  150  Average loss at step  1227 :  84.69828701873375\n",
      "150 3 12.612909317016602\n",
      "Epoch:  150  Average loss at step  1000 :  24.146317131996156\n",
      "Epoch:  150  Average loss at step  2000 :  24.43844703102112\n",
      "Epoch:  150  Average loss at step  3000 :  24.34469637489319\n",
      "Epoch:  150  Average loss at step  3222 :  24.303447969942493\n",
      "150 4 33.27001976966858\n",
      "150 5 1.1920928955078125e-06\n",
      "Training time took 99.007412 seconds to run 1 epoch\n",
      "Mean Rank:  249.161  of  75000\n",
      "Hits @ 10:  0.78016\n",
      "Hits @ 1:  0.4946\n",
      "Testing time took 164.205616 seconds.\n",
      "\n",
      "Epoch:  151  Average loss at step  1000 :  0.17826501840353012\n",
      "Epoch:  151  Average loss at step  2000 :  0.1838289222717285\n",
      "Epoch:  151  Average loss at step  3000 :  0.19972819024324417\n",
      "Epoch:  151  Average loss at step  3222 :  0.207630469440058\n",
      "151 0 29.52802538871765\n",
      "Training time took 29.635868 seconds to run 1 epoch\n",
      "Epoch:  152  Average loss at step  1000 :  8.49158368396759\n",
      "Epoch:  152  Average loss at step  2000 :  8.388412642478944\n",
      "Epoch:  152  Average loss at step  3000 :  8.464438501358032\n",
      "Epoch:  152  Average loss at step  4000 :  8.351767241001129\n",
      "Epoch:  152  Average loss at step  5000 :  8.032565472602844\n",
      "Epoch:  152  Average loss at step  6000 :  8.019620501518249\n",
      "Epoch:  152  Average loss at step  7000 :  8.283694149971009\n",
      "Epoch:  152  Average loss at step  8000 :  7.706389410972595\n",
      "Epoch:  152  Average loss at step  8472 :  7.57064623832905\n",
      "152 0 20.38108777999878\n",
      "Epoch:  152  Average loss at step  1000 :  1863.3845964355469\n",
      "Epoch:  152  Average loss at step  1491 :  1873.9302865603133\n",
      "152 1 11.77893853187561\n",
      "Epoch:  152  Average loss at step  1000 :  2610.986646362305\n",
      "Epoch:  152  Average loss at step  2000 :  2588.50533984375\n",
      "Epoch:  152  Average loss at step  2533 :  2589.935143280804\n",
      "152 2 19.981781482696533\n",
      "Epoch:  152  Average loss at step  1000 :  84.89248332595825\n",
      "Epoch:  152  Average loss at step  1227 :  84.14360097211203\n",
      "152 3 12.64411735534668\n",
      "Epoch:  152  Average loss at step  1000 :  23.727753119468687\n",
      "Epoch:  152  Average loss at step  2000 :  23.804188942909242\n",
      "Epoch:  152  Average loss at step  3000 :  23.979981282234192\n",
      "Epoch:  152  Average loss at step  3222 :  23.600509279061363\n",
      "152 4 33.4112229347229\n",
      "152 5 1.1920928955078125e-06\n",
      "Training time took 98.832143 seconds to run 1 epoch\n",
      "Epoch:  153  Average loss at step  1000 :  0.17592428737878799\n",
      "Epoch:  153  Average loss at step  2000 :  0.18276269322633742\n",
      "Epoch:  153  Average loss at step  3000 :  0.19740244656801223\n",
      "Epoch:  153  Average loss at step  3222 :  0.20560270979379053\n",
      "153 0 29.522393941879272\n",
      "Training time took 29.643123 seconds to run 1 epoch\n",
      "Epoch:  154  Average loss at step  1000 :  7.540600667476654\n",
      "Epoch:  154  Average loss at step  2000 :  7.996532422542572\n",
      "Epoch:  154  Average loss at step  3000 :  7.996374076843262\n",
      "Epoch:  154  Average loss at step  4000 :  8.48331875038147\n",
      "Epoch:  154  Average loss at step  5000 :  8.028866337776185\n",
      "Epoch:  154  Average loss at step  6000 :  8.338084397792816\n",
      "Epoch:  154  Average loss at step  7000 :  8.475063718318939\n",
      "Epoch:  154  Average loss at step  8000 :  8.380630633831025\n",
      "Epoch:  154  Average loss at step  8472 :  8.030140359962003\n",
      "154 0 21.508023738861084\n",
      "Epoch:  154  Average loss at step  1000 :  1871.125956970215\n",
      "Epoch:  154  Average loss at step  1491 :  1869.4084318691453\n",
      "154 1 11.735833883285522\n",
      "Epoch:  154  Average loss at step  1000 :  2615.2970838623046\n",
      "Epoch:  154  Average loss at step  2000 :  2604.825719482422\n",
      "Epoch:  154  Average loss at step  2533 :  2614.721074681647\n",
      "154 2 19.869342803955078\n",
      "Epoch:  154  Average loss at step  1000 :  85.21969309997559\n",
      "Epoch:  154  Average loss at step  1227 :  84.4693439578055\n",
      "154 3 12.728252649307251\n",
      "Epoch:  154  Average loss at step  1000 :  23.759006359100344\n",
      "Epoch:  154  Average loss at step  2000 :  23.20671739387512\n",
      "Epoch:  154  Average loss at step  3000 :  23.39564805030823\n",
      "Epoch:  154  Average loss at step  3222 :  23.166137078239245\n",
      "154 4 33.25567269325256\n",
      "154 5 1.1920928955078125e-06\n",
      "Training time took 99.734984 seconds to run 1 epoch\n",
      "Epoch:  155  Average loss at step  1000 :  0.17420962005853652\n",
      "Epoch:  155  Average loss at step  2000 :  0.1803605279326439\n",
      "Epoch:  155  Average loss at step  3000 :  0.19607300013303758\n",
      "Epoch:  155  Average loss at step  3222 :  0.20239604716052173\n",
      "155 0 29.489274978637695\n",
      "Training time took 29.609368 seconds to run 1 epoch\n",
      "Epoch:  156  Average loss at step  1000 :  8.25419277191162\n",
      "Epoch:  156  Average loss at step  2000 :  8.16778837108612\n",
      "Epoch:  156  Average loss at step  3000 :  7.9545722608566285\n",
      "Epoch:  156  Average loss at step  4000 :  8.13017598772049\n",
      "Epoch:  156  Average loss at step  5000 :  8.50057874059677\n",
      "Epoch:  156  Average loss at step  6000 :  8.407418603897094\n",
      "Epoch:  156  Average loss at step  7000 :  8.198012174606323\n",
      "Epoch:  156  Average loss at step  8000 :  8.09255140542984\n",
      "Epoch:  156  Average loss at step  8472 :  8.710113987797797\n",
      "156 0 20.880213737487793\n",
      "Epoch:  156  Average loss at step  1000 :  1887.8782079467774\n",
      "Epoch:  156  Average loss at step  1491 :  1870.5867221933213\n",
      "156 1 11.708195447921753\n",
      "Epoch:  156  Average loss at step  1000 :  2630.654782714844\n",
      "Epoch:  156  Average loss at step  2000 :  2586.292851196289\n",
      "Epoch:  156  Average loss at step  2533 :  2593.3834238105783\n",
      "156 2 19.89489722251892\n",
      "Epoch:  156  Average loss at step  1000 :  83.75945040893555\n",
      "Epoch:  156  Average loss at step  1227 :  84.82990284246273\n",
      "156 3 12.680647373199463\n",
      "Epoch:  156  Average loss at step  1000 :  23.24763899421692\n",
      "Epoch:  156  Average loss at step  2000 :  23.17338937664032\n",
      "Epoch:  156  Average loss at step  3000 :  23.190560830116272\n",
      "Epoch:  156  Average loss at step  3222 :  23.010448928257258\n",
      "156 4 33.20666170120239\n",
      "156 5 1.1920928955078125e-06\n",
      "Training time took 99.021302 seconds to run 1 epoch\n",
      "Epoch:  157  Average loss at step  1000 :  0.17123280531167984\n",
      "Epoch:  157  Average loss at step  2000 :  0.17838808256387712\n",
      "Epoch:  157  Average loss at step  3000 :  0.19263746362924575\n",
      "Epoch:  157  Average loss at step  3222 :  0.20310357280275973\n",
      "157 0 29.462207078933716\n",
      "Training time took 29.581012 seconds to run 1 epoch\n",
      "Epoch:  158  Average loss at step  1000 :  8.446361032485962\n",
      "Epoch:  158  Average loss at step  2000 :  7.558484838485718\n",
      "Epoch:  158  Average loss at step  3000 :  8.553843069076539\n",
      "Epoch:  158  Average loss at step  4000 :  8.048633949279786\n",
      "Epoch:  158  Average loss at step  5000 :  7.863635153293609\n",
      "Epoch:  158  Average loss at step  6000 :  8.029853526115417\n",
      "Epoch:  158  Average loss at step  7000 :  7.731315764427185\n",
      "Epoch:  158  Average loss at step  8000 :  8.275035177707672\n",
      "Epoch:  158  Average loss at step  8472 :  8.157299115496809\n",
      "158 0 21.062599420547485\n",
      "Epoch:  158  Average loss at step  1000 :  1890.8695701293946\n",
      "Epoch:  158  Average loss at step  1491 :  1909.719651763259\n",
      "158 1 11.694644212722778\n",
      "Epoch:  158  Average loss at step  1000 :  2634.956428955078\n",
      "Epoch:  158  Average loss at step  2000 :  2611.9116384277345\n",
      "Epoch:  158  Average loss at step  2533 :  2637.9748366754925\n",
      "158 2 19.968706846237183\n",
      "Epoch:  158  Average loss at step  1000 :  83.6364283027649\n",
      "Epoch:  158  Average loss at step  1227 :  83.9614095867519\n",
      "158 3 12.662877559661865\n",
      "Epoch:  158  Average loss at step  1000 :  22.91150027656555\n",
      "Epoch:  158  Average loss at step  2000 :  22.78362416267395\n",
      "Epoch:  158  Average loss at step  3000 :  22.713410990715026\n",
      "Epoch:  158  Average loss at step  3222 :  22.964079824675935\n",
      "158 4 33.316224575042725\n",
      "158 5 1.430511474609375e-06\n",
      "Training time took 99.33736 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  159  Average loss at step  1000 :  0.1702939169406891\n",
      "Epoch:  159  Average loss at step  2000 :  0.17546014857292175\n",
      "Epoch:  159  Average loss at step  3000 :  0.19096347296237945\n",
      "Epoch:  159  Average loss at step  3222 :  0.19984663926343407\n",
      "159 0 29.33397912979126\n",
      "Training time took 29.452651 seconds to run 1 epoch\n",
      "Epoch:  160  Average loss at step  1000 :  8.940312217712401\n",
      "Epoch:  160  Average loss at step  2000 :  8.21861493396759\n",
      "Epoch:  160  Average loss at step  3000 :  8.183842365264892\n",
      "Epoch:  160  Average loss at step  4000 :  8.381703492164611\n",
      "Epoch:  160  Average loss at step  5000 :  7.829975300788879\n",
      "Epoch:  160  Average loss at step  6000 :  8.322018928527832\n",
      "Epoch:  160  Average loss at step  7000 :  8.443122110366822\n",
      "Epoch:  160  Average loss at step  8000 :  7.843456729888916\n",
      "Epoch:  160  Average loss at step  8472 :  8.762800348953046\n",
      "160 0 20.420648097991943\n",
      "Epoch:  160  Average loss at step  1000 :  1881.9801491699218\n",
      "Epoch:  160  Average loss at step  1491 :  1917.5480648156783\n",
      "160 1 11.706852674484253\n",
      "Epoch:  160  Average loss at step  1000 :  2660.4672900390624\n",
      "Epoch:  160  Average loss at step  2000 :  2609.7324029541014\n",
      "Epoch:  160  Average loss at step  2533 :  2606.226984769766\n",
      "160 2 19.953899145126343\n",
      "Epoch:  160  Average loss at step  1000 :  82.79957363891602\n",
      "Epoch:  160  Average loss at step  1227 :  83.2699109634209\n",
      "160 3 12.641961336135864\n",
      "Epoch:  160  Average loss at step  1000 :  22.236918976783752\n",
      "Epoch:  160  Average loss at step  2000 :  22.52352330875397\n",
      "Epoch:  160  Average loss at step  3000 :  22.589918486595153\n",
      "Epoch:  160  Average loss at step  3222 :  22.312708636185906\n",
      "160 4 33.27852702140808\n",
      "160 5 1.6689300537109375e-06\n",
      "Training time took 98.630969 seconds to run 1 epoch\n",
      "Mean Rank:  236.08  of  75000\n",
      "Hits @ 10:  0.78812\n",
      "Hits @ 1:  0.50956\n",
      "Testing time took 164.171473 seconds.\n",
      "\n",
      "Epoch:  161  Average loss at step  1000 :  0.16724032104015352\n",
      "Epoch:  161  Average loss at step  2000 :  0.17458207738399506\n",
      "Epoch:  161  Average loss at step  3000 :  0.1890482628941536\n",
      "Epoch:  161  Average loss at step  3222 :  0.1971124994731117\n",
      "161 0 29.48581051826477\n",
      "Training time took 29.598904 seconds to run 1 epoch\n",
      "Epoch:  162  Average loss at step  1000 :  8.461211445331573\n",
      "Epoch:  162  Average loss at step  2000 :  8.244951226711272\n",
      "Epoch:  162  Average loss at step  3000 :  8.775770438194275\n",
      "Epoch:  162  Average loss at step  4000 :  8.527765488147736\n",
      "Epoch:  162  Average loss at step  5000 :  8.140940748214721\n",
      "Epoch:  162  Average loss at step  6000 :  8.118480250358582\n",
      "Epoch:  162  Average loss at step  7000 :  8.078676777362823\n",
      "Epoch:  162  Average loss at step  8000 :  8.232933035850525\n",
      "Epoch:  162  Average loss at step  8472 :  8.07177729145395\n",
      "162 0 20.591824293136597\n",
      "Epoch:  162  Average loss at step  1000 :  1894.1612734375\n",
      "Epoch:  162  Average loss at step  1491 :  1906.441612570784\n",
      "162 1 11.742718935012817\n",
      "Epoch:  162  Average loss at step  1000 :  2644.6736177978514\n",
      "Epoch:  162  Average loss at step  2000 :  2646.363828125\n",
      "Epoch:  162  Average loss at step  2533 :  2602.601004820885\n",
      "162 2 19.978013038635254\n",
      "Epoch:  162  Average loss at step  1000 :  82.53436404418946\n",
      "Epoch:  162  Average loss at step  1227 :  81.32189547331379\n",
      "162 3 12.688676834106445\n",
      "Epoch:  162  Average loss at step  1000 :  22.035758634567262\n",
      "Epoch:  162  Average loss at step  2000 :  22.169205561637877\n",
      "Epoch:  162  Average loss at step  3000 :  21.894394263267518\n",
      "Epoch:  162  Average loss at step  3222 :  22.191244631731287\n",
      "162 4 33.17589068412781\n",
      "162 5 1.1920928955078125e-06\n",
      "Training time took 98.820937 seconds to run 1 epoch\n",
      "Epoch:  163  Average loss at step  1000 :  0.1671284218430519\n",
      "Epoch:  163  Average loss at step  2000 :  0.17203393191099167\n",
      "Epoch:  163  Average loss at step  3000 :  0.18637790673971177\n",
      "Epoch:  163  Average loss at step  3222 :  0.19643648902008434\n",
      "163 0 29.535066604614258\n",
      "Training time took 29.652857 seconds to run 1 epoch\n",
      "Epoch:  164  Average loss at step  1000 :  8.109885681152344\n",
      "Epoch:  164  Average loss at step  2000 :  8.431295881271362\n",
      "Epoch:  164  Average loss at step  3000 :  8.166959370613098\n",
      "Epoch:  164  Average loss at step  4000 :  8.722451342582703\n",
      "Epoch:  164  Average loss at step  5000 :  8.175078373908997\n",
      "Epoch:  164  Average loss at step  6000 :  8.601131208896637\n",
      "Epoch:  164  Average loss at step  7000 :  7.474501848220825\n",
      "Epoch:  164  Average loss at step  8000 :  8.43614145040512\n",
      "Epoch:  164  Average loss at step  8472 :  7.881045779653257\n",
      "164 0 20.365222930908203\n",
      "Epoch:  164  Average loss at step  1000 :  1905.8246876831054\n",
      "Epoch:  164  Average loss at step  1491 :  1884.0815435207555\n",
      "164 1 11.780903339385986\n",
      "Epoch:  164  Average loss at step  1000 :  2642.3091206054687\n",
      "Epoch:  164  Average loss at step  2000 :  2661.5665017089846\n",
      "Epoch:  164  Average loss at step  2533 :  2619.7632113547315\n",
      "164 2 20.020256280899048\n",
      "Epoch:  164  Average loss at step  1000 :  82.14143212509155\n",
      "Epoch:  164  Average loss at step  1227 :  82.4748714563312\n",
      "164 3 12.648524284362793\n",
      "Epoch:  164  Average loss at step  1000 :  21.829002809524535\n",
      "Epoch:  164  Average loss at step  2000 :  21.857677824020385\n",
      "Epoch:  164  Average loss at step  3000 :  21.655770473480224\n",
      "Epoch:  164  Average loss at step  3222 :  21.51421690099096\n",
      "164 4 33.23329973220825\n",
      "164 5 1.430511474609375e-06\n",
      "Training time took 98.677171 seconds to run 1 epoch\n",
      "Epoch:  165  Average loss at step  1000 :  0.1636136964559555\n",
      "Epoch:  165  Average loss at step  2000 :  0.17142200464010238\n",
      "Epoch:  165  Average loss at step  3000 :  0.18380198884010315\n",
      "Epoch:  165  Average loss at step  3222 :  0.19487576469399692\n",
      "165 0 29.4503014087677\n",
      "Training time took 29.56927 seconds to run 1 epoch\n",
      "Epoch:  166  Average loss at step  1000 :  8.12588421344757\n",
      "Epoch:  166  Average loss at step  2000 :  8.0182836561203\n",
      "Epoch:  166  Average loss at step  3000 :  8.206020887374878\n",
      "Epoch:  166  Average loss at step  4000 :  8.115253016471863\n",
      "Epoch:  166  Average loss at step  5000 :  8.155728175163269\n",
      "Epoch:  166  Average loss at step  6000 :  8.169178436279298\n",
      "Epoch:  166  Average loss at step  7000 :  7.914298950195312\n",
      "Epoch:  166  Average loss at step  8000 :  7.642639667987823\n",
      "Epoch:  166  Average loss at step  8472 :  8.08392821778608\n",
      "166 0 19.832759380340576\n",
      "Epoch:  166  Average loss at step  1000 :  1893.095745727539\n",
      "Epoch:  166  Average loss at step  1491 :  1898.455093188287\n",
      "166 1 11.74345064163208\n",
      "Epoch:  166  Average loss at step  1000 :  2660.138118774414\n",
      "Epoch:  166  Average loss at step  2000 :  2658.134762939453\n",
      "Epoch:  166  Average loss at step  2533 :  2628.460921182967\n",
      "166 2 19.91539430618286\n",
      "Epoch:  166  Average loss at step  1000 :  81.51191192626953\n",
      "Epoch:  166  Average loss at step  1227 :  81.90879941265369\n",
      "166 3 12.669431447982788\n",
      "Epoch:  166  Average loss at step  1000 :  21.473423387527465\n",
      "Epoch:  166  Average loss at step  2000 :  21.48251881504059\n",
      "Epoch:  166  Average loss at step  3000 :  21.510701558113098\n",
      "Epoch:  166  Average loss at step  3222 :  21.490946421233254\n",
      "166 4 33.15271520614624\n",
      "166 5 1.430511474609375e-06\n",
      "Training time took 97.949248 seconds to run 1 epoch\n",
      "Epoch:  167  Average loss at step  1000 :  0.16187934052944183\n",
      "Epoch:  167  Average loss at step  2000 :  0.16810692256689072\n",
      "Epoch:  167  Average loss at step  3000 :  0.1839171086549759\n",
      "Epoch:  167  Average loss at step  3222 :  0.19076437290706108\n",
      "167 0 29.563528299331665\n",
      "Training time took 29.689424 seconds to run 1 epoch\n",
      "Epoch:  168  Average loss at step  1000 :  7.9086461296081545\n",
      "Epoch:  168  Average loss at step  2000 :  8.01756354045868\n",
      "Epoch:  168  Average loss at step  3000 :  8.118506195545196\n",
      "Epoch:  168  Average loss at step  4000 :  8.366626626014709\n",
      "Epoch:  168  Average loss at step  5000 :  8.248916318893432\n",
      "Epoch:  168  Average loss at step  6000 :  8.56107213640213\n",
      "Epoch:  168  Average loss at step  7000 :  7.974029572486877\n",
      "Epoch:  168  Average loss at step  8000 :  8.084398587226868\n",
      "Epoch:  168  Average loss at step  8472 :  8.677132336809306\n",
      "168 0 21.4786274433136\n",
      "Epoch:  168  Average loss at step  1000 :  1907.0659805908203\n",
      "Epoch:  168  Average loss at step  1491 :  1918.5475432549574\n",
      "168 1 11.734081745147705\n",
      "Epoch:  168  Average loss at step  1000 :  2666.2446643066405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  168  Average loss at step  2000 :  2645.651077758789\n",
      "Epoch:  168  Average loss at step  2533 :  2678.3606643484613\n",
      "168 2 19.941111087799072\n",
      "Epoch:  168  Average loss at step  1000 :  81.33760429000854\n",
      "Epoch:  168  Average loss at step  1227 :  82.0886939352494\n",
      "168 3 12.55147910118103\n",
      "Epoch:  168  Average loss at step  1000 :  21.11741903781891\n",
      "Epoch:  168  Average loss at step  2000 :  21.21144045829773\n",
      "Epoch:  168  Average loss at step  3000 :  20.940755086898804\n",
      "Epoch:  168  Average loss at step  3222 :  21.65009325044339\n",
      "168 4 33.2597291469574\n",
      "168 5 1.1920928955078125e-06\n",
      "Training time took 99.590928 seconds to run 1 epoch\n",
      "Epoch:  169  Average loss at step  1000 :  0.16000146287679673\n",
      "Epoch:  169  Average loss at step  2000 :  0.1669775293469429\n",
      "Epoch:  169  Average loss at step  3000 :  0.1809760057926178\n",
      "Epoch:  169  Average loss at step  3222 :  0.18845774821155573\n",
      "169 0 29.477893114089966\n",
      "Training time took 29.594893 seconds to run 1 epoch\n",
      "Epoch:  170  Average loss at step  1000 :  8.280371021270751\n",
      "Epoch:  170  Average loss at step  2000 :  8.437769555091858\n",
      "Epoch:  170  Average loss at step  3000 :  7.72814108467102\n",
      "Epoch:  170  Average loss at step  4000 :  8.215578114032745\n",
      "Epoch:  170  Average loss at step  5000 :  8.260157486915588\n",
      "Epoch:  170  Average loss at step  6000 :  7.581576604843139\n",
      "Epoch:  170  Average loss at step  7000 :  7.9246416459083555\n",
      "Epoch:  170  Average loss at step  8000 :  8.836782824516296\n",
      "Epoch:  170  Average loss at step  8472 :  8.261236815191298\n",
      "170 0 21.107131242752075\n",
      "Epoch:  170  Average loss at step  1000 :  1922.1860118408204\n",
      "Epoch:  170  Average loss at step  1491 :  1916.2127313937722\n",
      "170 1 11.735488653182983\n",
      "Epoch:  170  Average loss at step  1000 :  2656.720653564453\n",
      "Epoch:  170  Average loss at step  2000 :  2665.0991674804686\n",
      "Epoch:  170  Average loss at step  2533 :  2670.9237610214313\n",
      "170 2 19.930055379867554\n",
      "Epoch:  170  Average loss at step  1000 :  81.18759087371826\n",
      "Epoch:  170  Average loss at step  1227 :  80.32596997255031\n",
      "170 3 12.603004693984985\n",
      "Epoch:  170  Average loss at step  1000 :  21.094358102798463\n",
      "Epoch:  170  Average loss at step  2000 :  21.02629547023773\n",
      "Epoch:  170  Average loss at step  3000 :  20.90791818523407\n",
      "Epoch:  170  Average loss at step  3222 :  21.42634345728001\n",
      "170 4 33.20750570297241\n",
      "170 5 1.1920928955078125e-06\n",
      "Training time took 99.203374 seconds to run 1 epoch\n",
      "Mean Rank:  227.79912  of  75000\n",
      "Hits @ 10:  0.79596\n",
      "Hits @ 1:  0.52036\n",
      "Testing time took 164.171395 seconds.\n",
      "\n",
      "Epoch:  171  Average loss at step  1000 :  0.15879043054580688\n",
      "Epoch:  171  Average loss at step  2000 :  0.16534925085306168\n",
      "Epoch:  171  Average loss at step  3000 :  0.17943345659971238\n",
      "Epoch:  171  Average loss at step  3222 :  0.18535687709719853\n",
      "171 0 29.623323917388916\n",
      "Training time took 29.7334 seconds to run 1 epoch\n",
      "Epoch:  172  Average loss at step  1000 :  8.192154179573059\n",
      "Epoch:  172  Average loss at step  2000 :  8.195395792007446\n",
      "Epoch:  172  Average loss at step  3000 :  8.568963496208191\n",
      "Epoch:  172  Average loss at step  4000 :  8.120111762523651\n",
      "Epoch:  172  Average loss at step  5000 :  7.742052929878235\n",
      "Epoch:  172  Average loss at step  6000 :  8.54468671798706\n",
      "Epoch:  172  Average loss at step  7000 :  8.22245792388916\n",
      "Epoch:  172  Average loss at step  8000 :  8.527373289585114\n",
      "Epoch:  172  Average loss at step  8472 :  7.586538800257817\n",
      "172 0 21.276095390319824\n",
      "Epoch:  172  Average loss at step  1000 :  1934.720392578125\n",
      "Epoch:  172  Average loss at step  1491 :  1948.048557373728\n",
      "172 1 11.750537157058716\n",
      "Epoch:  172  Average loss at step  1000 :  2677.9948431396483\n",
      "Epoch:  172  Average loss at step  2000 :  2665.8382449951173\n",
      "Epoch:  172  Average loss at step  2533 :  2686.014038173121\n",
      "172 2 19.956441640853882\n",
      "Epoch:  172  Average loss at step  1000 :  81.3320792350769\n",
      "Epoch:  172  Average loss at step  1227 :  81.36561435768968\n",
      "172 3 12.704107999801636\n",
      "Epoch:  172  Average loss at step  1000 :  20.83036672973633\n",
      "Epoch:  172  Average loss at step  2000 :  20.80322637653351\n",
      "Epoch:  172  Average loss at step  3000 :  20.545110008239746\n",
      "Epoch:  172  Average loss at step  3222 :  20.503895255627885\n",
      "172 4 33.14051127433777\n",
      "172 5 1.430511474609375e-06\n",
      "Training time took 99.477238 seconds to run 1 epoch\n",
      "Epoch:  173  Average loss at step  1000 :  0.15695165139436723\n",
      "Epoch:  173  Average loss at step  2000 :  0.1641047130227089\n",
      "Epoch:  173  Average loss at step  3000 :  0.17692397397756576\n",
      "Epoch:  173  Average loss at step  3222 :  0.18552919467405024\n",
      "173 0 29.42766571044922\n",
      "Training time took 29.548742 seconds to run 1 epoch\n",
      "Epoch:  174  Average loss at step  1000 :  8.201279848575592\n",
      "Epoch:  174  Average loss at step  2000 :  7.920953015327454\n",
      "Epoch:  174  Average loss at step  3000 :  8.209576644420624\n",
      "Epoch:  174  Average loss at step  4000 :  8.129044120788574\n",
      "Epoch:  174  Average loss at step  5000 :  8.271085423946381\n",
      "Epoch:  174  Average loss at step  6000 :  8.467016199111939\n",
      "Epoch:  174  Average loss at step  7000 :  8.230051359176636\n",
      "Epoch:  174  Average loss at step  8000 :  8.08607293701172\n",
      "Epoch:  174  Average loss at step  8472 :  8.229368309088025\n",
      "174 0 21.112024307250977\n",
      "Epoch:  174  Average loss at step  1000 :  1941.067703857422\n",
      "Epoch:  174  Average loss at step  1491 :  1911.8330696072856\n",
      "174 1 11.73491644859314\n",
      "Epoch:  174  Average loss at step  1000 :  2705.108088623047\n",
      "Epoch:  174  Average loss at step  2000 :  2687.090257202148\n",
      "Epoch:  174  Average loss at step  2533 :  2675.0302048655817\n",
      "174 2 19.94866704940796\n",
      "Epoch:  174  Average loss at step  1000 :  81.11142723083496\n",
      "Epoch:  174  Average loss at step  1227 :  79.14830515506371\n",
      "174 3 12.670007467269897\n",
      "Epoch:  174  Average loss at step  1000 :  20.485047253608705\n",
      "Epoch:  174  Average loss at step  2000 :  20.483383876800538\n",
      "Epoch:  174  Average loss at step  3000 :  20.362323931694032\n",
      "Epoch:  174  Average loss at step  3222 :  20.62423740575666\n",
      "174 4 33.08709478378296\n",
      "174 5 1.430511474609375e-06\n",
      "Training time took 99.189849 seconds to run 1 epoch\n",
      "Epoch:  175  Average loss at step  1000 :  0.15648070353269578\n",
      "Epoch:  175  Average loss at step  2000 :  0.16145582723617555\n",
      "Epoch:  175  Average loss at step  3000 :  0.17554359018802643\n",
      "Epoch:  175  Average loss at step  3222 :  0.18392766822996412\n",
      "175 0 29.415934085845947\n",
      "Training time took 29.535918 seconds to run 1 epoch\n",
      "Epoch:  176  Average loss at step  1000 :  7.921385358333588\n",
      "Epoch:  176  Average loss at step  2000 :  8.75847294998169\n",
      "Epoch:  176  Average loss at step  3000 :  7.962127166748047\n",
      "Epoch:  176  Average loss at step  4000 :  7.667895292282105\n",
      "Epoch:  176  Average loss at step  5000 :  8.128109638214111\n",
      "Epoch:  176  Average loss at step  6000 :  8.237120162010193\n",
      "Epoch:  176  Average loss at step  7000 :  8.064143495082856\n",
      "Epoch:  176  Average loss at step  8000 :  7.949507168769836\n",
      "Epoch:  176  Average loss at step  8472 :  7.989887128504279\n",
      "176 0 20.46117901802063\n",
      "Epoch:  176  Average loss at step  1000 :  1929.8113003540038\n",
      "Epoch:  176  Average loss at step  1491 :  1918.2964160297483\n",
      "176 1 11.74062466621399\n",
      "Epoch:  176  Average loss at step  1000 :  2703.1933830566404\n",
      "Epoch:  176  Average loss at step  2000 :  2673.0879293212893\n",
      "Epoch:  176  Average loss at step  2533 :  2701.4177416238745\n",
      "176 2 19.933517932891846\n",
      "Epoch:  176  Average loss at step  1000 :  80.38537721633911\n",
      "Epoch:  176  Average loss at step  1227 :  79.20502871215783\n",
      "176 3 12.712900876998901\n",
      "Epoch:  176  Average loss at step  1000 :  20.27223871803284\n",
      "Epoch:  176  Average loss at step  2000 :  20.14440296268463\n",
      "Epoch:  176  Average loss at step  3000 :  20.096234243392946\n",
      "Epoch:  176  Average loss at step  3222 :  19.683903316918595\n",
      "176 4 33.15351462364197\n",
      "176 5 1.430511474609375e-06\n",
      "Training time took 98.646428 seconds to run 1 epoch\n",
      "Epoch:  177  Average loss at step  1000 :  0.15396814215183258\n",
      "Epoch:  177  Average loss at step  2000 :  0.160629527926445\n",
      "Epoch:  177  Average loss at step  3000 :  0.1733083443045616\n",
      "Epoch:  177  Average loss at step  3222 :  0.18330199459352783\n",
      "177 0 29.34788990020752\n",
      "Training time took 29.468051 seconds to run 1 epoch\n",
      "Epoch:  178  Average loss at step  1000 :  7.933001754760742\n",
      "Epoch:  178  Average loss at step  2000 :  7.829083741664887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  178  Average loss at step  3000 :  8.247924932003022\n",
      "Epoch:  178  Average loss at step  4000 :  8.164328282833099\n",
      "Epoch:  178  Average loss at step  5000 :  8.463287672996522\n",
      "Epoch:  178  Average loss at step  6000 :  8.496627558708191\n",
      "Epoch:  178  Average loss at step  7000 :  8.598582651615143\n",
      "Epoch:  178  Average loss at step  8000 :  7.981673813819885\n",
      "Epoch:  178  Average loss at step  8472 :  8.67335451392517\n",
      "178 0 20.47060203552246\n",
      "Epoch:  178  Average loss at step  1000 :  1917.4238764648437\n",
      "Epoch:  178  Average loss at step  1491 :  1921.4415741790453\n",
      "178 1 11.725772142410278\n",
      "Epoch:  178  Average loss at step  1000 :  2718.4687795410155\n",
      "Epoch:  178  Average loss at step  2000 :  2703.3850051269533\n",
      "Epoch:  178  Average loss at step  2533 :  2680.6271612727096\n",
      "178 2 19.95109510421753\n",
      "Epoch:  178  Average loss at step  1000 :  79.72788693237305\n",
      "Epoch:  178  Average loss at step  1227 :  79.97278105877608\n",
      "178 3 12.68687391281128\n",
      "Epoch:  178  Average loss at step  1000 :  19.76105831336975\n",
      "Epoch:  178  Average loss at step  2000 :  19.61456421661377\n",
      "Epoch:  178  Average loss at step  3000 :  19.891713949203492\n",
      "Epoch:  178  Average loss at step  3222 :  20.015136725120456\n",
      "178 4 33.19453430175781\n",
      "178 5 1.6689300537109375e-06\n",
      "Training time took 98.665849 seconds to run 1 epoch\n",
      "Epoch:  179  Average loss at step  1000 :  0.1533328382372856\n",
      "Epoch:  179  Average loss at step  2000 :  0.1581142651438713\n",
      "Epoch:  179  Average loss at step  3000 :  0.17211901104450225\n",
      "Epoch:  179  Average loss at step  3222 :  0.1801081086500691\n",
      "179 0 29.443209409713745\n",
      "Training time took 29.563251 seconds to run 1 epoch\n",
      "Epoch:  180  Average loss at step  1000 :  8.300525237083436\n",
      "Epoch:  180  Average loss at step  2000 :  8.803904187202454\n",
      "Epoch:  180  Average loss at step  3000 :  8.1369292011261\n",
      "Epoch:  180  Average loss at step  4000 :  8.508535892486572\n",
      "Epoch:  180  Average loss at step  5000 :  7.875680810928345\n",
      "Epoch:  180  Average loss at step  6000 :  7.730980394363403\n",
      "Epoch:  180  Average loss at step  7000 :  7.897853354930878\n",
      "Epoch:  180  Average loss at step  8000 :  8.421716994285584\n",
      "Epoch:  180  Average loss at step  8472 :  8.4773838851454\n",
      "180 0 21.27604389190674\n",
      "Epoch:  180  Average loss at step  1000 :  1937.849524291992\n",
      "Epoch:  180  Average loss at step  1491 :  1948.1770948541703\n",
      "180 1 11.72424602508545\n",
      "Epoch:  180  Average loss at step  1000 :  2701.0431416015626\n",
      "Epoch:  180  Average loss at step  2000 :  2714.4196212158204\n",
      "Epoch:  180  Average loss at step  2533 :  2716.716342457559\n",
      "180 2 19.94111704826355\n",
      "Epoch:  180  Average loss at step  1000 :  79.41220608901978\n",
      "Epoch:  180  Average loss at step  1227 :  79.01255984202625\n",
      "180 3 12.572185277938843\n",
      "Epoch:  180  Average loss at step  1000 :  19.574551268577576\n",
      "Epoch:  180  Average loss at step  2000 :  19.4350877532959\n",
      "Epoch:  180  Average loss at step  3000 :  19.577333444595336\n",
      "Epoch:  180  Average loss at step  3222 :  19.76340306883449\n",
      "180 4 33.246479749679565\n",
      "180 5 1.430511474609375e-06\n",
      "Training time took 99.405652 seconds to run 1 epoch\n",
      "Mean Rank:  218.81916  of  75000\n",
      "Hits @ 10:  0.8018\n",
      "Hits @ 1:  0.53112\n",
      "Testing time took 164.363475 seconds.\n",
      "\n",
      "Epoch:  181  Average loss at step  1000 :  0.1502300705909729\n",
      "Epoch:  181  Average loss at step  2000 :  0.15690971159934997\n",
      "Epoch:  181  Average loss at step  3000 :  0.1713346860408783\n",
      "Epoch:  181  Average loss at step  3222 :  0.17815642912996055\n",
      "181 0 29.492770671844482\n",
      "Training time took 29.600455 seconds to run 1 epoch\n",
      "Epoch:  182  Average loss at step  1000 :  8.033707042694092\n",
      "Epoch:  182  Average loss at step  2000 :  8.368386921405792\n",
      "Epoch:  182  Average loss at step  3000 :  8.316022521972656\n",
      "Epoch:  182  Average loss at step  4000 :  7.977145105361939\n",
      "Epoch:  182  Average loss at step  5000 :  8.497017704963683\n",
      "Epoch:  182  Average loss at step  6000 :  8.241362689971924\n",
      "Epoch:  182  Average loss at step  7000 :  8.095418626308442\n",
      "Epoch:  182  Average loss at step  8000 :  8.705209354400635\n",
      "Epoch:  182  Average loss at step  8472 :  8.769351042347626\n",
      "182 0 21.202025413513184\n",
      "Epoch:  182  Average loss at step  1000 :  1943.81278515625\n",
      "Epoch:  182  Average loss at step  1491 :  1951.1272628796924\n",
      "182 1 11.732381343841553\n",
      "Epoch:  182  Average loss at step  1000 :  2709.9796848144533\n",
      "Epoch:  182  Average loss at step  2000 :  2717.9057626953127\n",
      "Epoch:  182  Average loss at step  2533 :  2713.541708805237\n",
      "182 2 19.94259786605835\n",
      "Epoch:  182  Average loss at step  1000 :  79.46883653640747\n",
      "Epoch:  182  Average loss at step  1227 :  78.75032583542904\n",
      "182 3 12.661636590957642\n",
      "Epoch:  182  Average loss at step  1000 :  19.36092699432373\n",
      "Epoch:  182  Average loss at step  2000 :  19.228962986946105\n",
      "Epoch:  182  Average loss at step  3000 :  19.401078686714172\n",
      "Epoch:  182  Average loss at step  3222 :  19.084549983242052\n",
      "182 4 33.12319231033325\n",
      "182 5 1.6689300537109375e-06\n",
      "Training time took 99.30078 seconds to run 1 epoch\n",
      "Epoch:  183  Average loss at step  1000 :  0.14965413624048232\n",
      "Epoch:  183  Average loss at step  2000 :  0.15564370501041414\n",
      "Epoch:  183  Average loss at step  3000 :  0.1685849325656891\n",
      "Epoch:  183  Average loss at step  3222 :  0.17759823442947392\n",
      "183 0 29.42879819869995\n",
      "Training time took 29.552203 seconds to run 1 epoch\n",
      "Epoch:  184  Average loss at step  1000 :  7.997469727039337\n",
      "Epoch:  184  Average loss at step  2000 :  8.473383649826049\n",
      "Epoch:  184  Average loss at step  3000 :  7.991427269458771\n",
      "Epoch:  184  Average loss at step  4000 :  7.74578985786438\n",
      "Epoch:  184  Average loss at step  5000 :  8.036227100372315\n",
      "Epoch:  184  Average loss at step  6000 :  8.201575742721557\n",
      "Epoch:  184  Average loss at step  7000 :  8.40070574092865\n",
      "Epoch:  184  Average loss at step  8000 :  8.138696140289307\n",
      "Epoch:  184  Average loss at step  8472 :  8.159559495855554\n",
      "184 0 21.167855262756348\n",
      "Epoch:  184  Average loss at step  1000 :  1950.1556682739258\n",
      "Epoch:  184  Average loss at step  1491 :  1968.6141291753104\n",
      "184 1 11.671729564666748\n",
      "Epoch:  184  Average loss at step  1000 :  2705.468444946289\n",
      "Epoch:  184  Average loss at step  2000 :  2726.653956542969\n",
      "Epoch:  184  Average loss at step  2533 :  2711.4806562215144\n",
      "184 2 19.949049711227417\n",
      "Epoch:  184  Average loss at step  1000 :  78.59368965530396\n",
      "Epoch:  184  Average loss at step  1227 :  78.09161013170993\n",
      "184 3 12.69700312614441\n",
      "Epoch:  184  Average loss at step  1000 :  19.16212718009949\n",
      "Epoch:  184  Average loss at step  2000 :  19.09669464111328\n",
      "Epoch:  184  Average loss at step  3000 :  18.858137952804565\n",
      "Epoch:  184  Average loss at step  3222 :  19.134051611673577\n",
      "184 4 33.251248359680176\n",
      "184 5 9.5367431640625e-07\n",
      "Training time took 99.368962 seconds to run 1 epoch\n",
      "Epoch:  185  Average loss at step  1000 :  0.1479011476635933\n",
      "Epoch:  185  Average loss at step  2000 :  0.15430257642269135\n",
      "Epoch:  185  Average loss at step  3000 :  0.1671718048453331\n",
      "Epoch:  185  Average loss at step  3222 :  0.1747374490272011\n",
      "185 0 29.46611714363098\n",
      "Training time took 29.581569 seconds to run 1 epoch\n",
      "Epoch:  186  Average loss at step  1000 :  8.294841648101807\n",
      "Epoch:  186  Average loss at step  2000 :  8.172499042510987\n",
      "Epoch:  186  Average loss at step  3000 :  8.39805669260025\n",
      "Epoch:  186  Average loss at step  4000 :  8.088234929084777\n",
      "Epoch:  186  Average loss at step  5000 :  8.257871706962586\n",
      "Epoch:  186  Average loss at step  6000 :  7.998057197570801\n",
      "Epoch:  186  Average loss at step  7000 :  8.23789390707016\n",
      "Epoch:  186  Average loss at step  8000 :  8.214935641288758\n",
      "Epoch:  186  Average loss at step  8472 :  7.911372936610317\n",
      "186 0 20.81445288658142\n",
      "Epoch:  186  Average loss at step  1000 :  1934.6758001098633\n",
      "Epoch:  186  Average loss at step  1491 :  1964.0259477826205\n",
      "186 1 11.718203067779541\n",
      "Epoch:  186  Average loss at step  1000 :  2724.8729910888674\n",
      "Epoch:  186  Average loss at step  2000 :  2745.9797943115236\n",
      "Epoch:  186  Average loss at step  2533 :  2711.1077275853527\n",
      "186 2 19.906935214996338\n",
      "Epoch:  186  Average loss at step  1000 :  78.43719955825806\n",
      "Epoch:  186  Average loss at step  1227 :  79.0625819721509\n",
      "186 3 12.668106317520142\n",
      "Epoch:  186  Average loss at step  1000 :  18.968805477142332\n",
      "Epoch:  186  Average loss at step  2000 :  18.794259468078614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  186  Average loss at step  3000 :  18.82398396205902\n",
      "Epoch:  186  Average loss at step  3222 :  19.029017410719085\n",
      "186 4 33.37712740898132\n",
      "186 5 1.1920928955078125e-06\n",
      "Training time took 99.12607 seconds to run 1 epoch\n",
      "Epoch:  187  Average loss at step  1000 :  0.14583709585666657\n",
      "Epoch:  187  Average loss at step  2000 :  0.15216635376214982\n",
      "Epoch:  187  Average loss at step  3000 :  0.16558621907234192\n",
      "Epoch:  187  Average loss at step  3222 :  0.17574330188884138\n",
      "187 0 29.37993288040161\n",
      "Training time took 29.500249 seconds to run 1 epoch\n",
      "Epoch:  188  Average loss at step  1000 :  8.671520673274994\n",
      "Epoch:  188  Average loss at step  2000 :  8.282803414821625\n",
      "Epoch:  188  Average loss at step  3000 :  7.506038031578064\n",
      "Epoch:  188  Average loss at step  4000 :  8.0237128405571\n",
      "Epoch:  188  Average loss at step  5000 :  8.43372917842865\n",
      "Epoch:  188  Average loss at step  6000 :  8.159371762275695\n",
      "Epoch:  188  Average loss at step  7000 :  8.350264898300171\n",
      "Epoch:  188  Average loss at step  8000 :  8.22119262599945\n",
      "Epoch:  188  Average loss at step  8472 :  8.13781412564293\n",
      "188 0 20.308246850967407\n",
      "Epoch:  188  Average loss at step  1000 :  1960.7582570800782\n",
      "Epoch:  188  Average loss at step  1491 :  1971.046409306221\n",
      "188 1 11.737972021102905\n",
      "Epoch:  188  Average loss at step  1000 :  2734.5328854980467\n",
      "Epoch:  188  Average loss at step  2000 :  2730.443577758789\n",
      "Epoch:  188  Average loss at step  2533 :  2765.528708167826\n",
      "188 2 19.953059911727905\n",
      "Epoch:  188  Average loss at step  1000 :  78.17348651504517\n",
      "Epoch:  188  Average loss at step  1227 :  77.63368072489571\n",
      "188 3 12.699378967285156\n",
      "Epoch:  188  Average loss at step  1000 :  18.713846267700195\n",
      "Epoch:  188  Average loss at step  2000 :  18.609696679115295\n",
      "Epoch:  188  Average loss at step  3000 :  18.709815472602845\n",
      "Epoch:  188  Average loss at step  3222 :  18.631507403843237\n",
      "188 4 33.1920690536499\n",
      "188 5 1.430511474609375e-06\n",
      "Training time took 98.520012 seconds to run 1 epoch\n",
      "Epoch:  189  Average loss at step  1000 :  0.14633966797590256\n",
      "Epoch:  189  Average loss at step  2000 :  0.1522129244208336\n",
      "Epoch:  189  Average loss at step  3000 :  0.16401189291477203\n",
      "Epoch:  189  Average loss at step  3222 :  0.17261589761459561\n",
      "189 0 29.43888521194458\n",
      "Training time took 29.563748 seconds to run 1 epoch\n",
      "Epoch:  190  Average loss at step  1000 :  8.503077610015868\n",
      "Epoch:  190  Average loss at step  2000 :  7.999796046733856\n",
      "Epoch:  190  Average loss at step  3000 :  8.784971079826356\n",
      "Epoch:  190  Average loss at step  4000 :  8.35443789434433\n",
      "Epoch:  190  Average loss at step  5000 :  7.672971484184266\n",
      "Epoch:  190  Average loss at step  6000 :  8.201357598304748\n",
      "Epoch:  190  Average loss at step  7000 :  8.370410355567932\n",
      "Epoch:  190  Average loss at step  8000 :  7.986242050170898\n",
      "Epoch:  190  Average loss at step  8472 :  8.173650610675118\n",
      "190 0 20.47588038444519\n",
      "Epoch:  190  Average loss at step  1000 :  1961.710071533203\n",
      "Epoch:  190  Average loss at step  1491 :  1957.704231815922\n",
      "190 1 11.692815780639648\n",
      "Epoch:  190  Average loss at step  1000 :  2751.4825057373046\n",
      "Epoch:  190  Average loss at step  2000 :  2753.159788574219\n",
      "Epoch:  190  Average loss at step  2533 :  2740.340046373045\n",
      "190 2 19.984312057495117\n",
      "Epoch:  190  Average loss at step  1000 :  78.35787779998779\n",
      "Epoch:  190  Average loss at step  1227 :  76.62502741021632\n",
      "190 3 12.545920133590698\n",
      "Epoch:  190  Average loss at step  1000 :  18.521310589790343\n",
      "Epoch:  190  Average loss at step  2000 :  18.329387451171876\n",
      "Epoch:  190  Average loss at step  3000 :  18.37892484855652\n",
      "Epoch:  190  Average loss at step  3222 :  17.989527501231777\n",
      "190 4 33.27419114112854\n",
      "190 5 1.430511474609375e-06\n",
      "Training time took 98.596688 seconds to run 1 epoch\n",
      "Mean Rank:  212.7498  of  75000\n",
      "Hits @ 10:  0.80996\n",
      "Hits @ 1:  0.54152\n",
      "Testing time took 164.562979 seconds.\n",
      "\n",
      "Epoch:  191  Average loss at step  1000 :  0.14374830281734466\n",
      "Epoch:  191  Average loss at step  2000 :  0.14978999567031862\n",
      "Epoch:  191  Average loss at step  3000 :  0.1620362988114357\n",
      "Epoch:  191  Average loss at step  3222 :  0.16836492964497843\n",
      "191 0 29.468199014663696\n",
      "Training time took 29.575527 seconds to run 1 epoch\n",
      "Epoch:  192  Average loss at step  1000 :  8.955284762382508\n",
      "Epoch:  192  Average loss at step  2000 :  7.869041286945343\n",
      "Epoch:  192  Average loss at step  3000 :  8.155087599277497\n",
      "Epoch:  192  Average loss at step  4000 :  8.599768549919128\n",
      "Epoch:  192  Average loss at step  5000 :  8.29901328086853\n",
      "Epoch:  192  Average loss at step  6000 :  8.381615097999573\n",
      "Epoch:  192  Average loss at step  7000 :  8.115885787963867\n",
      "Epoch:  192  Average loss at step  8000 :  8.061723803520202\n",
      "Epoch:  192  Average loss at step  8472 :  8.098168602004318\n",
      "192 0 20.75542974472046\n",
      "Epoch:  192  Average loss at step  1000 :  1965.4359749755859\n",
      "Epoch:  192  Average loss at step  1491 :  1938.9893373808702\n",
      "192 1 11.747636079788208\n",
      "Epoch:  192  Average loss at step  1000 :  2764.3907884521486\n",
      "Epoch:  192  Average loss at step  2000 :  2762.269706298828\n",
      "Epoch:  192  Average loss at step  2533 :  2730.9308519561646\n",
      "192 2 19.945224046707153\n",
      "Epoch:  192  Average loss at step  1000 :  76.6223369064331\n",
      "Epoch:  192  Average loss at step  1227 :  76.2362639494965\n",
      "192 3 12.681056261062622\n",
      "Epoch:  192  Average loss at step  1000 :  18.402713312149046\n",
      "Epoch:  192  Average loss at step  2000 :  18.370926674842835\n",
      "Epoch:  192  Average loss at step  3000 :  18.28738502454758\n",
      "Epoch:  192  Average loss at step  3222 :  18.22982091812434\n",
      "192 4 33.218165159225464\n",
      "192 5 1.6689300537109375e-06\n",
      "Training time took 98.983632 seconds to run 1 epoch\n",
      "Epoch:  193  Average loss at step  1000 :  0.1435407493710518\n",
      "Epoch:  193  Average loss at step  2000 :  0.14957470065355302\n",
      "Epoch:  193  Average loss at step  3000 :  0.1605259598493576\n",
      "Epoch:  193  Average loss at step  3222 :  0.1694608840901061\n",
      "193 0 29.479422569274902\n",
      "Training time took 29.6062 seconds to run 1 epoch\n",
      "Epoch:  194  Average loss at step  1000 :  8.189848302841186\n",
      "Epoch:  194  Average loss at step  2000 :  8.632236667156219\n",
      "Epoch:  194  Average loss at step  3000 :  8.438499555587768\n",
      "Epoch:  194  Average loss at step  4000 :  7.990684659957886\n",
      "Epoch:  194  Average loss at step  5000 :  8.203059126853942\n",
      "Epoch:  194  Average loss at step  6000 :  7.805245143890381\n",
      "Epoch:  194  Average loss at step  7000 :  7.930555220603943\n",
      "Epoch:  194  Average loss at step  8000 :  7.859924757957459\n",
      "Epoch:  194  Average loss at step  8472 :  7.602126334955258\n",
      "194 0 20.24189782142639\n",
      "Epoch:  194  Average loss at step  1000 :  1964.5048996582032\n",
      "Epoch:  194  Average loss at step  1491 :  1983.491651099778\n",
      "194 1 11.724352598190308\n",
      "Epoch:  194  Average loss at step  1000 :  2773.4528930664064\n",
      "Epoch:  194  Average loss at step  2000 :  2762.909059082031\n",
      "Epoch:  194  Average loss at step  2533 :  2751.1779461660517\n",
      "194 2 19.9516704082489\n",
      "Epoch:  194  Average loss at step  1000 :  76.1853341293335\n",
      "Epoch:  194  Average loss at step  1227 :  76.2488243455433\n",
      "194 3 12.700806140899658\n",
      "Epoch:  194  Average loss at step  1000 :  18.082645266532896\n",
      "Epoch:  194  Average loss at step  2000 :  18.001544461250305\n",
      "Epoch:  194  Average loss at step  3000 :  18.112661266326903\n",
      "Epoch:  194  Average loss at step  3222 :  18.133139274550338\n",
      "194 4 33.30528521537781\n",
      "194 5 1.430511474609375e-06\n",
      "Training time took 98.565029 seconds to run 1 epoch\n",
      "Epoch:  195  Average loss at step  1000 :  0.14060418266057967\n",
      "Epoch:  195  Average loss at step  2000 :  0.14789119106531143\n",
      "Epoch:  195  Average loss at step  3000 :  0.159765695810318\n",
      "Epoch:  195  Average loss at step  3222 :  0.16844359184994467\n",
      "195 0 29.404470205307007\n",
      "Training time took 29.533812 seconds to run 1 epoch\n",
      "Epoch:  196  Average loss at step  1000 :  8.446390494346618\n",
      "Epoch:  196  Average loss at step  2000 :  8.166444090366364\n",
      "Epoch:  196  Average loss at step  3000 :  8.113700708389283\n",
      "Epoch:  196  Average loss at step  4000 :  8.49877160358429\n",
      "Epoch:  196  Average loss at step  5000 :  8.575363454818726\n",
      "Epoch:  196  Average loss at step  6000 :  8.127764785766601\n",
      "Epoch:  196  Average loss at step  7000 :  8.181618061542512\n",
      "Epoch:  196  Average loss at step  8000 :  7.784546875953675\n",
      "Epoch:  196  Average loss at step  8472 :  8.121380534369786\n",
      "196 0 20.369256734848022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  196  Average loss at step  1000 :  1979.1984985961915\n",
      "Epoch:  196  Average loss at step  1491 :  1986.644709393635\n",
      "196 1 11.779342651367188\n",
      "Epoch:  196  Average loss at step  1000 :  2762.9996669921875\n",
      "Epoch:  196  Average loss at step  2000 :  2767.6088837890625\n",
      "Epoch:  196  Average loss at step  2533 :  2760.953622247359\n",
      "196 2 19.88498020172119\n",
      "Epoch:  196  Average loss at step  1000 :  76.53487679290771\n",
      "Epoch:  196  Average loss at step  1227 :  76.79056204711145\n",
      "196 3 12.621706485748291\n",
      "Epoch:  196  Average loss at step  1000 :  17.79877789926529\n",
      "Epoch:  196  Average loss at step  2000 :  17.889885902404785\n",
      "Epoch:  196  Average loss at step  3000 :  17.686887632369995\n",
      "Epoch:  196  Average loss at step  3222 :  17.695171735329325\n",
      "196 4 33.36097860336304\n",
      "196 5 1.430511474609375e-06\n",
      "Training time took 98.693588 seconds to run 1 epoch\n",
      "Epoch:  197  Average loss at step  1000 :  0.14062876719236375\n",
      "Epoch:  197  Average loss at step  2000 :  0.14712827050685884\n",
      "Epoch:  197  Average loss at step  3000 :  0.15801883268356323\n",
      "Epoch:  197  Average loss at step  3222 :  0.16563364472236847\n",
      "197 0 29.495615005493164\n",
      "Training time took 29.617131 seconds to run 1 epoch\n",
      "Epoch:  198  Average loss at step  1000 :  8.4362585439682\n",
      "Epoch:  198  Average loss at step  2000 :  8.203483820915222\n",
      "Epoch:  198  Average loss at step  3000 :  8.059407918930054\n",
      "Epoch:  198  Average loss at step  4000 :  8.118682339668274\n",
      "Epoch:  198  Average loss at step  5000 :  8.040365877151489\n",
      "Epoch:  198  Average loss at step  6000 :  8.673893698692321\n",
      "Epoch:  198  Average loss at step  7000 :  7.47029856967926\n",
      "Epoch:  198  Average loss at step  8000 :  8.479641172409057\n",
      "Epoch:  198  Average loss at step  8472 :  8.436870145896897\n",
      "198 0 20.55607581138611\n",
      "Epoch:  198  Average loss at step  1000 :  1977.4437155151368\n",
      "Epoch:  198  Average loss at step  1491 :  1956.561441541755\n",
      "198 1 11.720083236694336\n",
      "Epoch:  198  Average loss at step  1000 :  2797.639940917969\n",
      "Epoch:  198  Average loss at step  2000 :  2762.9132061767577\n",
      "Epoch:  198  Average loss at step  2533 :  2795.7056966763766\n",
      "198 2 19.879444122314453\n",
      "Epoch:  198  Average loss at step  1000 :  76.37027473449707\n",
      "Epoch:  198  Average loss at step  1227 :  76.28010592336727\n",
      "198 3 12.697146654129028\n",
      "Epoch:  198  Average loss at step  1000 :  17.681673063278197\n",
      "Epoch:  198  Average loss at step  2000 :  17.458721823692322\n",
      "Epoch:  198  Average loss at step  3000 :  17.631582308769225\n",
      "Epoch:  198  Average loss at step  3222 :  17.568197610210827\n",
      "198 4 33.238821506500244\n",
      "198 5 1.6689300537109375e-06\n",
      "Training time took 98.728978 seconds to run 1 epoch\n",
      "Epoch:  199  Average loss at step  1000 :  0.1379969378709793\n",
      "Epoch:  199  Average loss at step  2000 :  0.14488816887140274\n",
      "Epoch:  199  Average loss at step  3000 :  0.15696120482683182\n",
      "Epoch:  199  Average loss at step  3222 :  0.16436459092074598\n",
      "199 0 29.479089975357056\n",
      "Training time took 29.59666 seconds to run 1 epoch\n",
      "Epoch:  200  Average loss at step  1000 :  8.612236384391785\n",
      "Epoch:  200  Average loss at step  2000 :  8.52555237865448\n",
      "Epoch:  200  Average loss at step  3000 :  8.535866857528687\n",
      "Epoch:  200  Average loss at step  4000 :  8.502021010398865\n",
      "Epoch:  200  Average loss at step  5000 :  8.358018577575683\n",
      "Epoch:  200  Average loss at step  6000 :  8.252139869689941\n",
      "Epoch:  200  Average loss at step  7000 :  8.155020252227784\n",
      "Epoch:  200  Average loss at step  8000 :  8.24568832874298\n",
      "Epoch:  200  Average loss at step  8472 :  7.362499629078532\n",
      "200 0 20.733587980270386\n",
      "Epoch:  200  Average loss at step  1000 :  2000.3569193115234\n",
      "Epoch:  200  Average loss at step  1491 :  1971.4484619404195\n",
      "200 1 11.756340026855469\n",
      "Epoch:  200  Average loss at step  1000 :  2783.535571899414\n",
      "Epoch:  200  Average loss at step  2000 :  2751.1545947265627\n",
      "Epoch:  200  Average loss at step  2533 :  2800.175204601646\n",
      "200 2 19.846596717834473\n",
      "Epoch:  200  Average loss at step  1000 :  76.46446154022217\n",
      "Epoch:  200  Average loss at step  1227 :  77.27370453789642\n",
      "200 3 12.628415584564209\n",
      "Epoch:  200  Average loss at step  1000 :  17.3518602437973\n",
      "Epoch:  200  Average loss at step  2000 :  17.434061511039733\n",
      "Epoch:  200  Average loss at step  3000 :  17.459218194007875\n",
      "Epoch:  200  Average loss at step  3222 :  17.721164379336813\n",
      "200 4 33.151073694229126\n",
      "200 5 1.1920928955078125e-06\n",
      "Training time took 98.766263 seconds to run 1 epoch\n",
      "Mean Rank:  206.4742  of  75000\n",
      "Hits @ 10:  0.81372\n",
      "Hits @ 1:  0.5458\n",
      "Testing time took 164.262479 seconds.\n",
      "\n",
      "Epoch:  201  Average loss at step  1000 :  0.13824167746305466\n",
      "Epoch:  201  Average loss at step  2000 :  0.14440431582927704\n",
      "Epoch:  201  Average loss at step  3000 :  0.15527506417036058\n",
      "Epoch:  201  Average loss at step  3222 :  0.1629226252713731\n",
      "201 0 29.48454737663269\n",
      "Training time took 29.590721 seconds to run 1 epoch\n",
      "Epoch:  202  Average loss at step  1000 :  7.9818856267929075\n",
      "Epoch:  202  Average loss at step  2000 :  8.244927634239197\n",
      "Epoch:  202  Average loss at step  3000 :  8.076579627513885\n",
      "Epoch:  202  Average loss at step  4000 :  7.888808334350586\n",
      "Epoch:  202  Average loss at step  5000 :  7.801866137504578\n",
      "Epoch:  202  Average loss at step  6000 :  8.227676352024078\n",
      "Epoch:  202  Average loss at step  7000 :  8.160131057739259\n",
      "Epoch:  202  Average loss at step  8000 :  8.01846808052063\n",
      "Epoch:  202  Average loss at step  8472 :  6.964945498683002\n",
      "202 0 21.33464479446411\n",
      "Epoch:  202  Average loss at step  1000 :  1982.6298602294921\n",
      "Epoch:  202  Average loss at step  1491 :  2018.4738626954677\n",
      "202 1 11.732146978378296\n",
      "Epoch:  202  Average loss at step  1000 :  2803.9890432128905\n",
      "Epoch:  202  Average loss at step  2000 :  2768.785191772461\n",
      "Epoch:  202  Average loss at step  2533 :  2743.260173082791\n",
      "202 2 19.731064319610596\n",
      "Epoch:  202  Average loss at step  1000 :  75.66757029342651\n",
      "Epoch:  202  Average loss at step  1227 :  76.66702588581569\n",
      "202 3 12.644026517868042\n",
      "Epoch:  202  Average loss at step  1000 :  17.406932037353517\n",
      "Epoch:  202  Average loss at step  2000 :  17.187700951576232\n",
      "Epoch:  202  Average loss at step  3000 :  17.126057533740997\n",
      "Epoch:  202  Average loss at step  3222 :  17.437821825739924\n",
      "202 4 33.32743716239929\n",
      "202 5 1.430511474609375e-06\n",
      "Training time took 99.40695 seconds to run 1 epoch\n",
      "Epoch:  203  Average loss at step  1000 :  0.13670356065034867\n",
      "Epoch:  203  Average loss at step  2000 :  0.14163219499588012\n",
      "Epoch:  203  Average loss at step  3000 :  0.1537779507637024\n",
      "Epoch:  203  Average loss at step  3222 :  0.16287210847867012\n",
      "203 0 29.427297353744507\n",
      "Training time took 29.556185 seconds to run 1 epoch\n",
      "Epoch:  204  Average loss at step  1000 :  8.616436522483825\n",
      "Epoch:  204  Average loss at step  2000 :  8.257212898254394\n",
      "Epoch:  204  Average loss at step  3000 :  8.599797115802765\n",
      "Epoch:  204  Average loss at step  4000 :  8.187070042610168\n",
      "Epoch:  204  Average loss at step  5000 :  8.035113698005675\n",
      "Epoch:  204  Average loss at step  6000 :  8.113678810119628\n",
      "Epoch:  204  Average loss at step  7000 :  7.746633088588714\n",
      "Epoch:  204  Average loss at step  8000 :  8.260981729507446\n",
      "Epoch:  204  Average loss at step  8472 :  8.075954296720345\n",
      "204 0 21.058851718902588\n",
      "Epoch:  204  Average loss at step  1000 :  1987.4721322631835\n",
      "Epoch:  204  Average loss at step  1491 :  1992.6840894311083\n",
      "204 1 11.739270687103271\n",
      "Epoch:  204  Average loss at step  1000 :  2792.7166424560546\n",
      "Epoch:  204  Average loss at step  2000 :  2792.5522125244142\n",
      "Epoch:  204  Average loss at step  2533 :  2780.4432245805224\n",
      "204 2 19.947710275650024\n",
      "Epoch:  204  Average loss at step  1000 :  76.5405287361145\n",
      "Epoch:  204  Average loss at step  1227 :  76.91345418478272\n",
      "204 3 12.59767198562622\n",
      "Epoch:  204  Average loss at step  1000 :  17.012108669281005\n",
      "Epoch:  204  Average loss at step  2000 :  16.986478593826295\n",
      "Epoch:  204  Average loss at step  3000 :  16.98358943939209\n",
      "Epoch:  204  Average loss at step  3222 :  17.282155442913638\n",
      "204 4 33.273927450180054\n",
      "204 5 1.430511474609375e-06\n",
      "Training time took 99.261727 seconds to run 1 epoch\n",
      "Epoch:  205  Average loss at step  1000 :  0.13538557648658753\n",
      "Epoch:  205  Average loss at step  2000 :  0.1407547453045845\n",
      "Epoch:  205  Average loss at step  3000 :  0.15357164984941482\n",
      "Epoch:  205  Average loss at step  3222 :  0.15991228375544206\n",
      "205 0 29.412004470825195\n",
      "Training time took 29.535375 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  206  Average loss at step  1000 :  8.26185496711731\n",
      "Epoch:  206  Average loss at step  2000 :  8.049058113098145\n",
      "Epoch:  206  Average loss at step  3000 :  8.245788083553315\n",
      "Epoch:  206  Average loss at step  4000 :  8.056056677341461\n",
      "Epoch:  206  Average loss at step  5000 :  8.276224502563476\n",
      "Epoch:  206  Average loss at step  6000 :  8.50208934879303\n",
      "Epoch:  206  Average loss at step  7000 :  8.464126938819886\n",
      "Epoch:  206  Average loss at step  8000 :  7.929410806655884\n",
      "Epoch:  206  Average loss at step  8472 :  8.58371859975847\n",
      "206 0 21.106947898864746\n",
      "Epoch:  206  Average loss at step  1000 :  1982.2552342529298\n",
      "Epoch:  206  Average loss at step  1491 :  2030.070743417428\n",
      "206 1 11.766610383987427\n",
      "Epoch:  206  Average loss at step  1000 :  2801.870645751953\n",
      "Epoch:  206  Average loss at step  2000 :  2808.3926744384767\n",
      "Epoch:  206  Average loss at step  2533 :  2821.0050043367705\n",
      "206 2 19.94326663017273\n",
      "Epoch:  206  Average loss at step  1000 :  76.07000424957275\n",
      "Epoch:  206  Average loss at step  1227 :  76.11033094256936\n",
      "206 3 12.683002710342407\n",
      "Epoch:  206  Average loss at step  1000 :  16.771278812885285\n",
      "Epoch:  206  Average loss at step  2000 :  16.696404116630553\n",
      "Epoch:  206  Average loss at step  3000 :  16.842490869998933\n",
      "Epoch:  206  Average loss at step  3222 :  16.89425029572134\n",
      "206 4 33.13414740562439\n",
      "206 5 1.430511474609375e-06\n",
      "Training time took 99.279245 seconds to run 1 epoch\n",
      "Epoch:  207  Average loss at step  1000 :  0.1343486132621765\n",
      "Epoch:  207  Average loss at step  2000 :  0.1396299239397049\n",
      "Epoch:  207  Average loss at step  3000 :  0.15253604727983475\n",
      "Epoch:  207  Average loss at step  3222 :  0.15795209505084964\n",
      "207 0 29.216556310653687\n",
      "Training time took 29.339659 seconds to run 1 epoch\n",
      "Epoch:  208  Average loss at step  1000 :  8.318195016860962\n",
      "Epoch:  208  Average loss at step  2000 :  8.422566684246064\n",
      "Epoch:  208  Average loss at step  3000 :  8.250071968555451\n",
      "Epoch:  208  Average loss at step  4000 :  8.23341000699997\n",
      "Epoch:  208  Average loss at step  5000 :  8.510022695064544\n",
      "Epoch:  208  Average loss at step  6000 :  8.211244339942931\n",
      "Epoch:  208  Average loss at step  7000 :  8.022824157714844\n",
      "Epoch:  208  Average loss at step  8000 :  8.505380201339722\n",
      "Epoch:  208  Average loss at step  8472 :  8.017276245246066\n",
      "208 0 20.45272135734558\n",
      "Epoch:  208  Average loss at step  1000 :  2037.0474044189452\n",
      "Epoch:  208  Average loss at step  1491 :  2004.071984947574\n",
      "208 1 11.754766464233398\n",
      "Epoch:  208  Average loss at step  1000 :  2836.3542685546877\n",
      "Epoch:  208  Average loss at step  2000 :  2826.5600927734376\n",
      "Epoch:  208  Average loss at step  2533 :  2799.8959266041134\n",
      "208 2 19.92958688735962\n",
      "Epoch:  208  Average loss at step  1000 :  75.3264285774231\n",
      "Epoch:  208  Average loss at step  1227 :  74.31962350714153\n",
      "208 3 12.660042762756348\n",
      "Epoch:  208  Average loss at step  1000 :  16.65141053390503\n",
      "Epoch:  208  Average loss at step  2000 :  16.3829808883667\n",
      "Epoch:  208  Average loss at step  3000 :  16.728174056053163\n",
      "Epoch:  208  Average loss at step  3222 :  16.274699150687372\n",
      "208 4 33.18979573249817\n",
      "208 5 1.430511474609375e-06\n",
      "Training time took 98.616224 seconds to run 1 epoch\n",
      "Epoch:  209  Average loss at step  1000 :  0.13222953873872756\n",
      "Epoch:  209  Average loss at step  2000 :  0.13918022572994232\n",
      "Epoch:  209  Average loss at step  3000 :  0.15081080442667008\n",
      "Epoch:  209  Average loss at step  3222 :  0.1568966726250415\n",
      "209 0 29.436378955841064\n",
      "Training time took 29.557242 seconds to run 1 epoch\n",
      "Epoch:  210  Average loss at step  1000 :  8.122163506507874\n",
      "Epoch:  210  Average loss at step  2000 :  8.600337872982026\n",
      "Epoch:  210  Average loss at step  3000 :  8.073665108680725\n",
      "Epoch:  210  Average loss at step  4000 :  7.950610862731933\n",
      "Epoch:  210  Average loss at step  5000 :  8.23896075630188\n",
      "Epoch:  210  Average loss at step  6000 :  7.521915191650391\n",
      "Epoch:  210  Average loss at step  7000 :  8.157785852432252\n",
      "Epoch:  210  Average loss at step  8000 :  8.415463084220887\n",
      "Epoch:  210  Average loss at step  8472 :  8.692558318405633\n",
      "210 0 20.62749195098877\n",
      "Epoch:  210  Average loss at step  1000 :  2006.3516320800782\n",
      "Epoch:  210  Average loss at step  1491 :  2008.3658995068988\n",
      "210 1 11.752216100692749\n",
      "Epoch:  210  Average loss at step  1000 :  2821.017128173828\n",
      "Epoch:  210  Average loss at step  2000 :  2829.6937521972654\n",
      "Epoch:  210  Average loss at step  2533 :  2783.212051646842\n",
      "210 2 19.93441343307495\n",
      "Epoch:  210  Average loss at step  1000 :  74.88465422439575\n",
      "Epoch:  210  Average loss at step  1227 :  73.85422906073273\n",
      "210 3 12.734734296798706\n",
      "Epoch:  210  Average loss at step  1000 :  16.49457388496399\n",
      "Epoch:  210  Average loss at step  2000 :  16.411601490974427\n",
      "Epoch:  210  Average loss at step  3000 :  16.5129036359787\n",
      "Epoch:  210  Average loss at step  3222 :  16.50245486667686\n",
      "210 4 33.18742895126343\n",
      "210 5 1.6689300537109375e-06\n",
      "Training time took 98.877607 seconds to run 1 epoch\n",
      "Mean Rank:  201.94228  of  75000\n",
      "Hits @ 10:  0.81704\n",
      "Hits @ 1:  0.55556\n",
      "Testing time took 164.566939 seconds.\n",
      "\n",
      "Epoch:  211  Average loss at step  1000 :  0.13283997631072997\n",
      "Epoch:  211  Average loss at step  2000 :  0.13739782857894897\n",
      "Epoch:  211  Average loss at step  3000 :  0.14979474091529846\n",
      "Epoch:  211  Average loss at step  3222 :  0.15450988081220815\n",
      "211 0 29.474340200424194\n",
      "Training time took 29.580703 seconds to run 1 epoch\n",
      "Epoch:  212  Average loss at step  1000 :  8.51569551229477\n",
      "Epoch:  212  Average loss at step  2000 :  8.57393587398529\n",
      "Epoch:  212  Average loss at step  3000 :  8.492666085720062\n",
      "Epoch:  212  Average loss at step  4000 :  8.193310756206513\n",
      "Epoch:  212  Average loss at step  5000 :  7.855406383514405\n",
      "Epoch:  212  Average loss at step  6000 :  8.781228375911713\n",
      "Epoch:  212  Average loss at step  7000 :  8.336903814792633\n",
      "Epoch:  212  Average loss at step  8000 :  7.976977728843689\n",
      "Epoch:  212  Average loss at step  8472 :  8.43759094291063\n",
      "212 0 21.060752868652344\n",
      "Epoch:  212  Average loss at step  1000 :  2019.8811661376953\n",
      "Epoch:  212  Average loss at step  1491 :  2023.2738482518191\n",
      "212 1 11.747591495513916\n",
      "Epoch:  212  Average loss at step  1000 :  2849.0167834472654\n",
      "Epoch:  212  Average loss at step  2000 :  2818.7715412597654\n",
      "Epoch:  212  Average loss at step  2533 :  2852.149926268669\n",
      "212 2 19.945112466812134\n",
      "Epoch:  212  Average loss at step  1000 :  75.40966854095458\n",
      "Epoch:  212  Average loss at step  1227 :  73.16038678918534\n",
      "212 3 12.6604483127594\n",
      "Epoch:  212  Average loss at step  1000 :  16.437259935855867\n",
      "Epoch:  212  Average loss at step  2000 :  16.50544477081299\n",
      "Epoch:  212  Average loss at step  3000 :  16.256375101566313\n",
      "Epoch:  212  Average loss at step  3222 :  16.574020195489414\n",
      "212 4 33.29996204376221\n",
      "212 5 1.430511474609375e-06\n",
      "Training time took 99.357486 seconds to run 1 epoch\n",
      "Epoch:  213  Average loss at step  1000 :  0.13069871389865875\n",
      "Epoch:  213  Average loss at step  2000 :  0.13606507807970047\n",
      "Epoch:  213  Average loss at step  3000 :  0.14758127981424332\n",
      "Epoch:  213  Average loss at step  3222 :  0.15279497641220616\n",
      "213 0 29.438095808029175\n",
      "Training time took 29.549022 seconds to run 1 epoch\n",
      "Epoch:  214  Average loss at step  1000 :  7.892502726554871\n",
      "Epoch:  214  Average loss at step  2000 :  7.780400015354156\n",
      "Epoch:  214  Average loss at step  3000 :  7.746204717159271\n",
      "Epoch:  214  Average loss at step  4000 :  8.506506511688233\n",
      "Epoch:  214  Average loss at step  5000 :  8.298351039886475\n",
      "Epoch:  214  Average loss at step  6000 :  8.203702570438384\n",
      "Epoch:  214  Average loss at step  7000 :  8.196604022026062\n",
      "Epoch:  214  Average loss at step  8000 :  8.005612594127655\n",
      "Epoch:  214  Average loss at step  8472 :  7.595544893345643\n",
      "214 0 20.730221033096313\n",
      "Epoch:  214  Average loss at step  1000 :  2029.2370580444335\n",
      "Epoch:  214  Average loss at step  1491 :  2034.7853378150749\n",
      "214 1 11.717434167861938\n",
      "Epoch:  214  Average loss at step  1000 :  2827.4634891357423\n",
      "Epoch:  214  Average loss at step  2000 :  2827.488067138672\n",
      "Epoch:  214  Average loss at step  2533 :  2808.5793778416237\n",
      "214 2 19.95594620704651\n",
      "Epoch:  214  Average loss at step  1000 :  74.69925929260253\n",
      "Epoch:  214  Average loss at step  1227 :  72.98419143071577\n",
      "214 3 12.580066204071045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  214  Average loss at step  1000 :  16.079135277748108\n",
      "Epoch:  214  Average loss at step  2000 :  16.30484836292267\n",
      "Epoch:  214  Average loss at step  3000 :  16.15935085773468\n",
      "Epoch:  214  Average loss at step  3222 :  15.974871073631759\n",
      "214 4 33.36874198913574\n",
      "214 5 1.1920928955078125e-06\n",
      "Training time took 98.98235 seconds to run 1 epoch\n",
      "Epoch:  215  Average loss at step  1000 :  0.13024438667297364\n",
      "Epoch:  215  Average loss at step  2000 :  0.1355079197883606\n",
      "Epoch:  215  Average loss at step  3000 :  0.14714935433864593\n",
      "Epoch:  215  Average loss at step  3222 :  0.15422863706524007\n",
      "215 0 29.428588151931763\n",
      "Training time took 29.554114 seconds to run 1 epoch\n",
      "Epoch:  216  Average loss at step  1000 :  8.048671251773834\n",
      "Epoch:  216  Average loss at step  2000 :  8.208843664169311\n",
      "Epoch:  216  Average loss at step  3000 :  8.06629845237732\n",
      "Epoch:  216  Average loss at step  4000 :  8.241276148796082\n",
      "Epoch:  216  Average loss at step  5000 :  8.647983095169067\n",
      "Epoch:  216  Average loss at step  6000 :  7.62896950674057\n",
      "Epoch:  216  Average loss at step  7000 :  8.322646483421325\n",
      "Epoch:  216  Average loss at step  8000 :  8.25799924659729\n",
      "Epoch:  216  Average loss at step  8472 :  8.132415546190403\n",
      "216 0 20.73888397216797\n",
      "Epoch:  216  Average loss at step  1000 :  2032.6387216796875\n",
      "Epoch:  216  Average loss at step  1491 :  2001.8045117981194\n",
      "216 1 11.75259780883789\n",
      "Epoch:  216  Average loss at step  1000 :  2841.6376870117188\n",
      "Epoch:  216  Average loss at step  2000 :  2845.020422973633\n",
      "Epoch:  216  Average loss at step  2533 :  2837.131066192018\n",
      "216 2 19.962411642074585\n",
      "Epoch:  216  Average loss at step  1000 :  74.04242578125\n",
      "Epoch:  216  Average loss at step  1227 :  74.29657897935756\n",
      "216 3 12.635051488876343\n",
      "Epoch:  216  Average loss at step  1000 :  16.01155803203583\n",
      "Epoch:  216  Average loss at step  2000 :  16.13300614643097\n",
      "Epoch:  216  Average loss at step  3000 :  16.084852835655212\n",
      "Epoch:  216  Average loss at step  3222 :  15.72089983810477\n",
      "216 4 33.27635335922241\n",
      "216 5 1.1920928955078125e-06\n",
      "Training time took 99.004764 seconds to run 1 epoch\n",
      "Epoch:  217  Average loss at step  1000 :  0.1285014511346817\n",
      "Epoch:  217  Average loss at step  2000 :  0.13443193596601485\n",
      "Epoch:  217  Average loss at step  3000 :  0.1456172434091568\n",
      "Epoch:  217  Average loss at step  3222 :  0.15245379066613635\n",
      "217 0 29.455463409423828\n",
      "Training time took 29.573723 seconds to run 1 epoch\n",
      "Epoch:  218  Average loss at step  1000 :  7.9165412168502804\n",
      "Epoch:  218  Average loss at step  2000 :  8.344151945590973\n",
      "Epoch:  218  Average loss at step  3000 :  8.631821341514588\n",
      "Epoch:  218  Average loss at step  4000 :  8.089671437263489\n",
      "Epoch:  218  Average loss at step  5000 :  7.751133457183838\n",
      "Epoch:  218  Average loss at step  6000 :  8.29592439365387\n",
      "Epoch:  218  Average loss at step  7000 :  7.917219937801361\n",
      "Epoch:  218  Average loss at step  8000 :  8.207056206703186\n",
      "Epoch:  218  Average loss at step  8472 :  8.067070732021174\n",
      "218 0 21.539690494537354\n",
      "Epoch:  218  Average loss at step  1000 :  2042.0535739135742\n",
      "Epoch:  218  Average loss at step  1491 :  2015.8627962907294\n",
      "218 1 11.71956205368042\n",
      "Epoch:  218  Average loss at step  1000 :  2884.679853149414\n",
      "Epoch:  218  Average loss at step  2000 :  2837.899592163086\n",
      "Epoch:  218  Average loss at step  2533 :  2851.5724315484863\n",
      "218 2 19.917174577713013\n",
      "Epoch:  218  Average loss at step  1000 :  74.85982888031006\n",
      "Epoch:  218  Average loss at step  1227 :  74.30848114785127\n",
      "218 3 12.637905597686768\n",
      "Epoch:  218  Average loss at step  1000 :  15.870822859764099\n",
      "Epoch:  218  Average loss at step  2000 :  15.801558304786683\n",
      "Epoch:  218  Average loss at step  3000 :  15.641768640518189\n",
      "Epoch:  218  Average loss at step  3222 :  15.773511733533587\n",
      "218 4 33.2869348526001\n",
      "218 5 1.1920928955078125e-06\n",
      "Training time took 99.747042 seconds to run 1 epoch\n",
      "Epoch:  219  Average loss at step  1000 :  0.12770962065458297\n",
      "Epoch:  219  Average loss at step  2000 :  0.13318112814426422\n",
      "Epoch:  219  Average loss at step  3000 :  0.1448400433063507\n",
      "Epoch:  219  Average loss at step  3222 :  0.15112631215281297\n",
      "219 0 29.410762548446655\n",
      "Training time took 29.530085 seconds to run 1 epoch\n",
      "Epoch:  220  Average loss at step  1000 :  7.897849876880645\n",
      "Epoch:  220  Average loss at step  2000 :  7.95873460483551\n",
      "Epoch:  220  Average loss at step  3000 :  8.297164604187012\n",
      "Epoch:  220  Average loss at step  4000 :  7.9194821066856385\n",
      "Epoch:  220  Average loss at step  5000 :  7.524471508026123\n",
      "Epoch:  220  Average loss at step  6000 :  7.947536774158478\n",
      "Epoch:  220  Average loss at step  7000 :  8.112819025993348\n",
      "Epoch:  220  Average loss at step  8000 :  7.937989114761352\n",
      "Epoch:  220  Average loss at step  8472 :  8.619607426376346\n",
      "220 0 20.868547201156616\n",
      "Epoch:  220  Average loss at step  1000 :  2025.5966583251952\n",
      "Epoch:  220  Average loss at step  1491 :  2052.0359499544393\n",
      "220 1 11.732136726379395\n",
      "Epoch:  220  Average loss at step  1000 :  2867.213944946289\n",
      "Epoch:  220  Average loss at step  2000 :  2844.5219361572267\n",
      "Epoch:  220  Average loss at step  2533 :  2860.4231420111955\n",
      "220 2 19.914245128631592\n",
      "Epoch:  220  Average loss at step  1000 :  74.18657431411744\n",
      "Epoch:  220  Average loss at step  1227 :  74.0282540622805\n",
      "220 3 12.598486423492432\n",
      "Epoch:  220  Average loss at step  1000 :  15.793652619838715\n",
      "Epoch:  220  Average loss at step  2000 :  15.594360550880433\n",
      "Epoch:  220  Average loss at step  3000 :  15.61436862230301\n",
      "Epoch:  220  Average loss at step  3222 :  15.712674113037913\n",
      "220 4 33.24263143539429\n",
      "220 5 1.430511474609375e-06\n",
      "Training time took 98.976655 seconds to run 1 epoch\n",
      "Mean Rank:  198.74828  of  75000\n",
      "Hits @ 10:  0.82384\n",
      "Hits @ 1:  0.56168\n",
      "Testing time took 164.409742 seconds.\n",
      "\n",
      "Epoch:  221  Average loss at step  1000 :  0.12676950585842134\n",
      "Epoch:  221  Average loss at step  2000 :  0.13255067348480223\n",
      "Epoch:  221  Average loss at step  3000 :  0.143383986890316\n",
      "Epoch:  221  Average loss at step  3222 :  0.14941222746463906\n",
      "221 0 29.458345413208008\n",
      "Training time took 29.564976 seconds to run 1 epoch\n",
      "Epoch:  222  Average loss at step  1000 :  8.172589958667755\n",
      "Epoch:  222  Average loss at step  2000 :  7.849523303985595\n",
      "Epoch:  222  Average loss at step  3000 :  7.882062659740448\n",
      "Epoch:  222  Average loss at step  4000 :  8.463391235351562\n",
      "Epoch:  222  Average loss at step  5000 :  8.026239959716797\n",
      "Epoch:  222  Average loss at step  6000 :  7.717046495437622\n",
      "Epoch:  222  Average loss at step  7000 :  8.143021258354187\n",
      "Epoch:  222  Average loss at step  8000 :  8.137206614494323\n",
      "Epoch:  222  Average loss at step  8472 :  8.685752215275542\n",
      "222 0 20.62674045562744\n",
      "Epoch:  222  Average loss at step  1000 :  2019.1802205200195\n",
      "Epoch:  222  Average loss at step  1491 :  2034.2261126602189\n",
      "222 1 11.75317931175232\n",
      "Epoch:  222  Average loss at step  1000 :  2861.9576826171874\n",
      "Epoch:  222  Average loss at step  2000 :  2841.2443704833986\n",
      "Epoch:  222  Average loss at step  2533 :  2880.6364855210472\n",
      "222 2 19.93040633201599\n",
      "Epoch:  222  Average loss at step  1000 :  74.60013795089722\n",
      "Epoch:  222  Average loss at step  1227 :  74.39445252926974\n",
      "222 3 12.623679637908936\n",
      "Epoch:  222  Average loss at step  1000 :  15.544236772537232\n",
      "Epoch:  222  Average loss at step  2000 :  15.617284769535065\n",
      "Epoch:  222  Average loss at step  3000 :  15.410825437068938\n",
      "Epoch:  222  Average loss at step  3222 :  15.511352281145163\n",
      "222 4 33.362327575683594\n",
      "222 5 1.430511474609375e-06\n",
      "Training time took 98.941387 seconds to run 1 epoch\n",
      "Epoch:  223  Average loss at step  1000 :  0.12528451615571976\n",
      "Epoch:  223  Average loss at step  2000 :  0.13157835471630097\n",
      "Epoch:  223  Average loss at step  3000 :  0.14249844479560853\n",
      "Epoch:  223  Average loss at step  3222 :  0.14743138132252015\n",
      "223 0 29.485263109207153\n",
      "Training time took 29.612349 seconds to run 1 epoch\n",
      "Epoch:  224  Average loss at step  1000 :  7.924644829750061\n",
      "Epoch:  224  Average loss at step  2000 :  7.988500240325927\n",
      "Epoch:  224  Average loss at step  3000 :  8.21143018579483\n",
      "Epoch:  224  Average loss at step  4000 :  8.152098176002502\n",
      "Epoch:  224  Average loss at step  5000 :  8.46563470172882\n",
      "Epoch:  224  Average loss at step  6000 :  7.896238517284393\n",
      "Epoch:  224  Average loss at step  7000 :  8.361450099945069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  224  Average loss at step  8000 :  8.335928523540497\n",
      "Epoch:  224  Average loss at step  8472 :  8.33443740264127\n",
      "224 0 20.33675241470337\n",
      "Epoch:  224  Average loss at step  1000 :  2060.860833984375\n",
      "Epoch:  224  Average loss at step  1491 :  2037.9758949412658\n",
      "224 1 11.745109796524048\n",
      "Epoch:  224  Average loss at step  1000 :  2889.654069946289\n",
      "Epoch:  224  Average loss at step  2000 :  2872.9200184326173\n",
      "Epoch:  224  Average loss at step  2533 :  2886.002142018978\n",
      "224 2 19.912337064743042\n",
      "Epoch:  224  Average loss at step  1000 :  74.10103836059571\n",
      "Epoch:  224  Average loss at step  1227 :  73.87998095154894\n",
      "224 3 12.639428615570068\n",
      "Epoch:  224  Average loss at step  1000 :  15.428475905895233\n",
      "Epoch:  224  Average loss at step  2000 :  15.351343312263488\n",
      "Epoch:  224  Average loss at step  3000 :  15.280851231575012\n",
      "Epoch:  224  Average loss at step  3222 :  15.089555409953663\n",
      "224 4 33.27100896835327\n",
      "224 5 1.430511474609375e-06\n",
      "Training time took 98.526517 seconds to run 1 epoch\n",
      "Epoch:  225  Average loss at step  1000 :  0.12441916114091874\n",
      "Epoch:  225  Average loss at step  2000 :  0.13073979473114014\n",
      "Epoch:  225  Average loss at step  3000 :  0.14158265960216523\n",
      "Epoch:  225  Average loss at step  3222 :  0.14747221679931988\n",
      "225 0 29.300967693328857\n",
      "Training time took 29.419567 seconds to run 1 epoch\n",
      "Epoch:  226  Average loss at step  1000 :  8.738592051506043\n",
      "Epoch:  226  Average loss at step  2000 :  8.32228767156601\n",
      "Epoch:  226  Average loss at step  3000 :  7.688895499229431\n",
      "Epoch:  226  Average loss at step  4000 :  8.087902876377106\n",
      "Epoch:  226  Average loss at step  5000 :  8.570301103115082\n",
      "Epoch:  226  Average loss at step  6000 :  8.610203404426574\n",
      "Epoch:  226  Average loss at step  7000 :  7.485437453746796\n",
      "Epoch:  226  Average loss at step  8000 :  8.24460819387436\n",
      "Epoch:  226  Average loss at step  8472 :  8.493696951632396\n",
      "226 0 21.157492876052856\n",
      "Epoch:  226  Average loss at step  1000 :  2046.6912947998046\n",
      "Epoch:  226  Average loss at step  1491 :  2047.9369737994484\n",
      "226 1 11.69066309928894\n",
      "Epoch:  226  Average loss at step  1000 :  2894.1194660644533\n",
      "Epoch:  226  Average loss at step  2000 :  2882.2741025390624\n",
      "Epoch:  226  Average loss at step  2533 :  2871.399562218958\n",
      "226 2 19.947221755981445\n",
      "Epoch:  226  Average loss at step  1000 :  74.11714875030518\n",
      "Epoch:  226  Average loss at step  1227 :  74.0273588613644\n",
      "226 3 12.682807683944702\n",
      "Epoch:  226  Average loss at step  1000 :  15.460028413772584\n",
      "Epoch:  226  Average loss at step  2000 :  15.238373356342315\n",
      "Epoch:  226  Average loss at step  3000 :  15.23747022151947\n",
      "Epoch:  226  Average loss at step  3222 :  15.189090464213713\n",
      "226 4 33.25258159637451\n",
      "226 5 1.1920928955078125e-06\n",
      "Training time took 99.376766 seconds to run 1 epoch\n",
      "Epoch:  227  Average loss at step  1000 :  0.12315818953514099\n",
      "Epoch:  227  Average loss at step  2000 :  0.12930917036533357\n",
      "Epoch:  227  Average loss at step  3000 :  0.1405385535955429\n",
      "Epoch:  227  Average loss at step  3222 :  0.146812033483237\n",
      "227 0 29.45415210723877\n",
      "Training time took 29.576794 seconds to run 1 epoch\n",
      "Epoch:  228  Average loss at step  1000 :  8.156731137275695\n",
      "Epoch:  228  Average loss at step  2000 :  8.594850303649903\n",
      "Epoch:  228  Average loss at step  3000 :  8.004979211330413\n",
      "Epoch:  228  Average loss at step  4000 :  8.17458231496811\n",
      "Epoch:  228  Average loss at step  5000 :  7.9502796983718875\n",
      "Epoch:  228  Average loss at step  6000 :  8.315218336105346\n",
      "Epoch:  228  Average loss at step  7000 :  8.08308514881134\n",
      "Epoch:  228  Average loss at step  8000 :  8.16387383556366\n",
      "Epoch:  228  Average loss at step  8472 :  8.06756554088671\n",
      "228 0 20.701011657714844\n",
      "Epoch:  228  Average loss at step  1000 :  2059.8002634887694\n",
      "Epoch:  228  Average loss at step  1491 :  2046.6055148598705\n",
      "228 1 11.757454872131348\n",
      "Epoch:  228  Average loss at step  1000 :  2912.54013684082\n",
      "Epoch:  228  Average loss at step  2000 :  2905.5718237304686\n",
      "Epoch:  228  Average loss at step  2533 :  2894.5737699581728\n",
      "228 2 19.942691802978516\n",
      "Epoch:  228  Average loss at step  1000 :  74.14573495864869\n",
      "Epoch:  228  Average loss at step  1227 :  74.27925772601087\n",
      "228 3 12.648900985717773\n",
      "Epoch:  228  Average loss at step  1000 :  15.315849691867829\n",
      "Epoch:  228  Average loss at step  2000 :  14.879103948116303\n",
      "Epoch:  228  Average loss at step  3000 :  15.072643723487854\n",
      "Epoch:  228  Average loss at step  3222 :  15.135319238536344\n",
      "228 4 33.13102412223816\n",
      "228 5 9.5367431640625e-07\n",
      "Training time took 98.825242 seconds to run 1 epoch\n",
      "Epoch:  229  Average loss at step  1000 :  0.12294175285100938\n",
      "Epoch:  229  Average loss at step  2000 :  0.1280863095521927\n",
      "Epoch:  229  Average loss at step  3000 :  0.13932551538944243\n",
      "Epoch:  229  Average loss at step  3222 :  0.14559801874403533\n",
      "229 0 29.467469930648804\n",
      "Training time took 29.587763 seconds to run 1 epoch\n",
      "Epoch:  230  Average loss at step  1000 :  8.414795333862305\n",
      "Epoch:  230  Average loss at step  2000 :  8.326772327423095\n",
      "Epoch:  230  Average loss at step  3000 :  8.246812425136566\n",
      "Epoch:  230  Average loss at step  4000 :  8.595140908241271\n",
      "Epoch:  230  Average loss at step  5000 :  8.443376350879669\n",
      "Epoch:  230  Average loss at step  6000 :  7.6424840669631955\n",
      "Epoch:  230  Average loss at step  7000 :  8.544055319786072\n",
      "Epoch:  230  Average loss at step  8000 :  8.803727193832398\n",
      "Epoch:  230  Average loss at step  8472 :  8.395590473934556\n",
      "230 0 20.45936131477356\n",
      "Epoch:  230  Average loss at step  1000 :  2073.115206298828\n",
      "Epoch:  230  Average loss at step  1491 :  2081.676625211811\n",
      "230 1 11.744828939437866\n",
      "Epoch:  230  Average loss at step  1000 :  2899.7776419677734\n",
      "Epoch:  230  Average loss at step  2000 :  2909.011600341797\n",
      "Epoch:  230  Average loss at step  2533 :  2911.951905076936\n",
      "230 2 19.956443786621094\n",
      "Epoch:  230  Average loss at step  1000 :  73.89369158554076\n",
      "Epoch:  230  Average loss at step  1227 :  72.04123312013205\n",
      "230 3 12.737626314163208\n",
      "Epoch:  230  Average loss at step  1000 :  14.95095962524414\n",
      "Epoch:  230  Average loss at step  2000 :  14.724241878509522\n",
      "Epoch:  230  Average loss at step  3000 :  14.962812204360961\n",
      "Epoch:  230  Average loss at step  3222 :  15.093216983866101\n",
      "230 4 33.274837493896484\n",
      "230 5 1.6689300537109375e-06\n",
      "Training time took 98.807782 seconds to run 1 epoch\n",
      "Mean Rank:  193.41248  of  75000\n",
      "Hits @ 10:  0.82704\n",
      "Hits @ 1:  0.56496\n",
      "Testing time took 163.984349 seconds.\n",
      "\n",
      "Epoch:  231  Average loss at step  1000 :  0.12167777585983276\n",
      "Epoch:  231  Average loss at step  2000 :  0.12735268533229827\n",
      "Epoch:  231  Average loss at step  3000 :  0.1387026874423027\n",
      "Epoch:  231  Average loss at step  3222 :  0.14525146411416073\n",
      "231 0 29.509358882904053\n",
      "Training time took 29.617164 seconds to run 1 epoch\n",
      "Epoch:  232  Average loss at step  1000 :  8.219818008422852\n",
      "Epoch:  232  Average loss at step  2000 :  7.7892952494621275\n",
      "Epoch:  232  Average loss at step  3000 :  8.221650734901429\n",
      "Epoch:  232  Average loss at step  4000 :  8.42453678035736\n",
      "Epoch:  232  Average loss at step  5000 :  8.061606948852539\n",
      "Epoch:  232  Average loss at step  6000 :  8.250373063087464\n",
      "Epoch:  232  Average loss at step  7000 :  8.50398127937317\n",
      "Epoch:  232  Average loss at step  8000 :  8.205058604240417\n",
      "Epoch:  232  Average loss at step  8472 :  7.725893049125562\n",
      "232 0 20.549537658691406\n",
      "Epoch:  232  Average loss at step  1000 :  2040.8008766479493\n",
      "Epoch:  232  Average loss at step  1491 :  2066.0455389774415\n",
      "232 1 11.70063853263855\n",
      "Epoch:  232  Average loss at step  1000 :  2904.9710626220703\n",
      "Epoch:  232  Average loss at step  2000 :  2894.1661274414064\n",
      "Epoch:  232  Average loss at step  2533 :  2870.3371496866985\n",
      "232 2 19.900603771209717\n",
      "Epoch:  232  Average loss at step  1000 :  73.79668975448608\n",
      "Epoch:  232  Average loss at step  1227 :  73.69174815067812\n",
      "232 3 12.697206974029541\n",
      "Epoch:  232  Average loss at step  1000 :  14.924166767120361\n",
      "Epoch:  232  Average loss at step  2000 :  14.747882261276246\n",
      "Epoch:  232  Average loss at step  3000 :  14.762914582252503\n",
      "Epoch:  232  Average loss at step  3222 :  14.91863463927443\n",
      "232 4 33.19447565078735\n",
      "232 5 1.1920928955078125e-06\n",
      "Training time took 98.692804 seconds to run 1 epoch\n",
      "Epoch:  233  Average loss at step  1000 :  0.12093186408281326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  233  Average loss at step  2000 :  0.12679706329107285\n",
      "Epoch:  233  Average loss at step  3000 :  0.13670115607976913\n",
      "Epoch:  233  Average loss at step  3222 :  0.14377078207892013\n",
      "233 0 29.41626000404358\n",
      "Training time took 29.544355 seconds to run 1 epoch\n",
      "Epoch:  234  Average loss at step  1000 :  7.831423415184021\n",
      "Epoch:  234  Average loss at step  2000 :  8.315059677124024\n",
      "Epoch:  234  Average loss at step  3000 :  8.086872789382934\n",
      "Epoch:  234  Average loss at step  4000 :  7.9079409112930295\n",
      "Epoch:  234  Average loss at step  5000 :  8.350954035758972\n",
      "Epoch:  234  Average loss at step  6000 :  7.999450479984284\n",
      "Epoch:  234  Average loss at step  7000 :  7.7146280574798585\n",
      "Epoch:  234  Average loss at step  8000 :  8.112496320724487\n",
      "Epoch:  234  Average loss at step  8472 :  8.054804924383292\n",
      "234 0 21.687623023986816\n",
      "Epoch:  234  Average loss at step  1000 :  2061.3120388183593\n",
      "Epoch:  234  Average loss at step  1491 :  2069.9796176419545\n",
      "234 1 11.732417345046997\n",
      "Epoch:  234  Average loss at step  1000 :  2916.3635206298827\n",
      "Epoch:  234  Average loss at step  2000 :  2872.7741616210938\n",
      "Epoch:  234  Average loss at step  2533 :  2882.3594364228925\n",
      "234 2 19.933161735534668\n",
      "Epoch:  234  Average loss at step  1000 :  73.85149010848998\n",
      "Epoch:  234  Average loss at step  1227 :  73.87490069097818\n",
      "234 3 12.607710123062134\n",
      "Epoch:  234  Average loss at step  1000 :  14.715442841529846\n",
      "Epoch:  234  Average loss at step  2000 :  14.671849501609803\n",
      "Epoch:  234  Average loss at step  3000 :  14.695650773525237\n",
      "Epoch:  234  Average loss at step  3222 :  14.662894593139141\n",
      "234 4 33.09138512611389\n",
      "234 5 1.430511474609375e-06\n",
      "Training time took 99.692437 seconds to run 1 epoch\n",
      "Epoch:  235  Average loss at step  1000 :  0.11895486187934876\n",
      "Epoch:  235  Average loss at step  2000 :  0.12526034063100816\n",
      "Epoch:  235  Average loss at step  3000 :  0.13635675400495528\n",
      "Epoch:  235  Average loss at step  3222 :  0.1429562766449958\n",
      "235 0 29.41545271873474\n",
      "Training time took 29.541631 seconds to run 1 epoch\n",
      "Epoch:  236  Average loss at step  1000 :  7.919994013786316\n",
      "Epoch:  236  Average loss at step  2000 :  8.303871428489686\n",
      "Epoch:  236  Average loss at step  3000 :  8.649837580680847\n",
      "Epoch:  236  Average loss at step  4000 :  8.293038352966308\n",
      "Epoch:  236  Average loss at step  5000 :  8.19107151222229\n",
      "Epoch:  236  Average loss at step  6000 :  8.399187858581543\n",
      "Epoch:  236  Average loss at step  7000 :  8.358484597206116\n",
      "Epoch:  236  Average loss at step  8000 :  8.421842906475067\n",
      "Epoch:  236  Average loss at step  8472 :  7.714345508700269\n",
      "236 0 20.808319568634033\n",
      "Epoch:  236  Average loss at step  1000 :  2073.153762023926\n",
      "Epoch:  236  Average loss at step  1491 :  2083.436543662785\n",
      "236 1 11.715118408203125\n",
      "Epoch:  236  Average loss at step  1000 :  2941.7181813964844\n",
      "Epoch:  236  Average loss at step  2000 :  2906.107751098633\n",
      "Epoch:  236  Average loss at step  2533 :  2922.2951190926838\n",
      "236 2 19.89084815979004\n",
      "Epoch:  236  Average loss at step  1000 :  73.67567651748658\n",
      "Epoch:  236  Average loss at step  1227 :  73.57474345725852\n",
      "236 3 12.630812168121338\n",
      "Epoch:  236  Average loss at step  1000 :  14.432566596508027\n",
      "Epoch:  236  Average loss at step  2000 :  14.51911240530014\n",
      "Epoch:  236  Average loss at step  3000 :  14.377212196826935\n",
      "Epoch:  236  Average loss at step  3222 :  14.297119665929268\n",
      "236 4 33.241559743881226\n",
      "236 5 1.430511474609375e-06\n",
      "Training time took 98.931144 seconds to run 1 epoch\n",
      "Epoch:  237  Average loss at step  1000 :  0.11979252851009368\n",
      "Epoch:  237  Average loss at step  2000 :  0.12497296941280366\n",
      "Epoch:  237  Average loss at step  3000 :  0.13554748207330702\n",
      "Epoch:  237  Average loss at step  3222 :  0.14099282442737862\n",
      "237 0 29.379412174224854\n",
      "Training time took 29.494946 seconds to run 1 epoch\n",
      "Epoch:  238  Average loss at step  1000 :  8.082421593666076\n",
      "Epoch:  238  Average loss at step  2000 :  8.536646842002868\n",
      "Epoch:  238  Average loss at step  3000 :  7.8962333211898805\n",
      "Epoch:  238  Average loss at step  4000 :  8.044844318389893\n",
      "Epoch:  238  Average loss at step  5000 :  8.063023678779603\n",
      "Epoch:  238  Average loss at step  6000 :  8.313107478141784\n",
      "Epoch:  238  Average loss at step  7000 :  7.994406822204589\n",
      "Epoch:  238  Average loss at step  8000 :  9.092404505252839\n",
      "Epoch:  238  Average loss at step  8472 :  8.303686323870595\n",
      "238 0 20.918917894363403\n",
      "Epoch:  238  Average loss at step  1000 :  2071.066565307617\n",
      "Epoch:  238  Average loss at step  1491 :  2104.357948199877\n",
      "238 1 11.704965353012085\n",
      "Epoch:  238  Average loss at step  1000 :  2920.714010986328\n",
      "Epoch:  238  Average loss at step  2000 :  2932.1898602294923\n",
      "Epoch:  238  Average loss at step  2533 :  2917.1404162282424\n",
      "238 2 19.954256534576416\n",
      "Epoch:  238  Average loss at step  1000 :  73.1280973777771\n",
      "Epoch:  238  Average loss at step  1227 :  74.00724088140636\n",
      "238 3 12.691098928451538\n",
      "Epoch:  238  Average loss at step  1000 :  14.508470500469208\n",
      "Epoch:  238  Average loss at step  2000 :  14.408469718933105\n",
      "Epoch:  238  Average loss at step  3000 :  14.33355525445938\n",
      "Epoch:  238  Average loss at step  3222 :  14.302786768806348\n",
      "238 4 33.491371393203735\n",
      "238 5 1.6689300537109375e-06\n",
      "Training time took 99.387022 seconds to run 1 epoch\n",
      "Epoch:  239  Average loss at step  1000 :  0.11812301766872406\n",
      "Epoch:  239  Average loss at step  2000 :  0.12341090619564056\n",
      "Epoch:  239  Average loss at step  3000 :  0.13357711923122406\n",
      "Epoch:  239  Average loss at step  3222 :  0.14152604629899174\n",
      "239 0 29.42252278327942\n",
      "Training time took 29.545001 seconds to run 1 epoch\n",
      "Epoch:  240  Average loss at step  1000 :  8.415766579627991\n",
      "Epoch:  240  Average loss at step  2000 :  8.638115549087525\n",
      "Epoch:  240  Average loss at step  3000 :  8.077207250595093\n",
      "Epoch:  240  Average loss at step  4000 :  7.881665315628052\n",
      "Epoch:  240  Average loss at step  5000 :  7.847656844139099\n",
      "Epoch:  240  Average loss at step  6000 :  8.227379912376405\n",
      "Epoch:  240  Average loss at step  7000 :  8.32198300075531\n",
      "Epoch:  240  Average loss at step  8000 :  8.079945895195006\n",
      "Epoch:  240  Average loss at step  8472 :  8.372619381673843\n",
      "240 0 20.608997583389282\n",
      "Epoch:  240  Average loss at step  1000 :  2098.888173095703\n",
      "Epoch:  240  Average loss at step  1491 :  2082.1454853145433\n",
      "240 1 11.754605293273926\n",
      "Epoch:  240  Average loss at step  1000 :  2941.1330560302736\n",
      "Epoch:  240  Average loss at step  2000 :  2907.240010864258\n",
      "Epoch:  240  Average loss at step  2533 :  2931.034819355577\n",
      "240 2 19.859022617340088\n",
      "Epoch:  240  Average loss at step  1000 :  72.68194912338257\n",
      "Epoch:  240  Average loss at step  1227 :  72.39389209610157\n",
      "240 3 12.681100130081177\n",
      "Epoch:  240  Average loss at step  1000 :  14.488057460784912\n",
      "Epoch:  240  Average loss at step  2000 :  14.24272015619278\n",
      "Epoch:  240  Average loss at step  3000 :  14.27285613679886\n",
      "Epoch:  240  Average loss at step  3222 :  14.180347077531017\n",
      "240 4 33.0798978805542\n",
      "240 5 1.430511474609375e-06\n",
      "Training time took 98.619656 seconds to run 1 epoch\n",
      "Mean Rank:  190.473  of  75000\n",
      "Hits @ 10:  0.83072\n",
      "Hits @ 1:  0.56964\n",
      "Testing time took 165.02442 seconds.\n",
      "\n",
      "Epoch:  241  Average loss at step  1000 :  0.11727543556690216\n",
      "Epoch:  241  Average loss at step  2000 :  0.12255221372842788\n",
      "Epoch:  241  Average loss at step  3000 :  0.1339025941491127\n",
      "Epoch:  241  Average loss at step  3222 :  0.13970245327581932\n",
      "241 0 29.402416944503784\n",
      "Training time took 29.51097 seconds to run 1 epoch\n",
      "Epoch:  242  Average loss at step  1000 :  7.846430077552795\n",
      "Epoch:  242  Average loss at step  2000 :  8.071850965499879\n",
      "Epoch:  242  Average loss at step  3000 :  8.610872343063354\n",
      "Epoch:  242  Average loss at step  4000 :  7.991092625617981\n",
      "Epoch:  242  Average loss at step  5000 :  7.877284781932831\n",
      "Epoch:  242  Average loss at step  6000 :  7.356688591957092\n",
      "Epoch:  242  Average loss at step  7000 :  7.881323533058167\n",
      "Epoch:  242  Average loss at step  8000 :  8.351477392196655\n",
      "Epoch:  242  Average loss at step  8472 :  8.227670482633716\n",
      "242 0 21.010242223739624\n",
      "Epoch:  242  Average loss at step  1000 :  2084.0782103881834\n",
      "Epoch:  242  Average loss at step  1491 :  2110.441386238555\n",
      "242 1 11.731682062149048\n",
      "Epoch:  242  Average loss at step  1000 :  2963.6361551513673\n",
      "Epoch:  242  Average loss at step  2000 :  2947.5989052734376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  242  Average loss at step  2533 :  2945.7298211987227\n",
      "242 2 19.899120569229126\n",
      "Epoch:  242  Average loss at step  1000 :  73.60645791244507\n",
      "Epoch:  242  Average loss at step  1227 :  71.9553536098583\n",
      "242 3 12.596941232681274\n",
      "Epoch:  242  Average loss at step  1000 :  14.14244830083847\n",
      "Epoch:  242  Average loss at step  2000 :  14.063535011291505\n",
      "Epoch:  242  Average loss at step  3000 :  14.064131033420562\n",
      "Epoch:  242  Average loss at step  3222 :  13.99102486262448\n",
      "242 4 33.22616267204285\n",
      "242 5 1.9073486328125e-06\n",
      "Training time took 99.122388 seconds to run 1 epoch\n",
      "Epoch:  243  Average loss at step  1000 :  0.11709198981523514\n",
      "Epoch:  243  Average loss at step  2000 :  0.12182004344463349\n",
      "Epoch:  243  Average loss at step  3000 :  0.13250868439674376\n",
      "Epoch:  243  Average loss at step  3222 :  0.13988661161289467\n",
      "243 0 29.45362424850464\n",
      "Training time took 29.569437 seconds to run 1 epoch\n",
      "Epoch:  244  Average loss at step  1000 :  8.223821314811707\n",
      "Epoch:  244  Average loss at step  2000 :  8.190947301864623\n",
      "Epoch:  244  Average loss at step  3000 :  8.040293628692627\n",
      "Epoch:  244  Average loss at step  4000 :  8.016024890899658\n",
      "Epoch:  244  Average loss at step  5000 :  8.549466702461242\n",
      "Epoch:  244  Average loss at step  6000 :  7.735455254554749\n",
      "Epoch:  244  Average loss at step  7000 :  8.350151918411255\n",
      "Epoch:  244  Average loss at step  8000 :  8.45367166185379\n",
      "Epoch:  244  Average loss at step  8472 :  8.050974507945273\n",
      "244 0 21.514349937438965\n",
      "Epoch:  244  Average loss at step  1000 :  2095.5305009765625\n",
      "Epoch:  244  Average loss at step  1491 :  2126.408909423584\n",
      "244 1 11.758215427398682\n",
      "Epoch:  244  Average loss at step  1000 :  2955.4392786865233\n",
      "Epoch:  244  Average loss at step  2000 :  2934.1653897705078\n",
      "Epoch:  244  Average loss at step  2533 :  2926.8010361187535\n",
      "244 2 19.9452223777771\n",
      "Epoch:  244  Average loss at step  1000 :  73.0591381149292\n",
      "Epoch:  244  Average loss at step  1227 :  71.75591533982497\n",
      "244 3 12.551178932189941\n",
      "Epoch:  244  Average loss at step  1000 :  13.969941471099853\n",
      "Epoch:  244  Average loss at step  2000 :  14.130392431735993\n",
      "Epoch:  244  Average loss at step  3000 :  14.060099576473236\n",
      "Epoch:  244  Average loss at step  3222 :  13.63410100671741\n",
      "244 4 33.078338384628296\n",
      "244 5 1.6689300537109375e-06\n",
      "Training time took 99.486479 seconds to run 1 epoch\n",
      "Epoch:  245  Average loss at step  1000 :  0.11535553526878357\n",
      "Epoch:  245  Average loss at step  2000 :  0.12129900723695755\n",
      "Epoch:  245  Average loss at step  3000 :  0.13147124773263932\n",
      "Epoch:  245  Average loss at step  3222 :  0.13661228549418025\n",
      "245 0 29.392477989196777\n",
      "Training time took 29.51181 seconds to run 1 epoch\n",
      "Epoch:  246  Average loss at step  1000 :  8.057894917488099\n",
      "Epoch:  246  Average loss at step  2000 :  8.075538591384888\n",
      "Epoch:  246  Average loss at step  3000 :  7.957154742240906\n",
      "Epoch:  246  Average loss at step  4000 :  8.096103486061097\n",
      "Epoch:  246  Average loss at step  5000 :  7.826078305244446\n",
      "Epoch:  246  Average loss at step  6000 :  7.78613641166687\n",
      "Epoch:  246  Average loss at step  7000 :  8.120743783950806\n",
      "Epoch:  246  Average loss at step  8000 :  7.995903628349304\n",
      "Epoch:  246  Average loss at step  8472 :  7.721851505603193\n",
      "246 0 20.593225717544556\n",
      "Epoch:  246  Average loss at step  1000 :  2116.3667381591795\n",
      "Epoch:  246  Average loss at step  1491 :  2114.9431514081452\n",
      "246 1 11.694079637527466\n",
      "Epoch:  246  Average loss at step  1000 :  2968.1855354003906\n",
      "Epoch:  246  Average loss at step  2000 :  2962.809277832031\n",
      "Epoch:  246  Average loss at step  2533 :  2955.7065680041082\n",
      "246 2 19.91490411758423\n",
      "Epoch:  246  Average loss at step  1000 :  73.40679751968383\n",
      "Epoch:  246  Average loss at step  1227 :  72.88672042081284\n",
      "246 3 12.653953790664673\n",
      "Epoch:  246  Average loss at step  1000 :  13.899773155212403\n",
      "Epoch:  246  Average loss at step  2000 :  13.875310276031493\n",
      "Epoch:  246  Average loss at step  3000 :  13.83755871105194\n",
      "Epoch:  246  Average loss at step  3222 :  13.82734791038914\n",
      "246 4 33.229817390441895\n",
      "246 5 1.6689300537109375e-06\n",
      "Training time took 98.735341 seconds to run 1 epoch\n",
      "Epoch:  247  Average loss at step  1000 :  0.11484841191768647\n",
      "Epoch:  247  Average loss at step  2000 :  0.1200649134516716\n",
      "Epoch:  247  Average loss at step  3000 :  0.13125775176286697\n",
      "Epoch:  247  Average loss at step  3222 :  0.13745407304688037\n",
      "247 0 29.449272632598877\n",
      "Training time took 29.56736 seconds to run 1 epoch\n",
      "Epoch:  248  Average loss at step  1000 :  7.704218905448913\n",
      "Epoch:  248  Average loss at step  2000 :  8.329958512306213\n",
      "Epoch:  248  Average loss at step  3000 :  8.190503931045532\n",
      "Epoch:  248  Average loss at step  4000 :  7.790973097801208\n",
      "Epoch:  248  Average loss at step  5000 :  8.200462339401245\n",
      "Epoch:  248  Average loss at step  6000 :  7.62730522441864\n",
      "Epoch:  248  Average loss at step  7000 :  8.632324642658233\n",
      "Epoch:  248  Average loss at step  8000 :  7.549925784111023\n",
      "Epoch:  248  Average loss at step  8472 :  8.095073661498194\n",
      "248 0 20.992167234420776\n",
      "Epoch:  248  Average loss at step  1000 :  2124.5146999511717\n",
      "Epoch:  248  Average loss at step  1491 :  2095.3412377331433\n",
      "248 1 11.714961051940918\n",
      "Epoch:  248  Average loss at step  1000 :  2965.2552175292967\n",
      "Epoch:  248  Average loss at step  2000 :  2972.532915527344\n",
      "Epoch:  248  Average loss at step  2533 :  2945.9873598240215\n",
      "248 2 19.936591863632202\n",
      "Epoch:  248  Average loss at step  1000 :  72.61468393707275\n",
      "Epoch:  248  Average loss at step  1227 :  72.74843033260339\n",
      "248 3 12.632758140563965\n",
      "Epoch:  248  Average loss at step  1000 :  13.6075960521698\n",
      "Epoch:  248  Average loss at step  2000 :  13.625360203266144\n",
      "Epoch:  248  Average loss at step  3000 :  13.59775841331482\n",
      "Epoch:  248  Average loss at step  3222 :  13.353693883413442\n",
      "248 4 33.364070653915405\n",
      "248 5 1.6689300537109375e-06\n",
      "Training time took 99.279595 seconds to run 1 epoch\n",
      "Epoch:  249  Average loss at step  1000 :  0.11453868854045868\n",
      "Epoch:  249  Average loss at step  2000 :  0.11900710278749466\n",
      "Epoch:  249  Average loss at step  3000 :  0.13002637499570846\n",
      "Epoch:  249  Average loss at step  3222 :  0.13532762892045233\n",
      "249 0 29.377787590026855\n",
      "Training time took 29.506417 seconds to run 1 epoch\n",
      "Epoch:  250  Average loss at step  1000 :  8.037266273021698\n",
      "Epoch:  250  Average loss at step  2000 :  8.039912734508514\n",
      "Epoch:  250  Average loss at step  3000 :  7.86579514503479\n",
      "Epoch:  250  Average loss at step  4000 :  8.34275370311737\n",
      "Epoch:  250  Average loss at step  5000 :  8.489801510810851\n",
      "Epoch:  250  Average loss at step  6000 :  7.5630096216201785\n",
      "Epoch:  250  Average loss at step  7000 :  8.290462641239166\n",
      "Epoch:  250  Average loss at step  8000 :  7.772830832481384\n",
      "Epoch:  250  Average loss at step  8472 :  8.260882940535623\n",
      "250 0 20.915167808532715\n",
      "Epoch:  250  Average loss at step  1000 :  2107.3173685302736\n",
      "Epoch:  250  Average loss at step  1491 :  2122.049699319086\n",
      "250 1 11.71463942527771\n",
      "Epoch:  250  Average loss at step  1000 :  2979.353435913086\n",
      "Epoch:  250  Average loss at step  2000 :  2992.5853195800782\n",
      "Epoch:  250  Average loss at step  2533 :  2973.3864113051604\n",
      "250 2 19.931681632995605\n",
      "Epoch:  250  Average loss at step  1000 :  72.70959024429321\n",
      "Epoch:  250  Average loss at step  1227 :  72.11670170612044\n",
      "250 3 12.629597425460815\n",
      "Epoch:  250  Average loss at step  1000 :  13.655461287021637\n",
      "Epoch:  250  Average loss at step  2000 :  13.465458261489868\n",
      "Epoch:  250  Average loss at step  3000 :  13.636032170772552\n",
      "Epoch:  250  Average loss at step  3222 :  13.20280496728487\n",
      "250 4 33.18476891517639\n",
      "250 5 1.1920928955078125e-06\n",
      "Training time took 99.027689 seconds to run 1 epoch\n",
      "Mean Rank:  185.05644  of  75000\n",
      "Hits @ 10:  0.83272\n",
      "Hits @ 1:  0.57764\n",
      "Testing time took 165.111073 seconds.\n",
      "\n",
      "Epoch:  251  Average loss at step  1000 :  0.11304470056295395\n",
      "Epoch:  251  Average loss at step  2000 :  0.11873241275548935\n",
      "Epoch:  251  Average loss at step  3000 :  0.1289384590983391\n",
      "Epoch:  251  Average loss at step  3222 :  0.1339232519142549\n",
      "251 0 29.442601442337036\n",
      "Training time took 29.550489 seconds to run 1 epoch\n",
      "Epoch:  252  Average loss at step  1000 :  8.036497138023377\n",
      "Epoch:  252  Average loss at step  2000 :  8.139947667121888\n",
      "Epoch:  252  Average loss at step  3000 :  8.108606540679931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  252  Average loss at step  4000 :  8.282483837604524\n",
      "Epoch:  252  Average loss at step  5000 :  8.166441194534302\n",
      "Epoch:  252  Average loss at step  6000 :  8.375498133659363\n",
      "Epoch:  252  Average loss at step  7000 :  8.211077908039092\n",
      "Epoch:  252  Average loss at step  8000 :  8.377237175941467\n",
      "Epoch:  252  Average loss at step  8472 :  8.053592230811102\n",
      "252 0 20.7652485370636\n",
      "Epoch:  252  Average loss at step  1000 :  2113.103774291992\n",
      "Epoch:  252  Average loss at step  1491 :  2082.321655902525\n",
      "252 1 11.671736717224121\n",
      "Epoch:  252  Average loss at step  1000 :  2960.7808286132813\n",
      "Epoch:  252  Average loss at step  2000 :  2957.0499296875\n",
      "Epoch:  252  Average loss at step  2533 :  2991.806591572952\n",
      "252 2 19.941138982772827\n",
      "Epoch:  252  Average loss at step  1000 :  72.31040685272217\n",
      "Epoch:  252  Average loss at step  1227 :  71.69943706976773\n",
      "252 3 12.663721799850464\n",
      "Epoch:  252  Average loss at step  1000 :  13.642633593082428\n",
      "Epoch:  252  Average loss at step  2000 :  13.412117255687713\n",
      "Epoch:  252  Average loss at step  3000 :  13.786939580917359\n",
      "Epoch:  252  Average loss at step  3222 :  13.34134534628173\n",
      "252 4 33.27010774612427\n",
      "252 5 1.430511474609375e-06\n",
      "Training time took 98.947635 seconds to run 1 epoch\n",
      "Epoch:  253  Average loss at step  1000 :  0.11274296164512634\n",
      "Epoch:  253  Average loss at step  2000 :  0.1172660745382309\n",
      "Epoch:  253  Average loss at step  3000 :  0.128155493080616\n",
      "Epoch:  253  Average loss at step  3222 :  0.1342206566552002\n",
      "253 0 29.395785093307495\n",
      "Training time took 29.519901 seconds to run 1 epoch\n",
      "Epoch:  254  Average loss at step  1000 :  8.418476223945618\n",
      "Epoch:  254  Average loss at step  2000 :  8.528479090690613\n",
      "Epoch:  254  Average loss at step  3000 :  7.933939000129699\n",
      "Epoch:  254  Average loss at step  4000 :  7.904529180526733\n",
      "Epoch:  254  Average loss at step  5000 :  8.168052613258363\n",
      "Epoch:  254  Average loss at step  6000 :  8.089972920417786\n",
      "Epoch:  254  Average loss at step  7000 :  7.581123511314392\n",
      "Epoch:  254  Average loss at step  8000 :  8.237957892417908\n",
      "Epoch:  254  Average loss at step  8472 :  8.252482638689562\n",
      "254 0 21.32929825782776\n",
      "Epoch:  254  Average loss at step  1000 :  2136.5236430664063\n",
      "Epoch:  254  Average loss at step  1491 :  2100.8287861335884\n",
      "254 1 11.714884042739868\n",
      "Epoch:  254  Average loss at step  1000 :  2986.0520615234377\n",
      "Epoch:  254  Average loss at step  2000 :  2969.3872717285158\n",
      "Epoch:  254  Average loss at step  2533 :  3021.2045589900576\n",
      "254 2 19.910696506500244\n",
      "Epoch:  254  Average loss at step  1000 :  72.79060893249512\n",
      "Epoch:  254  Average loss at step  1227 :  71.1689691252853\n",
      "254 3 12.722070217132568\n",
      "Epoch:  254  Average loss at step  1000 :  13.40071301317215\n",
      "Epoch:  254  Average loss at step  2000 :  13.536152075767516\n",
      "Epoch:  254  Average loss at step  3000 :  13.356430850982665\n",
      "Epoch:  254  Average loss at step  3222 :  13.367308729240278\n",
      "254 4 33.12250876426697\n",
      "254 5 1.430511474609375e-06\n",
      "Training time took 99.439825 seconds to run 1 epoch\n",
      "Epoch:  255  Average loss at step  1000 :  0.11205155074596405\n",
      "Epoch:  255  Average loss at step  2000 :  0.11669188320636749\n",
      "Epoch:  255  Average loss at step  3000 :  0.12751743710041047\n",
      "Epoch:  255  Average loss at step  3222 :  0.13286484791109504\n",
      "255 0 29.43657350540161\n",
      "Training time took 29.556339 seconds to run 1 epoch\n",
      "Epoch:  256  Average loss at step  1000 :  8.004743105888366\n",
      "Epoch:  256  Average loss at step  2000 :  8.555201846122742\n",
      "Epoch:  256  Average loss at step  3000 :  7.956569152355194\n",
      "Epoch:  256  Average loss at step  4000 :  7.8828379211425785\n",
      "Epoch:  256  Average loss at step  5000 :  8.127086598873138\n",
      "Epoch:  256  Average loss at step  6000 :  8.508313045501708\n",
      "Epoch:  256  Average loss at step  7000 :  8.522433885097504\n",
      "Epoch:  256  Average loss at step  8000 :  8.225659547328949\n",
      "Epoch:  256  Average loss at step  8472 :  7.025783049129811\n",
      "256 0 20.66403889656067\n",
      "Epoch:  256  Average loss at step  1000 :  2146.3603432617188\n",
      "Epoch:  256  Average loss at step  1491 :  2142.3804294273114\n",
      "256 1 11.703901767730713\n",
      "Epoch:  256  Average loss at step  1000 :  2985.6703305664064\n",
      "Epoch:  256  Average loss at step  2000 :  2986.4890141601563\n",
      "Epoch:  256  Average loss at step  2533 :  2979.8031777155807\n",
      "256 2 19.93148636817932\n",
      "Epoch:  256  Average loss at step  1000 :  73.27079452896118\n",
      "Epoch:  256  Average loss at step  1227 :  72.25689411100221\n",
      "256 3 12.628593683242798\n",
      "Epoch:  256  Average loss at step  1000 :  13.287819052696229\n",
      "Epoch:  256  Average loss at step  2000 :  13.451516836166382\n",
      "Epoch:  256  Average loss at step  3000 :  13.26644966840744\n",
      "Epoch:  256  Average loss at step  3222 :  13.50525168224155\n",
      "256 4 33.31039333343506\n",
      "256 5 1.430511474609375e-06\n",
      "Training time took 98.867389 seconds to run 1 epoch\n",
      "Epoch:  257  Average loss at step  1000 :  0.11216857773065567\n",
      "Epoch:  257  Average loss at step  2000 :  0.11623981577157974\n",
      "Epoch:  257  Average loss at step  3000 :  0.12548072707653046\n",
      "Epoch:  257  Average loss at step  3222 :  0.13218974352614676\n",
      "257 0 29.35079050064087\n",
      "Training time took 29.471902 seconds to run 1 epoch\n",
      "Epoch:  258  Average loss at step  1000 :  8.084975412368774\n",
      "Epoch:  258  Average loss at step  2000 :  8.647935470104217\n",
      "Epoch:  258  Average loss at step  3000 :  9.199446232795715\n",
      "Epoch:  258  Average loss at step  4000 :  8.699791529178619\n",
      "Epoch:  258  Average loss at step  5000 :  8.330606584548951\n",
      "Epoch:  258  Average loss at step  6000 :  7.946403592586518\n",
      "Epoch:  258  Average loss at step  7000 :  8.241082250118255\n",
      "Epoch:  258  Average loss at step  8000 :  7.995607577323914\n",
      "Epoch:  258  Average loss at step  8472 :  8.468186946894964\n",
      "258 0 20.63758158683777\n",
      "Epoch:  258  Average loss at step  1000 :  2140.777966430664\n",
      "Epoch:  258  Average loss at step  1491 :  2138.1477113988376\n",
      "258 1 11.711611032485962\n",
      "Epoch:  258  Average loss at step  1000 :  3005.763286743164\n",
      "Epoch:  258  Average loss at step  2000 :  2996.358514770508\n",
      "Epoch:  258  Average loss at step  2533 :  2996.9247040872096\n",
      "258 2 19.93816637992859\n",
      "Epoch:  258  Average loss at step  1000 :  72.0813948135376\n",
      "Epoch:  258  Average loss at step  1227 :  72.59938992363021\n",
      "258 3 12.688150644302368\n",
      "Epoch:  258  Average loss at step  1000 :  13.030511657714843\n",
      "Epoch:  258  Average loss at step  2000 :  13.027612074851989\n",
      "Epoch:  258  Average loss at step  3000 :  13.168604597091674\n",
      "Epoch:  258  Average loss at step  3222 :  13.202119306184514\n",
      "258 4 33.179882287979126\n",
      "258 5 1.430511474609375e-06\n",
      "Training time took 98.790915 seconds to run 1 epoch\n",
      "Epoch:  259  Average loss at step  1000 :  0.10992547059059143\n",
      "Epoch:  259  Average loss at step  2000 :  0.1152114863395691\n",
      "Epoch:  259  Average loss at step  3000 :  0.12521797758340836\n",
      "Epoch:  259  Average loss at step  3222 :  0.13189019924855272\n",
      "259 0 29.319053173065186\n",
      "Training time took 29.441862 seconds to run 1 epoch\n",
      "Epoch:  260  Average loss at step  1000 :  7.816941778182984\n",
      "Epoch:  260  Average loss at step  2000 :  8.309306257247925\n",
      "Epoch:  260  Average loss at step  3000 :  7.998377088546753\n",
      "Epoch:  260  Average loss at step  4000 :  7.938720781326294\n",
      "Epoch:  260  Average loss at step  5000 :  8.095902781486512\n",
      "Epoch:  260  Average loss at step  6000 :  8.010595252990722\n",
      "Epoch:  260  Average loss at step  7000 :  8.46475619649887\n",
      "Epoch:  260  Average loss at step  8000 :  8.39663777065277\n",
      "Epoch:  260  Average loss at step  8472 :  7.729120713118952\n",
      "260 0 20.611247301101685\n",
      "Epoch:  260  Average loss at step  1000 :  2130.14027734375\n",
      "Epoch:  260  Average loss at step  1491 :  2114.839581612004\n",
      "260 1 11.726074695587158\n",
      "Epoch:  260  Average loss at step  1000 :  3020.647979003906\n",
      "Epoch:  260  Average loss at step  2000 :  3010.660446411133\n",
      "Epoch:  260  Average loss at step  2533 :  3036.541904517862\n",
      "260 2 19.879962682724\n",
      "Epoch:  260  Average loss at step  1000 :  72.24683612060547\n",
      "Epoch:  260  Average loss at step  1227 :  71.69769567485501\n",
      "260 3 12.645137548446655\n",
      "Epoch:  260  Average loss at step  1000 :  13.194836473464965\n",
      "Epoch:  260  Average loss at step  2000 :  13.112743120670318\n",
      "Epoch:  260  Average loss at step  3000 :  12.953739604949952\n",
      "Epoch:  260  Average loss at step  3222 :  13.036582936532964\n",
      "260 4 33.21632623672485\n",
      "260 5 1.430511474609375e-06\n",
      "Training time took 98.733588 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank:  183.04312  of  75000\n",
      "Hits @ 10:  0.83664\n",
      "Hits @ 1:  0.57876\n",
      "Testing time took 165.117981 seconds.\n",
      "\n",
      "Epoch:  261  Average loss at step  1000 :  0.110536778986454\n",
      "Epoch:  261  Average loss at step  2000 :  0.11504405957460404\n",
      "Epoch:  261  Average loss at step  3000 :  0.12472812974452972\n",
      "Epoch:  261  Average loss at step  3222 :  0.13081213292242236\n",
      "261 0 29.39265751838684\n",
      "Training time took 29.503912 seconds to run 1 epoch\n",
      "Epoch:  262  Average loss at step  1000 :  8.143665877342224\n",
      "Epoch:  262  Average loss at step  2000 :  8.126575091362\n",
      "Epoch:  262  Average loss at step  3000 :  7.895827571868897\n",
      "Epoch:  262  Average loss at step  4000 :  7.986885884284973\n",
      "Epoch:  262  Average loss at step  5000 :  8.11832788181305\n",
      "Epoch:  262  Average loss at step  6000 :  7.93530002784729\n",
      "Epoch:  262  Average loss at step  7000 :  8.102011209487914\n",
      "Epoch:  262  Average loss at step  8000 :  8.166792984962463\n",
      "Epoch:  262  Average loss at step  8472 :  8.34453990446186\n",
      "262 0 20.60435175895691\n",
      "Epoch:  262  Average loss at step  1000 :  2155.0883736572264\n",
      "Epoch:  262  Average loss at step  1491 :  2139.0894759153703\n",
      "262 1 11.742165327072144\n",
      "Epoch:  262  Average loss at step  1000 :  2999.250487548828\n",
      "Epoch:  262  Average loss at step  2000 :  3016.6263455810545\n",
      "Epoch:  262  Average loss at step  2533 :  3017.4881924974543\n",
      "262 2 19.938027143478394\n",
      "Epoch:  262  Average loss at step  1000 :  71.7202834968567\n",
      "Epoch:  262  Average loss at step  1227 :  73.152418015005\n",
      "262 3 12.582797288894653\n",
      "Epoch:  262  Average loss at step  1000 :  12.792389523506165\n",
      "Epoch:  262  Average loss at step  2000 :  12.86755037689209\n",
      "Epoch:  262  Average loss at step  3000 :  12.907065437316895\n",
      "Epoch:  262  Average loss at step  3222 :  13.148252954119744\n",
      "262 4 33.2807412147522\n",
      "262 5 1.430511474609375e-06\n",
      "Training time took 98.782328 seconds to run 1 epoch\n",
      "Epoch:  263  Average loss at step  1000 :  0.10892219108343125\n",
      "Epoch:  263  Average loss at step  2000 :  0.11386713469028473\n",
      "Epoch:  263  Average loss at step  3000 :  0.1240052125453949\n",
      "Epoch:  263  Average loss at step  3222 :  0.129119184531983\n",
      "263 0 29.3702335357666\n",
      "Training time took 29.496516 seconds to run 1 epoch\n",
      "Epoch:  264  Average loss at step  1000 :  8.55483566379547\n",
      "Epoch:  264  Average loss at step  2000 :  8.020024243354797\n",
      "Epoch:  264  Average loss at step  3000 :  7.880274810791016\n",
      "Epoch:  264  Average loss at step  4000 :  8.381651655197144\n",
      "Epoch:  264  Average loss at step  5000 :  8.402054738044738\n",
      "Epoch:  264  Average loss at step  6000 :  7.918475392341613\n",
      "Epoch:  264  Average loss at step  7000 :  8.124232298374176\n",
      "Epoch:  264  Average loss at step  8000 :  8.377208629131317\n",
      "Epoch:  264  Average loss at step  8472 :  7.758140851350253\n",
      "264 0 20.261291980743408\n",
      "Epoch:  264  Average loss at step  1000 :  2159.1337349853516\n",
      "Epoch:  264  Average loss at step  1491 :  2144.118297120707\n",
      "264 1 11.692740678787231\n",
      "Epoch:  264  Average loss at step  1000 :  3021.133174926758\n",
      "Epoch:  264  Average loss at step  2000 :  3016.7679331054687\n",
      "Epoch:  264  Average loss at step  2533 :  3014.2745147453857\n",
      "264 2 19.86729383468628\n",
      "Epoch:  264  Average loss at step  1000 :  72.38051050186158\n",
      "Epoch:  264  Average loss at step  1227 :  72.72000413149873\n",
      "264 3 12.714150667190552\n",
      "Epoch:  264  Average loss at step  1000 :  12.79140288734436\n",
      "Epoch:  264  Average loss at step  2000 :  12.792247626304626\n",
      "Epoch:  264  Average loss at step  3000 :  12.892580307483673\n",
      "Epoch:  264  Average loss at step  3222 :  12.922654980075642\n",
      "264 4 33.19794845581055\n",
      "264 5 1.6689300537109375e-06\n",
      "Training time took 98.381397 seconds to run 1 epoch\n",
      "Epoch:  265  Average loss at step  1000 :  0.10857463490962982\n",
      "Epoch:  265  Average loss at step  2000 :  0.11343868488073348\n",
      "Epoch:  265  Average loss at step  3000 :  0.12294187438488006\n",
      "Epoch:  265  Average loss at step  3222 :  0.1307467943301892\n",
      "265 0 29.4142906665802\n",
      "Training time took 29.537102 seconds to run 1 epoch\n",
      "Epoch:  266  Average loss at step  1000 :  7.950561127662659\n",
      "Epoch:  266  Average loss at step  2000 :  8.514998578071594\n",
      "Epoch:  266  Average loss at step  3000 :  7.818093502044678\n",
      "Epoch:  266  Average loss at step  4000 :  8.122708215713502\n",
      "Epoch:  266  Average loss at step  5000 :  8.296372333049774\n",
      "Epoch:  266  Average loss at step  6000 :  8.037245704650879\n",
      "Epoch:  266  Average loss at step  7000 :  7.695524875640869\n",
      "Epoch:  266  Average loss at step  8000 :  8.089266764640808\n",
      "Epoch:  266  Average loss at step  8472 :  8.314950905025908\n",
      "266 0 20.690332174301147\n",
      "Epoch:  266  Average loss at step  1000 :  2153.948135864258\n",
      "Epoch:  266  Average loss at step  1491 :  2147.9469433432623\n",
      "266 1 11.745763540267944\n",
      "Epoch:  266  Average loss at step  1000 :  3021.64540625\n",
      "Epoch:  266  Average loss at step  2000 :  3019.782622680664\n",
      "Epoch:  266  Average loss at step  2533 :  3028.314529038666\n",
      "266 2 19.82693576812744\n",
      "Epoch:  266  Average loss at step  1000 :  72.1070771484375\n",
      "Epoch:  266  Average loss at step  1227 :  72.0393634859589\n",
      "266 3 12.699036836624146\n",
      "Epoch:  266  Average loss at step  1000 :  12.808491700649261\n",
      "Epoch:  266  Average loss at step  2000 :  12.623343336582185\n",
      "Epoch:  266  Average loss at step  3000 :  12.587252861022948\n",
      "Epoch:  266  Average loss at step  3222 :  12.699054214665553\n",
      "266 4 33.29995059967041\n",
      "266 5 1.430511474609375e-06\n",
      "Training time took 98.913908 seconds to run 1 epoch\n",
      "Epoch:  267  Average loss at step  1000 :  0.10703729295730591\n",
      "Epoch:  267  Average loss at step  2000 :  0.11233663821220398\n",
      "Epoch:  267  Average loss at step  3000 :  0.12216467773914337\n",
      "Epoch:  267  Average loss at step  3222 :  0.12768850787750413\n",
      "267 0 29.42513871192932\n",
      "Training time took 29.548477 seconds to run 1 epoch\n",
      "Epoch:  268  Average loss at step  1000 :  7.906822164535522\n",
      "Epoch:  268  Average loss at step  2000 :  7.876668847084045\n",
      "Epoch:  268  Average loss at step  3000 :  7.877043664455414\n",
      "Epoch:  268  Average loss at step  4000 :  7.996817810058594\n",
      "Epoch:  268  Average loss at step  5000 :  8.321795303344727\n",
      "Epoch:  268  Average loss at step  6000 :  8.16817672252655\n",
      "Epoch:  268  Average loss at step  7000 :  8.338975044250489\n",
      "Epoch:  268  Average loss at step  8000 :  8.510370777606964\n",
      "Epoch:  268  Average loss at step  8472 :  8.61881211659969\n",
      "268 0 20.535783767700195\n",
      "Epoch:  268  Average loss at step  1000 :  2152.2676872558595\n",
      "Epoch:  268  Average loss at step  1491 :  2147.281141080847\n",
      "268 1 11.725260734558105\n",
      "Epoch:  268  Average loss at step  1000 :  3025.9573898925782\n",
      "Epoch:  268  Average loss at step  2000 :  3018.256021850586\n",
      "Epoch:  268  Average loss at step  2533 :  3047.049397009457\n",
      "268 2 19.899438858032227\n",
      "Epoch:  268  Average loss at step  1000 :  72.07555331802368\n",
      "Epoch:  268  Average loss at step  1227 :  72.83392830583338\n",
      "268 3 12.655527591705322\n",
      "Epoch:  268  Average loss at step  1000 :  12.78489175081253\n",
      "Epoch:  268  Average loss at step  2000 :  12.42669865512848\n",
      "Epoch:  268  Average loss at step  3000 :  12.57731324481964\n",
      "Epoch:  268  Average loss at step  3222 :  12.640561240096883\n",
      "268 4 33.32458758354187\n",
      "268 5 1.6689300537109375e-06\n",
      "Training time took 98.780566 seconds to run 1 epoch\n",
      "Epoch:  269  Average loss at step  1000 :  0.10701515901088715\n",
      "Epoch:  269  Average loss at step  2000 :  0.11197093826532364\n",
      "Epoch:  269  Average loss at step  3000 :  0.1219874324798584\n",
      "Epoch:  269  Average loss at step  3222 :  0.1273360140359365\n",
      "269 0 29.456127882003784\n",
      "Training time took 29.579164 seconds to run 1 epoch\n",
      "Epoch:  270  Average loss at step  1000 :  8.296592650413514\n",
      "Epoch:  270  Average loss at step  2000 :  8.408581441402434\n",
      "Epoch:  270  Average loss at step  3000 :  8.155646047592164\n",
      "Epoch:  270  Average loss at step  4000 :  8.181344325065613\n",
      "Epoch:  270  Average loss at step  5000 :  8.21094452571869\n",
      "Epoch:  270  Average loss at step  6000 :  8.029678411006927\n",
      "Epoch:  270  Average loss at step  7000 :  7.81393346452713\n",
      "Epoch:  270  Average loss at step  8000 :  8.250200931549072\n",
      "Epoch:  270  Average loss at step  8472 :  8.325617845958746\n",
      "270 0 21.058699131011963\n",
      "Epoch:  270  Average loss at step  1000 :  2183.6795612792966\n",
      "Epoch:  270  Average loss at step  1491 :  2181.822506359104\n",
      "270 1 11.674108505249023\n",
      "Epoch:  270  Average loss at step  1000 :  3016.063432373047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  270  Average loss at step  2000 :  3042.455698852539\n",
      "Epoch:  270  Average loss at step  2533 :  3042.7004791169143\n",
      "270 2 19.939666032791138\n",
      "Epoch:  270  Average loss at step  1000 :  71.62923652267456\n",
      "Epoch:  270  Average loss at step  1227 :  70.70381067614018\n",
      "270 3 12.686767101287842\n",
      "Epoch:  270  Average loss at step  1000 :  12.377300099849702\n",
      "Epoch:  270  Average loss at step  2000 :  12.384508971214295\n",
      "Epoch:  270  Average loss at step  3000 :  12.475585448265075\n",
      "Epoch:  270  Average loss at step  3222 :  12.247754017095914\n",
      "270 4 33.33466911315918\n",
      "270 5 1.430511474609375e-06\n",
      "Training time took 99.330238 seconds to run 1 epoch\n",
      "Mean Rank:  180.43312  of  75000\n",
      "Hits @ 10:  0.83816\n",
      "Hits @ 1:  0.58444\n",
      "Testing time took 165.028376 seconds.\n",
      "\n",
      "Epoch:  271  Average loss at step  1000 :  0.10656282609701156\n",
      "Epoch:  271  Average loss at step  2000 :  0.11156445670127868\n",
      "Epoch:  271  Average loss at step  3000 :  0.12043350785970688\n",
      "Epoch:  271  Average loss at step  3222 :  0.1255494842548236\n",
      "271 0 29.452370643615723\n",
      "Training time took 29.560641 seconds to run 1 epoch\n",
      "Epoch:  272  Average loss at step  1000 :  8.137430032730103\n",
      "Epoch:  272  Average loss at step  2000 :  8.236996752738953\n",
      "Epoch:  272  Average loss at step  3000 :  8.598495028495789\n",
      "Epoch:  272  Average loss at step  4000 :  7.864540157318115\n",
      "Epoch:  272  Average loss at step  5000 :  8.045736924171448\n",
      "Epoch:  272  Average loss at step  6000 :  7.885796983718872\n",
      "Epoch:  272  Average loss at step  7000 :  8.204513021469117\n",
      "Epoch:  272  Average loss at step  8000 :  8.663011773586273\n",
      "Epoch:  272  Average loss at step  8472 :  7.983891276156404\n",
      "272 0 20.432230234146118\n",
      "Epoch:  272  Average loss at step  1000 :  2145.7316110839843\n",
      "Epoch:  272  Average loss at step  1491 :  2127.7381137187963\n",
      "272 1 11.677748203277588\n",
      "Epoch:  272  Average loss at step  1000 :  3092.185949951172\n",
      "Epoch:  272  Average loss at step  2000 :  3035.26569128418\n",
      "Epoch:  272  Average loss at step  2533 :  3044.254270657621\n",
      "272 2 19.93840456008911\n",
      "Epoch:  272  Average loss at step  1000 :  71.44378730010986\n",
      "Epoch:  272  Average loss at step  1227 :  70.78322347768137\n",
      "272 3 12.750607252120972\n",
      "Epoch:  272  Average loss at step  1000 :  12.592057250022888\n",
      "Epoch:  272  Average loss at step  2000 :  12.351973516464234\n",
      "Epoch:  272  Average loss at step  3000 :  12.33774759054184\n",
      "Epoch:  272  Average loss at step  3222 :  12.229225927794705\n",
      "272 4 33.18614482879639\n",
      "272 5 1.430511474609375e-06\n",
      "Training time took 98.617762 seconds to run 1 epoch\n",
      "Epoch:  273  Average loss at step  1000 :  0.1052614198923111\n",
      "Epoch:  273  Average loss at step  2000 :  0.11067610496282577\n",
      "Epoch:  273  Average loss at step  3000 :  0.12053001052141189\n",
      "Epoch:  273  Average loss at step  3222 :  0.12575644736772928\n",
      "273 0 29.33362913131714\n",
      "Training time took 29.454401 seconds to run 1 epoch\n",
      "Epoch:  274  Average loss at step  1000 :  7.955590408325195\n",
      "Epoch:  274  Average loss at step  2000 :  8.199698373317718\n",
      "Epoch:  274  Average loss at step  3000 :  8.237393074035644\n",
      "Epoch:  274  Average loss at step  4000 :  8.404205127716065\n",
      "Epoch:  274  Average loss at step  5000 :  7.955765778541565\n",
      "Epoch:  274  Average loss at step  6000 :  8.094907782554627\n",
      "Epoch:  274  Average loss at step  7000 :  7.733334860801697\n",
      "Epoch:  274  Average loss at step  8000 :  8.131044212341308\n",
      "Epoch:  274  Average loss at step  8472 :  7.9674461752999735\n",
      "274 0 20.40061354637146\n",
      "Epoch:  274  Average loss at step  1000 :  2173.949496948242\n",
      "Epoch:  274  Average loss at step  1491 :  2154.474364558044\n",
      "274 1 11.753834247589111\n",
      "Epoch:  274  Average loss at step  1000 :  3052.230392089844\n",
      "Epoch:  274  Average loss at step  2000 :  3059.338678100586\n",
      "Epoch:  274  Average loss at step  2533 :  3031.0600242619053\n",
      "274 2 19.92442536354065\n",
      "Epoch:  274  Average loss at step  1000 :  71.56278089141846\n",
      "Epoch:  274  Average loss at step  1227 :  71.95710395795822\n",
      "274 3 12.57856822013855\n",
      "Epoch:  274  Average loss at step  1000 :  12.553275017261505\n",
      "Epoch:  274  Average loss at step  2000 :  12.38488755941391\n",
      "Epoch:  274  Average loss at step  3000 :  12.468634551525115\n",
      "Epoch:  274  Average loss at step  3222 :  12.345544238192959\n",
      "274 4 33.209166049957275\n",
      "274 5 1.6689300537109375e-06\n",
      "Training time took 98.492369 seconds to run 1 epoch\n",
      "Epoch:  275  Average loss at step  1000 :  0.10497384661436081\n",
      "Epoch:  275  Average loss at step  2000 :  0.10964102643728256\n",
      "Epoch:  275  Average loss at step  3000 :  0.11898503702878951\n",
      "Epoch:  275  Average loss at step  3222 :  0.12743598202286827\n",
      "275 0 29.404011964797974\n",
      "Training time took 29.524409 seconds to run 1 epoch\n",
      "Epoch:  276  Average loss at step  1000 :  8.299412564277649\n",
      "Epoch:  276  Average loss at step  2000 :  7.949603273391723\n",
      "Epoch:  276  Average loss at step  3000 :  7.975142680168152\n",
      "Epoch:  276  Average loss at step  4000 :  8.247694734573365\n",
      "Epoch:  276  Average loss at step  5000 :  8.017761254310608\n",
      "Epoch:  276  Average loss at step  6000 :  8.271481287002564\n",
      "Epoch:  276  Average loss at step  7000 :  8.146214868545533\n",
      "Epoch:  276  Average loss at step  8000 :  8.456070650577546\n",
      "Epoch:  276  Average loss at step  8472 :  7.978727493619662\n",
      "276 0 20.477341413497925\n",
      "Epoch:  276  Average loss at step  1000 :  2184.18875579834\n",
      "Epoch:  276  Average loss at step  1491 :  2175.0039336613036\n",
      "276 1 11.667941808700562\n",
      "Epoch:  276  Average loss at step  1000 :  3054.1092749023437\n",
      "Epoch:  276  Average loss at step  2000 :  3078.5961612548826\n",
      "Epoch:  276  Average loss at step  2533 :  3062.113439115919\n",
      "276 2 19.89029359817505\n",
      "Epoch:  276  Average loss at step  1000 :  71.07823303222656\n",
      "Epoch:  276  Average loss at step  1227 :  71.49054680892144\n",
      "276 3 12.673633575439453\n",
      "Epoch:  276  Average loss at step  1000 :  12.42617744731903\n",
      "Epoch:  276  Average loss at step  2000 :  12.175330519676208\n",
      "Epoch:  276  Average loss at step  3000 :  12.308149321079254\n",
      "Epoch:  276  Average loss at step  3222 :  12.579634319166992\n",
      "276 4 33.23104906082153\n",
      "276 5 1.430511474609375e-06\n",
      "Training time took 98.561894 seconds to run 1 epoch\n",
      "Epoch:  277  Average loss at step  1000 :  0.1045200490951538\n",
      "Epoch:  277  Average loss at step  2000 :  0.10942979246377944\n",
      "Epoch:  277  Average loss at step  3000 :  0.11799698776006698\n",
      "Epoch:  277  Average loss at step  3222 :  0.12393020501010231\n",
      "277 0 29.441498041152954\n",
      "Training time took 29.567863 seconds to run 1 epoch\n",
      "Epoch:  278  Average loss at step  1000 :  8.063415427207946\n",
      "Epoch:  278  Average loss at step  2000 :  8.12061118555069\n",
      "Epoch:  278  Average loss at step  3000 :  7.8333073387146\n",
      "Epoch:  278  Average loss at step  4000 :  8.632346601486207\n",
      "Epoch:  278  Average loss at step  5000 :  7.566792500495911\n",
      "Epoch:  278  Average loss at step  6000 :  8.159828499794006\n",
      "Epoch:  278  Average loss at step  7000 :  7.9601769418716435\n",
      "Epoch:  278  Average loss at step  8000 :  8.413582167625428\n",
      "Epoch:  278  Average loss at step  8472 :  8.616561830147514\n",
      "278 0 20.75735306739807\n",
      "Epoch:  278  Average loss at step  1000 :  2209.559482116699\n",
      "Epoch:  278  Average loss at step  1491 :  2159.402124360111\n",
      "278 1 11.733195066452026\n",
      "Epoch:  278  Average loss at step  1000 :  3072.4575063476564\n",
      "Epoch:  278  Average loss at step  2000 :  3048.395913574219\n",
      "Epoch:  278  Average loss at step  2533 :  3061.4262112010692\n",
      "278 2 19.882496118545532\n",
      "Epoch:  278  Average loss at step  1000 :  71.73331478500366\n",
      "Epoch:  278  Average loss at step  1227 :  72.75054715552423\n",
      "278 3 12.688857793807983\n",
      "Epoch:  278  Average loss at step  1000 :  12.263329251289367\n",
      "Epoch:  278  Average loss at step  2000 :  11.978776859283448\n",
      "Epoch:  278  Average loss at step  3000 :  12.012499606132508\n",
      "Epoch:  278  Average loss at step  3222 :  11.96560709027526\n",
      "278 4 33.12752628326416\n",
      "278 5 1.430511474609375e-06\n",
      "Training time took 98.833096 seconds to run 1 epoch\n",
      "Epoch:  279  Average loss at step  1000 :  0.10340169316530227\n",
      "Epoch:  279  Average loss at step  2000 :  0.10866804105043411\n",
      "Epoch:  279  Average loss at step  3000 :  0.11785469436645508\n",
      "Epoch:  279  Average loss at step  3222 :  0.123045964347776\n",
      "279 0 29.390475511550903\n",
      "Training time took 29.513708 seconds to run 1 epoch\n",
      "Epoch:  280  Average loss at step  1000 :  8.254321185588836\n",
      "Epoch:  280  Average loss at step  2000 :  7.8780817804336545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  280  Average loss at step  3000 :  8.26392919063568\n",
      "Epoch:  280  Average loss at step  4000 :  8.327359589576721\n",
      "Epoch:  280  Average loss at step  5000 :  8.03528022480011\n",
      "Epoch:  280  Average loss at step  6000 :  8.222824349403382\n",
      "Epoch:  280  Average loss at step  7000 :  7.747272566318512\n",
      "Epoch:  280  Average loss at step  8000 :  8.183005640029908\n",
      "Epoch:  280  Average loss at step  8472 :  8.468266036574116\n",
      "280 0 21.154597759246826\n",
      "Epoch:  280  Average loss at step  1000 :  2174.006417480469\n",
      "Epoch:  280  Average loss at step  1491 :  2158.543480444243\n",
      "280 1 11.705618143081665\n",
      "Epoch:  280  Average loss at step  1000 :  3081.234433959961\n",
      "Epoch:  280  Average loss at step  2000 :  3079.586890991211\n",
      "Epoch:  280  Average loss at step  2533 :  3051.2228097475795\n",
      "280 2 19.87128520011902\n",
      "Epoch:  280  Average loss at step  1000 :  71.4520799369812\n",
      "Epoch:  280  Average loss at step  1227 :  70.51297190876524\n",
      "280 3 12.549766063690186\n",
      "Epoch:  280  Average loss at step  1000 :  12.022328959941865\n",
      "Epoch:  280  Average loss at step  2000 :  11.860590791225434\n",
      "Epoch:  280  Average loss at step  3000 :  11.88438221025467\n",
      "Epoch:  280  Average loss at step  3222 :  11.780247812689502\n",
      "280 4 33.303096771240234\n",
      "280 5 1.430511474609375e-06\n",
      "Training time took 99.219149 seconds to run 1 epoch\n",
      "Mean Rank:  180.22328  of  75000\n",
      "Hits @ 10:  0.83968\n",
      "Hits @ 1:  0.58656\n",
      "Testing time took 164.72226 seconds.\n",
      "\n",
      "Epoch:  281  Average loss at step  1000 :  0.10329145181179046\n",
      "Epoch:  281  Average loss at step  2000 :  0.10808587443828582\n",
      "Epoch:  281  Average loss at step  3000 :  0.11723741710186004\n",
      "Epoch:  281  Average loss at step  3222 :  0.12279316597325769\n",
      "281 0 29.47888970375061\n",
      "Training time took 29.587802 seconds to run 1 epoch\n",
      "Epoch:  282  Average loss at step  1000 :  8.174082333564758\n",
      "Epoch:  282  Average loss at step  2000 :  7.831372430801392\n",
      "Epoch:  282  Average loss at step  3000 :  7.867774753570557\n",
      "Epoch:  282  Average loss at step  4000 :  8.139811585426331\n",
      "Epoch:  282  Average loss at step  5000 :  8.077923455238341\n",
      "Epoch:  282  Average loss at step  6000 :  7.792569190979004\n",
      "Epoch:  282  Average loss at step  7000 :  8.023443307876587\n",
      "Epoch:  282  Average loss at step  8000 :  7.962393001556396\n",
      "Epoch:  282  Average loss at step  8472 :  8.432443550449545\n",
      "282 0 20.3590190410614\n",
      "Epoch:  282  Average loss at step  1000 :  2199.4553122558596\n",
      "Epoch:  282  Average loss at step  1491 :  2156.1873978441586\n",
      "282 1 11.702406883239746\n",
      "Epoch:  282  Average loss at step  1000 :  3076.618051635742\n",
      "Epoch:  282  Average loss at step  2000 :  3087.825611328125\n",
      "Epoch:  282  Average loss at step  2533 :  3080.484806401064\n",
      "282 2 19.936911821365356\n",
      "Epoch:  282  Average loss at step  1000 :  71.01559783172607\n",
      "Epoch:  282  Average loss at step  1227 :  71.97967230071934\n",
      "282 3 12.617196083068848\n",
      "Epoch:  282  Average loss at step  1000 :  11.945029882907868\n",
      "Epoch:  282  Average loss at step  2000 :  11.918606124401093\n",
      "Epoch:  282  Average loss at step  3000 :  11.675450316429139\n",
      "Epoch:  282  Average loss at step  3222 :  11.597892490830484\n",
      "282 4 33.219993591308594\n",
      "282 5 9.5367431640625e-07\n",
      "Training time took 98.481194 seconds to run 1 epoch\n",
      "Epoch:  283  Average loss at step  1000 :  0.10251525402069092\n",
      "Epoch:  283  Average loss at step  2000 :  0.10707541012763977\n",
      "Epoch:  283  Average loss at step  3000 :  0.11617660611867904\n",
      "Epoch:  283  Average loss at step  3222 :  0.1235286503260823\n",
      "283 0 29.44762086868286\n",
      "Training time took 29.57636 seconds to run 1 epoch\n",
      "Epoch:  284  Average loss at step  1000 :  7.70643717622757\n",
      "Epoch:  284  Average loss at step  2000 :  8.120715648651123\n",
      "Epoch:  284  Average loss at step  3000 :  8.221350366592407\n",
      "Epoch:  284  Average loss at step  4000 :  7.983422626495361\n",
      "Epoch:  284  Average loss at step  5000 :  8.130746758937835\n",
      "Epoch:  284  Average loss at step  6000 :  8.282914437294007\n",
      "Epoch:  284  Average loss at step  7000 :  7.83153578710556\n",
      "Epoch:  284  Average loss at step  8000 :  8.232230778694152\n",
      "Epoch:  284  Average loss at step  8472 :  8.08642245296266\n",
      "284 0 20.390003442764282\n",
      "Epoch:  284  Average loss at step  1000 :  2193.1179164428713\n",
      "Epoch:  284  Average loss at step  1491 :  2165.1308848965546\n",
      "284 1 11.733182191848755\n",
      "Epoch:  284  Average loss at step  1000 :  3104.988786621094\n",
      "Epoch:  284  Average loss at step  2000 :  3072.6614514160156\n",
      "Epoch:  284  Average loss at step  2533 :  3120.2296029561107\n",
      "284 2 20.006179332733154\n",
      "Epoch:  284  Average loss at step  1000 :  71.27391438293456\n",
      "Epoch:  284  Average loss at step  1227 :  70.39166507425594\n",
      "284 3 12.651259899139404\n",
      "Epoch:  284  Average loss at step  1000 :  11.623575099945068\n",
      "Epoch:  284  Average loss at step  2000 :  11.826928413391114\n",
      "Epoch:  284  Average loss at step  3000 :  11.587174506664276\n",
      "Epoch:  284  Average loss at step  3222 :  11.95035444999305\n",
      "284 4 33.27854251861572\n",
      "284 5 1.1920928955078125e-06\n",
      "Training time took 98.71155 seconds to run 1 epoch\n",
      "Epoch:  285  Average loss at step  1000 :  0.10203768050670624\n",
      "Epoch:  285  Average loss at step  2000 :  0.10669365340471268\n",
      "Epoch:  285  Average loss at step  3000 :  0.11583450120687484\n",
      "Epoch:  285  Average loss at step  3222 :  0.12182793901982043\n",
      "285 0 29.39270305633545\n",
      "Training time took 29.516353 seconds to run 1 epoch\n",
      "Epoch:  286  Average loss at step  1000 :  8.133848256111145\n",
      "Epoch:  286  Average loss at step  2000 :  7.63945198059082\n",
      "Epoch:  286  Average loss at step  3000 :  8.098710750579833\n",
      "Epoch:  286  Average loss at step  4000 :  8.295223752975463\n",
      "Epoch:  286  Average loss at step  5000 :  7.7958571252822875\n",
      "Epoch:  286  Average loss at step  6000 :  8.517004036903382\n",
      "Epoch:  286  Average loss at step  7000 :  8.211661568641663\n",
      "Epoch:  286  Average loss at step  8000 :  8.307412083625794\n",
      "Epoch:  286  Average loss at step  8472 :  7.528194078418153\n",
      "286 0 21.180944442749023\n",
      "Epoch:  286  Average loss at step  1000 :  2193.4267653808593\n",
      "Epoch:  286  Average loss at step  1491 :  2219.7954858655544\n",
      "286 1 11.746174573898315\n",
      "Epoch:  286  Average loss at step  1000 :  3103.8796204833984\n",
      "Epoch:  286  Average loss at step  2000 :  3081.8158937988283\n",
      "Epoch:  286  Average loss at step  2533 :  3113.983179075272\n",
      "286 2 19.95591974258423\n",
      "Epoch:  286  Average loss at step  1000 :  70.91492966079711\n",
      "Epoch:  286  Average loss at step  1227 :  70.90496583762649\n",
      "286 3 12.642750978469849\n",
      "Epoch:  286  Average loss at step  1000 :  11.640709280490876\n",
      "Epoch:  286  Average loss at step  2000 :  11.70617376613617\n",
      "Epoch:  286  Average loss at step  3000 :  11.582843012809754\n",
      "Epoch:  286  Average loss at step  3222 :  11.740789010563919\n",
      "286 4 33.43146586418152\n",
      "286 5 1.1920928955078125e-06\n",
      "Training time took 99.59402 seconds to run 1 epoch\n",
      "Epoch:  287  Average loss at step  1000 :  0.10146443212032318\n",
      "Epoch:  287  Average loss at step  2000 :  0.10584297406673432\n",
      "Epoch:  287  Average loss at step  3000 :  0.11520285677909851\n",
      "Epoch:  287  Average loss at step  3222 :  0.11987317515573125\n",
      "287 0 29.37851071357727\n",
      "Training time took 29.500937 seconds to run 1 epoch\n",
      "Epoch:  288  Average loss at step  1000 :  8.16978281402588\n",
      "Epoch:  288  Average loss at step  2000 :  7.895058070182801\n",
      "Epoch:  288  Average loss at step  3000 :  8.310729744911194\n",
      "Epoch:  288  Average loss at step  4000 :  8.15985239982605\n",
      "Epoch:  288  Average loss at step  5000 :  8.432448609352111\n",
      "Epoch:  288  Average loss at step  6000 :  7.909240231990815\n",
      "Epoch:  288  Average loss at step  7000 :  7.490351163864136\n",
      "Epoch:  288  Average loss at step  8000 :  8.244652379989624\n",
      "Epoch:  288  Average loss at step  8472 :  8.547025185065259\n",
      "288 0 20.458868265151978\n",
      "Epoch:  288  Average loss at step  1000 :  2189.9621353149414\n",
      "Epoch:  288  Average loss at step  1491 :  2214.3295334397217\n",
      "288 1 11.727288961410522\n",
      "Epoch:  288  Average loss at step  1000 :  3105.5846159667967\n",
      "Epoch:  288  Average loss at step  2000 :  3099.763896118164\n",
      "Epoch:  288  Average loss at step  2533 :  3082.8649827090844\n",
      "288 2 19.92945909500122\n",
      "Epoch:  288  Average loss at step  1000 :  71.07970196533203\n",
      "Epoch:  288  Average loss at step  1227 :  71.25742234029647\n",
      "288 3 12.651895523071289\n",
      "Epoch:  288  Average loss at step  1000 :  11.596285474300384\n",
      "Epoch:  288  Average loss at step  2000 :  11.456367064476014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  288  Average loss at step  3000 :  11.730411005020141\n",
      "Epoch:  288  Average loss at step  3222 :  11.23591743020896\n",
      "288 4 33.11281895637512\n",
      "288 5 1.6689300537109375e-06\n",
      "Training time took 98.498872 seconds to run 1 epoch\n",
      "Epoch:  289  Average loss at step  1000 :  0.10068578821420669\n",
      "Epoch:  289  Average loss at step  2000 :  0.10523763209581376\n",
      "Epoch:  289  Average loss at step  3000 :  0.11477952897548675\n",
      "Epoch:  289  Average loss at step  3222 :  0.12049830724969628\n",
      "289 0 29.415996313095093\n",
      "Training time took 29.543176 seconds to run 1 epoch\n",
      "Epoch:  290  Average loss at step  1000 :  8.245973795890809\n",
      "Epoch:  290  Average loss at step  2000 :  8.179621329307556\n",
      "Epoch:  290  Average loss at step  3000 :  8.224222210884093\n",
      "Epoch:  290  Average loss at step  4000 :  7.984580861091613\n",
      "Epoch:  290  Average loss at step  5000 :  8.040929553031921\n",
      "Epoch:  290  Average loss at step  6000 :  8.192798221588134\n",
      "Epoch:  290  Average loss at step  7000 :  8.084050462722779\n",
      "Epoch:  290  Average loss at step  8000 :  8.333564971923828\n",
      "Epoch:  290  Average loss at step  8472 :  8.872456672230983\n",
      "290 0 20.539122343063354\n",
      "Epoch:  290  Average loss at step  1000 :  2212.173557189941\n",
      "Epoch:  290  Average loss at step  1491 :  2199.0355216975786\n",
      "290 1 11.719332456588745\n",
      "Epoch:  290  Average loss at step  1000 :  3120.248491088867\n",
      "Epoch:  290  Average loss at step  2000 :  3107.7709083251953\n",
      "Epoch:  290  Average loss at step  2533 :  3130.913751191566\n",
      "290 2 19.88572931289673\n",
      "Epoch:  290  Average loss at step  1000 :  70.80677462768554\n",
      "Epoch:  290  Average loss at step  1227 :  71.09679916610041\n",
      "290 3 12.66986346244812\n",
      "Epoch:  290  Average loss at step  1000 :  11.455955272197723\n",
      "Epoch:  290  Average loss at step  2000 :  11.45845473575592\n",
      "Epoch:  290  Average loss at step  3000 :  11.332564961910247\n",
      "Epoch:  290  Average loss at step  3222 :  11.758584531986191\n",
      "290 4 33.091827154159546\n",
      "290 5 1.1920928955078125e-06\n",
      "Training time took 98.551248 seconds to run 1 epoch\n",
      "Mean Rank:  175.13772  of  75000\n",
      "Hits @ 10:  0.84128\n",
      "Hits @ 1:  0.5894\n",
      "Testing time took 164.679175 seconds.\n",
      "\n",
      "Epoch:  291  Average loss at step  1000 :  0.10058482110500336\n",
      "Epoch:  291  Average loss at step  2000 :  0.10450995004177094\n",
      "Epoch:  291  Average loss at step  3000 :  0.11336540770530701\n",
      "Epoch:  291  Average loss at step  3222 :  0.11886941286862854\n",
      "291 0 29.485708951950073\n",
      "Training time took 29.594063 seconds to run 1 epoch\n",
      "Epoch:  292  Average loss at step  1000 :  8.40462416934967\n",
      "Epoch:  292  Average loss at step  2000 :  7.736886679649353\n",
      "Epoch:  292  Average loss at step  3000 :  7.886268076896667\n",
      "Epoch:  292  Average loss at step  4000 :  7.647042615890503\n",
      "Epoch:  292  Average loss at step  5000 :  8.087237096786499\n",
      "Epoch:  292  Average loss at step  6000 :  8.29269409418106\n",
      "Epoch:  292  Average loss at step  7000 :  7.9149958658218384\n",
      "Epoch:  292  Average loss at step  8000 :  7.508321770668029\n",
      "Epoch:  292  Average loss at step  8472 :  7.9195991031362905\n",
      "292 0 20.3881573677063\n",
      "Epoch:  292  Average loss at step  1000 :  2209.478380126953\n",
      "Epoch:  292  Average loss at step  1491 :  2199.6478751505433\n",
      "292 1 11.721396923065186\n",
      "Epoch:  292  Average loss at step  1000 :  3086.601434326172\n",
      "Epoch:  292  Average loss at step  2000 :  3110.770817504883\n",
      "Epoch:  292  Average loss at step  2533 :  3104.8641057282075\n",
      "292 2 19.90484929084778\n",
      "Epoch:  292  Average loss at step  1000 :  70.31203562545777\n",
      "Epoch:  292  Average loss at step  1227 :  70.50427678202838\n",
      "292 3 12.583592653274536\n",
      "Epoch:  292  Average loss at step  1000 :  11.317771376132965\n",
      "Epoch:  292  Average loss at step  2000 :  11.296862619400024\n",
      "Epoch:  292  Average loss at step  3000 :  11.4011796541214\n",
      "Epoch:  292  Average loss at step  3222 :  11.382673128478944\n",
      "292 4 33.22789430618286\n",
      "292 5 1.6689300537109375e-06\n",
      "Training time took 98.45791 seconds to run 1 epoch\n",
      "Epoch:  293  Average loss at step  1000 :  0.0992976702451706\n",
      "Epoch:  293  Average loss at step  2000 :  0.10396624618768692\n",
      "Epoch:  293  Average loss at step  3000 :  0.11333798813819886\n",
      "Epoch:  293  Average loss at step  3222 :  0.11847869629764367\n",
      "293 0 29.438535928726196\n",
      "Training time took 29.559956 seconds to run 1 epoch\n",
      "Epoch:  294  Average loss at step  1000 :  8.317905386924744\n",
      "Epoch:  294  Average loss at step  2000 :  7.789041823387146\n",
      "Epoch:  294  Average loss at step  3000 :  8.108215034484862\n",
      "Epoch:  294  Average loss at step  4000 :  8.166963305950166\n",
      "Epoch:  294  Average loss at step  5000 :  8.554312034606934\n",
      "Epoch:  294  Average loss at step  6000 :  8.15766420841217\n",
      "Epoch:  294  Average loss at step  7000 :  7.725854608058929\n",
      "Epoch:  294  Average loss at step  8000 :  8.291084477424622\n",
      "Epoch:  294  Average loss at step  8472 :  8.54761837789732\n",
      "294 0 21.07850956916809\n",
      "Epoch:  294  Average loss at step  1000 :  2206.961555786133\n",
      "Epoch:  294  Average loss at step  1491 :  2211.9781714818528\n",
      "294 1 11.698615312576294\n",
      "Epoch:  294  Average loss at step  1000 :  3129.5773715820314\n",
      "Epoch:  294  Average loss at step  2000 :  3105.2412164306643\n",
      "Epoch:  294  Average loss at step  2533 :  3105.911828800955\n",
      "294 2 19.912960290908813\n",
      "Epoch:  294  Average loss at step  1000 :  70.18655466079711\n",
      "Epoch:  294  Average loss at step  1227 :  70.25593620344387\n",
      "294 3 12.607193946838379\n",
      "Epoch:  294  Average loss at step  1000 :  11.285988280773163\n",
      "Epoch:  294  Average loss at step  2000 :  11.161835174560547\n",
      "Epoch:  294  Average loss at step  3000 :  11.345351880073547\n",
      "Epoch:  294  Average loss at step  3222 :  11.065973730202638\n",
      "294 4 33.25096368789673\n",
      "294 5 1.6689300537109375e-06\n",
      "Training time took 99.193893 seconds to run 1 epoch\n",
      "Epoch:  295  Average loss at step  1000 :  0.09878347790241242\n",
      "Epoch:  295  Average loss at step  2000 :  0.10425116741657257\n",
      "Epoch:  295  Average loss at step  3000 :  0.11276160383224487\n",
      "Epoch:  295  Average loss at step  3222 :  0.11792899410224042\n",
      "295 0 29.37507390975952\n",
      "Training time took 29.500304 seconds to run 1 epoch\n",
      "Epoch:  296  Average loss at step  1000 :  7.937419808864593\n",
      "Epoch:  296  Average loss at step  2000 :  7.9625283079147335\n",
      "Epoch:  296  Average loss at step  3000 :  8.409523753166198\n",
      "Epoch:  296  Average loss at step  4000 :  7.9978440599441525\n",
      "Epoch:  296  Average loss at step  5000 :  8.251023760318756\n",
      "Epoch:  296  Average loss at step  6000 :  7.654434030532837\n",
      "Epoch:  296  Average loss at step  7000 :  8.547606355667114\n",
      "Epoch:  296  Average loss at step  8000 :  7.945081577301026\n",
      "Epoch:  296  Average loss at step  8472 :  8.06917924841719\n",
      "296 0 20.851141214370728\n",
      "Epoch:  296  Average loss at step  1000 :  2211.1484770507814\n",
      "Epoch:  296  Average loss at step  1491 :  2193.0905971480865\n",
      "296 1 11.645575284957886\n",
      "Epoch:  296  Average loss at step  1000 :  3128.2547922363283\n",
      "Epoch:  296  Average loss at step  2000 :  3092.617984375\n",
      "Epoch:  296  Average loss at step  2533 :  3146.6867020805635\n",
      "296 2 19.92288303375244\n",
      "Epoch:  296  Average loss at step  1000 :  70.50137860107422\n",
      "Epoch:  296  Average loss at step  1227 :  70.45875879507258\n",
      "296 3 12.579875469207764\n",
      "Epoch:  296  Average loss at step  1000 :  11.279745674610139\n",
      "Epoch:  296  Average loss at step  2000 :  11.094405582904816\n",
      "Epoch:  296  Average loss at step  3000 :  11.15692903804779\n",
      "Epoch:  296  Average loss at step  3222 :  11.299866094639164\n",
      "296 4 33.13816428184509\n",
      "296 5 1.430511474609375e-06\n",
      "Training time took 98.795413 seconds to run 1 epoch\n",
      "Epoch:  297  Average loss at step  1000 :  0.09789245587587357\n",
      "Epoch:  297  Average loss at step  2000 :  0.10289986437559127\n",
      "Epoch:  297  Average loss at step  3000 :  0.11170451468229294\n",
      "Epoch:  297  Average loss at step  3222 :  0.11834988155655965\n",
      "297 0 29.347196102142334\n",
      "Training time took 29.468051 seconds to run 1 epoch\n",
      "Epoch:  298  Average loss at step  1000 :  7.760313928127289\n",
      "Epoch:  298  Average loss at step  2000 :  7.829647849082947\n",
      "Epoch:  298  Average loss at step  3000 :  7.870473896980285\n",
      "Epoch:  298  Average loss at step  4000 :  8.071913172721862\n",
      "Epoch:  298  Average loss at step  5000 :  7.87896939945221\n",
      "Epoch:  298  Average loss at step  6000 :  8.101405647277833\n",
      "Epoch:  298  Average loss at step  7000 :  8.59535535812378\n",
      "Epoch:  298  Average loss at step  8000 :  7.92869590473175\n",
      "Epoch:  298  Average loss at step  8472 :  8.250894295957282\n",
      "298 0 20.464308738708496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  298  Average loss at step  1000 :  2236.601901977539\n",
      "Epoch:  298  Average loss at step  1491 :  2201.4333759514784\n",
      "298 1 11.738290786743164\n",
      "Epoch:  298  Average loss at step  1000 :  3144.488534667969\n",
      "Epoch:  298  Average loss at step  2000 :  3128.1574622802736\n",
      "Epoch:  298  Average loss at step  2533 :  3138.191684355383\n",
      "298 2 19.880547761917114\n",
      "Epoch:  298  Average loss at step  1000 :  70.0846115951538\n",
      "Epoch:  298  Average loss at step  1227 :  70.7372318805855\n",
      "298 3 12.662332534790039\n",
      "Epoch:  298  Average loss at step  1000 :  11.299119090557099\n",
      "Epoch:  298  Average loss at step  2000 :  11.137239196300506\n",
      "Epoch:  298  Average loss at step  3000 :  11.143453030109406\n",
      "Epoch:  298  Average loss at step  3222 :  10.982394592924267\n",
      "298 4 33.218977212905884\n",
      "298 5 1.430511474609375e-06\n",
      "Training time took 98.61138 seconds to run 1 epoch\n",
      "Epoch:  299  Average loss at step  1000 :  0.09816176372766494\n",
      "Epoch:  299  Average loss at step  2000 :  0.10230022835731506\n",
      "Epoch:  299  Average loss at step  3000 :  0.11125008141994476\n",
      "Epoch:  299  Average loss at step  3222 :  0.11675821963275979\n",
      "299 0 29.443709135055542\n",
      "Training time took 29.565612 seconds to run 1 epoch\n",
      "Epoch:  300  Average loss at step  1000 :  7.934643071174621\n",
      "Epoch:  300  Average loss at step  2000 :  8.684094715118409\n",
      "Epoch:  300  Average loss at step  3000 :  8.567492397785188\n",
      "Epoch:  300  Average loss at step  4000 :  8.429296543121337\n",
      "Epoch:  300  Average loss at step  5000 :  8.16706097984314\n",
      "Epoch:  300  Average loss at step  6000 :  7.5852501912117\n",
      "Epoch:  300  Average loss at step  7000 :  8.021034029960632\n",
      "Epoch:  300  Average loss at step  8000 :  7.9443547706604\n",
      "Epoch:  300  Average loss at step  8472 :  8.108281514462577\n",
      "300 0 21.25757908821106\n",
      "Epoch:  300  Average loss at step  1000 :  2227.4933834228514\n",
      "Epoch:  300  Average loss at step  1491 :  2186.6724251705227\n",
      "300 1 11.769389629364014\n",
      "Epoch:  300  Average loss at step  1000 :  3154.5788111572265\n",
      "Epoch:  300  Average loss at step  2000 :  3110.454143310547\n",
      "Epoch:  300  Average loss at step  2533 :  3098.8307609166645\n",
      "300 2 19.89866542816162\n",
      "Epoch:  300  Average loss at step  1000 :  69.92574044799805\n",
      "Epoch:  300  Average loss at step  1227 :  69.89500944713389\n",
      "300 3 12.601919889450073\n",
      "Epoch:  300  Average loss at step  1000 :  11.064887990951538\n",
      "Epoch:  300  Average loss at step  2000 :  10.899271693229675\n",
      "Epoch:  300  Average loss at step  3000 :  10.96806673002243\n",
      "Epoch:  300  Average loss at step  3222 :  11.312598789571144\n",
      "300 4 33.2516074180603\n",
      "300 5 1.6689300537109375e-06\n",
      "Training time took 99.409785 seconds to run 1 epoch\n",
      "Mean Rank:  175.88436  of  75000\n",
      "Hits @ 10:  0.84224\n",
      "Hits @ 1:  0.59128\n",
      "Testing time took 165.020123 seconds.\n",
      "\n",
      "Epoch:  301  Average loss at step  1000 :  0.09725718510150909\n",
      "Epoch:  301  Average loss at step  2000 :  0.10199455094337463\n",
      "Epoch:  301  Average loss at step  3000 :  0.11062397414445876\n",
      "Epoch:  301  Average loss at step  3222 :  0.11491744871022448\n",
      "301 0 29.418946504592896\n",
      "Training time took 29.53476 seconds to run 1 epoch\n",
      "Epoch:  302  Average loss at step  1000 :  8.383291546821594\n",
      "Epoch:  302  Average loss at step  2000 :  8.069083388328552\n",
      "Epoch:  302  Average loss at step  3000 :  8.1183960647583\n",
      "Epoch:  302  Average loss at step  4000 :  8.216743356704711\n",
      "Epoch:  302  Average loss at step  5000 :  8.337844245910645\n",
      "Epoch:  302  Average loss at step  6000 :  7.793959621429443\n",
      "Epoch:  302  Average loss at step  7000 :  8.532352295398713\n",
      "Epoch:  302  Average loss at step  8000 :  8.512537043094635\n",
      "Epoch:  302  Average loss at step  8472 :  9.181534847821178\n",
      "302 0 20.59012746810913\n",
      "Epoch:  302  Average loss at step  1000 :  2234.1441867065428\n",
      "Epoch:  302  Average loss at step  1491 :  2225.4641434389355\n",
      "302 1 11.708133697509766\n",
      "Epoch:  302  Average loss at step  1000 :  3137.6693076171873\n",
      "Epoch:  302  Average loss at step  2000 :  3153.937819946289\n",
      "Epoch:  302  Average loss at step  2533 :  3146.6331940506007\n",
      "302 2 19.904857635498047\n",
      "Epoch:  302  Average loss at step  1000 :  70.8530853843689\n",
      "Epoch:  302  Average loss at step  1227 :  69.39280555345766\n",
      "302 3 12.62281346321106\n",
      "Epoch:  302  Average loss at step  1000 :  10.95807871723175\n",
      "Epoch:  302  Average loss at step  2000 :  10.703289254665375\n",
      "Epoch:  302  Average loss at step  3000 :  10.942667446613312\n",
      "Epoch:  302  Average loss at step  3222 :  11.035078801624953\n",
      "302 4 33.005051612854004\n",
      "302 5 1.1920928955078125e-06\n",
      "Training time took 98.48176 seconds to run 1 epoch\n",
      "Epoch:  303  Average loss at step  1000 :  0.09680516821146011\n",
      "Epoch:  303  Average loss at step  2000 :  0.10111219769716263\n",
      "Epoch:  303  Average loss at step  3000 :  0.11049824649095535\n",
      "Epoch:  303  Average loss at step  3222 :  0.11504648781614757\n",
      "303 0 29.398916006088257\n",
      "Training time took 29.526445 seconds to run 1 epoch\n",
      "Epoch:  304  Average loss at step  1000 :  8.494273804187774\n",
      "Epoch:  304  Average loss at step  2000 :  8.217674946784973\n",
      "Epoch:  304  Average loss at step  3000 :  8.058870072364806\n",
      "Epoch:  304  Average loss at step  4000 :  7.7394946060180665\n",
      "Epoch:  304  Average loss at step  5000 :  7.672710550308228\n",
      "Epoch:  304  Average loss at step  6000 :  8.470223275184631\n",
      "Epoch:  304  Average loss at step  7000 :  8.503490662574768\n",
      "Epoch:  304  Average loss at step  8000 :  8.583361164093018\n",
      "Epoch:  304  Average loss at step  8472 :  8.293998136690792\n",
      "304 0 20.828622817993164\n",
      "Epoch:  304  Average loss at step  1000 :  2236.0171888427735\n",
      "Epoch:  304  Average loss at step  1491 :  2216.99534885081\n",
      "304 1 11.733173847198486\n",
      "Epoch:  304  Average loss at step  1000 :  3158.333228149414\n",
      "Epoch:  304  Average loss at step  2000 :  3151.851139404297\n",
      "Epoch:  304  Average loss at step  2533 :  3135.7310071662064\n",
      "304 2 19.934693813323975\n",
      "Epoch:  304  Average loss at step  1000 :  70.38642972183227\n",
      "Epoch:  304  Average loss at step  1227 :  69.621308191624\n",
      "304 3 12.61397385597229\n",
      "Epoch:  304  Average loss at step  1000 :  10.920092595100403\n",
      "Epoch:  304  Average loss at step  2000 :  10.880910705566405\n",
      "Epoch:  304  Average loss at step  3000 :  10.780953834533692\n",
      "Epoch:  304  Average loss at step  3222 :  10.68121238743964\n",
      "304 4 33.213134765625\n",
      "304 5 1.1920928955078125e-06\n",
      "Training time took 98.971422 seconds to run 1 epoch\n",
      "Epoch:  305  Average loss at step  1000 :  0.09598897904157638\n",
      "Epoch:  305  Average loss at step  2000 :  0.10077079385519028\n",
      "Epoch:  305  Average loss at step  3000 :  0.10939759302139282\n",
      "Epoch:  305  Average loss at step  3222 :  0.11611220062500002\n",
      "305 0 29.436105489730835\n",
      "Training time took 29.565299 seconds to run 1 epoch\n",
      "Epoch:  306  Average loss at step  1000 :  8.433331486701965\n",
      "Epoch:  306  Average loss at step  2000 :  8.380438245773316\n",
      "Epoch:  306  Average loss at step  3000 :  8.188512787818908\n",
      "Epoch:  306  Average loss at step  4000 :  8.048966247081756\n",
      "Epoch:  306  Average loss at step  5000 :  8.369896718025208\n",
      "Epoch:  306  Average loss at step  6000 :  7.76478920173645\n",
      "Epoch:  306  Average loss at step  7000 :  8.065609951019287\n",
      "Epoch:  306  Average loss at step  8000 :  8.018107654571534\n",
      "Epoch:  306  Average loss at step  8472 :  7.851941401067672\n",
      "306 0 20.88494324684143\n",
      "Epoch:  306  Average loss at step  1000 :  2246.5022794189454\n",
      "Epoch:  306  Average loss at step  1491 :  2230.530916519014\n",
      "306 1 11.729778051376343\n",
      "Epoch:  306  Average loss at step  1000 :  3173.8850014648438\n",
      "Epoch:  306  Average loss at step  2000 :  3159.055403930664\n",
      "Epoch:  306  Average loss at step  2533 :  3142.432775154368\n",
      "306 2 19.95628547668457\n",
      "Epoch:  306  Average loss at step  1000 :  70.04003601455689\n",
      "Epoch:  306  Average loss at step  1227 :  70.83847617084855\n",
      "306 3 12.669926881790161\n",
      "Epoch:  306  Average loss at step  1000 :  10.79835680437088\n",
      "Epoch:  306  Average loss at step  2000 :  10.576868366241454\n",
      "Epoch:  306  Average loss at step  3000 :  10.671944446086883\n",
      "Epoch:  306  Average loss at step  3222 :  10.751520517738014\n",
      "306 4 33.22364592552185\n",
      "306 5 1.1920928955078125e-06\n",
      "Training time took 99.087321 seconds to run 1 epoch\n",
      "Epoch:  307  Average loss at step  1000 :  0.0955819354057312\n",
      "Epoch:  307  Average loss at step  2000 :  0.09948116260766983\n",
      "Epoch:  307  Average loss at step  3000 :  0.10902075678110122\n",
      "Epoch:  307  Average loss at step  3222 :  0.11438351365972843\n",
      "307 0 29.351391553878784\n",
      "Training time took 29.478391 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  308  Average loss at step  1000 :  7.589918410778045\n",
      "Epoch:  308  Average loss at step  2000 :  7.802446327209473\n",
      "Epoch:  308  Average loss at step  3000 :  8.482733778953552\n",
      "Epoch:  308  Average loss at step  4000 :  7.710788898468017\n",
      "Epoch:  308  Average loss at step  5000 :  8.423517734527588\n",
      "Epoch:  308  Average loss at step  6000 :  8.375667972564697\n",
      "Epoch:  308  Average loss at step  7000 :  8.06850166130066\n",
      "Epoch:  308  Average loss at step  8000 :  7.767285334587097\n",
      "Epoch:  308  Average loss at step  8472 :  8.04771745171026\n",
      "308 0 21.158647537231445\n",
      "Epoch:  308  Average loss at step  1000 :  2268.957296813965\n",
      "Epoch:  308  Average loss at step  1491 :  2233.6173472434493\n",
      "308 1 11.743642330169678\n",
      "Epoch:  308  Average loss at step  1000 :  3137.5535362548826\n",
      "Epoch:  308  Average loss at step  2000 :  3159.623848388672\n",
      "Epoch:  308  Average loss at step  2533 :  3167.2001920454227\n",
      "308 2 19.885056495666504\n",
      "Epoch:  308  Average loss at step  1000 :  70.0444785041809\n",
      "Epoch:  308  Average loss at step  1227 :  69.12676580278203\n",
      "308 3 12.604819059371948\n",
      "Epoch:  308  Average loss at step  1000 :  10.785103653907775\n",
      "Epoch:  308  Average loss at step  2000 :  10.568209550380708\n",
      "Epoch:  308  Average loss at step  3000 :  10.668841132164001\n",
      "Epoch:  308  Average loss at step  3222 :  10.51348103450769\n",
      "308 4 33.299750566482544\n",
      "308 5 9.5367431640625e-07\n",
      "Training time took 99.338591 seconds to run 1 epoch\n",
      "Epoch:  309  Average loss at step  1000 :  0.09522501009702683\n",
      "Epoch:  309  Average loss at step  2000 :  0.09973659920692445\n",
      "Epoch:  309  Average loss at step  3000 :  0.10800512796640396\n",
      "Epoch:  309  Average loss at step  3222 :  0.11377607706458716\n",
      "309 0 29.34682321548462\n",
      "Training time took 29.471347 seconds to run 1 epoch\n",
      "Epoch:  310  Average loss at step  1000 :  8.255727458000184\n",
      "Epoch:  310  Average loss at step  2000 :  8.38115388059616\n",
      "Epoch:  310  Average loss at step  3000 :  8.135427919387817\n",
      "Epoch:  310  Average loss at step  4000 :  8.784447525024413\n",
      "Epoch:  310  Average loss at step  5000 :  7.924375734329224\n",
      "Epoch:  310  Average loss at step  6000 :  7.841957078933715\n",
      "Epoch:  310  Average loss at step  7000 :  8.229183306694031\n",
      "Epoch:  310  Average loss at step  8000 :  8.001681730270386\n",
      "Epoch:  310  Average loss at step  8472 :  7.7572088058217155\n",
      "310 0 20.75859785079956\n",
      "Epoch:  310  Average loss at step  1000 :  2252.8481716308593\n",
      "Epoch:  310  Average loss at step  1491 :  2217.729979369712\n",
      "310 1 11.718937158584595\n",
      "Epoch:  310  Average loss at step  1000 :  3150.8866716308594\n",
      "Epoch:  310  Average loss at step  2000 :  3145.3243443603515\n",
      "Epoch:  310  Average loss at step  2533 :  3201.145866172357\n",
      "310 2 19.847989082336426\n",
      "Epoch:  310  Average loss at step  1000 :  70.21756282424927\n",
      "Epoch:  310  Average loss at step  1227 :  70.3218123917755\n",
      "310 3 12.648102760314941\n",
      "Epoch:  310  Average loss at step  1000 :  10.686370801925658\n",
      "Epoch:  310  Average loss at step  2000 :  10.409022560596465\n",
      "Epoch:  310  Average loss at step  3000 :  10.605112558841705\n",
      "Epoch:  310  Average loss at step  3222 :  10.95826799720176\n",
      "310 4 33.1065456867218\n",
      "310 5 1.6689300537109375e-06\n",
      "Training time took 98.724246 seconds to run 1 epoch\n",
      "Mean Rank:  172.70472  of  75000\n",
      "Hits @ 10:  0.84572\n",
      "Hits @ 1:  0.59408\n",
      "Testing time took 164.541229 seconds.\n",
      "\n",
      "Epoch:  311  Average loss at step  1000 :  0.0939019204378128\n",
      "Epoch:  311  Average loss at step  2000 :  0.09914295494556427\n",
      "Epoch:  311  Average loss at step  3000 :  0.10811907058954238\n",
      "Epoch:  311  Average loss at step  3222 :  0.11299943521492402\n",
      "311 0 29.416399240493774\n",
      "Training time took 29.524158 seconds to run 1 epoch\n",
      "Epoch:  312  Average loss at step  1000 :  8.474542163848877\n",
      "Epoch:  312  Average loss at step  2000 :  7.769274295806885\n",
      "Epoch:  312  Average loss at step  3000 :  7.756251615524292\n",
      "Epoch:  312  Average loss at step  4000 :  7.819575177669525\n",
      "Epoch:  312  Average loss at step  5000 :  7.492465907096863\n",
      "Epoch:  312  Average loss at step  6000 :  8.680358032226563\n",
      "Epoch:  312  Average loss at step  7000 :  8.036770443439483\n",
      "Epoch:  312  Average loss at step  8000 :  7.976179911136628\n",
      "Epoch:  312  Average loss at step  8472 :  7.977031761840701\n",
      "312 0 20.339476823806763\n",
      "Epoch:  312  Average loss at step  1000 :  2258.837712036133\n",
      "Epoch:  312  Average loss at step  1491 :  2233.8301650335525\n",
      "312 1 11.747243881225586\n",
      "Epoch:  312  Average loss at step  1000 :  3170.4771013183595\n",
      "Epoch:  312  Average loss at step  2000 :  3195.510177734375\n",
      "Epoch:  312  Average loss at step  2533 :  3141.9337705943353\n",
      "312 2 19.915412187576294\n",
      "Epoch:  312  Average loss at step  1000 :  70.20515162658691\n",
      "Epoch:  312  Average loss at step  1227 :  68.61012605594833\n",
      "312 3 12.57823896408081\n",
      "Epoch:  312  Average loss at step  1000 :  10.57970594739914\n",
      "Epoch:  312  Average loss at step  2000 :  10.484831511974335\n",
      "Epoch:  312  Average loss at step  3000 :  10.47129343366623\n",
      "Epoch:  312  Average loss at step  3222 :  10.323110018897346\n",
      "312 4 33.181214332580566\n",
      "312 5 1.430511474609375e-06\n",
      "Training time took 98.403936 seconds to run 1 epoch\n",
      "Epoch:  313  Average loss at step  1000 :  0.09441195660829545\n",
      "Epoch:  313  Average loss at step  2000 :  0.0985654411315918\n",
      "Epoch:  313  Average loss at step  3000 :  0.10725604552030564\n",
      "Epoch:  313  Average loss at step  3222 :  0.11093063482762158\n",
      "313 0 29.40154004096985\n",
      "Training time took 29.523421 seconds to run 1 epoch\n",
      "Epoch:  314  Average loss at step  1000 :  8.368751929283142\n",
      "Epoch:  314  Average loss at step  2000 :  7.715001815319061\n",
      "Epoch:  314  Average loss at step  3000 :  7.640496797561646\n",
      "Epoch:  314  Average loss at step  4000 :  7.816317889213562\n",
      "Epoch:  314  Average loss at step  5000 :  8.155817320823669\n",
      "Epoch:  314  Average loss at step  6000 :  8.426406093120574\n",
      "Epoch:  314  Average loss at step  7000 :  8.282855427742005\n",
      "Epoch:  314  Average loss at step  8000 :  7.9666818943023685\n",
      "Epoch:  314  Average loss at step  8472 :  7.668113635637821\n",
      "314 0 20.822861909866333\n",
      "Epoch:  314  Average loss at step  1000 :  2238.2018835449217\n",
      "Epoch:  314  Average loss at step  1491 :  2281.9430042016875\n",
      "314 1 11.646913766860962\n",
      "Epoch:  314  Average loss at step  1000 :  3181.9701015625\n",
      "Epoch:  314  Average loss at step  2000 :  3158.649567993164\n",
      "Epoch:  314  Average loss at step  2533 :  3166.1186074581437\n",
      "314 2 19.90882182121277\n",
      "Epoch:  314  Average loss at step  1000 :  68.94398247909545\n",
      "Epoch:  314  Average loss at step  1227 :  69.1718256793824\n",
      "314 3 12.570879697799683\n",
      "Epoch:  314  Average loss at step  1000 :  10.383752038478852\n",
      "Epoch:  314  Average loss at step  2000 :  10.404319203853607\n",
      "Epoch:  314  Average loss at step  3000 :  10.46729482603073\n",
      "Epoch:  314  Average loss at step  3222 :  10.505756201522836\n",
      "314 4 33.21620416641235\n",
      "314 5 1.1920928955078125e-06\n",
      "Training time took 98.793673 seconds to run 1 epoch\n",
      "Epoch:  315  Average loss at step  1000 :  0.09398621326684951\n",
      "Epoch:  315  Average loss at step  2000 :  0.0976426631808281\n",
      "Epoch:  315  Average loss at step  3000 :  0.10640119582414627\n",
      "Epoch:  315  Average loss at step  3222 :  0.11223919459640991\n",
      "315 0 29.40241575241089\n",
      "Training time took 29.526621 seconds to run 1 epoch\n",
      "Epoch:  316  Average loss at step  1000 :  8.032075709342957\n",
      "Epoch:  316  Average loss at step  2000 :  7.6485589981079105\n",
      "Epoch:  316  Average loss at step  3000 :  8.336297493457794\n",
      "Epoch:  316  Average loss at step  4000 :  7.958703456401825\n",
      "Epoch:  316  Average loss at step  5000 :  8.272597145557404\n",
      "Epoch:  316  Average loss at step  6000 :  7.569379197120666\n",
      "Epoch:  316  Average loss at step  7000 :  8.077722944259644\n",
      "Epoch:  316  Average loss at step  8000 :  8.216217709064484\n",
      "Epoch:  316  Average loss at step  8472 :  7.868025608588133\n",
      "316 0 20.382359743118286\n",
      "Epoch:  316  Average loss at step  1000 :  2280.965103515625\n",
      "Epoch:  316  Average loss at step  1491 :  2255.8323350569567\n",
      "316 1 11.724070310592651\n",
      "Epoch:  316  Average loss at step  1000 :  3185.166783569336\n",
      "Epoch:  316  Average loss at step  2000 :  3192.3755906982424\n",
      "Epoch:  316  Average loss at step  2533 :  3156.7139116968424\n",
      "316 2 19.919050216674805\n",
      "Epoch:  316  Average loss at step  1000 :  69.81415522003174\n",
      "Epoch:  316  Average loss at step  1227 :  68.81272552472733\n",
      "316 3 12.664418935775757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  316  Average loss at step  1000 :  10.437596888065338\n",
      "Epoch:  316  Average loss at step  2000 :  10.276292430400849\n",
      "Epoch:  316  Average loss at step  3000 :  10.278978802204133\n",
      "Epoch:  316  Average loss at step  3222 :  10.233084495628455\n",
      "316 4 33.126641511917114\n",
      "316 5 1.6689300537109375e-06\n",
      "Training time took 98.46485 seconds to run 1 epoch\n",
      "Epoch:  317  Average loss at step  1000 :  0.09334924906492233\n",
      "Epoch:  317  Average loss at step  2000 :  0.09785007679462433\n",
      "Epoch:  317  Average loss at step  3000 :  0.10580670827627182\n",
      "Epoch:  317  Average loss at step  3222 :  0.11129694324814686\n",
      "317 0 29.41657590866089\n",
      "Training time took 29.538958 seconds to run 1 epoch\n",
      "Epoch:  318  Average loss at step  1000 :  7.818180270195008\n",
      "Epoch:  318  Average loss at step  2000 :  8.037878655433655\n",
      "Epoch:  318  Average loss at step  3000 :  8.0543898229599\n",
      "Epoch:  318  Average loss at step  4000 :  8.36738990688324\n",
      "Epoch:  318  Average loss at step  5000 :  8.405452217578889\n",
      "Epoch:  318  Average loss at step  6000 :  8.110879324913025\n",
      "Epoch:  318  Average loss at step  7000 :  7.913074433803558\n",
      "Epoch:  318  Average loss at step  8000 :  7.750724225044251\n",
      "Epoch:  318  Average loss at step  8472 :  8.652641779194207\n",
      "318 0 20.64098072052002\n",
      "Epoch:  318  Average loss at step  1000 :  2248.038712463379\n",
      "Epoch:  318  Average loss at step  1491 :  2276.197957014461\n",
      "318 1 11.73105502128601\n",
      "Epoch:  318  Average loss at step  1000 :  3216.682358520508\n",
      "Epoch:  318  Average loss at step  2000 :  3171.4624173583984\n",
      "Epoch:  318  Average loss at step  2533 :  3172.1889012183337\n",
      "318 2 19.935940504074097\n",
      "Epoch:  318  Average loss at step  1000 :  69.28188356781006\n",
      "Epoch:  318  Average loss at step  1227 :  69.24167943893798\n",
      "318 3 12.594515562057495\n",
      "Epoch:  318  Average loss at step  1000 :  10.46293542957306\n",
      "Epoch:  318  Average loss at step  2000 :  10.281133950710297\n",
      "Epoch:  318  Average loss at step  3000 :  10.349602745056153\n",
      "Epoch:  318  Average loss at step  3222 :  10.071089898750097\n",
      "318 4 33.14240026473999\n",
      "318 5 1.430511474609375e-06\n",
      "Training time took 98.688225 seconds to run 1 epoch\n",
      "Epoch:  319  Average loss at step  1000 :  0.09225503528118134\n",
      "Epoch:  319  Average loss at step  2000 :  0.09708414399623871\n",
      "Epoch:  319  Average loss at step  3000 :  0.10551836210489272\n",
      "Epoch:  319  Average loss at step  3222 :  0.11081323390791274\n",
      "319 0 29.400131940841675\n",
      "Training time took 29.522817 seconds to run 1 epoch\n",
      "Epoch:  320  Average loss at step  1000 :  8.234283440589905\n",
      "Epoch:  320  Average loss at step  2000 :  7.831416784286499\n",
      "Epoch:  320  Average loss at step  3000 :  7.921637068748474\n",
      "Epoch:  320  Average loss at step  4000 :  8.14989757156372\n",
      "Epoch:  320  Average loss at step  5000 :  8.042009504318237\n",
      "Epoch:  320  Average loss at step  6000 :  8.012212935447693\n",
      "Epoch:  320  Average loss at step  7000 :  8.180551672935486\n",
      "Epoch:  320  Average loss at step  8000 :  8.270291736602783\n",
      "Epoch:  320  Average loss at step  8472 :  8.627538560409354\n",
      "320 0 20.839348077774048\n",
      "Epoch:  320  Average loss at step  1000 :  2265.6610513305664\n",
      "Epoch:  320  Average loss at step  1491 :  2251.1029812239335\n",
      "320 1 11.73551082611084\n",
      "Epoch:  320  Average loss at step  1000 :  3212.551687255859\n",
      "Epoch:  320  Average loss at step  2000 :  3167.269940673828\n",
      "Epoch:  320  Average loss at step  2533 :  3238.8035467117934\n",
      "320 2 19.899444341659546\n",
      "Epoch:  320  Average loss at step  1000 :  69.09835515975952\n",
      "Epoch:  320  Average loss at step  1227 :  68.46228534040293\n",
      "320 3 12.65787959098816\n",
      "Epoch:  320  Average loss at step  1000 :  10.27576304578781\n",
      "Epoch:  320  Average loss at step  2000 :  9.945143933773041\n",
      "Epoch:  320  Average loss at step  3000 :  10.138291799545287\n",
      "Epoch:  320  Average loss at step  3222 :  10.096377303269305\n",
      "320 4 33.20356869697571\n",
      "320 5 1.430511474609375e-06\n",
      "Training time took 98.976748 seconds to run 1 epoch\n",
      "Mean Rank:  173.64664  of  75000\n",
      "Hits @ 10:  0.84572\n",
      "Hits @ 1:  0.59496\n",
      "Testing time took 164.859056 seconds.\n",
      "\n",
      "Epoch:  321  Average loss at step  1000 :  0.09215756374597549\n",
      "Epoch:  321  Average loss at step  2000 :  0.09616078156232834\n",
      "Epoch:  321  Average loss at step  3000 :  0.10486803412437438\n",
      "Epoch:  321  Average loss at step  3222 :  0.11071873219096288\n",
      "321 0 29.44760823249817\n",
      "Training time took 29.564807 seconds to run 1 epoch\n",
      "Epoch:  322  Average loss at step  1000 :  7.714058284759521\n",
      "Epoch:  322  Average loss at step  2000 :  7.9706538352966305\n",
      "Epoch:  322  Average loss at step  3000 :  8.169342561721802\n",
      "Epoch:  322  Average loss at step  4000 :  8.417292042732239\n",
      "Epoch:  322  Average loss at step  5000 :  7.375745141983033\n",
      "Epoch:  322  Average loss at step  6000 :  7.710141374588012\n",
      "Epoch:  322  Average loss at step  7000 :  7.698609996795654\n",
      "Epoch:  322  Average loss at step  8000 :  7.874029669761658\n",
      "Epoch:  322  Average loss at step  8472 :  8.068874119993817\n",
      "322 0 20.92437481880188\n",
      "Epoch:  322  Average loss at step  1000 :  2252.7925064697265\n",
      "Epoch:  322  Average loss at step  1491 :  2277.3926420283474\n",
      "322 1 11.760652303695679\n",
      "Epoch:  322  Average loss at step  1000 :  3175.431875488281\n",
      "Epoch:  322  Average loss at step  2000 :  3181.9487869873046\n",
      "Epoch:  322  Average loss at step  2533 :  3206.897969757288\n",
      "322 2 19.91956853866577\n",
      "Epoch:  322  Average loss at step  1000 :  69.43073258972169\n",
      "Epoch:  322  Average loss at step  1227 :  69.78394967002295\n",
      "322 3 12.632154703140259\n",
      "Epoch:  322  Average loss at step  1000 :  10.084049513339997\n",
      "Epoch:  322  Average loss at step  2000 :  10.155090837478637\n",
      "Epoch:  322  Average loss at step  3000 :  10.063967274665833\n",
      "Epoch:  322  Average loss at step  3222 :  10.230886675773878\n",
      "322 4 33.36009430885315\n",
      "322 5 1.430511474609375e-06\n",
      "Training time took 99.248919 seconds to run 1 epoch\n",
      "Epoch:  323  Average loss at step  1000 :  0.0916849611401558\n",
      "Epoch:  323  Average loss at step  2000 :  0.09588953894376755\n",
      "Epoch:  323  Average loss at step  3000 :  0.10403183823823929\n",
      "Epoch:  323  Average loss at step  3222 :  0.10938655923346488\n",
      "323 0 29.45541524887085\n",
      "Training time took 29.577851 seconds to run 1 epoch\n",
      "Epoch:  324  Average loss at step  1000 :  7.956546126365661\n",
      "Epoch:  324  Average loss at step  2000 :  8.357668813228607\n",
      "Epoch:  324  Average loss at step  3000 :  7.976987819671631\n",
      "Epoch:  324  Average loss at step  4000 :  8.017568274974822\n",
      "Epoch:  324  Average loss at step  5000 :  8.398525904655456\n",
      "Epoch:  324  Average loss at step  6000 :  7.929589400291443\n",
      "Epoch:  324  Average loss at step  7000 :  8.07651197195053\n",
      "Epoch:  324  Average loss at step  8000 :  8.571835072517395\n",
      "Epoch:  324  Average loss at step  8472 :  8.41790384420752\n",
      "324 0 20.723502159118652\n",
      "Epoch:  324  Average loss at step  1000 :  2255.642453979492\n",
      "Epoch:  324  Average loss at step  1491 :  2248.6379451571825\n",
      "324 1 11.762937784194946\n",
      "Epoch:  324  Average loss at step  1000 :  3207.2859036865234\n",
      "Epoch:  324  Average loss at step  2000 :  3229.669210693359\n",
      "Epoch:  324  Average loss at step  2533 :  3221.5602235077463\n",
      "324 2 19.905644178390503\n",
      "Epoch:  324  Average loss at step  1000 :  69.38179392623901\n",
      "Epoch:  324  Average loss at step  1227 :  68.7869789351404\n",
      "324 3 12.721469640731812\n",
      "Epoch:  324  Average loss at step  1000 :  10.1319031996727\n",
      "Epoch:  324  Average loss at step  2000 :  10.019185272216797\n",
      "Epoch:  324  Average loss at step  3000 :  9.967533050060272\n",
      "Epoch:  324  Average loss at step  3222 :  9.834295176581627\n",
      "324 4 33.15500497817993\n",
      "324 5 1.430511474609375e-06\n",
      "Training time took 98.918303 seconds to run 1 epoch\n",
      "Epoch:  325  Average loss at step  1000 :  0.09117653918266297\n",
      "Epoch:  325  Average loss at step  2000 :  0.09575663942098618\n",
      "Epoch:  325  Average loss at step  3000 :  0.10376826095581054\n",
      "Epoch:  325  Average loss at step  3222 :  0.10732108665558594\n",
      "325 0 29.408825397491455\n",
      "Training time took 29.540267 seconds to run 1 epoch\n",
      "Epoch:  326  Average loss at step  1000 :  7.855376023769379\n",
      "Epoch:  326  Average loss at step  2000 :  8.467442135334014\n",
      "Epoch:  326  Average loss at step  3000 :  8.085443145751952\n",
      "Epoch:  326  Average loss at step  4000 :  7.764067999839782\n",
      "Epoch:  326  Average loss at step  5000 :  8.118801950454712\n",
      "Epoch:  326  Average loss at step  6000 :  7.5426247701644895\n",
      "Epoch:  326  Average loss at step  7000 :  8.35983770942688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  326  Average loss at step  8000 :  8.276911177635192\n",
      "Epoch:  326  Average loss at step  8472 :  8.03415211355801\n",
      "326 0 20.868538856506348\n",
      "Epoch:  326  Average loss at step  1000 :  2287.5676455078124\n",
      "Epoch:  326  Average loss at step  1491 :  2279.046934089461\n",
      "326 1 11.751644849777222\n",
      "Epoch:  326  Average loss at step  1000 :  3222.87333203125\n",
      "Epoch:  326  Average loss at step  2000 :  3200.5933928222657\n",
      "Epoch:  326  Average loss at step  2533 :  3235.808366697292\n",
      "326 2 19.92746329307556\n",
      "Epoch:  326  Average loss at step  1000 :  68.94283674621582\n",
      "Epoch:  326  Average loss at step  1227 :  68.70568212720447\n",
      "326 3 12.610135316848755\n",
      "Epoch:  326  Average loss at step  1000 :  10.128355937480926\n",
      "Epoch:  326  Average loss at step  2000 :  9.86922595024109\n",
      "Epoch:  326  Average loss at step  3000 :  10.121494766235351\n",
      "Epoch:  326  Average loss at step  3222 :  9.780130463400608\n",
      "326 4 33.11630415916443\n",
      "326 5 1.1920928955078125e-06\n",
      "Training time took 98.910538 seconds to run 1 epoch\n",
      "Epoch:  327  Average loss at step  1000 :  0.09049036598205566\n",
      "Epoch:  327  Average loss at step  2000 :  0.09472798889875413\n",
      "Epoch:  327  Average loss at step  3000 :  0.10378876686096192\n",
      "Epoch:  327  Average loss at step  3222 :  0.10758885963446484\n",
      "327 0 29.366601705551147\n",
      "Training time took 29.485935 seconds to run 1 epoch\n",
      "Epoch:  328  Average loss at step  1000 :  8.248984907150268\n",
      "Epoch:  328  Average loss at step  2000 :  7.926208763122559\n",
      "Epoch:  328  Average loss at step  3000 :  8.15000938129425\n",
      "Epoch:  328  Average loss at step  4000 :  8.344640426635742\n",
      "Epoch:  328  Average loss at step  5000 :  7.799036857604981\n",
      "Epoch:  328  Average loss at step  6000 :  8.08320520591736\n",
      "Epoch:  328  Average loss at step  7000 :  7.483799196243286\n",
      "Epoch:  328  Average loss at step  8000 :  7.722987111091614\n",
      "Epoch:  328  Average loss at step  8472 :  7.3089481518257555\n",
      "328 0 20.68168807029724\n",
      "Epoch:  328  Average loss at step  1000 :  2286.5912604980467\n",
      "Epoch:  328  Average loss at step  1491 :  2318.6332751900727\n",
      "328 1 11.712719440460205\n",
      "Epoch:  328  Average loss at step  1000 :  3203.3055723876955\n",
      "Epoch:  328  Average loss at step  2000 :  3203.341625732422\n",
      "Epoch:  328  Average loss at step  2533 :  3202.9159370958373\n",
      "328 2 19.909823656082153\n",
      "Epoch:  328  Average loss at step  1000 :  69.10313496017456\n",
      "Epoch:  328  Average loss at step  1227 :  68.3508217779146\n",
      "328 3 12.660637378692627\n",
      "Epoch:  328  Average loss at step  1000 :  9.955680477619172\n",
      "Epoch:  328  Average loss at step  2000 :  9.809365016460418\n",
      "Epoch:  328  Average loss at step  3000 :  9.956279771327972\n",
      "Epoch:  328  Average loss at step  3222 :  10.053031718737383\n",
      "328 4 33.16808223724365\n",
      "328 5 1.430511474609375e-06\n",
      "Training time took 98.773401 seconds to run 1 epoch\n",
      "Epoch:  329  Average loss at step  1000 :  0.09031824243068695\n",
      "Epoch:  329  Average loss at step  2000 :  0.09485425978899002\n",
      "Epoch:  329  Average loss at step  3000 :  0.10253217285871506\n",
      "Epoch:  329  Average loss at step  3222 :  0.10758780479689414\n",
      "329 0 29.37772536277771\n",
      "Training time took 29.497737 seconds to run 1 epoch\n",
      "Epoch:  330  Average loss at step  1000 :  7.62323831653595\n",
      "Epoch:  330  Average loss at step  2000 :  7.985213699340821\n",
      "Epoch:  330  Average loss at step  3000 :  8.044035582542419\n",
      "Epoch:  330  Average loss at step  4000 :  8.293714440345765\n",
      "Epoch:  330  Average loss at step  5000 :  8.455254191398621\n",
      "Epoch:  330  Average loss at step  6000 :  8.354158236026764\n",
      "Epoch:  330  Average loss at step  7000 :  7.9809821057319645\n",
      "Epoch:  330  Average loss at step  8000 :  8.148745433807374\n",
      "Epoch:  330  Average loss at step  8472 :  8.331078211250594\n",
      "330 0 20.723734140396118\n",
      "Epoch:  330  Average loss at step  1000 :  2267.473934753418\n",
      "Epoch:  330  Average loss at step  1491 :  2312.850629212747\n",
      "330 1 11.733716249465942\n",
      "Epoch:  330  Average loss at step  1000 :  3221.4988461914063\n",
      "Epoch:  330  Average loss at step  2000 :  3198.1312196044923\n",
      "Epoch:  330  Average loss at step  2533 :  3224.7441903561603\n",
      "330 2 19.93233036994934\n",
      "Epoch:  330  Average loss at step  1000 :  68.81174114608764\n",
      "Epoch:  330  Average loss at step  1227 :  68.57776321247552\n",
      "330 3 12.73429560661316\n",
      "Epoch:  330  Average loss at step  1000 :  9.82688338470459\n",
      "Epoch:  330  Average loss at step  2000 :  9.722951838493348\n",
      "Epoch:  330  Average loss at step  3000 :  9.762471396923065\n",
      "Epoch:  330  Average loss at step  3222 :  9.563598208402464\n",
      "330 4 33.230812311172485\n",
      "330 5 1.430511474609375e-06\n",
      "Training time took 98.983863 seconds to run 1 epoch\n",
      "Mean Rank:  169.2216  of  75000\n",
      "Hits @ 10:  0.84676\n",
      "Hits @ 1:  0.59804\n",
      "Testing time took 165.152889 seconds.\n",
      "\n",
      "Epoch:  331  Average loss at step  1000 :  0.08981024199724197\n",
      "Epoch:  331  Average loss at step  2000 :  0.09410105419158936\n",
      "Epoch:  331  Average loss at step  3000 :  0.1021807222366333\n",
      "Epoch:  331  Average loss at step  3222 :  0.10620018951211473\n",
      "331 0 29.492608070373535\n",
      "Training time took 29.601596 seconds to run 1 epoch\n",
      "Epoch:  332  Average loss at step  1000 :  8.477551103591919\n",
      "Epoch:  332  Average loss at step  2000 :  7.902792017936706\n",
      "Epoch:  332  Average loss at step  3000 :  7.37740354347229\n",
      "Epoch:  332  Average loss at step  4000 :  8.37342769241333\n",
      "Epoch:  332  Average loss at step  5000 :  7.840808500289917\n",
      "Epoch:  332  Average loss at step  6000 :  8.096467781066895\n",
      "Epoch:  332  Average loss at step  7000 :  7.921041533470154\n",
      "Epoch:  332  Average loss at step  8000 :  8.552920533180236\n",
      "Epoch:  332  Average loss at step  8472 :  7.449319758200088\n",
      "332 0 20.95362615585327\n",
      "Epoch:  332  Average loss at step  1000 :  2289.6267144775393\n",
      "Epoch:  332  Average loss at step  1491 :  2297.8606738243457\n",
      "332 1 11.68908977508545\n",
      "Epoch:  332  Average loss at step  1000 :  3222.7932545166013\n",
      "Epoch:  332  Average loss at step  2000 :  3243.0887380371096\n",
      "Epoch:  332  Average loss at step  2533 :  3228.3888169662787\n",
      "332 2 19.823867559432983\n",
      "Epoch:  332  Average loss at step  1000 :  68.97921487426758\n",
      "Epoch:  332  Average loss at step  1227 :  68.56577336333261\n",
      "332 3 12.684991359710693\n",
      "Epoch:  332  Average loss at step  1000 :  9.821569403171539\n",
      "Epoch:  332  Average loss at step  2000 :  9.79320333147049\n",
      "Epoch:  332  Average loss at step  3000 :  9.712258407592774\n",
      "Epoch:  332  Average loss at step  3222 :  9.800193324418764\n",
      "332 4 33.21285939216614\n",
      "332 5 1.1920928955078125e-06\n",
      "Training time took 99.000861 seconds to run 1 epoch\n",
      "Epoch:  333  Average loss at step  1000 :  0.08962623941898346\n",
      "Epoch:  333  Average loss at step  2000 :  0.09388641202449799\n",
      "Epoch:  333  Average loss at step  3000 :  0.10145174115896224\n",
      "Epoch:  333  Average loss at step  3222 :  0.10517896819704382\n",
      "333 0 29.391332864761353\n",
      "Training time took 29.512777 seconds to run 1 epoch\n",
      "Epoch:  334  Average loss at step  1000 :  8.043261490821838\n",
      "Epoch:  334  Average loss at step  2000 :  8.468375056266785\n",
      "Epoch:  334  Average loss at step  3000 :  8.081766353607177\n",
      "Epoch:  334  Average loss at step  4000 :  8.398761588573455\n",
      "Epoch:  334  Average loss at step  5000 :  8.138375062942504\n",
      "Epoch:  334  Average loss at step  6000 :  8.244316661834716\n",
      "Epoch:  334  Average loss at step  7000 :  8.768720051765442\n",
      "Epoch:  334  Average loss at step  8000 :  8.149897130966187\n",
      "Epoch:  334  Average loss at step  8472 :  7.222907815692552\n",
      "334 0 20.660377502441406\n",
      "Epoch:  334  Average loss at step  1000 :  2313.8796407470704\n",
      "Epoch:  334  Average loss at step  1491 :  2315.998485475749\n",
      "334 1 11.710801362991333\n",
      "Epoch:  334  Average loss at step  1000 :  3217.550479370117\n",
      "Epoch:  334  Average loss at step  2000 :  3210.2982194824217\n",
      "Epoch:  334  Average loss at step  2533 :  3194.487248156047\n",
      "334 2 19.859843015670776\n",
      "Epoch:  334  Average loss at step  1000 :  69.3227318572998\n",
      "Epoch:  334  Average loss at step  1227 :  68.94145441680087\n",
      "334 3 12.640949249267578\n",
      "Epoch:  334  Average loss at step  1000 :  9.680989802837372\n",
      "Epoch:  334  Average loss at step  2000 :  9.583682120800018\n",
      "Epoch:  334  Average loss at step  3000 :  9.5277120013237\n",
      "Epoch:  334  Average loss at step  3222 :  9.790950368986941\n",
      "334 4 33.132853984832764\n",
      "334 5 1.430511474609375e-06\n",
      "Training time took 98.639144 seconds to run 1 epoch\n",
      "Epoch:  335  Average loss at step  1000 :  0.08903131937980652\n",
      "Epoch:  335  Average loss at step  2000 :  0.09312406015396119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  335  Average loss at step  3000 :  0.10118242311477661\n",
      "Epoch:  335  Average loss at step  3222 :  0.10602759887733536\n",
      "335 0 29.40122675895691\n",
      "Training time took 29.52052 seconds to run 1 epoch\n",
      "Epoch:  336  Average loss at step  1000 :  7.634534628391266\n",
      "Epoch:  336  Average loss at step  2000 :  8.148086447715759\n",
      "Epoch:  336  Average loss at step  3000 :  7.968238947868347\n",
      "Epoch:  336  Average loss at step  4000 :  8.450841119289398\n",
      "Epoch:  336  Average loss at step  5000 :  8.058264910697938\n",
      "Epoch:  336  Average loss at step  6000 :  8.517495303153991\n",
      "Epoch:  336  Average loss at step  7000 :  8.20928452348709\n",
      "Epoch:  336  Average loss at step  8000 :  8.46713896894455\n",
      "Epoch:  336  Average loss at step  8472 :  8.069788851563318\n",
      "336 0 20.618090629577637\n",
      "Epoch:  336  Average loss at step  1000 :  2318.0437388916016\n",
      "Epoch:  336  Average loss at step  1491 :  2270.275421636772\n",
      "336 1 11.657472372055054\n",
      "Epoch:  336  Average loss at step  1000 :  3258.6298010253904\n",
      "Epoch:  336  Average loss at step  2000 :  3234.206586303711\n",
      "Epoch:  336  Average loss at step  2533 :  3216.1464342859304\n",
      "336 2 19.94900107383728\n",
      "Epoch:  336  Average loss at step  1000 :  68.55361151504516\n",
      "Epoch:  336  Average loss at step  1227 :  68.58522098181281\n",
      "336 3 12.691309690475464\n",
      "Epoch:  336  Average loss at step  1000 :  9.502344582557678\n",
      "Epoch:  336  Average loss at step  2000 :  9.616897382736205\n",
      "Epoch:  336  Average loss at step  3000 :  9.525859641075135\n",
      "Epoch:  336  Average loss at step  3222 :  9.797870951409934\n",
      "336 4 33.229177713394165\n",
      "336 5 1.1920928955078125e-06\n",
      "Training time took 98.787036 seconds to run 1 epoch\n",
      "Epoch:  337  Average loss at step  1000 :  0.08839696496725083\n",
      "Epoch:  337  Average loss at step  2000 :  0.09274967324733734\n",
      "Epoch:  337  Average loss at step  3000 :  0.10086901646852493\n",
      "Epoch:  337  Average loss at step  3222 :  0.10582539262184491\n",
      "337 0 29.452061653137207\n",
      "Training time took 29.570818 seconds to run 1 epoch\n",
      "Epoch:  338  Average loss at step  1000 :  7.716320837497711\n",
      "Epoch:  338  Average loss at step  2000 :  8.50238465976715\n",
      "Epoch:  338  Average loss at step  3000 :  8.295109684944153\n",
      "Epoch:  338  Average loss at step  4000 :  8.266154585838319\n",
      "Epoch:  338  Average loss at step  5000 :  8.206777629852295\n",
      "Epoch:  338  Average loss at step  6000 :  8.306202984333039\n",
      "Epoch:  338  Average loss at step  7000 :  8.366174978256225\n",
      "Epoch:  338  Average loss at step  8000 :  8.106742402076721\n",
      "Epoch:  338  Average loss at step  8472 :  8.14978088649939\n",
      "338 0 20.781389236450195\n",
      "Epoch:  338  Average loss at step  1000 :  2278.7360061035156\n",
      "Epoch:  338  Average loss at step  1491 :  2320.3304986139983\n",
      "338 1 11.71158218383789\n",
      "Epoch:  338  Average loss at step  1000 :  3247.4681787109375\n",
      "Epoch:  338  Average loss at step  2000 :  3234.420616821289\n",
      "Epoch:  338  Average loss at step  2533 :  3252.2808897312893\n",
      "338 2 19.93937635421753\n",
      "Epoch:  338  Average loss at step  1000 :  68.33006972885131\n",
      "Epoch:  338  Average loss at step  1227 :  67.82608897252545\n",
      "338 3 12.625141620635986\n",
      "Epoch:  338  Average loss at step  1000 :  9.490250670909882\n",
      "Epoch:  338  Average loss at step  2000 :  9.447636173248291\n",
      "Epoch:  338  Average loss at step  3000 :  9.515350121498107\n",
      "Epoch:  338  Average loss at step  3222 :  9.468680687987174\n",
      "338 4 33.187461137771606\n",
      "338 5 1.6689300537109375e-06\n",
      "Training time took 98.876526 seconds to run 1 epoch\n",
      "Epoch:  339  Average loss at step  1000 :  0.08771060788631439\n",
      "Epoch:  339  Average loss at step  2000 :  0.09174378579854965\n",
      "Epoch:  339  Average loss at step  3000 :  0.10041988116502762\n",
      "Epoch:  339  Average loss at step  3222 :  0.1044770395697659\n",
      "339 0 29.397889852523804\n",
      "Training time took 29.519252 seconds to run 1 epoch\n",
      "Epoch:  340  Average loss at step  1000 :  8.326834834098817\n",
      "Epoch:  340  Average loss at step  2000 :  8.208865057945252\n",
      "Epoch:  340  Average loss at step  3000 :  8.003425642967224\n",
      "Epoch:  340  Average loss at step  4000 :  7.988789873123169\n",
      "Epoch:  340  Average loss at step  5000 :  7.837867999553681\n",
      "Epoch:  340  Average loss at step  6000 :  7.627335082054138\n",
      "Epoch:  340  Average loss at step  7000 :  8.2867971906662\n",
      "Epoch:  340  Average loss at step  8000 :  8.217743001937865\n",
      "Epoch:  340  Average loss at step  8472 :  8.224453510591886\n",
      "340 0 20.3632595539093\n",
      "Epoch:  340  Average loss at step  1000 :  2309.7857170410157\n",
      "Epoch:  340  Average loss at step  1491 :  2270.6089036170824\n",
      "340 1 11.71605134010315\n",
      "Epoch:  340  Average loss at step  1000 :  3269.8986083984373\n",
      "Epoch:  340  Average loss at step  2000 :  3276.416439086914\n",
      "Epoch:  340  Average loss at step  2533 :  3275.203042900913\n",
      "340 2 19.917469263076782\n",
      "Epoch:  340  Average loss at step  1000 :  68.50208339691162\n",
      "Epoch:  340  Average loss at step  1227 :  69.28767743116758\n",
      "340 3 12.649850130081177\n",
      "Epoch:  340  Average loss at step  1000 :  9.427601279258727\n",
      "Epoch:  340  Average loss at step  2000 :  9.519824758052826\n",
      "Epoch:  340  Average loss at step  3000 :  9.371386799335479\n",
      "Epoch:  340  Average loss at step  3222 :  9.975497422181306\n",
      "340 4 33.10394525527954\n",
      "340 5 1.430511474609375e-06\n",
      "Training time took 98.398447 seconds to run 1 epoch\n",
      "Mean Rank:  171.33996  of  75000\n",
      "Hits @ 10:  0.84764\n",
      "Hits @ 1:  0.59976\n",
      "Testing time took 164.885825 seconds.\n",
      "\n",
      "Epoch:  341  Average loss at step  1000 :  0.08786553537845612\n",
      "Epoch:  341  Average loss at step  2000 :  0.09178259992599487\n",
      "Epoch:  341  Average loss at step  3000 :  0.09992721527814866\n",
      "Epoch:  341  Average loss at step  3222 :  0.10436098430104625\n",
      "341 0 29.428196907043457\n",
      "Training time took 29.535999 seconds to run 1 epoch\n",
      "Epoch:  342  Average loss at step  1000 :  7.952353378295898\n",
      "Epoch:  342  Average loss at step  2000 :  7.488527874946595\n",
      "Epoch:  342  Average loss at step  3000 :  7.948600218772889\n",
      "Epoch:  342  Average loss at step  4000 :  8.319540916919708\n",
      "Epoch:  342  Average loss at step  5000 :  8.15695069694519\n",
      "Epoch:  342  Average loss at step  6000 :  8.274061396598816\n",
      "Epoch:  342  Average loss at step  7000 :  7.9105058231353755\n",
      "Epoch:  342  Average loss at step  8000 :  8.353983602523805\n",
      "Epoch:  342  Average loss at step  8472 :  7.5917061164208\n",
      "342 0 20.88107967376709\n",
      "Epoch:  342  Average loss at step  1000 :  2313.7018188476563\n",
      "Epoch:  342  Average loss at step  1491 :  2296.392672453303\n",
      "342 1 11.696954488754272\n",
      "Epoch:  342  Average loss at step  1000 :  3271.2380367431642\n",
      "Epoch:  342  Average loss at step  2000 :  3271.219478149414\n",
      "Epoch:  342  Average loss at step  2533 :  3246.5452217945494\n",
      "342 2 19.867502689361572\n",
      "Epoch:  342  Average loss at step  1000 :  68.90924821472169\n",
      "Epoch:  342  Average loss at step  1227 :  68.84059041821342\n",
      "342 3 12.661427021026611\n",
      "Epoch:  342  Average loss at step  1000 :  9.265401767253875\n",
      "Epoch:  342  Average loss at step  2000 :  9.268151801109314\n",
      "Epoch:  342  Average loss at step  3000 :  9.2744229722023\n",
      "Epoch:  342  Average loss at step  3222 :  9.652937024611173\n",
      "342 4 33.20558524131775\n",
      "342 5 1.430511474609375e-06\n",
      "Training time took 98.960155 seconds to run 1 epoch\n",
      "Epoch:  343  Average loss at step  1000 :  0.08714198422431946\n",
      "Epoch:  343  Average loss at step  2000 :  0.0909045683145523\n",
      "Epoch:  343  Average loss at step  3000 :  0.09888525956869125\n",
      "Epoch:  343  Average loss at step  3222 :  0.1042610999801396\n",
      "343 0 29.437269926071167\n",
      "Training time took 29.564057 seconds to run 1 epoch\n",
      "Epoch:  344  Average loss at step  1000 :  8.024524243354797\n",
      "Epoch:  344  Average loss at step  2000 :  7.980245358467102\n",
      "Epoch:  344  Average loss at step  3000 :  8.208438629150391\n",
      "Epoch:  344  Average loss at step  4000 :  8.103229588508606\n",
      "Epoch:  344  Average loss at step  5000 :  7.827424501419068\n",
      "Epoch:  344  Average loss at step  6000 :  8.350028010368348\n",
      "Epoch:  344  Average loss at step  7000 :  8.070776264190673\n",
      "Epoch:  344  Average loss at step  8000 :  8.0269273147583\n",
      "Epoch:  344  Average loss at step  8472 :  7.878225899366019\n",
      "344 0 20.961894035339355\n",
      "Epoch:  344  Average loss at step  1000 :  2328.3829061889646\n",
      "Epoch:  344  Average loss at step  1491 :  2275.739072298845\n",
      "344 1 11.735976219177246\n",
      "Epoch:  344  Average loss at step  1000 :  3235.034446044922\n",
      "Epoch:  344  Average loss at step  2000 :  3254.5351099853515\n",
      "Epoch:  344  Average loss at step  2533 :  3251.1130724231793\n",
      "344 2 19.85000228881836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  344  Average loss at step  1000 :  69.06171200561523\n",
      "Epoch:  344  Average loss at step  1227 :  69.48898646293712\n",
      "344 3 12.648528099060059\n",
      "Epoch:  344  Average loss at step  1000 :  9.31066632413864\n",
      "Epoch:  344  Average loss at step  2000 :  9.244948852539062\n",
      "Epoch:  344  Average loss at step  3000 :  9.257873274803162\n",
      "Epoch:  344  Average loss at step  3222 :  9.109191660804425\n",
      "344 4 33.17031693458557\n",
      "344 5 1.430511474609375e-06\n",
      "Training time took 99.007327 seconds to run 1 epoch\n",
      "Epoch:  345  Average loss at step  1000 :  0.08652997416257859\n",
      "Epoch:  345  Average loss at step  2000 :  0.09122073668241501\n",
      "Epoch:  345  Average loss at step  3000 :  0.09870032966136932\n",
      "Epoch:  345  Average loss at step  3222 :  0.10236415283670063\n",
      "345 0 29.363001346588135\n",
      "Training time took 29.481647 seconds to run 1 epoch\n",
      "Epoch:  346  Average loss at step  1000 :  7.935688283920288\n",
      "Epoch:  346  Average loss at step  2000 :  7.911547592163086\n",
      "Epoch:  346  Average loss at step  3000 :  8.286464609146119\n",
      "Epoch:  346  Average loss at step  4000 :  8.054942200660706\n",
      "Epoch:  346  Average loss at step  5000 :  8.032306067466736\n",
      "Epoch:  346  Average loss at step  6000 :  7.935803182125092\n",
      "Epoch:  346  Average loss at step  7000 :  8.200917757987977\n",
      "Epoch:  346  Average loss at step  8000 :  8.072197847366333\n",
      "Epoch:  346  Average loss at step  8472 :  7.886685107125778\n",
      "346 0 20.230277061462402\n",
      "Epoch:  346  Average loss at step  1000 :  2312.180235961914\n",
      "Epoch:  346  Average loss at step  1491 :  2340.7840850210314\n",
      "346 1 11.692529201507568\n",
      "Epoch:  346  Average loss at step  1000 :  3255.6351400146486\n",
      "Epoch:  346  Average loss at step  2000 :  3239.074818359375\n",
      "Epoch:  346  Average loss at step  2533 :  3256.2154396429096\n",
      "346 2 19.9379780292511\n",
      "Epoch:  346  Average loss at step  1000 :  68.36973812484742\n",
      "Epoch:  346  Average loss at step  1227 :  68.98382651967334\n",
      "346 3 12.623422384262085\n",
      "Epoch:  346  Average loss at step  1000 :  9.282728953361511\n",
      "Epoch:  346  Average loss at step  2000 :  9.09933451461792\n",
      "Epoch:  346  Average loss at step  3000 :  9.220968391895294\n",
      "Epoch:  346  Average loss at step  3222 :  9.191292579218377\n",
      "346 4 33.13803291320801\n",
      "346 5 1.430511474609375e-06\n",
      "Training time took 98.274185 seconds to run 1 epoch\n",
      "Epoch:  347  Average loss at step  1000 :  0.08629372924566268\n",
      "Epoch:  347  Average loss at step  2000 :  0.09000970250368118\n",
      "Epoch:  347  Average loss at step  3000 :  0.0988217282295227\n",
      "Epoch:  347  Average loss at step  3222 :  0.10399941040906133\n",
      "347 0 29.425155639648438\n",
      "Training time took 29.543968 seconds to run 1 epoch\n",
      "Epoch:  348  Average loss at step  1000 :  8.096301351547242\n",
      "Epoch:  348  Average loss at step  2000 :  8.34582120323181\n",
      "Epoch:  348  Average loss at step  3000 :  8.355595014572144\n",
      "Epoch:  348  Average loss at step  4000 :  8.175467694282531\n",
      "Epoch:  348  Average loss at step  5000 :  7.973017322540283\n",
      "Epoch:  348  Average loss at step  6000 :  7.966198990821838\n",
      "Epoch:  348  Average loss at step  7000 :  8.298760947227478\n",
      "Epoch:  348  Average loss at step  8000 :  7.830157517433166\n",
      "Epoch:  348  Average loss at step  8472 :  8.179261584136407\n",
      "348 0 20.288856029510498\n",
      "Epoch:  348  Average loss at step  1000 :  2301.5796154785157\n",
      "Epoch:  348  Average loss at step  1491 :  2354.851074666322\n",
      "348 1 11.732653856277466\n",
      "Epoch:  348  Average loss at step  1000 :  3263.0968502197265\n",
      "Epoch:  348  Average loss at step  2000 :  3271.603740356445\n",
      "Epoch:  348  Average loss at step  2533 :  3269.7406873332693\n",
      "348 2 19.884225368499756\n",
      "Epoch:  348  Average loss at step  1000 :  68.39995164871216\n",
      "Epoch:  348  Average loss at step  1227 :  68.70839078609275\n",
      "348 3 12.651554584503174\n",
      "Epoch:  348  Average loss at step  1000 :  9.086780685901642\n",
      "Epoch:  348  Average loss at step  2000 :  9.137284284114838\n",
      "Epoch:  348  Average loss at step  3000 :  9.122800580501556\n",
      "Epoch:  348  Average loss at step  3222 :  9.038970459237127\n",
      "348 4 33.18751549720764\n",
      "348 5 1.430511474609375e-06\n",
      "Training time took 98.384473 seconds to run 1 epoch\n",
      "Epoch:  349  Average loss at step  1000 :  0.08582937306165696\n",
      "Epoch:  349  Average loss at step  2000 :  0.09010077035427093\n",
      "Epoch:  349  Average loss at step  3000 :  0.09747829127311707\n",
      "Epoch:  349  Average loss at step  3222 :  0.10193038054549064\n",
      "349 0 29.434558629989624\n",
      "Training time took 29.556615 seconds to run 1 epoch\n",
      "Epoch:  350  Average loss at step  1000 :  8.221380948066711\n",
      "Epoch:  350  Average loss at step  2000 :  7.804877184867859\n",
      "Epoch:  350  Average loss at step  3000 :  8.067049615859986\n",
      "Epoch:  350  Average loss at step  4000 :  8.207284724712371\n",
      "Epoch:  350  Average loss at step  5000 :  7.833706286907196\n",
      "Epoch:  350  Average loss at step  6000 :  8.049118265151977\n",
      "Epoch:  350  Average loss at step  7000 :  8.700161219596863\n",
      "Epoch:  350  Average loss at step  8000 :  7.947587540626526\n",
      "Epoch:  350  Average loss at step  8472 :  8.097521887687313\n",
      "350 0 20.911853313446045\n",
      "Epoch:  350  Average loss at step  1000 :  2320.204777282715\n",
      "Epoch:  350  Average loss at step  1491 :  2301.135985064977\n",
      "350 1 11.713680505752563\n",
      "Epoch:  350  Average loss at step  1000 :  3282.667630981445\n",
      "Epoch:  350  Average loss at step  2000 :  3243.2000203857424\n",
      "Epoch:  350  Average loss at step  2533 :  3221.297980657947\n",
      "350 2 19.84620761871338\n",
      "Epoch:  350  Average loss at step  1000 :  67.99234980773926\n",
      "Epoch:  350  Average loss at step  1227 :  67.69780748737303\n",
      "350 3 12.623992204666138\n",
      "Epoch:  350  Average loss at step  1000 :  9.087045040130615\n",
      "Epoch:  350  Average loss at step  2000 :  9.055688680171967\n",
      "Epoch:  350  Average loss at step  3000 :  8.961067162036896\n",
      "Epoch:  350  Average loss at step  3222 :  8.616208836455103\n",
      "350 4 33.196728467941284\n",
      "350 5 7.152557373046875e-07\n",
      "Training time took 98.943132 seconds to run 1 epoch\n",
      "Mean Rank:  165.93336  of  75000\n",
      "Hits @ 10:  0.84808\n",
      "Hits @ 1:  0.60356\n",
      "Testing time took 165.015351 seconds.\n",
      "\n",
      "Epoch:  351  Average loss at step  1000 :  0.08496335887908936\n",
      "Epoch:  351  Average loss at step  2000 :  0.08971130841970444\n",
      "Epoch:  351  Average loss at step  3000 :  0.09745951908826828\n",
      "Epoch:  351  Average loss at step  3222 :  0.1026063170173061\n",
      "351 0 29.423980712890625\n",
      "Training time took 29.5333 seconds to run 1 epoch\n",
      "Epoch:  352  Average loss at step  1000 :  8.12329596376419\n",
      "Epoch:  352  Average loss at step  2000 :  8.159166286468507\n",
      "Epoch:  352  Average loss at step  3000 :  8.019438665390014\n",
      "Epoch:  352  Average loss at step  4000 :  8.73134200000763\n",
      "Epoch:  352  Average loss at step  5000 :  8.521876287460326\n",
      "Epoch:  352  Average loss at step  6000 :  8.161087516784669\n",
      "Epoch:  352  Average loss at step  7000 :  8.275824509620666\n",
      "Epoch:  352  Average loss at step  8000 :  8.041749787330627\n",
      "Epoch:  352  Average loss at step  8472 :  8.15144517588588\n",
      "352 0 20.38201093673706\n",
      "Epoch:  352  Average loss at step  1000 :  2332.1231947021483\n",
      "Epoch:  352  Average loss at step  1491 :  2296.0257710115397\n",
      "352 1 11.750097513198853\n",
      "Epoch:  352  Average loss at step  1000 :  3293.00040234375\n",
      "Epoch:  352  Average loss at step  2000 :  3261.129279663086\n",
      "Epoch:  352  Average loss at step  2533 :  3250.8005326400867\n",
      "352 2 19.931581020355225\n",
      "Epoch:  352  Average loss at step  1000 :  68.44005883789063\n",
      "Epoch:  352  Average loss at step  1227 :  67.70510090177363\n",
      "352 3 12.567199945449829\n",
      "Epoch:  352  Average loss at step  1000 :  8.910975653648377\n",
      "Epoch:  352  Average loss at step  2000 :  8.915218552589417\n",
      "Epoch:  352  Average loss at step  3000 :  8.7232295255661\n",
      "Epoch:  352  Average loss at step  3222 :  9.22610500827768\n",
      "352 4 33.30913424491882\n",
      "352 5 1.1920928955078125e-06\n",
      "Training time took 98.572061 seconds to run 1 epoch\n",
      "Epoch:  353  Average loss at step  1000 :  0.08525346970558166\n",
      "Epoch:  353  Average loss at step  2000 :  0.08919198328256607\n",
      "Epoch:  353  Average loss at step  3000 :  0.0969544227719307\n",
      "Epoch:  353  Average loss at step  3222 :  0.10185176219120635\n",
      "353 0 29.36326551437378\n",
      "Training time took 29.48492 seconds to run 1 epoch\n",
      "Epoch:  354  Average loss at step  1000 :  8.204388845920564\n",
      "Epoch:  354  Average loss at step  2000 :  7.978829706192017\n",
      "Epoch:  354  Average loss at step  3000 :  8.180256840705871\n",
      "Epoch:  354  Average loss at step  4000 :  8.171844378471375\n",
      "Epoch:  354  Average loss at step  5000 :  8.123159935951232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  354  Average loss at step  6000 :  8.053577931404114\n",
      "Epoch:  354  Average loss at step  7000 :  7.886783687114716\n",
      "Epoch:  354  Average loss at step  8000 :  7.903495781898498\n",
      "Epoch:  354  Average loss at step  8472 :  8.542161137415848\n",
      "354 0 21.062446117401123\n",
      "Epoch:  354  Average loss at step  1000 :  2328.7643479614258\n",
      "Epoch:  354  Average loss at step  1491 :  2335.5966606806055\n",
      "354 1 11.730477094650269\n",
      "Epoch:  354  Average loss at step  1000 :  3258.7790537109377\n",
      "Epoch:  354  Average loss at step  2000 :  3259.4771450195312\n",
      "Epoch:  354  Average loss at step  2533 :  3280.5505388989263\n",
      "354 2 19.908735036849976\n",
      "Epoch:  354  Average loss at step  1000 :  68.22847426223755\n",
      "Epoch:  354  Average loss at step  1227 :  68.1949402083001\n",
      "354 3 12.623313665390015\n",
      "Epoch:  354  Average loss at step  1000 :  9.019383777618408\n",
      "Epoch:  354  Average loss at step  2000 :  8.9002525267601\n",
      "Epoch:  354  Average loss at step  3000 :  8.883069362163544\n",
      "Epoch:  354  Average loss at step  3222 :  9.181063490280671\n",
      "354 4 33.16759014129639\n",
      "354 5 1.430511474609375e-06\n",
      "Training time took 99.133214 seconds to run 1 epoch\n",
      "Epoch:  355  Average loss at step  1000 :  0.08482078284025192\n",
      "Epoch:  355  Average loss at step  2000 :  0.08831870305538178\n",
      "Epoch:  355  Average loss at step  3000 :  0.0965290356874466\n",
      "Epoch:  355  Average loss at step  3222 :  0.10211228770154288\n",
      "355 0 29.361643075942993\n",
      "Training time took 29.48447 seconds to run 1 epoch\n",
      "Epoch:  356  Average loss at step  1000 :  7.80099395942688\n",
      "Epoch:  356  Average loss at step  2000 :  8.052448818206788\n",
      "Epoch:  356  Average loss at step  3000 :  8.065225568771362\n",
      "Epoch:  356  Average loss at step  4000 :  8.03483098602295\n",
      "Epoch:  356  Average loss at step  5000 :  7.9470401110649105\n",
      "Epoch:  356  Average loss at step  6000 :  8.207925407409668\n",
      "Epoch:  356  Average loss at step  7000 :  8.29560031414032\n",
      "Epoch:  356  Average loss at step  8000 :  7.740930457115173\n",
      "Epoch:  356  Average loss at step  8472 :  7.945815035728246\n",
      "356 0 20.626479625701904\n",
      "Epoch:  356  Average loss at step  1000 :  2314.542278808594\n",
      "Epoch:  356  Average loss at step  1491 :  2314.1132917231866\n",
      "356 1 11.68657898902893\n",
      "Epoch:  356  Average loss at step  1000 :  3276.1780357666016\n",
      "Epoch:  356  Average loss at step  2000 :  3260.0494216308593\n",
      "Epoch:  356  Average loss at step  2533 :  3270.5414888648456\n",
      "356 2 19.881290197372437\n",
      "Epoch:  356  Average loss at step  1000 :  68.02971545791625\n",
      "Epoch:  356  Average loss at step  1227 :  68.40215812484857\n",
      "356 3 12.63200831413269\n",
      "Epoch:  356  Average loss at step  1000 :  8.971273948669433\n",
      "Epoch:  356  Average loss at step  2000 :  9.01210760831833\n",
      "Epoch:  356  Average loss at step  3000 :  8.929157018184663\n",
      "Epoch:  356  Average loss at step  3222 :  8.805363977573089\n",
      "356 4 33.10140323638916\n",
      "356 5 1.430511474609375e-06\n",
      "Training time took 98.551634 seconds to run 1 epoch\n",
      "Epoch:  357  Average loss at step  1000 :  0.0842987614274025\n",
      "Epoch:  357  Average loss at step  2000 :  0.0881894651055336\n",
      "Epoch:  357  Average loss at step  3000 :  0.09593343967199326\n",
      "Epoch:  357  Average loss at step  3222 :  0.09909908593744766\n",
      "357 0 29.314332723617554\n",
      "Training time took 29.434253 seconds to run 1 epoch\n",
      "Epoch:  358  Average loss at step  1000 :  8.17188288640976\n",
      "Epoch:  358  Average loss at step  2000 :  7.762142909049988\n",
      "Epoch:  358  Average loss at step  3000 :  8.081620499610901\n",
      "Epoch:  358  Average loss at step  4000 :  8.681144785881042\n",
      "Epoch:  358  Average loss at step  5000 :  8.459694128990174\n",
      "Epoch:  358  Average loss at step  6000 :  8.058621885299683\n",
      "Epoch:  358  Average loss at step  7000 :  8.107113085269928\n",
      "Epoch:  358  Average loss at step  8000 :  8.170287662506103\n",
      "Epoch:  358  Average loss at step  8472 :  7.932085748247236\n",
      "358 0 20.525805950164795\n",
      "Epoch:  358  Average loss at step  1000 :  2345.568178649902\n",
      "Epoch:  358  Average loss at step  1491 :  2336.1678491885777\n",
      "358 1 11.720355987548828\n",
      "Epoch:  358  Average loss at step  1000 :  3317.0141923828123\n",
      "Epoch:  358  Average loss at step  2000 :  3270.890612426758\n",
      "Epoch:  358  Average loss at step  2533 :  3268.7833409387717\n",
      "358 2 19.923377990722656\n",
      "Epoch:  358  Average loss at step  1000 :  68.35552962112426\n",
      "Epoch:  358  Average loss at step  1227 :  67.87232408958177\n",
      "358 3 12.618781805038452\n",
      "Epoch:  358  Average loss at step  1000 :  8.821120314121247\n",
      "Epoch:  358  Average loss at step  2000 :  8.705149935245514\n",
      "Epoch:  358  Average loss at step  3000 :  8.891168263435365\n",
      "Epoch:  358  Average loss at step  3222 :  8.591812017226955\n",
      "358 4 33.1601448059082\n",
      "358 5 1.6689300537109375e-06\n",
      "Training time took 98.595874 seconds to run 1 epoch\n",
      "Epoch:  359  Average loss at step  1000 :  0.08436836338043213\n",
      "Epoch:  359  Average loss at step  2000 :  0.08767803162336349\n",
      "Epoch:  359  Average loss at step  3000 :  0.09576930981874467\n",
      "Epoch:  359  Average loss at step  3222 :  0.09976068269821212\n",
      "359 0 29.39618444442749\n",
      "Training time took 29.518137 seconds to run 1 epoch\n",
      "Epoch:  360  Average loss at step  1000 :  8.523850313186646\n",
      "Epoch:  360  Average loss at step  2000 :  7.996677298545837\n",
      "Epoch:  360  Average loss at step  3000 :  8.070974549770355\n",
      "Epoch:  360  Average loss at step  4000 :  8.122418711185455\n",
      "Epoch:  360  Average loss at step  5000 :  8.112695309638976\n",
      "Epoch:  360  Average loss at step  6000 :  7.92958860206604\n",
      "Epoch:  360  Average loss at step  7000 :  7.863383595943451\n",
      "Epoch:  360  Average loss at step  8000 :  7.7890909385681155\n",
      "Epoch:  360  Average loss at step  8472 :  8.560411754313645\n",
      "360 0 20.6795551776886\n",
      "Epoch:  360  Average loss at step  1000 :  2344.73624230957\n",
      "Epoch:  360  Average loss at step  1491 :  2347.453941202396\n",
      "360 1 11.661359071731567\n",
      "Epoch:  360  Average loss at step  1000 :  3293.5253859863283\n",
      "Epoch:  360  Average loss at step  2000 :  3289.9523228759767\n",
      "Epoch:  360  Average loss at step  2533 :  3288.7347219617945\n",
      "360 2 19.90057635307312\n",
      "Epoch:  360  Average loss at step  1000 :  68.08140144348144\n",
      "Epoch:  360  Average loss at step  1227 :  68.34515903846679\n",
      "360 3 12.622175693511963\n",
      "Epoch:  360  Average loss at step  1000 :  8.803386846065521\n",
      "Epoch:  360  Average loss at step  2000 :  8.74885060596466\n",
      "Epoch:  360  Average loss at step  3000 :  8.66922762441635\n",
      "Epoch:  360  Average loss at step  3222 :  8.594285077320407\n",
      "360 4 33.08347177505493\n",
      "360 5 1.430511474609375e-06\n",
      "Training time took 98.596056 seconds to run 1 epoch\n",
      "Mean Rank:  169.03788  of  75000\n",
      "Hits @ 10:  0.84924\n",
      "Hits @ 1:  0.60584\n",
      "Testing time took 164.725968 seconds.\n",
      "\n",
      "Epoch:  361  Average loss at step  1000 :  0.08354329413175583\n",
      "Epoch:  361  Average loss at step  2000 :  0.08720505505800247\n",
      "Epoch:  361  Average loss at step  3000 :  0.09500713276863099\n",
      "Epoch:  361  Average loss at step  3222 :  0.09861869875716267\n",
      "361 0 29.447319507598877\n",
      "Training time took 29.555735 seconds to run 1 epoch\n",
      "Epoch:  362  Average loss at step  1000 :  8.11751549911499\n",
      "Epoch:  362  Average loss at step  2000 :  7.668586300849914\n",
      "Epoch:  362  Average loss at step  3000 :  8.049227378845215\n",
      "Epoch:  362  Average loss at step  4000 :  8.290282976150513\n",
      "Epoch:  362  Average loss at step  5000 :  7.806520748138428\n",
      "Epoch:  362  Average loss at step  6000 :  8.400923511505127\n",
      "Epoch:  362  Average loss at step  7000 :  7.7416204242706295\n",
      "Epoch:  362  Average loss at step  8000 :  7.8339345779418945\n",
      "Epoch:  362  Average loss at step  8472 :  8.336467246269361\n",
      "362 0 20.253711938858032\n",
      "Epoch:  362  Average loss at step  1000 :  2334.979557861328\n",
      "Epoch:  362  Average loss at step  1491 :  2335.9086460224407\n",
      "362 1 11.696458339691162\n",
      "Epoch:  362  Average loss at step  1000 :  3303.3373153076172\n",
      "Epoch:  362  Average loss at step  2000 :  3254.7189885253906\n",
      "Epoch:  362  Average loss at step  2533 :  3256.892898674859\n",
      "362 2 19.846762895584106\n",
      "Epoch:  362  Average loss at step  1000 :  68.42249948883057\n",
      "Epoch:  362  Average loss at step  1227 :  66.95261587667261\n",
      "362 3 12.56112289428711\n",
      "Epoch:  362  Average loss at step  1000 :  8.620136666297913\n",
      "Epoch:  362  Average loss at step  2000 :  8.780551353931427\n",
      "Epoch:  362  Average loss at step  3000 :  8.695377004623413\n",
      "Epoch:  362  Average loss at step  3222 :  8.418592173047262\n",
      "362 4 33.21953558921814\n",
      "362 5 1.430511474609375e-06\n",
      "Training time took 98.225949 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  363  Average loss at step  1000 :  0.0833926687836647\n",
      "Epoch:  363  Average loss at step  2000 :  0.08692708176374435\n",
      "Epoch:  363  Average loss at step  3000 :  0.09461610746383667\n",
      "Epoch:  363  Average loss at step  3222 :  0.1003729654662681\n",
      "363 0 29.432793140411377\n",
      "Training time took 29.556997 seconds to run 1 epoch\n",
      "Epoch:  364  Average loss at step  1000 :  8.551791214942932\n",
      "Epoch:  364  Average loss at step  2000 :  8.185605880737304\n",
      "Epoch:  364  Average loss at step  3000 :  8.506716284275054\n",
      "Epoch:  364  Average loss at step  4000 :  7.870013175964355\n",
      "Epoch:  364  Average loss at step  5000 :  8.13362143611908\n",
      "Epoch:  364  Average loss at step  6000 :  8.149017722129821\n",
      "Epoch:  364  Average loss at step  7000 :  8.022630559921264\n",
      "Epoch:  364  Average loss at step  8000 :  8.369509377479552\n",
      "Epoch:  364  Average loss at step  8472 :  7.243494123105338\n",
      "364 0 20.606228828430176\n",
      "Epoch:  364  Average loss at step  1000 :  2356.6772373046874\n",
      "Epoch:  364  Average loss at step  1491 :  2323.096683805163\n",
      "364 1 11.669148445129395\n",
      "Epoch:  364  Average loss at step  1000 :  3267.1607537841796\n",
      "Epoch:  364  Average loss at step  2000 :  3302.414873779297\n",
      "Epoch:  364  Average loss at step  2533 :  3283.1186451213066\n",
      "364 2 19.952312231063843\n",
      "Epoch:  364  Average loss at step  1000 :  67.62327408981324\n",
      "Epoch:  364  Average loss at step  1227 :  67.91002782898313\n",
      "364 3 12.572349548339844\n",
      "Epoch:  364  Average loss at step  1000 :  8.678042401790618\n",
      "Epoch:  364  Average loss at step  2000 :  8.64873978281021\n",
      "Epoch:  364  Average loss at step  3000 :  8.60918874835968\n",
      "Epoch:  364  Average loss at step  3222 :  8.46628741379528\n",
      "364 4 33.29421854019165\n",
      "364 5 1.430511474609375e-06\n",
      "Training time took 98.736606 seconds to run 1 epoch\n",
      "Epoch:  365  Average loss at step  1000 :  0.08293805259466171\n",
      "Epoch:  365  Average loss at step  2000 :  0.08624063873291016\n",
      "Epoch:  365  Average loss at step  3000 :  0.09429325556755067\n",
      "Epoch:  365  Average loss at step  3222 :  0.09926074672248911\n",
      "365 0 29.44235134124756\n",
      "Training time took 29.563324 seconds to run 1 epoch\n",
      "Epoch:  366  Average loss at step  1000 :  8.288221044540405\n",
      "Epoch:  366  Average loss at step  2000 :  7.966609045982361\n",
      "Epoch:  366  Average loss at step  3000 :  7.643115406036377\n",
      "Epoch:  366  Average loss at step  4000 :  8.507127559661866\n",
      "Epoch:  366  Average loss at step  5000 :  8.084179845809937\n",
      "Epoch:  366  Average loss at step  6000 :  7.938385880470276\n",
      "Epoch:  366  Average loss at step  7000 :  8.151129397392273\n",
      "Epoch:  366  Average loss at step  8000 :  8.26542346572876\n",
      "Epoch:  366  Average loss at step  8472 :  8.471801597605253\n",
      "366 0 20.538475036621094\n",
      "Epoch:  366  Average loss at step  1000 :  2342.069466430664\n",
      "Epoch:  366  Average loss at step  1491 :  2324.145622565009\n",
      "366 1 11.709845066070557\n",
      "Epoch:  366  Average loss at step  1000 :  3304.1481879882813\n",
      "Epoch:  366  Average loss at step  2000 :  3297.191289794922\n",
      "Epoch:  366  Average loss at step  2533 :  3286.934151814557\n",
      "366 2 19.946805715560913\n",
      "Epoch:  366  Average loss at step  1000 :  68.03782695388794\n",
      "Epoch:  366  Average loss at step  1227 :  67.96110306933892\n",
      "366 3 12.620869398117065\n",
      "Epoch:  366  Average loss at step  1000 :  8.460910584449769\n",
      "Epoch:  366  Average loss at step  2000 :  8.506100352764129\n",
      "Epoch:  366  Average loss at step  3000 :  8.510899427890777\n",
      "Epoch:  366  Average loss at step  3222 :  8.730091218333701\n",
      "366 4 33.09544825553894\n",
      "366 5 1.430511474609375e-06\n",
      "Training time took 98.544264 seconds to run 1 epoch\n",
      "Epoch:  367  Average loss at step  1000 :  0.082431846678257\n",
      "Epoch:  367  Average loss at step  2000 :  0.08637636983394623\n",
      "Epoch:  367  Average loss at step  3000 :  0.09392087638378144\n",
      "Epoch:  367  Average loss at step  3222 :  0.09867295092851122\n",
      "367 0 29.421130657196045\n",
      "Training time took 29.541399 seconds to run 1 epoch\n",
      "Epoch:  368  Average loss at step  1000 :  8.206980961799621\n",
      "Epoch:  368  Average loss at step  2000 :  8.228994912147522\n",
      "Epoch:  368  Average loss at step  3000 :  7.778776065349579\n",
      "Epoch:  368  Average loss at step  4000 :  8.238137994766236\n",
      "Epoch:  368  Average loss at step  5000 :  8.095794377326966\n",
      "Epoch:  368  Average loss at step  6000 :  7.683866215229035\n",
      "Epoch:  368  Average loss at step  7000 :  7.490872040748596\n",
      "Epoch:  368  Average loss at step  8000 :  8.261143568992615\n",
      "Epoch:  368  Average loss at step  8472 :  8.555821810618285\n",
      "368 0 20.63272976875305\n",
      "Epoch:  368  Average loss at step  1000 :  2359.107917114258\n",
      "Epoch:  368  Average loss at step  1491 :  2377.572093071043\n",
      "368 1 11.722272157669067\n",
      "Epoch:  368  Average loss at step  1000 :  3335.1851320800783\n",
      "Epoch:  368  Average loss at step  2000 :  3312.9123276367186\n",
      "Epoch:  368  Average loss at step  2533 :  3309.1981462583963\n",
      "368 2 19.921852350234985\n",
      "Epoch:  368  Average loss at step  1000 :  68.02641606140136\n",
      "Epoch:  368  Average loss at step  1227 :  67.96194784967439\n",
      "368 3 12.621687173843384\n",
      "Epoch:  368  Average loss at step  1000 :  8.55043827867508\n",
      "Epoch:  368  Average loss at step  2000 :  8.440885617733002\n",
      "Epoch:  368  Average loss at step  3000 :  8.548869193077087\n",
      "Epoch:  368  Average loss at step  3222 :  8.321282213227933\n",
      "368 4 33.10759615898132\n",
      "368 5 1.430511474609375e-06\n",
      "Training time took 98.64257 seconds to run 1 epoch\n",
      "Epoch:  369  Average loss at step  1000 :  0.08194586688280106\n",
      "Epoch:  369  Average loss at step  2000 :  0.08571046835184097\n",
      "Epoch:  369  Average loss at step  3000 :  0.09310974937677384\n",
      "Epoch:  369  Average loss at step  3222 :  0.0981389650327459\n",
      "369 0 29.34881019592285\n",
      "Training time took 29.46933 seconds to run 1 epoch\n",
      "Epoch:  370  Average loss at step  1000 :  8.393968352794648\n",
      "Epoch:  370  Average loss at step  2000 :  8.63065194606781\n",
      "Epoch:  370  Average loss at step  3000 :  8.061226382255555\n",
      "Epoch:  370  Average loss at step  4000 :  7.778765988349915\n",
      "Epoch:  370  Average loss at step  5000 :  8.128139522552491\n",
      "Epoch:  370  Average loss at step  6000 :  8.600334871292114\n",
      "Epoch:  370  Average loss at step  7000 :  8.164646238327027\n",
      "Epoch:  370  Average loss at step  8000 :  7.619880097389221\n",
      "Epoch:  370  Average loss at step  8472 :  8.154657565951878\n",
      "370 0 21.0169460773468\n",
      "Epoch:  370  Average loss at step  1000 :  2366.819885131836\n",
      "Epoch:  370  Average loss at step  1491 :  2344.5025002072757\n",
      "370 1 11.683038473129272\n",
      "Epoch:  370  Average loss at step  1000 :  3305.7730697021484\n",
      "Epoch:  370  Average loss at step  2000 :  3307.6202570800783\n",
      "Epoch:  370  Average loss at step  2533 :  3324.110389253195\n",
      "370 2 19.92479968070984\n",
      "Epoch:  370  Average loss at step  1000 :  67.20602275085449\n",
      "Epoch:  370  Average loss at step  1227 :  68.11945716594364\n",
      "370 3 12.5941903591156\n",
      "Epoch:  370  Average loss at step  1000 :  8.530633282661437\n",
      "Epoch:  370  Average loss at step  2000 :  8.263008985996246\n",
      "Epoch:  370  Average loss at step  3000 :  8.50425063419342\n",
      "Epoch:  370  Average loss at step  3222 :  8.36483456636943\n",
      "370 4 33.268166065216064\n",
      "370 5 1.1920928955078125e-06\n",
      "Training time took 99.160813 seconds to run 1 epoch\n",
      "Mean Rank:  165.17108  of  75000\n",
      "Hits @ 10:  0.8494\n",
      "Hits @ 1:  0.606\n",
      "Testing time took 164.669859 seconds.\n",
      "\n",
      "Epoch:  371  Average loss at step  1000 :  0.0818777739405632\n",
      "Epoch:  371  Average loss at step  2000 :  0.08543509888648987\n",
      "Epoch:  371  Average loss at step  3000 :  0.09312249583005905\n",
      "Epoch:  371  Average loss at step  3222 :  0.09763516481655732\n",
      "371 0 29.494296550750732\n",
      "Training time took 29.606482 seconds to run 1 epoch\n",
      "Epoch:  372  Average loss at step  1000 :  7.8986527490615845\n",
      "Epoch:  372  Average loss at step  2000 :  8.226635757446289\n",
      "Epoch:  372  Average loss at step  3000 :  7.904220546722412\n",
      "Epoch:  372  Average loss at step  4000 :  8.190662816047668\n",
      "Epoch:  372  Average loss at step  5000 :  8.06209826374054\n",
      "Epoch:  372  Average loss at step  6000 :  7.869988425254822\n",
      "Epoch:  372  Average loss at step  7000 :  7.757712568283081\n",
      "Epoch:  372  Average loss at step  8000 :  8.892879574775696\n",
      "Epoch:  372  Average loss at step  8472 :  7.86632366260564\n",
      "372 0 20.790149688720703\n",
      "Epoch:  372  Average loss at step  1000 :  2387.2210299072267\n",
      "Epoch:  372  Average loss at step  1491 :  2322.372763810523\n",
      "372 1 11.75023365020752\n",
      "Epoch:  372  Average loss at step  1000 :  3332.97094921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  372  Average loss at step  2000 :  3297.176049926758\n",
      "Epoch:  372  Average loss at step  2533 :  3323.0049616536876\n",
      "372 2 19.966456413269043\n",
      "Epoch:  372  Average loss at step  1000 :  67.48053886032105\n",
      "Epoch:  372  Average loss at step  1227 :  66.93427890779776\n",
      "372 3 12.584250926971436\n",
      "Epoch:  372  Average loss at step  1000 :  8.368452738285065\n",
      "Epoch:  372  Average loss at step  2000 :  8.303739825725556\n",
      "Epoch:  372  Average loss at step  3000 :  8.408497857570648\n",
      "Epoch:  372  Average loss at step  3222 :  8.505481222214348\n",
      "372 4 33.24642634391785\n",
      "372 5 1.1920928955078125e-06\n",
      "Training time took 98.973271 seconds to run 1 epoch\n",
      "Epoch:  373  Average loss at step  1000 :  0.08163655734062195\n",
      "Epoch:  373  Average loss at step  2000 :  0.08518679648637771\n",
      "Epoch:  373  Average loss at step  3000 :  0.09257626628875733\n",
      "Epoch:  373  Average loss at step  3222 :  0.0967610711482355\n",
      "373 0 29.442009925842285\n",
      "Training time took 29.564222 seconds to run 1 epoch\n",
      "Epoch:  374  Average loss at step  1000 :  8.362198427200317\n",
      "Epoch:  374  Average loss at step  2000 :  8.572083138465882\n",
      "Epoch:  374  Average loss at step  3000 :  8.039628218650817\n",
      "Epoch:  374  Average loss at step  4000 :  8.19770830154419\n",
      "Epoch:  374  Average loss at step  5000 :  8.046196304321288\n",
      "Epoch:  374  Average loss at step  6000 :  7.662269772529602\n",
      "Epoch:  374  Average loss at step  7000 :  7.983029145240784\n",
      "Epoch:  374  Average loss at step  8000 :  8.48862426328659\n",
      "Epoch:  374  Average loss at step  8472 :  8.0831373189707\n",
      "374 0 20.378026723861694\n",
      "Epoch:  374  Average loss at step  1000 :  2383.2794263916016\n",
      "Epoch:  374  Average loss at step  1491 :  2378.440174541575\n",
      "374 1 11.696829080581665\n",
      "Epoch:  374  Average loss at step  1000 :  3299.731266845703\n",
      "Epoch:  374  Average loss at step  2000 :  3307.0229102783205\n",
      "Epoch:  374  Average loss at step  2533 :  3294.5085830438975\n",
      "374 2 19.91907835006714\n",
      "Epoch:  374  Average loss at step  1000 :  67.66496309661865\n",
      "Epoch:  374  Average loss at step  1227 :  66.90600403575213\n",
      "374 3 12.666934251785278\n",
      "Epoch:  374  Average loss at step  1000 :  8.35941893005371\n",
      "Epoch:  374  Average loss at step  2000 :  8.284360885620117\n",
      "Epoch:  374  Average loss at step  3000 :  8.332367134571076\n",
      "Epoch:  374  Average loss at step  3222 :  8.519279943904543\n",
      "374 4 33.266311168670654\n",
      "374 5 1.6689300537109375e-06\n",
      "Training time took 98.581419 seconds to run 1 epoch\n",
      "Epoch:  375  Average loss at step  1000 :  0.08065056866407394\n",
      "Epoch:  375  Average loss at step  2000 :  0.08478993600606918\n",
      "Epoch:  375  Average loss at step  3000 :  0.09199259757995605\n",
      "Epoch:  375  Average loss at step  3222 :  0.09633457188271383\n",
      "375 0 29.39480996131897\n",
      "Training time took 29.52294 seconds to run 1 epoch\n",
      "Epoch:  376  Average loss at step  1000 :  7.891689344406128\n",
      "Epoch:  376  Average loss at step  2000 :  8.257296585083008\n",
      "Epoch:  376  Average loss at step  3000 :  8.094508071899414\n",
      "Epoch:  376  Average loss at step  4000 :  7.8710582828521725\n",
      "Epoch:  376  Average loss at step  5000 :  7.510477361679077\n",
      "Epoch:  376  Average loss at step  6000 :  8.32413399219513\n",
      "Epoch:  376  Average loss at step  7000 :  8.269259026527404\n",
      "Epoch:  376  Average loss at step  8000 :  8.05854960346222\n",
      "Epoch:  376  Average loss at step  8472 :  9.067241441545267\n",
      "376 0 20.39960265159607\n",
      "Epoch:  376  Average loss at step  1000 :  2374.3663399658203\n",
      "Epoch:  376  Average loss at step  1491 :  2365.000182410489\n",
      "376 1 11.711965322494507\n",
      "Epoch:  376  Average loss at step  1000 :  3319.690772705078\n",
      "Epoch:  376  Average loss at step  2000 :  3299.722278564453\n",
      "Epoch:  376  Average loss at step  2533 :  3345.3071460308756\n",
      "376 2 19.813642978668213\n",
      "Epoch:  376  Average loss at step  1000 :  67.7151685218811\n",
      "Epoch:  376  Average loss at step  1227 :  66.80934845588675\n",
      "376 3 12.639310359954834\n",
      "Epoch:  376  Average loss at step  1000 :  8.33520384645462\n",
      "Epoch:  376  Average loss at step  2000 :  8.160336465358734\n",
      "Epoch:  376  Average loss at step  3000 :  8.19577629327774\n",
      "Epoch:  376  Average loss at step  3222 :  8.121809717936946\n",
      "376 4 33.350828409194946\n",
      "376 5 1.430511474609375e-06\n",
      "Training time took 98.556369 seconds to run 1 epoch\n",
      "Epoch:  377  Average loss at step  1000 :  0.08056620508432388\n",
      "Epoch:  377  Average loss at step  2000 :  0.08473172670602798\n",
      "Epoch:  377  Average loss at step  3000 :  0.091740776181221\n",
      "Epoch:  377  Average loss at step  3222 :  0.09632014554638922\n",
      "377 0 29.35929822921753\n",
      "Training time took 29.481231 seconds to run 1 epoch\n",
      "Epoch:  378  Average loss at step  1000 :  7.891695174217224\n",
      "Epoch:  378  Average loss at step  2000 :  8.223677414894103\n",
      "Epoch:  378  Average loss at step  3000 :  7.999700053215027\n",
      "Epoch:  378  Average loss at step  4000 :  7.839996531486511\n",
      "Epoch:  378  Average loss at step  5000 :  8.141186129570007\n",
      "Epoch:  378  Average loss at step  6000 :  8.287503818511963\n",
      "Epoch:  378  Average loss at step  7000 :  8.221327085494995\n",
      "Epoch:  378  Average loss at step  8000 :  8.38033136844635\n",
      "Epoch:  378  Average loss at step  8472 :  7.97138786251155\n",
      "378 0 20.272300243377686\n",
      "Epoch:  378  Average loss at step  1000 :  2391.597060058594\n",
      "Epoch:  378  Average loss at step  1491 :  2355.8492737953984\n",
      "378 1 11.711768388748169\n",
      "Epoch:  378  Average loss at step  1000 :  3318.2792980957033\n",
      "Epoch:  378  Average loss at step  2000 :  3311.9113411865233\n",
      "Epoch:  378  Average loss at step  2533 :  3313.1193562154062\n",
      "378 2 19.88796305656433\n",
      "Epoch:  378  Average loss at step  1000 :  67.62452812957764\n",
      "Epoch:  378  Average loss at step  1227 :  66.42370162992815\n",
      "378 3 12.63530969619751\n",
      "Epoch:  378  Average loss at step  1000 :  8.379401730537415\n",
      "Epoch:  378  Average loss at step  2000 :  8.255664132595061\n",
      "Epoch:  378  Average loss at step  3000 :  8.30498460817337\n",
      "Epoch:  378  Average loss at step  3222 :  8.115318467587334\n",
      "378 4 33.19044780731201\n",
      "378 5 1.1920928955078125e-06\n",
      "Training time took 98.329259 seconds to run 1 epoch\n",
      "Epoch:  379  Average loss at step  1000 :  0.0799975808262825\n",
      "Epoch:  379  Average loss at step  2000 :  0.08405391144752503\n",
      "Epoch:  379  Average loss at step  3000 :  0.09121056342124939\n",
      "Epoch:  379  Average loss at step  3222 :  0.09516263389053661\n",
      "379 0 29.384746313095093\n",
      "Training time took 29.505967 seconds to run 1 epoch\n",
      "Epoch:  380  Average loss at step  1000 :  7.840382189750671\n",
      "Epoch:  380  Average loss at step  2000 :  8.482356729507446\n",
      "Epoch:  380  Average loss at step  3000 :  8.221492941856384\n",
      "Epoch:  380  Average loss at step  4000 :  8.184708478927613\n",
      "Epoch:  380  Average loss at step  5000 :  8.260534840106963\n",
      "Epoch:  380  Average loss at step  6000 :  7.801703948974609\n",
      "Epoch:  380  Average loss at step  7000 :  8.16575697517395\n",
      "Epoch:  380  Average loss at step  8000 :  7.995811087608337\n",
      "Epoch:  380  Average loss at step  8472 :  7.870247807164158\n",
      "380 0 20.782216787338257\n",
      "Epoch:  380  Average loss at step  1000 :  2383.4782857666014\n",
      "Epoch:  380  Average loss at step  1491 :  2388.6117685558215\n",
      "380 1 11.663997650146484\n",
      "Epoch:  380  Average loss at step  1000 :  3329.1231622314453\n",
      "Epoch:  380  Average loss at step  2000 :  3322.284008911133\n",
      "Epoch:  380  Average loss at step  2533 :  3325.396343762188\n",
      "380 2 19.859057664871216\n",
      "Epoch:  380  Average loss at step  1000 :  67.5507667427063\n",
      "Epoch:  380  Average loss at step  1227 :  66.24269647455638\n",
      "380 3 12.618979454040527\n",
      "Epoch:  380  Average loss at step  1000 :  8.168842411994934\n",
      "Epoch:  380  Average loss at step  2000 :  8.008195200443268\n",
      "Epoch:  380  Average loss at step  3000 :  8.083644751548768\n",
      "Epoch:  380  Average loss at step  3222 :  8.156280298916565\n",
      "380 4 32.987085819244385\n",
      "380 5 1.6689300537109375e-06\n",
      "Training time took 98.556858 seconds to run 1 epoch\n",
      "Mean Rank:  166.59304  of  75000\n",
      "Hits @ 10:  0.84968\n",
      "Hits @ 1:  0.60688\n",
      "Testing time took 165.10085 seconds.\n",
      "\n",
      "Epoch:  381  Average loss at step  1000 :  0.07949519580602646\n",
      "Epoch:  381  Average loss at step  2000 :  0.08416528928279876\n",
      "Epoch:  381  Average loss at step  3000 :  0.09093202310800552\n",
      "Epoch:  381  Average loss at step  3222 :  0.0968251399538495\n",
      "381 0 29.4080171585083\n",
      "Training time took 29.519834 seconds to run 1 epoch\n",
      "Epoch:  382  Average loss at step  1000 :  7.914987530708313\n",
      "Epoch:  382  Average loss at step  2000 :  8.140982662200928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  382  Average loss at step  3000 :  7.8232503538131715\n",
      "Epoch:  382  Average loss at step  4000 :  8.580059840202331\n",
      "Epoch:  382  Average loss at step  5000 :  7.725175194740295\n",
      "Epoch:  382  Average loss at step  6000 :  8.157122002601623\n",
      "Epoch:  382  Average loss at step  7000 :  8.257778779983521\n",
      "Epoch:  382  Average loss at step  8000 :  8.18617299938202\n",
      "Epoch:  382  Average loss at step  8472 :  7.48512695420654\n",
      "382 0 20.2834255695343\n",
      "Epoch:  382  Average loss at step  1000 :  2401.7870419921874\n",
      "Epoch:  382  Average loss at step  1491 :  2412.143320855952\n",
      "382 1 11.7154700756073\n",
      "Epoch:  382  Average loss at step  1000 :  3338.3683564453127\n",
      "Epoch:  382  Average loss at step  2000 :  3369.905017211914\n",
      "Epoch:  382  Average loss at step  2533 :  3360.8279446132724\n",
      "382 2 19.88999032974243\n",
      "Epoch:  382  Average loss at step  1000 :  67.67793484497071\n",
      "Epoch:  382  Average loss at step  1227 :  66.65493918068961\n",
      "382 3 12.597489356994629\n",
      "Epoch:  382  Average loss at step  1000 :  8.024725453853607\n",
      "Epoch:  382  Average loss at step  2000 :  7.9744642038345335\n",
      "Epoch:  382  Average loss at step  3000 :  7.997426132678986\n",
      "Epoch:  382  Average loss at step  3222 :  8.076411088594655\n",
      "382 4 33.1561324596405\n",
      "382 5 1.1920928955078125e-06\n",
      "Training time took 98.276241 seconds to run 1 epoch\n",
      "Epoch:  383  Average loss at step  1000 :  0.07930839157104493\n",
      "Epoch:  383  Average loss at step  2000 :  0.08315823686122895\n",
      "Epoch:  383  Average loss at step  3000 :  0.0907558366060257\n",
      "Epoch:  383  Average loss at step  3222 :  0.0943010949683891\n",
      "383 0 29.41152000427246\n",
      "Training time took 29.531062 seconds to run 1 epoch\n",
      "Epoch:  384  Average loss at step  1000 :  8.372164620399476\n",
      "Epoch:  384  Average loss at step  2000 :  8.584800374507903\n",
      "Epoch:  384  Average loss at step  3000 :  7.7615753297805785\n",
      "Epoch:  384  Average loss at step  4000 :  8.40757272529602\n",
      "Epoch:  384  Average loss at step  5000 :  8.14389040184021\n",
      "Epoch:  384  Average loss at step  6000 :  8.311190013885499\n",
      "Epoch:  384  Average loss at step  7000 :  7.780266886711121\n",
      "Epoch:  384  Average loss at step  8000 :  8.603974656105041\n",
      "Epoch:  384  Average loss at step  8472 :  8.385286071720351\n",
      "384 0 20.06020450592041\n",
      "Epoch:  384  Average loss at step  1000 :  2373.1715216674806\n",
      "Epoch:  384  Average loss at step  1491 :  2378.7167022284234\n",
      "384 1 11.730881214141846\n",
      "Epoch:  384  Average loss at step  1000 :  3327.803937988281\n",
      "Epoch:  384  Average loss at step  2000 :  3346.0199354248048\n",
      "Epoch:  384  Average loss at step  2533 :  3348.558892806894\n",
      "384 2 19.917601585388184\n",
      "Epoch:  384  Average loss at step  1000 :  67.36937990570068\n",
      "Epoch:  384  Average loss at step  1227 :  67.07301056316146\n",
      "384 3 12.677290678024292\n",
      "Epoch:  384  Average loss at step  1000 :  8.137884528636933\n",
      "Epoch:  384  Average loss at step  2000 :  8.002964525699616\n",
      "Epoch:  384  Average loss at step  3000 :  7.956814136981964\n",
      "Epoch:  384  Average loss at step  3222 :  7.828615212789144\n",
      "384 4 33.09864568710327\n",
      "384 5 1.6689300537109375e-06\n",
      "Training time took 98.117854 seconds to run 1 epoch\n",
      "Epoch:  385  Average loss at step  1000 :  0.07851497691869735\n",
      "Epoch:  385  Average loss at step  2000 :  0.08319430583715438\n",
      "Epoch:  385  Average loss at step  3000 :  0.09022642958164215\n",
      "Epoch:  385  Average loss at step  3222 :  0.09407739084880476\n",
      "385 0 29.375603675842285\n",
      "Training time took 29.499933 seconds to run 1 epoch\n",
      "Epoch:  386  Average loss at step  1000 :  7.584386688232422\n",
      "Epoch:  386  Average loss at step  2000 :  8.081067310333252\n",
      "Epoch:  386  Average loss at step  3000 :  8.039757435798645\n",
      "Epoch:  386  Average loss at step  4000 :  8.291433314323426\n",
      "Epoch:  386  Average loss at step  5000 :  8.233033913135529\n",
      "Epoch:  386  Average loss at step  6000 :  8.080076102256776\n",
      "Epoch:  386  Average loss at step  7000 :  7.947029277324677\n",
      "Epoch:  386  Average loss at step  8000 :  7.896372632026672\n",
      "Epoch:  386  Average loss at step  8472 :  8.143094207185987\n",
      "386 0 20.046680688858032\n",
      "Epoch:  386  Average loss at step  1000 :  2383.1715325927735\n",
      "Epoch:  386  Average loss at step  1491 :  2412.906295990518\n",
      "386 1 11.735016345977783\n",
      "Epoch:  386  Average loss at step  1000 :  3354.0767014160156\n",
      "Epoch:  386  Average loss at step  2000 :  3333.422065673828\n",
      "Epoch:  386  Average loss at step  2533 :  3329.9950428064244\n",
      "386 2 19.902876615524292\n",
      "Epoch:  386  Average loss at step  1000 :  67.15636082839966\n",
      "Epoch:  386  Average loss at step  1227 :  67.3958292898137\n",
      "386 3 12.5384681224823\n",
      "Epoch:  386  Average loss at step  1000 :  7.960835419178009\n",
      "Epoch:  386  Average loss at step  2000 :  7.9126128783226015\n",
      "Epoch:  386  Average loss at step  3000 :  7.9067783093452455\n",
      "Epoch:  386  Average loss at step  3222 :  8.312290501220064\n",
      "386 4 32.98828625679016\n",
      "386 5 1.6689300537109375e-06\n",
      "Training time took 97.850435 seconds to run 1 epoch\n",
      "Epoch:  387  Average loss at step  1000 :  0.0787680224776268\n",
      "Epoch:  387  Average loss at step  2000 :  0.08230076348781586\n",
      "Epoch:  387  Average loss at step  3000 :  0.08989529091119766\n",
      "Epoch:  387  Average loss at step  3222 :  0.09394831354167406\n",
      "387 0 29.41468572616577\n",
      "Training time took 29.536272 seconds to run 1 epoch\n",
      "Epoch:  388  Average loss at step  1000 :  7.837983032226562\n",
      "Epoch:  388  Average loss at step  2000 :  7.788953880310059\n",
      "Epoch:  388  Average loss at step  3000 :  7.6612089128494265\n",
      "Epoch:  388  Average loss at step  4000 :  8.552129462242126\n",
      "Epoch:  388  Average loss at step  5000 :  8.041563924789429\n",
      "Epoch:  388  Average loss at step  6000 :  7.857259953498841\n",
      "Epoch:  388  Average loss at step  7000 :  8.572243036270141\n",
      "Epoch:  388  Average loss at step  8000 :  8.36193891096115\n",
      "Epoch:  388  Average loss at step  8472 :  8.120884182325552\n",
      "388 0 20.579710721969604\n",
      "Epoch:  388  Average loss at step  1000 :  2373.208826293945\n",
      "Epoch:  388  Average loss at step  1491 :  2418.8735045323733\n",
      "388 1 11.739617586135864\n",
      "Epoch:  388  Average loss at step  1000 :  3352.6570603027344\n",
      "Epoch:  388  Average loss at step  2000 :  3346.885813598633\n",
      "Epoch:  388  Average loss at step  2533 :  3372.982115054209\n",
      "388 2 19.91944169998169\n",
      "Epoch:  388  Average loss at step  1000 :  67.14419814682007\n",
      "Epoch:  388  Average loss at step  1227 :  67.50644857684553\n",
      "388 3 12.579563856124878\n",
      "Epoch:  388  Average loss at step  1000 :  7.952908980369568\n",
      "Epoch:  388  Average loss at step  2000 :  7.905995135307312\n",
      "Epoch:  388  Average loss at step  3000 :  7.8538182454109196\n",
      "Epoch:  388  Average loss at step  3222 :  7.855337753819309\n",
      "388 4 33.10988402366638\n",
      "388 5 1.430511474609375e-06\n",
      "Training time took 98.566679 seconds to run 1 epoch\n",
      "Epoch:  389  Average loss at step  1000 :  0.07842969179153442\n",
      "Epoch:  389  Average loss at step  2000 :  0.08243875205516815\n",
      "Epoch:  389  Average loss at step  3000 :  0.08940996724367142\n",
      "Epoch:  389  Average loss at step  3222 :  0.09235917074539576\n",
      "389 0 29.402831077575684\n",
      "Training time took 29.527708 seconds to run 1 epoch\n",
      "Epoch:  390  Average loss at step  1000 :  8.373291271686554\n",
      "Epoch:  390  Average loss at step  2000 :  8.217487927436828\n",
      "Epoch:  390  Average loss at step  3000 :  8.242942908287048\n",
      "Epoch:  390  Average loss at step  4000 :  8.087359199523926\n",
      "Epoch:  390  Average loss at step  5000 :  8.22397833776474\n",
      "Epoch:  390  Average loss at step  6000 :  7.7921032075881955\n",
      "Epoch:  390  Average loss at step  7000 :  8.218603652000427\n",
      "Epoch:  390  Average loss at step  8000 :  8.385110187530518\n",
      "Epoch:  390  Average loss at step  8472 :  8.277846161869181\n",
      "390 0 20.845534086227417\n",
      "Epoch:  390  Average loss at step  1000 :  2389.344514770508\n",
      "Epoch:  390  Average loss at step  1491 :  2384.166975706901\n",
      "390 1 11.671658277511597\n",
      "Epoch:  390  Average loss at step  1000 :  3360.8659298095704\n",
      "Epoch:  390  Average loss at step  2000 :  3382.1131224365236\n",
      "Epoch:  390  Average loss at step  2533 :  3344.192520369311\n",
      "390 2 19.921968460083008\n",
      "Epoch:  390  Average loss at step  1000 :  66.88725665283204\n",
      "Epoch:  390  Average loss at step  1227 :  65.72394941335594\n",
      "390 3 12.660691022872925\n",
      "Epoch:  390  Average loss at step  1000 :  7.959479664802552\n",
      "Epoch:  390  Average loss at step  2000 :  7.76469624042511\n",
      "Epoch:  390  Average loss at step  3000 :  7.767809626579285\n",
      "Epoch:  390  Average loss at step  3222 :  7.815283430378066\n",
      "390 4 33.20150065422058\n",
      "390 5 1.430511474609375e-06\n",
      "Training time took 98.948965 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank:  163.82172  of  75000\n",
      "Hits @ 10:  0.85072\n",
      "Hits @ 1:  0.60864\n",
      "Testing time took 164.336536 seconds.\n",
      "\n",
      "Epoch:  391  Average loss at step  1000 :  0.07805178773403168\n",
      "Epoch:  391  Average loss at step  2000 :  0.08150449603796005\n",
      "Epoch:  391  Average loss at step  3000 :  0.089206756234169\n",
      "Epoch:  391  Average loss at step  3222 :  0.0942006255233518\n",
      "391 0 29.488075733184814\n",
      "Training time took 29.595451 seconds to run 1 epoch\n",
      "Epoch:  392  Average loss at step  1000 :  7.919792276382446\n",
      "Epoch:  392  Average loss at step  2000 :  8.007521747589111\n",
      "Epoch:  392  Average loss at step  3000 :  8.041800486564636\n",
      "Epoch:  392  Average loss at step  4000 :  8.274521181106568\n",
      "Epoch:  392  Average loss at step  5000 :  8.29847342157364\n",
      "Epoch:  392  Average loss at step  6000 :  8.215426948547364\n",
      "Epoch:  392  Average loss at step  7000 :  8.120746217250824\n",
      "Epoch:  392  Average loss at step  8000 :  7.918520058631897\n",
      "Epoch:  392  Average loss at step  8472 :  8.86068467975275\n",
      "392 0 20.773082494735718\n",
      "Epoch:  392  Average loss at step  1000 :  2396.171701660156\n",
      "Epoch:  392  Average loss at step  1491 :  2374.0065190266273\n",
      "392 1 11.670065879821777\n",
      "Epoch:  392  Average loss at step  1000 :  3337.9092489013674\n",
      "Epoch:  392  Average loss at step  2000 :  3365.8898896484375\n",
      "Epoch:  392  Average loss at step  2533 :  3366.466442920192\n",
      "392 2 19.927229642868042\n",
      "Epoch:  392  Average loss at step  1000 :  66.6721918144226\n",
      "Epoch:  392  Average loss at step  1227 :  66.8462339547576\n",
      "392 3 12.655885457992554\n",
      "Epoch:  392  Average loss at step  1000 :  7.812539054393769\n",
      "Epoch:  392  Average loss at step  2000 :  7.8579672589302065\n",
      "Epoch:  392  Average loss at step  3000 :  7.765512927532196\n",
      "Epoch:  392  Average loss at step  3222 :  7.697318594127296\n",
      "392 4 33.18610739707947\n",
      "392 5 1.6689300537109375e-06\n",
      "Training time took 98.855794 seconds to run 1 epoch\n",
      "Epoch:  393  Average loss at step  1000 :  0.07715455144643783\n",
      "Epoch:  393  Average loss at step  2000 :  0.08168785643577575\n",
      "Epoch:  393  Average loss at step  3000 :  0.0885307440161705\n",
      "Epoch:  393  Average loss at step  3222 :  0.09418200512486774\n",
      "393 0 29.388821601867676\n",
      "Training time took 29.510185 seconds to run 1 epoch\n",
      "Epoch:  394  Average loss at step  1000 :  8.304495697021485\n",
      "Epoch:  394  Average loss at step  2000 :  8.143210766792297\n",
      "Epoch:  394  Average loss at step  3000 :  8.267658731460571\n",
      "Epoch:  394  Average loss at step  4000 :  8.114421475410461\n",
      "Epoch:  394  Average loss at step  5000 :  8.326374258041382\n",
      "Epoch:  394  Average loss at step  6000 :  7.392779769897461\n",
      "Epoch:  394  Average loss at step  7000 :  8.191350883960723\n",
      "Epoch:  394  Average loss at step  8000 :  8.193711443901062\n",
      "Epoch:  394  Average loss at step  8472 :  7.831600490437466\n",
      "394 0 20.542545557022095\n",
      "Epoch:  394  Average loss at step  1000 :  2371.2466213378907\n",
      "Epoch:  394  Average loss at step  1491 :  2371.087722198652\n",
      "394 1 11.70315432548523\n",
      "Epoch:  394  Average loss at step  1000 :  3356.6743145751952\n",
      "Epoch:  394  Average loss at step  2000 :  3376.452633300781\n",
      "Epoch:  394  Average loss at step  2533 :  3354.0764950220023\n",
      "394 2 19.88330101966858\n",
      "Epoch:  394  Average loss at step  1000 :  66.29990545654297\n",
      "Epoch:  394  Average loss at step  1227 :  67.09931368084597\n",
      "394 3 12.657365083694458\n",
      "Epoch:  394  Average loss at step  1000 :  7.927645706653595\n",
      "Epoch:  394  Average loss at step  2000 :  7.896928101539612\n",
      "Epoch:  394  Average loss at step  3000 :  7.793513170719146\n",
      "Epoch:  394  Average loss at step  3222 :  7.716263971898632\n",
      "394 4 33.119568824768066\n",
      "394 5 1.1920928955078125e-06\n",
      "Training time took 98.533638 seconds to run 1 epoch\n",
      "Epoch:  395  Average loss at step  1000 :  0.0775312385559082\n",
      "Epoch:  395  Average loss at step  2000 :  0.08117293554544448\n",
      "Epoch:  395  Average loss at step  3000 :  0.08783037084341049\n",
      "Epoch:  395  Average loss at step  3222 :  0.09164712014321408\n",
      "395 0 29.438390254974365\n",
      "Training time took 29.559944 seconds to run 1 epoch\n",
      "Epoch:  396  Average loss at step  1000 :  8.156055032730103\n",
      "Epoch:  396  Average loss at step  2000 :  8.515224016189576\n",
      "Epoch:  396  Average loss at step  3000 :  8.355308344841003\n",
      "Epoch:  396  Average loss at step  4000 :  8.135634631156922\n",
      "Epoch:  396  Average loss at step  5000 :  8.13575947856903\n",
      "Epoch:  396  Average loss at step  6000 :  8.167058688163758\n",
      "Epoch:  396  Average loss at step  7000 :  8.55792361831665\n",
      "Epoch:  396  Average loss at step  8000 :  7.903913313865662\n",
      "Epoch:  396  Average loss at step  8472 :  8.153373695918514\n",
      "396 0 20.6839919090271\n",
      "Epoch:  396  Average loss at step  1000 :  2404.439672607422\n",
      "Epoch:  396  Average loss at step  1491 :  2352.3590335920153\n",
      "396 1 11.74409008026123\n",
      "Epoch:  396  Average loss at step  1000 :  3364.157199951172\n",
      "Epoch:  396  Average loss at step  2000 :  3374.6173734130857\n",
      "Epoch:  396  Average loss at step  2533 :  3370.817391723546\n",
      "396 2 19.934465169906616\n",
      "Epoch:  396  Average loss at step  1000 :  66.3685106124878\n",
      "Epoch:  396  Average loss at step  1227 :  66.71605962782832\n",
      "396 3 12.659318923950195\n",
      "Epoch:  396  Average loss at step  1000 :  7.827597588062287\n",
      "Epoch:  396  Average loss at step  2000 :  7.7212881407737735\n",
      "Epoch:  396  Average loss at step  3000 :  7.693790675640106\n",
      "Epoch:  396  Average loss at step  3222 :  7.682087843675092\n",
      "396 4 33.251781940460205\n",
      "396 5 1.430511474609375e-06\n",
      "Training time took 98.911085 seconds to run 1 epoch\n",
      "Epoch:  397  Average loss at step  1000 :  0.07726173710823059\n",
      "Epoch:  397  Average loss at step  2000 :  0.08112489533424377\n",
      "Epoch:  397  Average loss at step  3000 :  0.0878740696310997\n",
      "Epoch:  397  Average loss at step  3222 :  0.09195859557262158\n",
      "397 0 29.387389183044434\n",
      "Training time took 29.512771 seconds to run 1 epoch\n",
      "Epoch:  398  Average loss at step  1000 :  8.012473059177399\n",
      "Epoch:  398  Average loss at step  2000 :  7.912936423301697\n",
      "Epoch:  398  Average loss at step  3000 :  8.093933970451355\n",
      "Epoch:  398  Average loss at step  4000 :  8.114396730899811\n",
      "Epoch:  398  Average loss at step  5000 :  8.316792889595032\n",
      "Epoch:  398  Average loss at step  6000 :  7.494189306259155\n",
      "Epoch:  398  Average loss at step  7000 :  8.345567542076111\n",
      "Epoch:  398  Average loss at step  8000 :  8.326636228561402\n",
      "Epoch:  398  Average loss at step  8472 :  8.00594895537997\n",
      "398 0 21.033470630645752\n",
      "Epoch:  398  Average loss at step  1000 :  2382.913127319336\n",
      "Epoch:  398  Average loss at step  1491 :  2409.2875700261334\n",
      "398 1 11.6718430519104\n",
      "Epoch:  398  Average loss at step  1000 :  3405.9740584716797\n",
      "Epoch:  398  Average loss at step  2000 :  3350.541133178711\n",
      "Epoch:  398  Average loss at step  2533 :  3369.1445709596755\n",
      "398 2 19.913482904434204\n",
      "Epoch:  398  Average loss at step  1000 :  67.18650672531128\n",
      "Epoch:  398  Average loss at step  1227 :  66.3184366686057\n",
      "398 3 12.623816967010498\n",
      "Epoch:  398  Average loss at step  1000 :  7.5511091895103455\n",
      "Epoch:  398  Average loss at step  2000 :  7.523075778961181\n",
      "Epoch:  398  Average loss at step  3000 :  7.632324009418488\n",
      "Epoch:  398  Average loss at step  3222 :  7.942308245808839\n",
      "398 4 33.242680311203\n",
      "398 5 1.1920928955078125e-06\n",
      "Training time took 99.123612 seconds to run 1 epoch\n",
      "Epoch:  399  Average loss at step  1000 :  0.07668152230978012\n",
      "Epoch:  399  Average loss at step  2000 :  0.08055445283651352\n",
      "Epoch:  399  Average loss at step  3000 :  0.0874240157008171\n",
      "Epoch:  399  Average loss at step  3222 :  0.09173886599276422\n",
      "399 0 29.330991506576538\n",
      "Training time took 29.4503 seconds to run 1 epoch\n",
      "Epoch:  400  Average loss at step  1000 :  8.6360277633667\n",
      "Epoch:  400  Average loss at step  2000 :  8.44302718925476\n",
      "Epoch:  400  Average loss at step  3000 :  8.508892289161682\n",
      "Epoch:  400  Average loss at step  4000 :  7.57032793712616\n",
      "Epoch:  400  Average loss at step  5000 :  7.854004550933838\n",
      "Epoch:  400  Average loss at step  6000 :  7.8378221864700315\n",
      "Epoch:  400  Average loss at step  7000 :  8.196553208351135\n",
      "Epoch:  400  Average loss at step  8000 :  7.7144614572525025\n",
      "Epoch:  400  Average loss at step  8472 :  8.218108075142998\n",
      "400 0 20.382814168930054\n",
      "Epoch:  400  Average loss at step  1000 :  2417.5147978515624\n",
      "Epoch:  400  Average loss at step  1491 :  2415.4203593518455\n",
      "400 1 11.746129035949707\n",
      "Epoch:  400  Average loss at step  1000 :  3375.2514951171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  400  Average loss at step  2000 :  3379.0068924560546\n",
      "Epoch:  400  Average loss at step  2533 :  3399.7794275305682\n",
      "400 2 19.883442163467407\n",
      "Epoch:  400  Average loss at step  1000 :  67.18283092117309\n",
      "Epoch:  400  Average loss at step  1227 :  66.91774538346202\n",
      "400 3 12.600837230682373\n",
      "Epoch:  400  Average loss at step  1000 :  7.56478872013092\n",
      "Epoch:  400  Average loss at step  2000 :  7.636557992458344\n",
      "Epoch:  400  Average loss at step  3000 :  7.639859199523926\n",
      "Epoch:  400  Average loss at step  3222 :  7.567845957226262\n",
      "400 4 33.262312173843384\n",
      "400 5 1.6689300537109375e-06\n",
      "Training time took 98.522175 seconds to run 1 epoch\n",
      "Mean Rank:  163.83468  of  75000\n",
      "Hits @ 10:  0.85116\n",
      "Hits @ 1:  0.6074\n",
      "Testing time took 164.632925 seconds.\n",
      "\n",
      "Epoch:  401  Average loss at step  1000 :  0.07612717288732529\n",
      "Epoch:  401  Average loss at step  2000 :  0.0798842101097107\n",
      "Epoch:  401  Average loss at step  3000 :  0.08745591968297958\n",
      "Epoch:  401  Average loss at step  3222 :  0.0918822959240302\n",
      "401 0 29.445179224014282\n",
      "Training time took 29.553291 seconds to run 1 epoch\n",
      "Epoch:  402  Average loss at step  1000 :  8.176489857673644\n",
      "Epoch:  402  Average loss at step  2000 :  7.771139278411865\n",
      "Epoch:  402  Average loss at step  3000 :  7.7365338277816775\n",
      "Epoch:  402  Average loss at step  4000 :  8.218965154647828\n",
      "Epoch:  402  Average loss at step  5000 :  7.583706214427948\n",
      "Epoch:  402  Average loss at step  6000 :  8.64736660861969\n",
      "Epoch:  402  Average loss at step  7000 :  8.539804558753968\n",
      "Epoch:  402  Average loss at step  8000 :  7.474623501300812\n",
      "Epoch:  402  Average loss at step  8472 :  8.765641795289085\n",
      "402 0 21.24235963821411\n",
      "Epoch:  402  Average loss at step  1000 :  2419.8466282958984\n",
      "Epoch:  402  Average loss at step  1491 :  2403.8126494990215\n",
      "402 1 11.770183801651001\n",
      "Epoch:  402  Average loss at step  1000 :  3396.952188720703\n",
      "Epoch:  402  Average loss at step  2000 :  3376.8630841064455\n",
      "Epoch:  402  Average loss at step  2533 :  3391.5111961460825\n",
      "402 2 19.969058752059937\n",
      "Epoch:  402  Average loss at step  1000 :  67.07003359985352\n",
      "Epoch:  402  Average loss at step  1227 :  66.83081675150106\n",
      "402 3 12.560550212860107\n",
      "Epoch:  402  Average loss at step  1000 :  7.5901799554824825\n",
      "Epoch:  402  Average loss at step  2000 :  7.651045988082886\n",
      "Epoch:  402  Average loss at step  3000 :  7.669693185329438\n",
      "Epoch:  402  Average loss at step  3222 :  7.563327953130636\n",
      "402 4 33.13156795501709\n",
      "402 5 1.430511474609375e-06\n",
      "Training time took 99.308699 seconds to run 1 epoch\n",
      "Epoch:  403  Average loss at step  1000 :  0.07632630151510239\n",
      "Epoch:  403  Average loss at step  2000 :  0.07935851937532425\n",
      "Epoch:  403  Average loss at step  3000 :  0.08694719660282135\n",
      "Epoch:  403  Average loss at step  3222 :  0.0911397661386274\n",
      "403 0 29.373530626296997\n",
      "Training time took 29.495583 seconds to run 1 epoch\n",
      "Epoch:  404  Average loss at step  1000 :  8.085291528701783\n",
      "Epoch:  404  Average loss at step  2000 :  8.153260013580322\n",
      "Epoch:  404  Average loss at step  3000 :  7.983646647453308\n",
      "Epoch:  404  Average loss at step  4000 :  8.202037001132965\n",
      "Epoch:  404  Average loss at step  5000 :  7.718299078941345\n",
      "Epoch:  404  Average loss at step  6000 :  8.460890857696533\n",
      "Epoch:  404  Average loss at step  7000 :  7.662494733810425\n",
      "Epoch:  404  Average loss at step  8000 :  8.498057888031006\n",
      "Epoch:  404  Average loss at step  8472 :  7.683583144992647\n",
      "404 0 20.796730518341064\n",
      "Epoch:  404  Average loss at step  1000 :  2400.923577026367\n",
      "Epoch:  404  Average loss at step  1491 :  2401.2280517612935\n",
      "404 1 11.694667100906372\n",
      "Epoch:  404  Average loss at step  1000 :  3415.410541503906\n",
      "Epoch:  404  Average loss at step  2000 :  3365.146381591797\n",
      "Epoch:  404  Average loss at step  2533 :  3361.5414862677026\n",
      "404 2 19.918403387069702\n",
      "Epoch:  404  Average loss at step  1000 :  66.04582432174682\n",
      "Epoch:  404  Average loss at step  1227 :  66.460316698789\n",
      "404 3 12.564730405807495\n",
      "Epoch:  404  Average loss at step  1000 :  7.597460332870483\n",
      "Epoch:  404  Average loss at step  2000 :  7.546595433712006\n",
      "Epoch:  404  Average loss at step  3000 :  7.396509860515595\n",
      "Epoch:  404  Average loss at step  3222 :  7.556281289505085\n",
      "404 4 32.989463329315186\n",
      "404 5 1.430511474609375e-06\n",
      "Training time took 98.611558 seconds to run 1 epoch\n",
      "Epoch:  405  Average loss at step  1000 :  0.07606626391410827\n",
      "Epoch:  405  Average loss at step  2000 :  0.07955303508043289\n",
      "Epoch:  405  Average loss at step  3000 :  0.08629458636045456\n",
      "Epoch:  405  Average loss at step  3222 :  0.08951803690518986\n",
      "405 0 29.501894235610962\n",
      "Training time took 29.620754 seconds to run 1 epoch\n",
      "Epoch:  406  Average loss at step  1000 :  8.012347904205322\n",
      "Epoch:  406  Average loss at step  2000 :  8.045713168144227\n",
      "Epoch:  406  Average loss at step  3000 :  7.4465891318321225\n",
      "Epoch:  406  Average loss at step  4000 :  7.941288452148438\n",
      "Epoch:  406  Average loss at step  5000 :  8.274171689987183\n",
      "Epoch:  406  Average loss at step  6000 :  7.684281632423401\n",
      "Epoch:  406  Average loss at step  7000 :  8.534680393218995\n",
      "Epoch:  406  Average loss at step  8000 :  8.699144180297852\n",
      "Epoch:  406  Average loss at step  8472 :  7.859269886883859\n",
      "406 0 21.13205337524414\n",
      "Epoch:  406  Average loss at step  1000 :  2409.6043370361326\n",
      "Epoch:  406  Average loss at step  1491 :  2442.881684797381\n",
      "406 1 11.675118207931519\n",
      "Epoch:  406  Average loss at step  1000 :  3366.722890136719\n",
      "Epoch:  406  Average loss at step  2000 :  3392.9955505371095\n",
      "Epoch:  406  Average loss at step  2533 :  3378.185417761199\n",
      "406 2 19.955819129943848\n",
      "Epoch:  406  Average loss at step  1000 :  66.51484866333008\n",
      "Epoch:  406  Average loss at step  1227 :  66.14361355436934\n",
      "406 3 12.63655161857605\n",
      "Epoch:  406  Average loss at step  1000 :  7.5614749207496645\n",
      "Epoch:  406  Average loss at step  2000 :  7.43991727924347\n",
      "Epoch:  406  Average loss at step  3000 :  7.412171083450318\n",
      "Epoch:  406  Average loss at step  3222 :  7.549728521222047\n",
      "406 4 33.12016224861145\n",
      "406 5 1.1920928955078125e-06\n",
      "Training time took 99.153606 seconds to run 1 epoch\n",
      "Epoch:  407  Average loss at step  1000 :  0.07488854044675827\n",
      "Epoch:  407  Average loss at step  2000 :  0.07920693612098693\n",
      "Epoch:  407  Average loss at step  3000 :  0.08617752236127853\n",
      "Epoch:  407  Average loss at step  3222 :  0.0911719207945316\n",
      "407 0 29.424370765686035\n",
      "Training time took 29.551905 seconds to run 1 epoch\n",
      "Epoch:  408  Average loss at step  1000 :  7.551931432723999\n",
      "Epoch:  408  Average loss at step  2000 :  8.224328838348388\n",
      "Epoch:  408  Average loss at step  3000 :  7.92498303604126\n",
      "Epoch:  408  Average loss at step  4000 :  7.4552165870666505\n",
      "Epoch:  408  Average loss at step  5000 :  8.03955657863617\n",
      "Epoch:  408  Average loss at step  6000 :  7.9065087757110595\n",
      "Epoch:  408  Average loss at step  7000 :  8.19596108341217\n",
      "Epoch:  408  Average loss at step  8000 :  8.446862827301025\n",
      "Epoch:  408  Average loss at step  8472 :  8.048140721847101\n",
      "408 0 20.46562099456787\n",
      "Epoch:  408  Average loss at step  1000 :  2449.97056829834\n",
      "Epoch:  408  Average loss at step  1491 :  2405.625119750397\n",
      "408 1 11.668049097061157\n",
      "Epoch:  408  Average loss at step  1000 :  3395.2181678466795\n",
      "Epoch:  408  Average loss at step  2000 :  3362.326187866211\n",
      "Epoch:  408  Average loss at step  2533 :  3368.6112765400494\n",
      "408 2 19.868642807006836\n",
      "Epoch:  408  Average loss at step  1000 :  67.07372566223144\n",
      "Epoch:  408  Average loss at step  1227 :  67.67158198641675\n",
      "408 3 12.604506969451904\n",
      "Epoch:  408  Average loss at step  1000 :  7.510978387355804\n",
      "Epoch:  408  Average loss at step  2000 :  7.409146444797516\n",
      "Epoch:  408  Average loss at step  3000 :  7.47840914773941\n",
      "Epoch:  408  Average loss at step  3222 :  7.425230447728188\n",
      "408 4 33.358317613601685\n",
      "408 5 1.430511474609375e-06\n",
      "Training time took 98.598253 seconds to run 1 epoch\n",
      "Epoch:  409  Average loss at step  1000 :  0.07525010347366333\n",
      "Epoch:  409  Average loss at step  2000 :  0.07871768081188202\n",
      "Epoch:  409  Average loss at step  3000 :  0.08621014773845673\n",
      "Epoch:  409  Average loss at step  3222 :  0.08956667565120044\n",
      "409 0 29.426167488098145\n",
      "Training time took 29.555142 seconds to run 1 epoch\n",
      "Epoch:  410  Average loss at step  1000 :  8.38473779296875\n",
      "Epoch:  410  Average loss at step  2000 :  7.670691062927246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  410  Average loss at step  3000 :  7.609776951789856\n",
      "Epoch:  410  Average loss at step  4000 :  7.705179355621338\n",
      "Epoch:  410  Average loss at step  5000 :  8.645567490577697\n",
      "Epoch:  410  Average loss at step  6000 :  7.829866308212281\n",
      "Epoch:  410  Average loss at step  7000 :  8.585672352790832\n",
      "Epoch:  410  Average loss at step  8000 :  7.717609413146973\n",
      "Epoch:  410  Average loss at step  8472 :  7.814122739932486\n",
      "410 0 20.46569514274597\n",
      "Epoch:  410  Average loss at step  1000 :  2413.3021978759766\n",
      "Epoch:  410  Average loss at step  1491 :  2395.055533202369\n",
      "410 1 11.720189571380615\n",
      "Epoch:  410  Average loss at step  1000 :  3411.438842163086\n",
      "Epoch:  410  Average loss at step  2000 :  3399.5123884277345\n",
      "Epoch:  410  Average loss at step  2533 :  3415.208603173133\n",
      "410 2 19.887126207351685\n",
      "Epoch:  410  Average loss at step  1000 :  66.39591375350952\n",
      "Epoch:  410  Average loss at step  1227 :  67.28007270771589\n",
      "410 3 12.67097806930542\n",
      "Epoch:  410  Average loss at step  1000 :  7.390603619575501\n",
      "Epoch:  410  Average loss at step  2000 :  7.43306140422821\n",
      "Epoch:  410  Average loss at step  3000 :  7.416734784603119\n",
      "Epoch:  410  Average loss at step  3222 :  7.530670715682579\n",
      "410 4 32.90303421020508\n",
      "410 5 1.6689300537109375e-06\n",
      "Training time took 98.285477 seconds to run 1 epoch\n",
      "Mean Rank:  163.02056  of  75000\n",
      "Hits @ 10:  0.8514\n",
      "Hits @ 1:  0.61012\n",
      "Testing time took 165.017549 seconds.\n",
      "\n",
      "Epoch:  411  Average loss at step  1000 :  0.07478853684663772\n",
      "Epoch:  411  Average loss at step  2000 :  0.07808863300085067\n",
      "Epoch:  411  Average loss at step  3000 :  0.08545822924375535\n",
      "Epoch:  411  Average loss at step  3222 :  0.08805975934016745\n",
      "411 0 29.43751859664917\n",
      "Training time took 29.549204 seconds to run 1 epoch\n",
      "Epoch:  412  Average loss at step  1000 :  7.991255976676941\n",
      "Epoch:  412  Average loss at step  2000 :  7.909606760025024\n",
      "Epoch:  412  Average loss at step  3000 :  8.41026665210724\n",
      "Epoch:  412  Average loss at step  4000 :  8.063330617427827\n",
      "Epoch:  412  Average loss at step  5000 :  7.956327414512634\n",
      "Epoch:  412  Average loss at step  6000 :  8.546200036048889\n",
      "Epoch:  412  Average loss at step  7000 :  8.014583947181702\n",
      "Epoch:  412  Average loss at step  8000 :  8.465364144325257\n",
      "Epoch:  412  Average loss at step  8472 :  7.504782646946316\n",
      "412 0 21.600569009780884\n",
      "Epoch:  412  Average loss at step  1000 :  2424.0640064697263\n",
      "Epoch:  412  Average loss at step  1491 :  2402.5579062792813\n",
      "412 1 11.72538709640503\n",
      "Epoch:  412  Average loss at step  1000 :  3386.1637166748046\n",
      "Epoch:  412  Average loss at step  2000 :  3377.7258416748045\n",
      "Epoch:  412  Average loss at step  2533 :  3386.877747235906\n",
      "412 2 19.952725887298584\n",
      "Epoch:  412  Average loss at step  1000 :  66.58803299331665\n",
      "Epoch:  412  Average loss at step  1227 :  65.78315943210006\n",
      "412 3 12.607651710510254\n",
      "Epoch:  412  Average loss at step  1000 :  7.246168105602265\n",
      "Epoch:  412  Average loss at step  2000 :  7.268525067806244\n",
      "Epoch:  412  Average loss at step  3000 :  7.3718830285072325\n",
      "Epoch:  412  Average loss at step  3222 :  7.394344627179271\n",
      "412 4 33.04643964767456\n",
      "412 5 9.5367431640625e-07\n",
      "Training time took 99.580087 seconds to run 1 epoch\n",
      "Epoch:  413  Average loss at step  1000 :  0.07510761761665344\n",
      "Epoch:  413  Average loss at step  2000 :  0.07828599816560745\n",
      "Epoch:  413  Average loss at step  3000 :  0.08494338977336884\n",
      "Epoch:  413  Average loss at step  3222 :  0.08986872668127696\n",
      "413 0 29.38007664680481\n",
      "Training time took 29.498381 seconds to run 1 epoch\n",
      "Epoch:  414  Average loss at step  1000 :  8.178543130397797\n",
      "Epoch:  414  Average loss at step  2000 :  8.36081348323822\n",
      "Epoch:  414  Average loss at step  3000 :  8.114541335105896\n",
      "Epoch:  414  Average loss at step  4000 :  8.495177610397338\n",
      "Epoch:  414  Average loss at step  5000 :  8.09215079021454\n",
      "Epoch:  414  Average loss at step  6000 :  7.742426355361938\n",
      "Epoch:  414  Average loss at step  7000 :  8.171103753089906\n",
      "Epoch:  414  Average loss at step  8000 :  7.876012344360351\n",
      "Epoch:  414  Average loss at step  8472 :  7.737242325999367\n",
      "414 0 20.48183536529541\n",
      "Epoch:  414  Average loss at step  1000 :  2430.927341308594\n",
      "Epoch:  414  Average loss at step  1491 :  2412.9150646735693\n",
      "414 1 11.718246459960938\n",
      "Epoch:  414  Average loss at step  1000 :  3431.53168359375\n",
      "Epoch:  414  Average loss at step  2000 :  3387.1655853271486\n",
      "Epoch:  414  Average loss at step  2533 :  3399.418820181597\n",
      "414 2 19.98486590385437\n",
      "Epoch:  414  Average loss at step  1000 :  66.63680659866333\n",
      "Epoch:  414  Average loss at step  1227 :  66.08114943914758\n",
      "414 3 12.665766954421997\n",
      "Epoch:  414  Average loss at step  1000 :  7.160489970207214\n",
      "Epoch:  414  Average loss at step  2000 :  7.310443411827087\n",
      "Epoch:  414  Average loss at step  3000 :  7.385854915618896\n",
      "Epoch:  414  Average loss at step  3222 :  7.335841474948022\n",
      "414 4 33.43514680862427\n",
      "414 5 1.6689300537109375e-06\n",
      "Training time took 98.918273 seconds to run 1 epoch\n",
      "Epoch:  415  Average loss at step  1000 :  0.07445478880405426\n",
      "Epoch:  415  Average loss at step  2000 :  0.07799610775709152\n",
      "Epoch:  415  Average loss at step  3000 :  0.08441297781467438\n",
      "Epoch:  415  Average loss at step  3222 :  0.0885137285022319\n",
      "415 0 29.380730390548706\n",
      "Training time took 29.505682 seconds to run 1 epoch\n",
      "Epoch:  416  Average loss at step  1000 :  8.304067073345184\n",
      "Epoch:  416  Average loss at step  2000 :  7.766359306335449\n",
      "Epoch:  416  Average loss at step  3000 :  7.876546513080597\n",
      "Epoch:  416  Average loss at step  4000 :  7.7824713220596315\n",
      "Epoch:  416  Average loss at step  5000 :  8.25290758895874\n",
      "Epoch:  416  Average loss at step  6000 :  8.013172872543334\n",
      "Epoch:  416  Average loss at step  7000 :  8.382715909004212\n",
      "Epoch:  416  Average loss at step  8000 :  8.27706386566162\n",
      "Epoch:  416  Average loss at step  8472 :  8.149863889274954\n",
      "416 0 20.957330226898193\n",
      "Epoch:  416  Average loss at step  1000 :  2441.9530923461916\n",
      "Epoch:  416  Average loss at step  1491 :  2420.3436114814135\n",
      "416 1 11.662816762924194\n",
      "Epoch:  416  Average loss at step  1000 :  3404.3329759521484\n",
      "Epoch:  416  Average loss at step  2000 :  3382.9916579589844\n",
      "Epoch:  416  Average loss at step  2533 :  3388.2776130819952\n",
      "416 2 19.915881395339966\n",
      "Epoch:  416  Average loss at step  1000 :  66.72882423400878\n",
      "Epoch:  416  Average loss at step  1227 :  67.10187993020381\n",
      "416 3 12.658783674240112\n",
      "Epoch:  416  Average loss at step  1000 :  7.239513269901275\n",
      "Epoch:  416  Average loss at step  2000 :  7.325418762683868\n",
      "Epoch:  416  Average loss at step  3000 :  7.279628629207611\n",
      "Epoch:  416  Average loss at step  3222 :  7.407677961312642\n",
      "416 4 33.29870057106018\n",
      "416 5 1.6689300537109375e-06\n",
      "Training time took 99.12593 seconds to run 1 epoch\n",
      "Epoch:  417  Average loss at step  1000 :  0.07440636116266251\n",
      "Epoch:  417  Average loss at step  2000 :  0.07723268288373947\n",
      "Epoch:  417  Average loss at step  3000 :  0.08443932539224625\n",
      "Epoch:  417  Average loss at step  3222 :  0.08841703371313811\n",
      "417 0 29.405816555023193\n",
      "Training time took 29.534543 seconds to run 1 epoch\n",
      "Epoch:  418  Average loss at step  1000 :  7.868708377838135\n",
      "Epoch:  418  Average loss at step  2000 :  8.281536147117615\n",
      "Epoch:  418  Average loss at step  3000 :  8.742333713531494\n",
      "Epoch:  418  Average loss at step  4000 :  8.402038674354554\n",
      "Epoch:  418  Average loss at step  5000 :  7.934830047607422\n",
      "Epoch:  418  Average loss at step  6000 :  8.33699557209015\n",
      "Epoch:  418  Average loss at step  7000 :  7.89721933555603\n",
      "Epoch:  418  Average loss at step  8000 :  8.042513221740723\n",
      "Epoch:  418  Average loss at step  8472 :  7.709933741935307\n",
      "418 0 20.643396377563477\n",
      "Epoch:  418  Average loss at step  1000 :  2400.3966241455078\n",
      "Epoch:  418  Average loss at step  1491 :  2438.0239562260977\n",
      "418 1 11.729165077209473\n",
      "Epoch:  418  Average loss at step  1000 :  3425.3055213623047\n",
      "Epoch:  418  Average loss at step  2000 :  3415.4332727050783\n",
      "Epoch:  418  Average loss at step  2533 :  3400.6962782242463\n",
      "418 2 19.84618830680847\n",
      "Epoch:  418  Average loss at step  1000 :  66.84291895675659\n",
      "Epoch:  418  Average loss at step  1227 :  66.430396779569\n",
      "418 3 12.598050117492676\n",
      "Epoch:  418  Average loss at step  1000 :  7.313947513103485\n",
      "Epoch:  418  Average loss at step  2000 :  7.251175892829895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  418  Average loss at step  3000 :  7.133189020633697\n",
      "Epoch:  418  Average loss at step  3222 :  7.224822347830039\n",
      "418 4 33.238372802734375\n",
      "418 5 1.430511474609375e-06\n",
      "Training time took 98.695873 seconds to run 1 epoch\n",
      "Epoch:  419  Average loss at step  1000 :  0.07382400131225586\n",
      "Epoch:  419  Average loss at step  2000 :  0.07734183937311173\n",
      "Epoch:  419  Average loss at step  3000 :  0.08390176886320114\n",
      "Epoch:  419  Average loss at step  3222 :  0.08770462504189074\n",
      "419 0 29.412261724472046\n",
      "Training time took 29.531142 seconds to run 1 epoch\n",
      "Epoch:  420  Average loss at step  1000 :  7.803420581817627\n",
      "Epoch:  420  Average loss at step  2000 :  7.883606934547425\n",
      "Epoch:  420  Average loss at step  3000 :  7.817877051353455\n",
      "Epoch:  420  Average loss at step  4000 :  8.029568645477294\n",
      "Epoch:  420  Average loss at step  5000 :  7.832359315872193\n",
      "Epoch:  420  Average loss at step  6000 :  8.314495655059815\n",
      "Epoch:  420  Average loss at step  7000 :  7.919944947242737\n",
      "Epoch:  420  Average loss at step  8000 :  8.589030179023743\n",
      "Epoch:  420  Average loss at step  8472 :  7.885881413588129\n",
      "420 0 20.404986143112183\n",
      "Epoch:  420  Average loss at step  1000 :  2439.679412963867\n",
      "Epoch:  420  Average loss at step  1491 :  2447.8472456672635\n",
      "420 1 11.740700483322144\n",
      "Epoch:  420  Average loss at step  1000 :  3418.4585251464846\n",
      "Epoch:  420  Average loss at step  2000 :  3409.1380078125\n",
      "Epoch:  420  Average loss at step  2533 :  3446.247959499032\n",
      "420 2 19.898210287094116\n",
      "Epoch:  420  Average loss at step  1000 :  66.20633325576782\n",
      "Epoch:  420  Average loss at step  1227 :  67.17552506161624\n",
      "420 3 12.588956594467163\n",
      "Epoch:  420  Average loss at step  1000 :  7.234207044124603\n",
      "Epoch:  420  Average loss at step  2000 :  7.190994094848633\n",
      "Epoch:  420  Average loss at step  3000 :  7.06321928024292\n",
      "Epoch:  420  Average loss at step  3222 :  7.37746265266406\n",
      "420 4 33.28276038169861\n",
      "420 5 1.430511474609375e-06\n",
      "Training time took 98.58492 seconds to run 1 epoch\n",
      "Mean Rank:  164.09896  of  75000\n",
      "Hits @ 10:  0.85308\n",
      "Hits @ 1:  0.612\n",
      "Testing time took 165.045444 seconds.\n",
      "\n",
      "Epoch:  421  Average loss at step  1000 :  0.07341458094120025\n",
      "Epoch:  421  Average loss at step  2000 :  0.07729935109615325\n",
      "Epoch:  421  Average loss at step  3000 :  0.0833029517531395\n",
      "Epoch:  421  Average loss at step  3222 :  0.08800078017291103\n",
      "421 0 29.398011445999146\n",
      "Training time took 29.508242 seconds to run 1 epoch\n",
      "Epoch:  422  Average loss at step  1000 :  8.496417041778564\n",
      "Epoch:  422  Average loss at step  2000 :  7.9319915771484375\n",
      "Epoch:  422  Average loss at step  3000 :  8.151046053886414\n",
      "Epoch:  422  Average loss at step  4000 :  8.150761140823365\n",
      "Epoch:  422  Average loss at step  5000 :  8.38860036468506\n",
      "Epoch:  422  Average loss at step  6000 :  7.239946732521057\n",
      "Epoch:  422  Average loss at step  7000 :  7.905443722724915\n",
      "Epoch:  422  Average loss at step  8000 :  8.057907493114472\n",
      "Epoch:  422  Average loss at step  8472 :  7.987921009555109\n",
      "422 0 20.722734689712524\n",
      "Epoch:  422  Average loss at step  1000 :  2436.3304521484374\n",
      "Epoch:  422  Average loss at step  1491 :  2483.0528290514144\n",
      "422 1 11.696361541748047\n",
      "Epoch:  422  Average loss at step  1000 :  3421.1492750244142\n",
      "Epoch:  422  Average loss at step  2000 :  3427.107739379883\n",
      "Epoch:  422  Average loss at step  2533 :  3431.3313612421534\n",
      "422 2 19.91556167602539\n",
      "Epoch:  422  Average loss at step  1000 :  66.71601520156861\n",
      "Epoch:  422  Average loss at step  1227 :  66.95667017267195\n",
      "422 3 12.654278755187988\n",
      "Epoch:  422  Average loss at step  1000 :  7.29420972108841\n",
      "Epoch:  422  Average loss at step  2000 :  7.263458336830139\n",
      "Epoch:  422  Average loss at step  3000 :  7.0111517286300655\n",
      "Epoch:  422  Average loss at step  3222 :  6.934037243422456\n",
      "422 4 33.17304563522339\n",
      "422 5 1.1920928955078125e-06\n",
      "Training time took 98.782614 seconds to run 1 epoch\n",
      "Epoch:  423  Average loss at step  1000 :  0.07300095784664154\n",
      "Epoch:  423  Average loss at step  2000 :  0.07666816908121109\n",
      "Epoch:  423  Average loss at step  3000 :  0.0834610652923584\n",
      "Epoch:  423  Average loss at step  3222 :  0.08807681268207174\n",
      "423 0 29.382046461105347\n",
      "Training time took 29.504596 seconds to run 1 epoch\n",
      "Epoch:  424  Average loss at step  1000 :  8.198831387519837\n",
      "Epoch:  424  Average loss at step  2000 :  8.221736360549928\n",
      "Epoch:  424  Average loss at step  3000 :  7.733636570930481\n",
      "Epoch:  424  Average loss at step  4000 :  8.652819470405579\n",
      "Epoch:  424  Average loss at step  5000 :  8.09540000152588\n",
      "Epoch:  424  Average loss at step  6000 :  7.727996334075928\n",
      "Epoch:  424  Average loss at step  7000 :  8.325340177536011\n",
      "Epoch:  424  Average loss at step  8000 :  7.974775412559509\n",
      "Epoch:  424  Average loss at step  8472 :  7.739886863745411\n",
      "424 0 20.500765562057495\n",
      "Epoch:  424  Average loss at step  1000 :  2461.6696513671877\n",
      "Epoch:  424  Average loss at step  1491 :  2455.023192737747\n",
      "424 1 11.70021367073059\n",
      "Epoch:  424  Average loss at step  1000 :  3420.2117333984374\n",
      "Epoch:  424  Average loss at step  2000 :  3407.600913696289\n",
      "Epoch:  424  Average loss at step  2533 :  3481.0154876175566\n",
      "424 2 19.89911961555481\n",
      "Epoch:  424  Average loss at step  1000 :  66.72134711837768\n",
      "Epoch:  424  Average loss at step  1227 :  66.1238182762248\n",
      "424 3 12.58887767791748\n",
      "Epoch:  424  Average loss at step  1000 :  7.034910815238953\n",
      "Epoch:  424  Average loss at step  2000 :  7.008574234008789\n",
      "Epoch:  424  Average loss at step  3000 :  6.9876114988327025\n",
      "Epoch:  424  Average loss at step  3222 :  6.840921184349026\n",
      "424 4 33.32166838645935\n",
      "424 5 1.430511474609375e-06\n",
      "Training time took 98.656419 seconds to run 1 epoch\n",
      "Epoch:  425  Average loss at step  1000 :  0.07313962942361832\n",
      "Epoch:  425  Average loss at step  2000 :  0.07606214725971222\n",
      "Epoch:  425  Average loss at step  3000 :  0.08328910320997238\n",
      "Epoch:  425  Average loss at step  3222 :  0.08599269952901457\n",
      "425 0 29.390151500701904\n",
      "Training time took 29.50961 seconds to run 1 epoch\n",
      "Epoch:  426  Average loss at step  1000 :  7.943798267364502\n",
      "Epoch:  426  Average loss at step  2000 :  8.139651019096375\n",
      "Epoch:  426  Average loss at step  3000 :  7.90524654006958\n",
      "Epoch:  426  Average loss at step  4000 :  8.249877123832702\n",
      "Epoch:  426  Average loss at step  5000 :  8.055064129829407\n",
      "Epoch:  426  Average loss at step  6000 :  8.123170977115631\n",
      "Epoch:  426  Average loss at step  7000 :  7.836094621658325\n",
      "Epoch:  426  Average loss at step  8000 :  7.513399285316467\n",
      "Epoch:  426  Average loss at step  8472 :  7.53300188352851\n",
      "426 0 20.51081895828247\n",
      "Epoch:  426  Average loss at step  1000 :  2423.582734863281\n",
      "Epoch:  426  Average loss at step  1491 :  2422.050866611942\n",
      "426 1 11.732066869735718\n",
      "Epoch:  426  Average loss at step  1000 :  3454.131480102539\n",
      "Epoch:  426  Average loss at step  2000 :  3436.86279296875\n",
      "Epoch:  426  Average loss at step  2533 :  3458.2339348714345\n",
      "426 2 19.860180854797363\n",
      "Epoch:  426  Average loss at step  1000 :  66.3661422958374\n",
      "Epoch:  426  Average loss at step  1227 :  66.93800641246386\n",
      "426 3 12.663980484008789\n",
      "Epoch:  426  Average loss at step  1000 :  7.187099523067475\n",
      "Epoch:  426  Average loss at step  2000 :  7.077205236434937\n",
      "Epoch:  426  Average loss at step  3000 :  7.09745326757431\n",
      "Epoch:  426  Average loss at step  3222 :  6.886879582981014\n",
      "426 4 33.36659288406372\n",
      "426 5 1.430511474609375e-06\n",
      "Training time took 98.770996 seconds to run 1 epoch\n",
      "Epoch:  427  Average loss at step  1000 :  0.07278899627923965\n",
      "Epoch:  427  Average loss at step  2000 :  0.07608625018596649\n",
      "Epoch:  427  Average loss at step  3000 :  0.08226752203702926\n",
      "Epoch:  427  Average loss at step  3222 :  0.08695839431273375\n",
      "427 0 29.451293468475342\n",
      "Training time took 29.579783 seconds to run 1 epoch\n",
      "Epoch:  428  Average loss at step  1000 :  8.11622297000885\n",
      "Epoch:  428  Average loss at step  2000 :  8.404316981315613\n",
      "Epoch:  428  Average loss at step  3000 :  8.408989954948426\n",
      "Epoch:  428  Average loss at step  4000 :  7.997544516563416\n",
      "Epoch:  428  Average loss at step  5000 :  8.248247073173523\n",
      "Epoch:  428  Average loss at step  6000 :  8.491807186126708\n",
      "Epoch:  428  Average loss at step  7000 :  8.004610458374023\n",
      "Epoch:  428  Average loss at step  8000 :  7.87199449634552\n",
      "Epoch:  428  Average loss at step  8472 :  7.877242604113967\n",
      "428 0 21.302336931228638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  428  Average loss at step  1000 :  2472.8368223876955\n",
      "Epoch:  428  Average loss at step  1491 :  2479.9908790279896\n",
      "428 1 11.692396402359009\n",
      "Epoch:  428  Average loss at step  1000 :  3427.346114868164\n",
      "Epoch:  428  Average loss at step  2000 :  3436.0102486572264\n",
      "Epoch:  428  Average loss at step  2533 :  3473.461478605121\n",
      "428 2 19.918293476104736\n",
      "Epoch:  428  Average loss at step  1000 :  66.5215269432068\n",
      "Epoch:  428  Average loss at step  1227 :  66.43799677331441\n",
      "428 3 12.670453071594238\n",
      "Epoch:  428  Average loss at step  1000 :  7.04118549489975\n",
      "Epoch:  428  Average loss at step  2000 :  6.999177207946778\n",
      "Epoch:  428  Average loss at step  3000 :  6.9662197804450985\n",
      "Epoch:  428  Average loss at step  3222 :  6.95980921573298\n",
      "428 4 33.01970076560974\n",
      "428 5 1.430511474609375e-06\n",
      "Training time took 99.243192 seconds to run 1 epoch\n",
      "Epoch:  429  Average loss at step  1000 :  0.07211518687009812\n",
      "Epoch:  429  Average loss at step  2000 :  0.07501042032241821\n",
      "Epoch:  429  Average loss at step  3000 :  0.08277963274717332\n",
      "Epoch:  429  Average loss at step  3222 :  0.0863167794737753\n",
      "429 0 29.389291763305664\n",
      "Training time took 29.509362 seconds to run 1 epoch\n",
      "Epoch:  430  Average loss at step  1000 :  8.171356977462768\n",
      "Epoch:  430  Average loss at step  2000 :  8.228310797691345\n",
      "Epoch:  430  Average loss at step  3000 :  8.02365679359436\n",
      "Epoch:  430  Average loss at step  4000 :  8.05362361049652\n",
      "Epoch:  430  Average loss at step  5000 :  8.545575085639953\n",
      "Epoch:  430  Average loss at step  6000 :  7.951216629028321\n",
      "Epoch:  430  Average loss at step  7000 :  7.948399603843689\n",
      "Epoch:  430  Average loss at step  8000 :  8.078830328941345\n",
      "Epoch:  430  Average loss at step  8472 :  7.776768185996143\n",
      "430 0 20.596237421035767\n",
      "Epoch:  430  Average loss at step  1000 :  2449.5203626708985\n",
      "Epoch:  430  Average loss at step  1491 :  2463.4690398078965\n",
      "430 1 11.734419584274292\n",
      "Epoch:  430  Average loss at step  1000 :  3462.774138305664\n",
      "Epoch:  430  Average loss at step  2000 :  3430.637127685547\n",
      "Epoch:  430  Average loss at step  2533 :  3438.7498161351195\n",
      "430 2 19.849488258361816\n",
      "Epoch:  430  Average loss at step  1000 :  65.71962503051758\n",
      "Epoch:  430  Average loss at step  1227 :  66.18320751017686\n",
      "430 3 12.716382026672363\n",
      "Epoch:  430  Average loss at step  1000 :  6.963600022792816\n",
      "Epoch:  430  Average loss at step  2000 :  7.063745248317718\n",
      "Epoch:  430  Average loss at step  3000 :  6.918587547302246\n",
      "Epoch:  430  Average loss at step  3222 :  6.5235726345659355\n",
      "430 4 33.19191646575928\n",
      "430 5 1.1920928955078125e-06\n",
      "Training time took 98.727708 seconds to run 1 epoch\n",
      "Mean Rank:  163.19808  of  75000\n",
      "Hits @ 10:  0.85264\n",
      "Hits @ 1:  0.6126\n",
      "Testing time took 165.140069 seconds.\n",
      "\n",
      "Epoch:  431  Average loss at step  1000 :  0.07195639896392822\n",
      "Epoch:  431  Average loss at step  2000 :  0.07575043880939483\n",
      "Epoch:  431  Average loss at step  3000 :  0.08205890893936157\n",
      "Epoch:  431  Average loss at step  3222 :  0.08597176822649268\n",
      "431 0 29.44697380065918\n",
      "Training time took 29.559622 seconds to run 1 epoch\n",
      "Epoch:  432  Average loss at step  1000 :  7.978213068008423\n",
      "Epoch:  432  Average loss at step  2000 :  7.954503170967102\n",
      "Epoch:  432  Average loss at step  3000 :  7.778268931388855\n",
      "Epoch:  432  Average loss at step  4000 :  8.218389486312866\n",
      "Epoch:  432  Average loss at step  5000 :  7.718314949989319\n",
      "Epoch:  432  Average loss at step  6000 :  8.171245757102966\n",
      "Epoch:  432  Average loss at step  7000 :  7.636462884426117\n",
      "Epoch:  432  Average loss at step  8000 :  8.009498081207276\n",
      "Epoch:  432  Average loss at step  8472 :  7.676319207558632\n",
      "432 0 20.752315044403076\n",
      "Epoch:  432  Average loss at step  1000 :  2449.0436284179686\n",
      "Epoch:  432  Average loss at step  1491 :  2443.7239189801435\n",
      "432 1 11.710148334503174\n",
      "Epoch:  432  Average loss at step  1000 :  3434.6135354003904\n",
      "Epoch:  432  Average loss at step  2000 :  3445.06323828125\n",
      "Epoch:  432  Average loss at step  2533 :  3450.2328474118435\n",
      "432 2 19.951603651046753\n",
      "Epoch:  432  Average loss at step  1000 :  66.16866749191284\n",
      "Epoch:  432  Average loss at step  1227 :  66.05138662143627\n",
      "432 3 12.695118427276611\n",
      "Epoch:  432  Average loss at step  1000 :  6.976194183826447\n",
      "Epoch:  432  Average loss at step  2000 :  6.985474282741547\n",
      "Epoch:  432  Average loss at step  3000 :  6.960328261375428\n",
      "Epoch:  432  Average loss at step  3222 :  6.98407917036479\n",
      "432 4 33.10647511482239\n",
      "432 5 1.1920928955078125e-06\n",
      "Training time took 98.857549 seconds to run 1 epoch\n",
      "Epoch:  433  Average loss at step  1000 :  0.07158601713180542\n",
      "Epoch:  433  Average loss at step  2000 :  0.0749924092888832\n",
      "Epoch:  433  Average loss at step  3000 :  0.08225095039606094\n",
      "Epoch:  433  Average loss at step  3222 :  0.08602823822006334\n",
      "433 0 29.46675181388855\n",
      "Training time took 29.585752 seconds to run 1 epoch\n",
      "Epoch:  434  Average loss at step  1000 :  8.317422332763671\n",
      "Epoch:  434  Average loss at step  2000 :  7.702086215496063\n",
      "Epoch:  434  Average loss at step  3000 :  8.37057810306549\n",
      "Epoch:  434  Average loss at step  4000 :  8.298210230827332\n",
      "Epoch:  434  Average loss at step  5000 :  8.02348871231079\n",
      "Epoch:  434  Average loss at step  6000 :  8.115326225757599\n",
      "Epoch:  434  Average loss at step  7000 :  8.443870416641236\n",
      "Epoch:  434  Average loss at step  8000 :  8.429881701469421\n",
      "Epoch:  434  Average loss at step  8472 :  7.853016131428465\n",
      "434 0 20.747731924057007\n",
      "Epoch:  434  Average loss at step  1000 :  2476.5424244384767\n",
      "Epoch:  434  Average loss at step  1491 :  2458.00404294846\n",
      "434 1 11.73141622543335\n",
      "Epoch:  434  Average loss at step  1000 :  3484.6336240234373\n",
      "Epoch:  434  Average loss at step  2000 :  3455.722730102539\n",
      "Epoch:  434  Average loss at step  2533 :  3483.172858417857\n",
      "434 2 19.932976961135864\n",
      "Epoch:  434  Average loss at step  1000 :  65.99719342803955\n",
      "Epoch:  434  Average loss at step  1227 :  66.5146322860849\n",
      "434 3 12.623749494552612\n",
      "Epoch:  434  Average loss at step  1000 :  6.943688302516938\n",
      "Epoch:  434  Average loss at step  2000 :  6.80904587650299\n",
      "Epoch:  434  Average loss at step  3000 :  6.918770302772522\n",
      "Epoch:  434  Average loss at step  3222 :  7.005587922340912\n",
      "434 4 33.13922452926636\n",
      "434 5 1.9073486328125e-06\n",
      "Training time took 98.821729 seconds to run 1 epoch\n",
      "Epoch:  435  Average loss at step  1000 :  0.07138586920499802\n",
      "Epoch:  435  Average loss at step  2000 :  0.07502266329526901\n",
      "Epoch:  435  Average loss at step  3000 :  0.0813328201174736\n",
      "Epoch:  435  Average loss at step  3222 :  0.08476354097024394\n",
      "435 0 29.431243181228638\n",
      "Training time took 29.550598 seconds to run 1 epoch\n",
      "Epoch:  436  Average loss at step  1000 :  8.308396869659424\n",
      "Epoch:  436  Average loss at step  2000 :  7.84261536693573\n",
      "Epoch:  436  Average loss at step  3000 :  8.264476555347443\n",
      "Epoch:  436  Average loss at step  4000 :  8.564595251083373\n",
      "Epoch:  436  Average loss at step  5000 :  7.990416934013367\n",
      "Epoch:  436  Average loss at step  6000 :  8.259547825813293\n",
      "Epoch:  436  Average loss at step  7000 :  8.120477928161622\n",
      "Epoch:  436  Average loss at step  8000 :  8.058039883613587\n",
      "Epoch:  436  Average loss at step  8472 :  8.398256554455228\n",
      "436 0 21.048182249069214\n",
      "Epoch:  436  Average loss at step  1000 :  2454.7790344238283\n",
      "Epoch:  436  Average loss at step  1491 :  2462.2894337461234\n",
      "436 1 11.695501804351807\n",
      "Epoch:  436  Average loss at step  1000 :  3441.205744995117\n",
      "Epoch:  436  Average loss at step  2000 :  3455.7356079101564\n",
      "Epoch:  436  Average loss at step  2533 :  3459.702030327143\n",
      "436 2 19.92797040939331\n",
      "Epoch:  436  Average loss at step  1000 :  66.35216511535644\n",
      "Epoch:  436  Average loss at step  1227 :  65.08736100695197\n",
      "436 3 12.646100997924805\n",
      "Epoch:  436  Average loss at step  1000 :  6.945558010101318\n",
      "Epoch:  436  Average loss at step  2000 :  6.87203903055191\n",
      "Epoch:  436  Average loss at step  3000 :  6.925632306575775\n",
      "Epoch:  436  Average loss at step  3222 :  6.912007411909267\n",
      "436 4 33.18901205062866\n",
      "436 5 1.430511474609375e-06\n",
      "Training time took 99.154709 seconds to run 1 epoch\n",
      "Epoch:  437  Average loss at step  1000 :  0.07118264412879943\n",
      "Epoch:  437  Average loss at step  2000 :  0.07423158818483352\n",
      "Epoch:  437  Average loss at step  3000 :  0.08111043465137481\n",
      "Epoch:  437  Average loss at step  3222 :  0.08591987242399947\n",
      "437 0 29.423060655593872\n",
      "Training time took 29.54195 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  438  Average loss at step  1000 :  7.993292112350463\n",
      "Epoch:  438  Average loss at step  2000 :  7.871773787498475\n",
      "Epoch:  438  Average loss at step  3000 :  8.003550282478333\n",
      "Epoch:  438  Average loss at step  4000 :  7.508190121650696\n",
      "Epoch:  438  Average loss at step  5000 :  8.285103415489196\n",
      "Epoch:  438  Average loss at step  6000 :  7.643200872421264\n",
      "Epoch:  438  Average loss at step  7000 :  8.273149297714234\n",
      "Epoch:  438  Average loss at step  8000 :  8.154305906772613\n",
      "Epoch:  438  Average loss at step  8472 :  7.824714946491822\n",
      "438 0 21.34679889678955\n",
      "Epoch:  438  Average loss at step  1000 :  2471.758737182617\n",
      "Epoch:  438  Average loss at step  1491 :  2475.799897096216\n",
      "438 1 11.723553895950317\n",
      "Epoch:  438  Average loss at step  1000 :  3492.418980957031\n",
      "Epoch:  438  Average loss at step  2000 :  3476.307996826172\n",
      "Epoch:  438  Average loss at step  2533 :  3417.010127976932\n",
      "438 2 19.85777235031128\n",
      "Epoch:  438  Average loss at step  1000 :  66.13086519241332\n",
      "Epoch:  438  Average loss at step  1227 :  66.35502440668454\n",
      "438 3 12.685537099838257\n",
      "Epoch:  438  Average loss at step  1000 :  6.998179815769196\n",
      "Epoch:  438  Average loss at step  2000 :  6.925976021289825\n",
      "Epoch:  438  Average loss at step  3000 :  6.843335311889648\n",
      "Epoch:  438  Average loss at step  3222 :  6.639613025260329\n",
      "438 4 33.09469652175903\n",
      "438 5 1.1920928955078125e-06\n",
      "Training time took 99.358812 seconds to run 1 epoch\n",
      "Epoch:  439  Average loss at step  1000 :  0.07103894335031509\n",
      "Epoch:  439  Average loss at step  2000 :  0.07439053773880006\n",
      "Epoch:  439  Average loss at step  3000 :  0.08072488212585449\n",
      "Epoch:  439  Average loss at step  3222 :  0.085646043477624\n",
      "439 0 29.470062732696533\n",
      "Training time took 29.59397 seconds to run 1 epoch\n",
      "Epoch:  440  Average loss at step  1000 :  7.805008770942688\n",
      "Epoch:  440  Average loss at step  2000 :  8.304862872600555\n",
      "Epoch:  440  Average loss at step  3000 :  7.850465922355652\n",
      "Epoch:  440  Average loss at step  4000 :  7.92192338180542\n",
      "Epoch:  440  Average loss at step  5000 :  8.155141551971436\n",
      "Epoch:  440  Average loss at step  6000 :  8.134194091320039\n",
      "Epoch:  440  Average loss at step  7000 :  8.298034824848175\n",
      "Epoch:  440  Average loss at step  8000 :  7.930381983757019\n",
      "Epoch:  440  Average loss at step  8472 :  7.797304393227054\n",
      "440 0 20.555038928985596\n",
      "Epoch:  440  Average loss at step  1000 :  2464.3386802978516\n",
      "Epoch:  440  Average loss at step  1491 :  2463.241351684001\n",
      "440 1 11.735459327697754\n",
      "Epoch:  440  Average loss at step  1000 :  3468.105631347656\n",
      "Epoch:  440  Average loss at step  2000 :  3466.999724609375\n",
      "Epoch:  440  Average loss at step  2533 :  3480.2148035539344\n",
      "440 2 19.977294445037842\n",
      "Epoch:  440  Average loss at step  1000 :  66.07691533660889\n",
      "Epoch:  440  Average loss at step  1227 :  65.53803789456279\n",
      "440 3 12.734221935272217\n",
      "Epoch:  440  Average loss at step  1000 :  6.828366533756256\n",
      "Epoch:  440  Average loss at step  2000 :  6.883994757652283\n",
      "Epoch:  440  Average loss at step  3000 :  6.74372938299179\n",
      "Epoch:  440  Average loss at step  3222 :  6.990780858792086\n",
      "440 4 33.14174509048462\n",
      "440 5 1.6689300537109375e-06\n",
      "Training time took 98.794275 seconds to run 1 epoch\n",
      "Mean Rank:  164.14812  of  75000\n",
      "Hits @ 10:  0.85244\n",
      "Hits @ 1:  0.61336\n",
      "Testing time took 165.248409 seconds.\n",
      "\n",
      "Epoch:  441  Average loss at step  1000 :  0.07017823326587677\n",
      "Epoch:  441  Average loss at step  2000 :  0.07360599279403686\n",
      "Epoch:  441  Average loss at step  3000 :  0.08083203119039535\n",
      "Epoch:  441  Average loss at step  3222 :  0.08462142978770829\n",
      "441 0 29.550215482711792\n",
      "Training time took 29.659098 seconds to run 1 epoch\n",
      "Epoch:  442  Average loss at step  1000 :  7.603480883598328\n",
      "Epoch:  442  Average loss at step  2000 :  8.097200887680053\n",
      "Epoch:  442  Average loss at step  3000 :  8.093134977340698\n",
      "Epoch:  442  Average loss at step  4000 :  8.309492010116577\n",
      "Epoch:  442  Average loss at step  5000 :  7.65217411327362\n",
      "Epoch:  442  Average loss at step  6000 :  8.137399729728699\n",
      "Epoch:  442  Average loss at step  7000 :  7.605638434410095\n",
      "Epoch:  442  Average loss at step  8000 :  8.342252728462219\n",
      "Epoch:  442  Average loss at step  8472 :  8.085704808081154\n",
      "442 0 20.98367667198181\n",
      "Epoch:  442  Average loss at step  1000 :  2458.246006103516\n",
      "Epoch:  442  Average loss at step  1491 :  2441.2087361913073\n",
      "442 1 11.717006921768188\n",
      "Epoch:  442  Average loss at step  1000 :  3480.99028125\n",
      "Epoch:  442  Average loss at step  2000 :  3447.4733935546874\n",
      "Epoch:  442  Average loss at step  2533 :  3424.4903338464974\n",
      "442 2 19.942123889923096\n",
      "Epoch:  442  Average loss at step  1000 :  65.94562330245972\n",
      "Epoch:  442  Average loss at step  1227 :  65.12340963525799\n",
      "442 3 12.634206056594849\n",
      "Epoch:  442  Average loss at step  1000 :  6.8445807447433475\n",
      "Epoch:  442  Average loss at step  2000 :  6.733208407878876\n",
      "Epoch:  442  Average loss at step  3000 :  6.691822434902191\n",
      "Epoch:  442  Average loss at step  3222 :  6.885961447624679\n",
      "442 4 33.20168995857239\n",
      "442 5 1.6689300537109375e-06\n",
      "Training time took 99.124436 seconds to run 1 epoch\n",
      "Epoch:  443  Average loss at step  1000 :  0.07046382689476013\n",
      "Epoch:  443  Average loss at step  2000 :  0.07353095126152039\n",
      "Epoch:  443  Average loss at step  3000 :  0.08072019970417023\n",
      "Epoch:  443  Average loss at step  3222 :  0.0839379345882152\n",
      "443 0 29.48348593711853\n",
      "Training time took 29.603079 seconds to run 1 epoch\n",
      "Epoch:  444  Average loss at step  1000 :  8.718617122650146\n",
      "Epoch:  444  Average loss at step  2000 :  7.946259100914001\n",
      "Epoch:  444  Average loss at step  3000 :  8.136073897361756\n",
      "Epoch:  444  Average loss at step  4000 :  8.061766413211823\n",
      "Epoch:  444  Average loss at step  5000 :  7.930094537734985\n",
      "Epoch:  444  Average loss at step  6000 :  8.118679655075073\n",
      "Epoch:  444  Average loss at step  7000 :  8.131389907836914\n",
      "Epoch:  444  Average loss at step  8000 :  8.347928374290467\n",
      "Epoch:  444  Average loss at step  8472 :  7.988746732601128\n",
      "444 0 20.955986738204956\n",
      "Epoch:  444  Average loss at step  1000 :  2457.2450930175783\n",
      "Epoch:  444  Average loss at step  1491 :  2483.3366290386516\n",
      "444 1 11.758553981781006\n",
      "Epoch:  444  Average loss at step  1000 :  3507.691867919922\n",
      "Epoch:  444  Average loss at step  2000 :  3456.4644732666015\n",
      "Epoch:  444  Average loss at step  2533 :  3495.4562470504534\n",
      "444 2 19.926904439926147\n",
      "Epoch:  444  Average loss at step  1000 :  65.20951620101928\n",
      "Epoch:  444  Average loss at step  1227 :  65.42739157967634\n",
      "444 3 12.590604543685913\n",
      "Epoch:  444  Average loss at step  1000 :  6.866795989990234\n",
      "Epoch:  444  Average loss at step  2000 :  6.762528564453125\n",
      "Epoch:  444  Average loss at step  3000 :  6.665127664089203\n",
      "Epoch:  444  Average loss at step  3222 :  6.946387439885495\n",
      "444 4 32.76733374595642\n",
      "444 5 1.1920928955078125e-06\n",
      "Training time took 98.644908 seconds to run 1 epoch\n",
      "Epoch:  445  Average loss at step  1000 :  0.07035090428590775\n",
      "Epoch:  445  Average loss at step  2000 :  0.07320604228973389\n",
      "Epoch:  445  Average loss at step  3000 :  0.0797226927280426\n",
      "Epoch:  445  Average loss at step  3222 :  0.08333070433339954\n",
      "445 0 29.806010246276855\n",
      "Training time took 29.938544 seconds to run 1 epoch\n",
      "Epoch:  446  Average loss at step  1000 :  8.165437808990479\n",
      "Epoch:  446  Average loss at step  2000 :  7.933343334197998\n",
      "Epoch:  446  Average loss at step  3000 :  8.053722928047181\n",
      "Epoch:  446  Average loss at step  4000 :  7.8522286834716795\n",
      "Epoch:  446  Average loss at step  5000 :  8.776756158828736\n",
      "Epoch:  446  Average loss at step  6000 :  8.205746425628663\n",
      "Epoch:  446  Average loss at step  7000 :  7.995187058448791\n",
      "Epoch:  446  Average loss at step  8000 :  8.035422755241393\n",
      "Epoch:  446  Average loss at step  8472 :  8.45069104456081\n",
      "446 0 23.660653114318848\n",
      "Epoch:  446  Average loss at step  1000 :  2470.0814826660157\n",
      "Epoch:  446  Average loss at step  1491 :  2497.6622506983717\n",
      "446 1 12.119599342346191\n",
      "Epoch:  446  Average loss at step  1000 :  3500.4092119140623\n",
      "Epoch:  446  Average loss at step  2000 :  3470.085386352539\n",
      "Epoch:  446  Average loss at step  2533 :  3473.7909872307932\n",
      "446 2 20.80260467529297\n",
      "Epoch:  446  Average loss at step  1000 :  66.0891846961975\n",
      "Epoch:  446  Average loss at step  1227 :  66.38677774342567\n",
      "446 3 13.087265253067017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  446  Average loss at step  1000 :  6.820684944152832\n",
      "Epoch:  446  Average loss at step  2000 :  6.696800375938415\n",
      "Epoch:  446  Average loss at step  3000 :  6.681953471660614\n",
      "Epoch:  446  Average loss at step  3222 :  6.478550348455756\n",
      "446 4 34.115084171295166\n",
      "446 5 9.5367431640625e-07\n",
      "Training time took 104.512042 seconds to run 1 epoch\n",
      "Epoch:  447  Average loss at step  1000 :  0.06981873470544815\n",
      "Epoch:  447  Average loss at step  2000 :  0.07303524172306061\n",
      "Epoch:  447  Average loss at step  3000 :  0.07964780074357987\n",
      "Epoch:  447  Average loss at step  3222 :  0.08289173856111269\n",
      "447 0 30.617196083068848\n",
      "Training time took 30.751115 seconds to run 1 epoch\n",
      "Epoch:  448  Average loss at step  1000 :  8.494758820056916\n",
      "Epoch:  448  Average loss at step  2000 :  7.87333269405365\n",
      "Epoch:  448  Average loss at step  3000 :  7.96435962677002\n",
      "Epoch:  448  Average loss at step  4000 :  8.746421204566955\n",
      "Epoch:  448  Average loss at step  5000 :  8.022287839889527\n",
      "Epoch:  448  Average loss at step  6000 :  7.793886585235596\n",
      "Epoch:  448  Average loss at step  7000 :  8.181844550132752\n",
      "Epoch:  448  Average loss at step  8000 :  8.39296441745758\n",
      "Epoch:  448  Average loss at step  8472 :  7.9857354354162196\n",
      "448 0 23.4064302444458\n",
      "Epoch:  448  Average loss at step  1000 :  2480.85193548584\n",
      "Epoch:  448  Average loss at step  1491 :  2456.4620253388657\n",
      "448 1 12.105569124221802\n",
      "Epoch:  448  Average loss at step  1000 :  3503.935255126953\n",
      "Epoch:  448  Average loss at step  2000 :  3476.1331126708983\n",
      "Epoch:  448  Average loss at step  2533 :  3430.7013214080357\n",
      "448 2 20.025643587112427\n",
      "Epoch:  448  Average loss at step  1000 :  65.71813095855713\n",
      "Epoch:  448  Average loss at step  1227 :  66.68895065597755\n",
      "448 3 12.933316469192505\n",
      "Epoch:  448  Average loss at step  1000 :  6.708746958255768\n",
      "Epoch:  448  Average loss at step  2000 :  6.629439550876618\n",
      "Epoch:  448  Average loss at step  3000 :  6.732574373722076\n",
      "Epoch:  448  Average loss at step  3222 :  6.726769995099694\n",
      "448 4 34.309953689575195\n",
      "448 5 1.1920928955078125e-06\n",
      "Training time took 103.474472 seconds to run 1 epoch\n",
      "Epoch:  449  Average loss at step  1000 :  0.06991535353660583\n",
      "Epoch:  449  Average loss at step  2000 :  0.07321248537302018\n",
      "Epoch:  449  Average loss at step  3000 :  0.07931422871351242\n",
      "Epoch:  449  Average loss at step  3222 :  0.08276295879296522\n",
      "449 0 29.882294178009033\n",
      "Training time took 30.015337 seconds to run 1 epoch\n",
      "Epoch:  450  Average loss at step  1000 :  8.115148986816406\n",
      "Epoch:  450  Average loss at step  2000 :  7.915135940551758\n",
      "Epoch:  450  Average loss at step  3000 :  8.294613209724426\n",
      "Epoch:  450  Average loss at step  4000 :  8.604652325630187\n",
      "Epoch:  450  Average loss at step  5000 :  8.170359144210815\n",
      "Epoch:  450  Average loss at step  6000 :  7.75947999382019\n",
      "Epoch:  450  Average loss at step  7000 :  8.00960828113556\n",
      "Epoch:  450  Average loss at step  8000 :  7.800072557449341\n",
      "Epoch:  450  Average loss at step  8472 :  9.208174540319474\n",
      "450 0 23.762192964553833\n",
      "Epoch:  450  Average loss at step  1000 :  2459.35546887207\n",
      "Epoch:  450  Average loss at step  1491 :  2504.1067583145764\n",
      "450 1 12.247955560684204\n",
      "Epoch:  450  Average loss at step  1000 :  3490.716620727539\n",
      "Epoch:  450  Average loss at step  2000 :  3462.4906883544922\n",
      "Epoch:  450  Average loss at step  2533 :  3491.5839546959874\n",
      "450 2 20.735040426254272\n",
      "Epoch:  450  Average loss at step  1000 :  65.56716019058227\n",
      "Epoch:  450  Average loss at step  1227 :  65.44839590833905\n",
      "450 3 13.162182331085205\n",
      "Epoch:  450  Average loss at step  1000 :  6.669576798915863\n",
      "Epoch:  450  Average loss at step  2000 :  6.600047152996063\n",
      "Epoch:  450  Average loss at step  3000 :  6.580019243717194\n",
      "Epoch:  450  Average loss at step  3222 :  6.493766989211223\n",
      "450 4 33.597216844558716\n",
      "450 5 9.5367431640625e-07\n",
      "Training time took 104.234487 seconds to run 1 epoch\n",
      "Mean Rank:  162.28956  of  75000\n",
      "Hits @ 10:  0.85348\n",
      "Hits @ 1:  0.61604\n",
      "Testing time took 192.496934 seconds.\n",
      "\n",
      "Epoch:  451  Average loss at step  1000 :  0.06924381774663925\n",
      "Epoch:  451  Average loss at step  2000 :  0.07280746197700501\n",
      "Epoch:  451  Average loss at step  3000 :  0.07880866438150406\n",
      "Epoch:  451  Average loss at step  3222 :  0.08318573209563195\n",
      "451 0 30.718916654586792\n",
      "Training time took 30.853972 seconds to run 1 epoch\n",
      "Epoch:  452  Average loss at step  1000 :  7.956668482780456\n",
      "Epoch:  452  Average loss at step  2000 :  8.16689388179779\n",
      "Epoch:  452  Average loss at step  3000 :  7.966274889469147\n",
      "Epoch:  452  Average loss at step  4000 :  7.610696610450745\n",
      "Epoch:  452  Average loss at step  5000 :  8.044815184593201\n",
      "Epoch:  452  Average loss at step  6000 :  7.729731908798218\n",
      "Epoch:  452  Average loss at step  7000 :  7.667373742103576\n",
      "Epoch:  452  Average loss at step  8000 :  8.255625878334046\n",
      "Epoch:  452  Average loss at step  8472 :  7.942213143311091\n",
      "452 0 22.860993146896362\n",
      "Epoch:  452  Average loss at step  1000 :  2485.704822998047\n",
      "Epoch:  452  Average loss at step  1491 :  2508.024277433662\n",
      "452 1 12.24271821975708\n",
      "Epoch:  452  Average loss at step  1000 :  3473.5514998779295\n",
      "Epoch:  452  Average loss at step  2000 :  3501.718801025391\n",
      "Epoch:  452  Average loss at step  2533 :  3457.1787271168755\n",
      "452 2 20.162617444992065\n",
      "Epoch:  452  Average loss at step  1000 :  65.68297233200073\n",
      "Epoch:  452  Average loss at step  1227 :  65.29513541793942\n",
      "452 3 13.196412086486816\n",
      "Epoch:  452  Average loss at step  1000 :  6.605990870475769\n",
      "Epoch:  452  Average loss at step  2000 :  6.524454198360443\n",
      "Epoch:  452  Average loss at step  3000 :  6.6044007635116575\n",
      "Epoch:  452  Average loss at step  3222 :  6.725319913845885\n",
      "452 4 34.010801553726196\n",
      "452 5 1.6689300537109375e-06\n",
      "Training time took 103.183369 seconds to run 1 epoch\n",
      "Epoch:  453  Average loss at step  1000 :  0.06929877889156341\n",
      "Epoch:  453  Average loss at step  2000 :  0.07230270367860794\n",
      "Epoch:  453  Average loss at step  3000 :  0.07846308124065399\n",
      "Epoch:  453  Average loss at step  3222 :  0.08274035147971508\n",
      "453 0 30.74298405647278\n",
      "Training time took 30.883862 seconds to run 1 epoch\n",
      "Epoch:  454  Average loss at step  1000 :  7.96883669757843\n",
      "Epoch:  454  Average loss at step  2000 :  7.975494704246521\n",
      "Epoch:  454  Average loss at step  3000 :  8.462958527565002\n",
      "Epoch:  454  Average loss at step  4000 :  7.810151547431945\n",
      "Epoch:  454  Average loss at step  5000 :  8.14636552810669\n",
      "Epoch:  454  Average loss at step  6000 :  7.995261815071106\n",
      "Epoch:  454  Average loss at step  7000 :  8.5853726978302\n",
      "Epoch:  454  Average loss at step  8000 :  8.427965692520141\n",
      "Epoch:  454  Average loss at step  8472 :  7.977816141864489\n",
      "454 0 21.696622848510742\n",
      "Epoch:  454  Average loss at step  1000 :  2504.8151286621096\n",
      "Epoch:  454  Average loss at step  1491 :  2506.910982159737\n",
      "454 1 11.773632764816284\n",
      "Epoch:  454  Average loss at step  1000 :  3494.23587890625\n",
      "Epoch:  454  Average loss at step  2000 :  3507.2328262939454\n",
      "Epoch:  454  Average loss at step  2533 :  3466.5080428656725\n",
      "454 2 19.895931482315063\n",
      "Epoch:  454  Average loss at step  1000 :  65.71910799026489\n",
      "Epoch:  454  Average loss at step  1227 :  65.07564872344192\n",
      "454 3 12.654138088226318\n",
      "Epoch:  454  Average loss at step  1000 :  6.769031100749969\n",
      "Epoch:  454  Average loss at step  2000 :  6.641870422363281\n",
      "Epoch:  454  Average loss at step  3000 :  6.507345355987549\n",
      "Epoch:  454  Average loss at step  3222 :  6.674676329720685\n",
      "454 4 33.11117720603943\n",
      "454 5 1.430511474609375e-06\n",
      "Training time took 99.813216 seconds to run 1 epoch\n",
      "Epoch:  455  Average loss at step  1000 :  0.0688826334476471\n",
      "Epoch:  455  Average loss at step  2000 :  0.07197661936283112\n",
      "Epoch:  455  Average loss at step  3000 :  0.07855531454086304\n",
      "Epoch:  455  Average loss at step  3222 :  0.08223210620329169\n",
      "455 0 29.480320930480957\n",
      "Training time took 29.602832 seconds to run 1 epoch\n",
      "Epoch:  456  Average loss at step  1000 :  7.734916490554809\n",
      "Epoch:  456  Average loss at step  2000 :  7.843690188884735\n",
      "Epoch:  456  Average loss at step  3000 :  7.723105688095092\n",
      "Epoch:  456  Average loss at step  4000 :  8.037844263076781\n",
      "Epoch:  456  Average loss at step  5000 :  7.832489621162415\n",
      "Epoch:  456  Average loss at step  6000 :  7.820123705863953\n",
      "Epoch:  456  Average loss at step  7000 :  7.908735653877258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  456  Average loss at step  8000 :  7.871920813560486\n",
      "Epoch:  456  Average loss at step  8472 :  7.828610735015267\n",
      "456 0 20.807377815246582\n",
      "Epoch:  456  Average loss at step  1000 :  2514.4653946533203\n",
      "Epoch:  456  Average loss at step  1491 :  2525.9440598153633\n",
      "456 1 11.666540384292603\n",
      "Epoch:  456  Average loss at step  1000 :  3514.3683524169924\n",
      "Epoch:  456  Average loss at step  2000 :  3492.069517578125\n",
      "Epoch:  456  Average loss at step  2533 :  3475.9718208784757\n",
      "456 2 20.002695322036743\n",
      "Epoch:  456  Average loss at step  1000 :  65.43125093841553\n",
      "Epoch:  456  Average loss at step  1227 :  65.32043401157976\n",
      "456 3 12.659803628921509\n",
      "Epoch:  456  Average loss at step  1000 :  6.576433045387268\n",
      "Epoch:  456  Average loss at step  2000 :  6.537246263027191\n",
      "Epoch:  456  Average loss at step  3000 :  6.347545315265656\n",
      "Epoch:  456  Average loss at step  3222 :  6.537573861395717\n",
      "456 4 33.64794611930847\n",
      "456 5 1.6689300537109375e-06\n",
      "Training time took 99.416854 seconds to run 1 epoch\n",
      "Epoch:  457  Average loss at step  1000 :  0.068526526927948\n",
      "Epoch:  457  Average loss at step  2000 :  0.07197084891796111\n",
      "Epoch:  457  Average loss at step  3000 :  0.0782403911948204\n",
      "Epoch:  457  Average loss at step  3222 :  0.08149938820974774\n",
      "457 0 30.191197872161865\n",
      "Training time took 30.321804 seconds to run 1 epoch\n",
      "Epoch:  458  Average loss at step  1000 :  8.31158655166626\n",
      "Epoch:  458  Average loss at step  2000 :  7.977732493877411\n",
      "Epoch:  458  Average loss at step  3000 :  8.141985188484192\n",
      "Epoch:  458  Average loss at step  4000 :  7.898385251998901\n",
      "Epoch:  458  Average loss at step  5000 :  7.585316681861878\n",
      "Epoch:  458  Average loss at step  6000 :  7.914817601680755\n",
      "Epoch:  458  Average loss at step  7000 :  8.041413715362548\n",
      "Epoch:  458  Average loss at step  8000 :  8.592494119644165\n",
      "Epoch:  458  Average loss at step  8472 :  8.468063539147431\n",
      "458 0 23.010173797607422\n",
      "Epoch:  458  Average loss at step  1000 :  2512.7395380249022\n",
      "Epoch:  458  Average loss at step  1491 :  2461.352594511708\n",
      "458 1 12.238065242767334\n",
      "Epoch:  458  Average loss at step  1000 :  3480.9948424072268\n",
      "Epoch:  458  Average loss at step  2000 :  3495.46747265625\n",
      "Epoch:  458  Average loss at step  2533 :  3493.096952736255\n",
      "458 2 20.822376251220703\n",
      "Epoch:  458  Average loss at step  1000 :  65.44709008407592\n",
      "Epoch:  458  Average loss at step  1227 :  65.12362612736379\n",
      "458 3 13.1004798412323\n",
      "Epoch:  458  Average loss at step  1000 :  6.51903096818924\n",
      "Epoch:  458  Average loss at step  2000 :  6.4000460505485535\n",
      "Epoch:  458  Average loss at step  3000 :  6.383183136940002\n",
      "Epoch:  458  Average loss at step  3222 :  6.377778874986286\n",
      "458 4 33.96084499359131\n",
      "458 5 1.430511474609375e-06\n",
      "Training time took 103.836918 seconds to run 1 epoch\n",
      "Epoch:  459  Average loss at step  1000 :  0.06809002387523651\n",
      "Epoch:  459  Average loss at step  2000 :  0.07175825184583665\n",
      "Epoch:  459  Average loss at step  3000 :  0.07773206162452698\n",
      "Epoch:  459  Average loss at step  3222 :  0.0821426365538654\n",
      "459 0 30.726867198944092\n",
      "Training time took 30.868782 seconds to run 1 epoch\n",
      "Epoch:  460  Average loss at step  1000 :  8.05570479631424\n",
      "Epoch:  460  Average loss at step  2000 :  8.385761274337769\n",
      "Epoch:  460  Average loss at step  3000 :  7.719881936073303\n",
      "Epoch:  460  Average loss at step  4000 :  8.044746447563172\n",
      "Epoch:  460  Average loss at step  5000 :  7.81656628704071\n",
      "Epoch:  460  Average loss at step  6000 :  8.32173410654068\n",
      "Epoch:  460  Average loss at step  7000 :  7.90803507232666\n",
      "Epoch:  460  Average loss at step  8000 :  8.602655307769776\n",
      "Epoch:  460  Average loss at step  8472 :  8.315213878866842\n",
      "460 0 23.913061141967773\n",
      "Epoch:  460  Average loss at step  1000 :  2504.897807373047\n",
      "Epoch:  460  Average loss at step  1491 :  2528.9993504635017\n",
      "460 1 12.27820634841919\n",
      "Epoch:  460  Average loss at step  1000 :  3501.5374058837892\n",
      "Epoch:  460  Average loss at step  2000 :  3495.107266845703\n",
      "Epoch:  460  Average loss at step  2533 :  3509.5917797687293\n",
      "460 2 20.884560108184814\n",
      "Epoch:  460  Average loss at step  1000 :  65.90454451370239\n",
      "Epoch:  460  Average loss at step  1227 :  66.27001837070152\n",
      "460 3 12.921376466751099\n",
      "Epoch:  460  Average loss at step  1000 :  6.46410833454132\n",
      "Epoch:  460  Average loss at step  2000 :  6.4710555238723755\n",
      "Epoch:  460  Average loss at step  3000 :  6.374618039131165\n",
      "Epoch:  460  Average loss at step  3222 :  6.164360136778309\n",
      "460 4 34.17547535896301\n",
      "460 5 1.9073486328125e-06\n",
      "Training time took 104.889209 seconds to run 1 epoch\n",
      "Mean Rank:  163.18548  of  75000\n",
      "Hits @ 10:  0.85376\n",
      "Hits @ 1:  0.61532\n",
      "Testing time took 188.844807 seconds.\n",
      "\n",
      "Epoch:  461  Average loss at step  1000 :  0.06793926852941513\n",
      "Epoch:  461  Average loss at step  2000 :  0.07120095747709275\n",
      "Epoch:  461  Average loss at step  3000 :  0.0777507860660553\n",
      "Epoch:  461  Average loss at step  3222 :  0.0816393342984887\n",
      "461 0 29.6684627532959\n",
      "Training time took 29.776403 seconds to run 1 epoch\n",
      "Epoch:  462  Average loss at step  1000 :  8.08699059867859\n",
      "Epoch:  462  Average loss at step  2000 :  7.737440860748291\n",
      "Epoch:  462  Average loss at step  3000 :  7.815906007766723\n",
      "Epoch:  462  Average loss at step  4000 :  8.318585629463195\n",
      "Epoch:  462  Average loss at step  5000 :  8.319726596832275\n",
      "Epoch:  462  Average loss at step  6000 :  7.641609704017639\n",
      "Epoch:  462  Average loss at step  7000 :  8.032925315856934\n",
      "Epoch:  462  Average loss at step  8000 :  8.068239508152008\n",
      "Epoch:  462  Average loss at step  8472 :  8.37514960377767\n",
      "462 0 18.997135639190674\n",
      "Epoch:  462  Average loss at step  1000 :  2495.922669921875\n",
      "Epoch:  462  Average loss at step  1491 :  2504.414101836613\n",
      "462 1 11.327434301376343\n",
      "Epoch:  462  Average loss at step  1000 :  3515.2558198242186\n",
      "Epoch:  462  Average loss at step  2000 :  3476.0319779052734\n",
      "Epoch:  462  Average loss at step  2533 :  3489.9842001471143\n",
      "462 2 19.81103777885437\n",
      "Epoch:  462  Average loss at step  1000 :  65.38044426727295\n",
      "Epoch:  462  Average loss at step  1227 :  65.27256556054137\n",
      "462 3 12.582255363464355\n",
      "Epoch:  462  Average loss at step  1000 :  6.4115076894760135\n",
      "Epoch:  462  Average loss at step  2000 :  6.503188934803009\n",
      "Epoch:  462  Average loss at step  3000 :  6.245148228168487\n",
      "Epoch:  462  Average loss at step  3222 :  6.319725349892518\n",
      "462 4 33.14895558357239\n",
      "462 5 1.430511474609375e-06\n",
      "Training time took 96.522551 seconds to run 1 epoch\n",
      "Epoch:  463  Average loss at step  1000 :  0.06809691381454468\n",
      "Epoch:  463  Average loss at step  2000 :  0.0712210413813591\n",
      "Epoch:  463  Average loss at step  3000 :  0.07704047292470932\n",
      "Epoch:  463  Average loss at step  3222 :  0.08119807053524829\n",
      "463 0 29.391626596450806\n",
      "Training time took 29.511117 seconds to run 1 epoch\n",
      "Epoch:  464  Average loss at step  1000 :  8.333466436386109\n",
      "Epoch:  464  Average loss at step  2000 :  7.732869080543518\n",
      "Epoch:  464  Average loss at step  3000 :  8.08818993473053\n",
      "Epoch:  464  Average loss at step  4000 :  8.261046352386474\n",
      "Epoch:  464  Average loss at step  5000 :  8.232823727607727\n",
      "Epoch:  464  Average loss at step  6000 :  8.128726068496704\n",
      "Epoch:  464  Average loss at step  7000 :  7.939658854484558\n",
      "Epoch:  464  Average loss at step  8000 :  8.561874279975891\n",
      "Epoch:  464  Average loss at step  8472 :  8.743050150937862\n",
      "464 0 20.991008043289185\n",
      "Epoch:  464  Average loss at step  1000 :  2505.2070802001954\n",
      "Epoch:  464  Average loss at step  1491 :  2505.4435492052394\n",
      "464 1 11.735195636749268\n",
      "Epoch:  464  Average loss at step  1000 :  3500.1432745361326\n",
      "Epoch:  464  Average loss at step  2000 :  3509.9134127197267\n",
      "Epoch:  464  Average loss at step  2533 :  3555.4194313545177\n",
      "464 2 19.845961332321167\n",
      "Epoch:  464  Average loss at step  1000 :  65.27724596023559\n",
      "Epoch:  464  Average loss at step  1227 :  65.62737114729141\n",
      "464 3 12.55579137802124\n",
      "Epoch:  464  Average loss at step  1000 :  6.439751740455628\n",
      "Epoch:  464  Average loss at step  2000 :  6.440723823070526\n",
      "Epoch:  464  Average loss at step  3000 :  6.387172545909881\n",
      "Epoch:  464  Average loss at step  3222 :  6.090056803665946\n",
      "464 4 31.08681344985962\n",
      "464 5 1.6689300537109375e-06\n",
      "Training time took 96.852761 seconds to run 1 epoch\n",
      "Epoch:  465  Average loss at step  1000 :  0.06734273332357407\n",
      "Epoch:  465  Average loss at step  2000 :  0.07102729094028473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  465  Average loss at step  3000 :  0.07674795025587082\n",
      "Epoch:  465  Average loss at step  3222 :  0.08080770181047074\n",
      "465 0 29.399807929992676\n",
      "Training time took 29.52372 seconds to run 1 epoch\n",
      "Epoch:  466  Average loss at step  1000 :  8.437050181388855\n",
      "Epoch:  466  Average loss at step  2000 :  8.17742711353302\n",
      "Epoch:  466  Average loss at step  3000 :  8.075925140380859\n",
      "Epoch:  466  Average loss at step  4000 :  7.703350289344788\n",
      "Epoch:  466  Average loss at step  5000 :  8.410791052818299\n",
      "Epoch:  466  Average loss at step  6000 :  7.852992979049683\n",
      "Epoch:  466  Average loss at step  7000 :  7.981120432853698\n",
      "Epoch:  466  Average loss at step  8000 :  8.37964223098755\n",
      "Epoch:  466  Average loss at step  8472 :  7.329968194656757\n",
      "466 0 21.231544256210327\n",
      "Epoch:  466  Average loss at step  1000 :  2500.200845336914\n",
      "Epoch:  466  Average loss at step  1491 :  2534.0216985332686\n",
      "466 1 11.670742988586426\n",
      "Epoch:  466  Average loss at step  1000 :  3518.950885986328\n",
      "Epoch:  466  Average loss at step  2000 :  3540.2901939697267\n",
      "Epoch:  466  Average loss at step  2533 :  3506.227856372813\n",
      "466 2 19.96657395362854\n",
      "Epoch:  466  Average loss at step  1000 :  64.7337438545227\n",
      "Epoch:  466  Average loss at step  1227 :  65.73086060071152\n",
      "466 3 12.638688325881958\n",
      "Epoch:  466  Average loss at step  1000 :  6.481535416603088\n",
      "Epoch:  466  Average loss at step  2000 :  6.29068369102478\n",
      "Epoch:  466  Average loss at step  3000 :  6.517828358650208\n",
      "Epoch:  466  Average loss at step  3222 :  6.435650461179337\n",
      "466 4 33.23096227645874\n",
      "466 5 1.430511474609375e-06\n",
      "Training time took 99.379363 seconds to run 1 epoch\n",
      "Epoch:  467  Average loss at step  1000 :  0.06729156672954559\n",
      "Epoch:  467  Average loss at step  2000 :  0.07085437470674515\n",
      "Epoch:  467  Average loss at step  3000 :  0.07707698291540147\n",
      "Epoch:  467  Average loss at step  3222 :  0.08039142325114292\n",
      "467 0 29.37064003944397\n",
      "Training time took 29.492472 seconds to run 1 epoch\n",
      "Epoch:  468  Average loss at step  1000 :  8.07480244064331\n",
      "Epoch:  468  Average loss at step  2000 :  7.658363637924194\n",
      "Epoch:  468  Average loss at step  3000 :  8.537763388633728\n",
      "Epoch:  468  Average loss at step  4000 :  8.288798250198365\n",
      "Epoch:  468  Average loss at step  5000 :  8.29871496295929\n",
      "Epoch:  468  Average loss at step  6000 :  7.991278913497925\n",
      "Epoch:  468  Average loss at step  7000 :  8.249274597167968\n",
      "Epoch:  468  Average loss at step  8000 :  7.784338979244232\n",
      "Epoch:  468  Average loss at step  8472 :  7.265393575410335\n",
      "468 0 20.078524112701416\n",
      "Epoch:  468  Average loss at step  1000 :  2512.151292358398\n",
      "Epoch:  468  Average loss at step  1491 :  2439.0247219324165\n",
      "468 1 11.724633693695068\n",
      "Epoch:  468  Average loss at step  1000 :  3510.980221801758\n",
      "Epoch:  468  Average loss at step  2000 :  3485.26716015625\n",
      "Epoch:  468  Average loss at step  2533 :  3528.7756923983407\n",
      "468 2 19.939773321151733\n",
      "Epoch:  468  Average loss at step  1000 :  65.24299296951294\n",
      "Epoch:  468  Average loss at step  1227 :  65.05935964467808\n",
      "468 3 12.698846101760864\n",
      "Epoch:  468  Average loss at step  1000 :  6.321825541496277\n",
      "Epoch:  468  Average loss at step  2000 :  6.160445054531097\n",
      "Epoch:  468  Average loss at step  3000 :  6.23653611087799\n",
      "Epoch:  468  Average loss at step  3222 :  6.4327237902619085\n",
      "468 4 33.25916862487793\n",
      "468 5 1.430511474609375e-06\n",
      "Training time took 98.347319 seconds to run 1 epoch\n",
      "Epoch:  469  Average loss at step  1000 :  0.0667156721353531\n",
      "Epoch:  469  Average loss at step  2000 :  0.07032222610712051\n",
      "Epoch:  469  Average loss at step  3000 :  0.07652051693201065\n",
      "Epoch:  469  Average loss at step  3222 :  0.08066344571083456\n",
      "469 0 29.46902894973755\n",
      "Training time took 29.591182 seconds to run 1 epoch\n",
      "Epoch:  470  Average loss at step  1000 :  8.093132061004638\n",
      "Epoch:  470  Average loss at step  2000 :  7.79275368976593\n",
      "Epoch:  470  Average loss at step  3000 :  8.42099815750122\n",
      "Epoch:  470  Average loss at step  4000 :  7.86798986530304\n",
      "Epoch:  470  Average loss at step  5000 :  7.9931157817840575\n",
      "Epoch:  470  Average loss at step  6000 :  8.484427649497986\n",
      "Epoch:  470  Average loss at step  7000 :  8.616773094177246\n",
      "Epoch:  470  Average loss at step  8000 :  8.30228155708313\n",
      "Epoch:  470  Average loss at step  8472 :  7.989653075350033\n",
      "470 0 20.550806522369385\n",
      "Epoch:  470  Average loss at step  1000 :  2498.0610013427736\n",
      "Epoch:  470  Average loss at step  1491 :  2486.749825426996\n",
      "470 1 11.759381532669067\n",
      "Epoch:  470  Average loss at step  1000 :  3535.4371737060546\n",
      "Epoch:  470  Average loss at step  2000 :  3516.0336398925783\n",
      "Epoch:  470  Average loss at step  2533 :  3479.087200895385\n",
      "470 2 19.91428542137146\n",
      "Epoch:  470  Average loss at step  1000 :  65.25669755554199\n",
      "Epoch:  470  Average loss at step  1227 :  65.70738786823692\n",
      "470 3 12.642818212509155\n",
      "Epoch:  470  Average loss at step  1000 :  6.274596275806427\n",
      "Epoch:  470  Average loss at step  2000 :  6.307518572807312\n",
      "Epoch:  470  Average loss at step  3000 :  6.199121375083923\n",
      "Epoch:  470  Average loss at step  3222 :  6.224405797816158\n",
      "470 4 33.098275661468506\n",
      "470 5 1.430511474609375e-06\n",
      "Training time took 98.601331 seconds to run 1 epoch\n",
      "Mean Rank:  160.44916  of  75000\n",
      "Hits @ 10:  0.854\n",
      "Hits @ 1:  0.61604\n",
      "Testing time took 163.911553 seconds.\n",
      "\n",
      "Epoch:  471  Average loss at step  1000 :  0.06716149097681046\n",
      "Epoch:  471  Average loss at step  2000 :  0.06999966883659363\n",
      "Epoch:  471  Average loss at step  3000 :  0.07598174524307251\n",
      "Epoch:  471  Average loss at step  3222 :  0.07982022534382646\n",
      "471 0 29.413846015930176\n",
      "Training time took 29.522675 seconds to run 1 epoch\n",
      "Epoch:  472  Average loss at step  1000 :  8.059226970672608\n",
      "Epoch:  472  Average loss at step  2000 :  8.13913143825531\n",
      "Epoch:  472  Average loss at step  3000 :  8.344615695953369\n",
      "Epoch:  472  Average loss at step  4000 :  8.69114608001709\n",
      "Epoch:  472  Average loss at step  5000 :  8.41117998123169\n",
      "Epoch:  472  Average loss at step  6000 :  8.214273847579957\n",
      "Epoch:  472  Average loss at step  7000 :  8.218904624938965\n",
      "Epoch:  472  Average loss at step  8000 :  8.24160653591156\n",
      "Epoch:  472  Average loss at step  8472 :  7.934209985839486\n",
      "472 0 20.540462017059326\n",
      "Epoch:  472  Average loss at step  1000 :  2523.5549084472655\n",
      "Epoch:  472  Average loss at step  1491 :  2527.1064174436783\n",
      "472 1 11.725325584411621\n",
      "Epoch:  472  Average loss at step  1000 :  3498.9098619384768\n",
      "Epoch:  472  Average loss at step  2000 :  3545.488543334961\n",
      "Epoch:  472  Average loss at step  2533 :  3560.9466427695247\n",
      "472 2 19.889994621276855\n",
      "Epoch:  472  Average loss at step  1000 :  65.30891844940186\n",
      "Epoch:  472  Average loss at step  1227 :  65.4581639870509\n",
      "472 3 12.676094055175781\n",
      "Epoch:  472  Average loss at step  1000 :  6.282067598342896\n",
      "Epoch:  472  Average loss at step  2000 :  6.160661214828491\n",
      "Epoch:  472  Average loss at step  3000 :  6.233329843521118\n",
      "Epoch:  472  Average loss at step  3222 :  6.0515149424364045\n",
      "472 4 33.31678485870361\n",
      "472 5 1.6689300537109375e-06\n",
      "Training time took 98.792719 seconds to run 1 epoch\n",
      "Epoch:  473  Average loss at step  1000 :  0.06652604633569717\n",
      "Epoch:  473  Average loss at step  2000 :  0.070057799577713\n",
      "Epoch:  473  Average loss at step  3000 :  0.07613286739587784\n",
      "Epoch:  473  Average loss at step  3222 :  0.07913208950467651\n",
      "473 0 29.379645109176636\n",
      "Training time took 29.500347 seconds to run 1 epoch\n",
      "Epoch:  474  Average loss at step  1000 :  8.048542715072632\n",
      "Epoch:  474  Average loss at step  2000 :  8.083839777946473\n",
      "Epoch:  474  Average loss at step  3000 :  8.16143151473999\n",
      "Epoch:  474  Average loss at step  4000 :  8.257823312759399\n",
      "Epoch:  474  Average loss at step  5000 :  8.513150563240051\n",
      "Epoch:  474  Average loss at step  6000 :  8.026694729804992\n",
      "Epoch:  474  Average loss at step  7000 :  7.71976628112793\n",
      "Epoch:  474  Average loss at step  8000 :  7.813010548591614\n",
      "Epoch:  474  Average loss at step  8472 :  7.922134858421182\n",
      "474 0 21.917290687561035\n",
      "Epoch:  474  Average loss at step  1000 :  2537.796574707031\n",
      "Epoch:  474  Average loss at step  1491 :  2476.1544721541736\n",
      "474 1 11.70656967163086\n",
      "Epoch:  474  Average loss at step  1000 :  3564.204308105469\n",
      "Epoch:  474  Average loss at step  2000 :  3517.695280883789\n",
      "Epoch:  474  Average loss at step  2533 :  3558.5821546280617\n",
      "474 2 19.894043445587158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  474  Average loss at step  1000 :  65.12403984832764\n",
      "Epoch:  474  Average loss at step  1227 :  64.33769504094244\n",
      "474 3 12.59095573425293\n",
      "Epoch:  474  Average loss at step  1000 :  6.142950596809388\n",
      "Epoch:  474  Average loss at step  2000 :  6.109460739135742\n",
      "Epoch:  474  Average loss at step  3000 :  6.237309940338135\n",
      "Epoch:  474  Average loss at step  3222 :  6.089851926823217\n",
      "474 4 33.20026159286499\n",
      "474 5 1.1920928955078125e-06\n",
      "Training time took 99.942182 seconds to run 1 epoch\n",
      "Epoch:  475  Average loss at step  1000 :  0.06600367528200149\n",
      "Epoch:  475  Average loss at step  2000 :  0.06959653210639953\n",
      "Epoch:  475  Average loss at step  3000 :  0.0760126286149025\n",
      "Epoch:  475  Average loss at step  3222 :  0.07976603719985405\n",
      "475 0 29.427257776260376\n",
      "Training time took 29.553893 seconds to run 1 epoch\n",
      "Epoch:  476  Average loss at step  1000 :  8.49830022239685\n",
      "Epoch:  476  Average loss at step  2000 :  7.975096531391144\n",
      "Epoch:  476  Average loss at step  3000 :  8.2667073097229\n",
      "Epoch:  476  Average loss at step  4000 :  8.180198722839355\n",
      "Epoch:  476  Average loss at step  5000 :  7.975174640655518\n",
      "Epoch:  476  Average loss at step  6000 :  7.54414900970459\n",
      "Epoch:  476  Average loss at step  7000 :  8.16724846315384\n",
      "Epoch:  476  Average loss at step  8000 :  7.85331688785553\n",
      "Epoch:  476  Average loss at step  8472 :  8.155406536855\n",
      "476 0 20.439428567886353\n",
      "Epoch:  476  Average loss at step  1000 :  2499.1366274414063\n",
      "Epoch:  476  Average loss at step  1491 :  2537.4005581860415\n",
      "476 1 11.744017839431763\n",
      "Epoch:  476  Average loss at step  1000 :  3503.2261163330077\n",
      "Epoch:  476  Average loss at step  2000 :  3534.422112426758\n",
      "Epoch:  476  Average loss at step  2533 :  3559.1268262320777\n",
      "476 2 19.990307569503784\n",
      "Epoch:  476  Average loss at step  1000 :  65.05481043243408\n",
      "Epoch:  476  Average loss at step  1227 :  64.25104506851879\n",
      "476 3 12.619863748550415\n",
      "Epoch:  476  Average loss at step  1000 :  6.212721756458283\n",
      "Epoch:  476  Average loss at step  2000 :  6.183884841918945\n",
      "Epoch:  476  Average loss at step  3000 :  6.079848413467407\n",
      "Epoch:  476  Average loss at step  3222 :  6.18892497675452\n",
      "476 4 33.12088108062744\n",
      "476 5 1.6689300537109375e-06\n",
      "Training time took 98.572769 seconds to run 1 epoch\n",
      "Epoch:  477  Average loss at step  1000 :  0.06595695298910141\n",
      "Epoch:  477  Average loss at step  2000 :  0.06908787596225739\n",
      "Epoch:  477  Average loss at step  3000 :  0.07551032012701034\n",
      "Epoch:  477  Average loss at step  3222 :  0.07986950597773392\n",
      "477 0 29.449414253234863\n",
      "Training time took 29.569205 seconds to run 1 epoch\n",
      "Epoch:  478  Average loss at step  1000 :  7.997526433944702\n",
      "Epoch:  478  Average loss at step  2000 :  7.810743445396423\n",
      "Epoch:  478  Average loss at step  3000 :  8.59662881565094\n",
      "Epoch:  478  Average loss at step  4000 :  7.954532504081726\n",
      "Epoch:  478  Average loss at step  5000 :  7.985375663757324\n",
      "Epoch:  478  Average loss at step  6000 :  7.936050110816955\n",
      "Epoch:  478  Average loss at step  7000 :  7.866818971633911\n",
      "Epoch:  478  Average loss at step  8000 :  8.174626073837281\n",
      "Epoch:  478  Average loss at step  8472 :  8.095334334232007\n",
      "478 0 20.57940149307251\n",
      "Epoch:  478  Average loss at step  1000 :  2535.8617534790037\n",
      "Epoch:  478  Average loss at step  1491 :  2506.280768342817\n",
      "478 1 11.706209897994995\n",
      "Epoch:  478  Average loss at step  1000 :  3553.0398671875\n",
      "Epoch:  478  Average loss at step  2000 :  3530.0125895996093\n",
      "Epoch:  478  Average loss at step  2533 :  3544.3503803226936\n",
      "478 2 19.928886890411377\n",
      "Epoch:  478  Average loss at step  1000 :  65.21867382049561\n",
      "Epoch:  478  Average loss at step  1227 :  64.45085020044692\n",
      "478 3 12.592444658279419\n",
      "Epoch:  478  Average loss at step  1000 :  6.2213543276786805\n",
      "Epoch:  478  Average loss at step  2000 :  6.281630107879638\n",
      "Epoch:  478  Average loss at step  3000 :  6.027296191215515\n",
      "Epoch:  478  Average loss at step  3222 :  5.970028465158738\n",
      "478 4 33.06800937652588\n",
      "478 5 1.430511474609375e-06\n",
      "Training time took 98.511794 seconds to run 1 epoch\n",
      "Epoch:  479  Average loss at step  1000 :  0.06591840052604675\n",
      "Epoch:  479  Average loss at step  2000 :  0.06931451761722565\n",
      "Epoch:  479  Average loss at step  3000 :  0.07527474689483643\n",
      "Epoch:  479  Average loss at step  3222 :  0.07826612892725941\n",
      "479 0 29.411515474319458\n",
      "Training time took 29.5321 seconds to run 1 epoch\n",
      "Epoch:  480  Average loss at step  1000 :  8.347510226249694\n",
      "Epoch:  480  Average loss at step  2000 :  8.366854006767273\n",
      "Epoch:  480  Average loss at step  3000 :  7.783586793899536\n",
      "Epoch:  480  Average loss at step  4000 :  8.047446698188782\n",
      "Epoch:  480  Average loss at step  5000 :  7.983930662155151\n",
      "Epoch:  480  Average loss at step  6000 :  8.083714047431945\n",
      "Epoch:  480  Average loss at step  7000 :  8.220963150024414\n",
      "Epoch:  480  Average loss at step  8000 :  8.274987513542175\n",
      "Epoch:  480  Average loss at step  8472 :  7.424741649226965\n",
      "480 0 20.4964542388916\n",
      "Epoch:  480  Average loss at step  1000 :  2514.496872924805\n",
      "Epoch:  480  Average loss at step  1491 :  2560.294121596224\n",
      "480 1 11.753164291381836\n",
      "Epoch:  480  Average loss at step  1000 :  3545.6165751953126\n",
      "Epoch:  480  Average loss at step  2000 :  3528.632368774414\n",
      "Epoch:  480  Average loss at step  2533 :  3551.3067233940224\n",
      "480 2 19.909684658050537\n",
      "Epoch:  480  Average loss at step  1000 :  64.59977367019653\n",
      "Epoch:  480  Average loss at step  1227 :  65.34083575035281\n",
      "480 3 12.599923849105835\n",
      "Epoch:  480  Average loss at step  1000 :  6.123848262310028\n",
      "Epoch:  480  Average loss at step  2000 :  6.073918168544769\n",
      "Epoch:  480  Average loss at step  3000 :  6.069238532066345\n",
      "Epoch:  480  Average loss at step  3222 :  6.064897654051814\n",
      "480 4 33.204691648483276\n",
      "480 5 1.6689300537109375e-06\n",
      "Training time took 98.594168 seconds to run 1 epoch\n",
      "Mean Rank:  161.92204  of  75000\n",
      "Hits @ 10:  0.85424\n",
      "Hits @ 1:  0.6156\n",
      "Testing time took 163.523519 seconds.\n",
      "\n",
      "Epoch:  481  Average loss at step  1000 :  0.06508532679080963\n",
      "Epoch:  481  Average loss at step  2000 :  0.06919220232963562\n",
      "Epoch:  481  Average loss at step  3000 :  0.0749229507446289\n",
      "Epoch:  481  Average loss at step  3222 :  0.07832854593417816\n",
      "481 0 29.39246129989624\n",
      "Training time took 29.5045 seconds to run 1 epoch\n",
      "Epoch:  482  Average loss at step  1000 :  8.022308743476868\n",
      "Epoch:  482  Average loss at step  2000 :  8.427142745971679\n",
      "Epoch:  482  Average loss at step  3000 :  8.153807527542114\n",
      "Epoch:  482  Average loss at step  4000 :  8.159291729927062\n",
      "Epoch:  482  Average loss at step  5000 :  8.192084362030029\n",
      "Epoch:  482  Average loss at step  6000 :  8.06952444410324\n",
      "Epoch:  482  Average loss at step  7000 :  8.140098518371582\n",
      "Epoch:  482  Average loss at step  8000 :  8.057551562309266\n",
      "Epoch:  482  Average loss at step  8472 :  8.978022271640373\n",
      "482 0 21.232247352600098\n",
      "Epoch:  482  Average loss at step  1000 :  2549.2016361083984\n",
      "Epoch:  482  Average loss at step  1491 :  2563.2507226001544\n",
      "482 1 11.74055528640747\n",
      "Epoch:  482  Average loss at step  1000 :  3552.4272396240235\n",
      "Epoch:  482  Average loss at step  2000 :  3560.349521484375\n",
      "Epoch:  482  Average loss at step  2533 :  3540.935593761233\n",
      "482 2 19.929225206375122\n",
      "Epoch:  482  Average loss at step  1000 :  65.38039739990235\n",
      "Epoch:  482  Average loss at step  1227 :  64.4333222496466\n",
      "482 3 12.666372299194336\n",
      "Epoch:  482  Average loss at step  1000 :  6.206618777751922\n",
      "Epoch:  482  Average loss at step  2000 :  6.005671929836273\n",
      "Epoch:  482  Average loss at step  3000 :  6.0306494822502135\n",
      "Epoch:  482  Average loss at step  3222 :  6.083553955214487\n",
      "482 4 33.19897747039795\n",
      "482 5 1.9073486328125e-06\n",
      "Training time took 99.409591 seconds to run 1 epoch\n",
      "Epoch:  483  Average loss at step  1000 :  0.06605136787891389\n",
      "Epoch:  483  Average loss at step  2000 :  0.06841555458307266\n",
      "Epoch:  483  Average loss at step  3000 :  0.07485478788614273\n",
      "Epoch:  483  Average loss at step  3222 :  0.07888194100265793\n",
      "483 0 29.448164224624634\n",
      "Training time took 29.56831 seconds to run 1 epoch\n",
      "Epoch:  484  Average loss at step  1000 :  8.46381982421875\n",
      "Epoch:  484  Average loss at step  2000 :  8.580736131668091\n",
      "Epoch:  484  Average loss at step  3000 :  8.176885255336762\n",
      "Epoch:  484  Average loss at step  4000 :  8.184094769477845\n",
      "Epoch:  484  Average loss at step  5000 :  7.929453145027161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  484  Average loss at step  6000 :  8.232510622024536\n",
      "Epoch:  484  Average loss at step  7000 :  7.689370141029358\n",
      "Epoch:  484  Average loss at step  8000 :  7.955717191696167\n",
      "Epoch:  484  Average loss at step  8472 :  7.623790287059756\n",
      "484 0 21.26288366317749\n",
      "Epoch:  484  Average loss at step  1000 :  2527.2150775146483\n",
      "Epoch:  484  Average loss at step  1491 :  2507.190530709492\n",
      "484 1 11.763202905654907\n",
      "Epoch:  484  Average loss at step  1000 :  3544.473172241211\n",
      "Epoch:  484  Average loss at step  2000 :  3567.1899962158204\n",
      "Epoch:  484  Average loss at step  2533 :  3539.18169188875\n",
      "484 2 19.90061926841736\n",
      "Epoch:  484  Average loss at step  1000 :  65.08842156600952\n",
      "Epoch:  484  Average loss at step  1227 :  64.2025327453196\n",
      "484 3 12.603358507156372\n",
      "Epoch:  484  Average loss at step  1000 :  6.141055449485779\n",
      "Epoch:  484  Average loss at step  2000 :  6.175234495162964\n",
      "Epoch:  484  Average loss at step  3000 :  6.027556429386139\n",
      "Epoch:  484  Average loss at step  3222 :  6.0839880737377685\n",
      "484 4 33.15456795692444\n",
      "484 5 1.430511474609375e-06\n",
      "Training time took 99.31603 seconds to run 1 epoch\n",
      "Epoch:  485  Average loss at step  1000 :  0.06471740287542344\n",
      "Epoch:  485  Average loss at step  2000 :  0.06860980081558228\n",
      "Epoch:  485  Average loss at step  3000 :  0.07404225039482117\n",
      "Epoch:  485  Average loss at step  3222 :  0.07779504965952445\n",
      "485 0 29.37657332420349\n",
      "Training time took 29.500093 seconds to run 1 epoch\n",
      "Epoch:  486  Average loss at step  1000 :  8.16184595632553\n",
      "Epoch:  486  Average loss at step  2000 :  7.755726661682129\n",
      "Epoch:  486  Average loss at step  3000 :  8.168879902839661\n",
      "Epoch:  486  Average loss at step  4000 :  8.738783302307128\n",
      "Epoch:  486  Average loss at step  5000 :  7.678867676734924\n",
      "Epoch:  486  Average loss at step  6000 :  7.98837371635437\n",
      "Epoch:  486  Average loss at step  7000 :  8.27043103313446\n",
      "Epoch:  486  Average loss at step  8000 :  7.606536039352417\n",
      "Epoch:  486  Average loss at step  8472 :  7.737804882939565\n",
      "486 0 20.521482706069946\n",
      "Epoch:  486  Average loss at step  1000 :  2546.151197998047\n",
      "Epoch:  486  Average loss at step  1491 :  2533.6154134834014\n",
      "486 1 11.708998680114746\n",
      "Epoch:  486  Average loss at step  1000 :  3566.995214111328\n",
      "Epoch:  486  Average loss at step  2000 :  3530.758006591797\n",
      "Epoch:  486  Average loss at step  2533 :  3524.2441529040725\n",
      "486 2 19.92536187171936\n",
      "Epoch:  486  Average loss at step  1000 :  65.05536371994019\n",
      "Epoch:  486  Average loss at step  1227 :  65.31647197379903\n",
      "486 3 12.580329895019531\n",
      "Epoch:  486  Average loss at step  1000 :  5.927276961803436\n",
      "Epoch:  486  Average loss at step  2000 :  5.934855853557587\n",
      "Epoch:  486  Average loss at step  3000 :  6.064142282009125\n",
      "Epoch:  486  Average loss at step  3222 :  5.718678699802633\n",
      "486 4 33.152015209198\n",
      "486 5 4.76837158203125e-07\n",
      "Training time took 98.515377 seconds to run 1 epoch\n",
      "Epoch:  487  Average loss at step  1000 :  0.06517310225963592\n",
      "Epoch:  487  Average loss at step  2000 :  0.06813715571165085\n",
      "Epoch:  487  Average loss at step  3000 :  0.07478638571500779\n",
      "Epoch:  487  Average loss at step  3222 :  0.07820945286238574\n",
      "487 0 29.445619344711304\n",
      "Training time took 29.564848 seconds to run 1 epoch\n",
      "Epoch:  488  Average loss at step  1000 :  7.834569696903229\n",
      "Epoch:  488  Average loss at step  2000 :  8.266027030944825\n",
      "Epoch:  488  Average loss at step  3000 :  8.039756093025208\n",
      "Epoch:  488  Average loss at step  4000 :  8.115675505638123\n",
      "Epoch:  488  Average loss at step  5000 :  8.21092271757126\n",
      "Epoch:  488  Average loss at step  6000 :  7.613447067260743\n",
      "Epoch:  488  Average loss at step  7000 :  8.284938382148743\n",
      "Epoch:  488  Average loss at step  8000 :  8.280740950584411\n",
      "Epoch:  488  Average loss at step  8472 :  9.269212479350735\n",
      "488 0 20.996238946914673\n",
      "Epoch:  488  Average loss at step  1000 :  2547.181069213867\n",
      "Epoch:  488  Average loss at step  1491 :  2538.3139277350515\n",
      "488 1 11.707514762878418\n",
      "Epoch:  488  Average loss at step  1000 :  3532.8594514160154\n",
      "Epoch:  488  Average loss at step  2000 :  3571.800240966797\n",
      "Epoch:  488  Average loss at step  2533 :  3559.227872533834\n",
      "488 2 19.918565273284912\n",
      "Epoch:  488  Average loss at step  1000 :  64.97171524810791\n",
      "Epoch:  488  Average loss at step  1227 :  65.91449524994779\n",
      "488 3 12.635254383087158\n",
      "Epoch:  488  Average loss at step  1000 :  6.073448546409607\n",
      "Epoch:  488  Average loss at step  2000 :  6.040469807624817\n",
      "Epoch:  488  Average loss at step  3000 :  5.964599466800689\n",
      "Epoch:  488  Average loss at step  3222 :  5.7046569454732365\n",
      "488 4 33.197351694107056\n",
      "488 5 1.430511474609375e-06\n",
      "Training time took 99.080631 seconds to run 1 epoch\n",
      "Epoch:  489  Average loss at step  1000 :  0.0647205190062523\n",
      "Epoch:  489  Average loss at step  2000 :  0.06738198256492614\n",
      "Epoch:  489  Average loss at step  3000 :  0.07394645124673843\n",
      "Epoch:  489  Average loss at step  3222 :  0.0769502789153371\n",
      "489 0 29.4060640335083\n",
      "Training time took 29.527136 seconds to run 1 epoch\n",
      "Epoch:  490  Average loss at step  1000 :  7.915181858062744\n",
      "Epoch:  490  Average loss at step  2000 :  8.218778467178344\n",
      "Epoch:  490  Average loss at step  3000 :  8.263658768653869\n",
      "Epoch:  490  Average loss at step  4000 :  8.231295647621154\n",
      "Epoch:  490  Average loss at step  5000 :  8.363368155479431\n",
      "Epoch:  490  Average loss at step  6000 :  8.054717907905578\n",
      "Epoch:  490  Average loss at step  7000 :  7.872085527420044\n",
      "Epoch:  490  Average loss at step  8000 :  8.378824744701385\n",
      "Epoch:  490  Average loss at step  8472 :  8.213643083385788\n",
      "490 0 21.077855348587036\n",
      "Epoch:  490  Average loss at step  1000 :  2534.3205631103515\n",
      "Epoch:  490  Average loss at step  1491 :  2567.065155922576\n",
      "490 1 11.713104724884033\n",
      "Epoch:  490  Average loss at step  1000 :  3555.715967163086\n",
      "Epoch:  490  Average loss at step  2000 :  3560.3112567138674\n",
      "Epoch:  490  Average loss at step  2533 :  3549.1629752055987\n",
      "490 2 19.909553289413452\n",
      "Epoch:  490  Average loss at step  1000 :  65.52958168792725\n",
      "Epoch:  490  Average loss at step  1227 :  64.1755350656249\n",
      "490 3 12.633607387542725\n",
      "Epoch:  490  Average loss at step  1000 :  6.0338010687828065\n",
      "Epoch:  490  Average loss at step  2000 :  5.939824422359466\n",
      "Epoch:  490  Average loss at step  3000 :  6.075553713798523\n",
      "Epoch:  490  Average loss at step  3222 :  6.050142729232879\n",
      "490 4 33.27432584762573\n",
      "490 5 1.1920928955078125e-06\n",
      "Training time took 99.238898 seconds to run 1 epoch\n",
      "Mean Rank:  158.92932  of  75000\n",
      "Hits @ 10:  0.85464\n",
      "Hits @ 1:  0.61776\n",
      "Testing time took 163.240986 seconds.\n",
      "\n",
      "Epoch:  491  Average loss at step  1000 :  0.06438901263475418\n",
      "Epoch:  491  Average loss at step  2000 :  0.06785038322210311\n",
      "Epoch:  491  Average loss at step  3000 :  0.07384134781360627\n",
      "Epoch:  491  Average loss at step  3222 :  0.0771669677328732\n",
      "491 0 29.423563480377197\n",
      "Training time took 29.532858 seconds to run 1 epoch\n",
      "Epoch:  492  Average loss at step  1000 :  8.776858665466309\n",
      "Epoch:  492  Average loss at step  2000 :  7.786572694778442\n",
      "Epoch:  492  Average loss at step  3000 :  8.53707359600067\n",
      "Epoch:  492  Average loss at step  4000 :  8.669967289924621\n",
      "Epoch:  492  Average loss at step  5000 :  8.02195588684082\n",
      "Epoch:  492  Average loss at step  6000 :  7.357536308288574\n",
      "Epoch:  492  Average loss at step  7000 :  8.153387428283692\n",
      "Epoch:  492  Average loss at step  8000 :  7.910491656303406\n",
      "Epoch:  492  Average loss at step  8472 :  7.816192985496781\n",
      "492 0 20.78234577178955\n",
      "Epoch:  492  Average loss at step  1000 :  2552.765919067383\n",
      "Epoch:  492  Average loss at step  1491 :  2545.0085383823493\n",
      "492 1 11.703407526016235\n",
      "Epoch:  492  Average loss at step  1000 :  3560.515847167969\n",
      "Epoch:  492  Average loss at step  2000 :  3560.3691486816406\n",
      "Epoch:  492  Average loss at step  2533 :  3574.5564749584755\n",
      "492 2 19.959486484527588\n",
      "Epoch:  492  Average loss at step  1000 :  64.55282991027832\n",
      "Epoch:  492  Average loss at step  1227 :  64.39254219848509\n",
      "492 3 12.69341230392456\n",
      "Epoch:  492  Average loss at step  1000 :  6.046156756401062\n",
      "Epoch:  492  Average loss at step  2000 :  5.817908166885376\n",
      "Epoch:  492  Average loss at step  3000 :  5.943996668338776\n",
      "Epoch:  492  Average loss at step  3222 :  6.260040284580521\n",
      "492 4 33.15131330490112\n",
      "492 5 1.430511474609375e-06\n",
      "Training time took 98.93584 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  493  Average loss at step  1000 :  0.06480298036336898\n",
      "Epoch:  493  Average loss at step  2000 :  0.06739213669300079\n",
      "Epoch:  493  Average loss at step  3000 :  0.07307221251726151\n",
      "Epoch:  493  Average loss at step  3222 :  0.07760378670490138\n",
      "493 0 29.470204830169678\n",
      "Training time took 29.596608 seconds to run 1 epoch\n",
      "Epoch:  494  Average loss at step  1000 :  7.7906607179641725\n",
      "Epoch:  494  Average loss at step  2000 :  7.9965805311203\n",
      "Epoch:  494  Average loss at step  3000 :  8.062209922790528\n",
      "Epoch:  494  Average loss at step  4000 :  7.826884462356567\n",
      "Epoch:  494  Average loss at step  5000 :  8.022441667556762\n",
      "Epoch:  494  Average loss at step  6000 :  8.063650925636292\n",
      "Epoch:  494  Average loss at step  7000 :  8.19586420917511\n",
      "Epoch:  494  Average loss at step  8000 :  8.369442660331726\n",
      "Epoch:  494  Average loss at step  8472 :  8.372803178810464\n",
      "494 0 20.328964948654175\n",
      "Epoch:  494  Average loss at step  1000 :  2533.394699951172\n",
      "Epoch:  494  Average loss at step  1491 :  2500.547316256343\n",
      "494 1 11.6832754611969\n",
      "Epoch:  494  Average loss at step  1000 :  3587.1324836425783\n",
      "Epoch:  494  Average loss at step  2000 :  3579.978296508789\n",
      "Epoch:  494  Average loss at step  2533 :  3567.1722892764387\n",
      "494 2 19.96133327484131\n",
      "Epoch:  494  Average loss at step  1000 :  65.12500105285645\n",
      "Epoch:  494  Average loss at step  1227 :  65.24442934509243\n",
      "494 3 12.689345121383667\n",
      "Epoch:  494  Average loss at step  1000 :  5.946649054050446\n",
      "Epoch:  494  Average loss at step  2000 :  5.72713458776474\n",
      "Epoch:  494  Average loss at step  3000 :  5.7181232333183285\n",
      "Epoch:  494  Average loss at step  3222 :  6.0950418374322775\n",
      "494 4 33.401267290115356\n",
      "494 5 1.6689300537109375e-06\n",
      "Training time took 98.700201 seconds to run 1 epoch\n",
      "Epoch:  495  Average loss at step  1000 :  0.06418667942285537\n",
      "Epoch:  495  Average loss at step  2000 :  0.06718395203351975\n",
      "Epoch:  495  Average loss at step  3000 :  0.07317096793651581\n",
      "Epoch:  495  Average loss at step  3222 :  0.07655010593133318\n",
      "495 0 29.388017416000366\n",
      "Training time took 29.506775 seconds to run 1 epoch\n",
      "Epoch:  496  Average loss at step  1000 :  8.643523281097412\n",
      "Epoch:  496  Average loss at step  2000 :  8.280898510932923\n",
      "Epoch:  496  Average loss at step  3000 :  8.10533487701416\n",
      "Epoch:  496  Average loss at step  4000 :  7.6789448451995845\n",
      "Epoch:  496  Average loss at step  5000 :  7.9343710107803345\n",
      "Epoch:  496  Average loss at step  6000 :  7.9839309282302855\n",
      "Epoch:  496  Average loss at step  7000 :  8.494577556610107\n",
      "Epoch:  496  Average loss at step  8000 :  8.400890655517578\n",
      "Epoch:  496  Average loss at step  8472 :  7.88035150912241\n",
      "496 0 20.873671054840088\n",
      "Epoch:  496  Average loss at step  1000 :  2561.8616730957033\n",
      "Epoch:  496  Average loss at step  1491 :  2552.772457665251\n",
      "496 1 11.697787284851074\n",
      "Epoch:  496  Average loss at step  1000 :  3583.655739013672\n",
      "Epoch:  496  Average loss at step  2000 :  3540.3573985595704\n",
      "Epoch:  496  Average loss at step  2533 :  3537.43109036105\n",
      "496 2 19.921946048736572\n",
      "Epoch:  496  Average loss at step  1000 :  64.61479143142701\n",
      "Epoch:  496  Average loss at step  1227 :  64.94922293780283\n",
      "496 3 12.657336950302124\n",
      "Epoch:  496  Average loss at step  1000 :  5.870569416046143\n",
      "Epoch:  496  Average loss at step  2000 :  5.771678475856781\n",
      "Epoch:  496  Average loss at step  3000 :  5.791432092189789\n",
      "Epoch:  496  Average loss at step  3222 :  5.939569531805917\n",
      "496 4 33.159501791000366\n",
      "496 5 1.430511474609375e-06\n",
      "Training time took 98.935758 seconds to run 1 epoch\n",
      "Epoch:  497  Average loss at step  1000 :  0.06399572628736495\n",
      "Epoch:  497  Average loss at step  2000 :  0.06689510989189149\n",
      "Epoch:  497  Average loss at step  3000 :  0.07288988798856735\n",
      "Epoch:  497  Average loss at step  3222 :  0.076255428003348\n",
      "497 0 29.377333164215088\n",
      "Training time took 29.496496 seconds to run 1 epoch\n",
      "Epoch:  498  Average loss at step  1000 :  7.795527535438538\n",
      "Epoch:  498  Average loss at step  2000 :  7.913586455345154\n",
      "Epoch:  498  Average loss at step  3000 :  7.805628558158874\n",
      "Epoch:  498  Average loss at step  4000 :  8.046379792690278\n",
      "Epoch:  498  Average loss at step  5000 :  8.39866603755951\n",
      "Epoch:  498  Average loss at step  6000 :  8.232109363555908\n",
      "Epoch:  498  Average loss at step  7000 :  7.998565647125244\n",
      "Epoch:  498  Average loss at step  8000 :  7.920218338012695\n",
      "Epoch:  498  Average loss at step  8472 :  8.324701875798604\n",
      "498 0 20.165422439575195\n",
      "Epoch:  498  Average loss at step  1000 :  2558.0626883544924\n",
      "Epoch:  498  Average loss at step  1491 :  2550.1591976600057\n",
      "498 1 11.726223707199097\n",
      "Epoch:  498  Average loss at step  1000 :  3560.2848623046875\n",
      "Epoch:  498  Average loss at step  2000 :  3573.7302470703125\n",
      "Epoch:  498  Average loss at step  2533 :  3624.320276956767\n",
      "498 2 19.93366026878357\n",
      "Epoch:  498  Average loss at step  1000 :  64.70640087127686\n",
      "Epoch:  498  Average loss at step  1227 :  65.48326731033181\n",
      "498 3 12.662379026412964\n",
      "Epoch:  498  Average loss at step  1000 :  5.814980426311493\n",
      "Epoch:  498  Average loss at step  2000 :  5.8264321188926695\n",
      "Epoch:  498  Average loss at step  3000 :  5.783322373867035\n",
      "Epoch:  498  Average loss at step  3222 :  5.782695650774599\n",
      "498 4 33.348326444625854\n",
      "498 5 1.430511474609375e-06\n",
      "Training time took 98.492916 seconds to run 1 epoch\n",
      "Epoch:  499  Average loss at step  1000 :  0.06377476406097413\n",
      "Epoch:  499  Average loss at step  2000 :  0.06673581939935684\n",
      "Epoch:  499  Average loss at step  3000 :  0.07251224035024643\n",
      "Epoch:  499  Average loss at step  3222 :  0.07667034477033131\n",
      "499 0 29.402596473693848\n",
      "Training time took 29.527729 seconds to run 1 epoch\n",
      "Epoch:  500  Average loss at step  1000 :  7.757708520889282\n",
      "Epoch:  500  Average loss at step  2000 :  8.062689931869507\n",
      "Epoch:  500  Average loss at step  3000 :  8.170212707519532\n",
      "Epoch:  500  Average loss at step  4000 :  8.346030910491944\n",
      "Epoch:  500  Average loss at step  5000 :  7.958608678817749\n",
      "Epoch:  500  Average loss at step  6000 :  7.820365995407104\n",
      "Epoch:  500  Average loss at step  7000 :  8.958752283096313\n",
      "Epoch:  500  Average loss at step  8000 :  8.309891765594482\n",
      "Epoch:  500  Average loss at step  8472 :  7.517549146755275\n",
      "500 0 20.32615566253662\n",
      "Epoch:  500  Average loss at step  1000 :  2590.875203979492\n",
      "Epoch:  500  Average loss at step  1491 :  2578.548696598484\n",
      "500 1 11.711420774459839\n",
      "Epoch:  500  Average loss at step  1000 :  3570.40131640625\n",
      "Epoch:  500  Average loss at step  2000 :  3591.7743638916018\n",
      "Epoch:  500  Average loss at step  2533 :  3563.906413307989\n",
      "500 2 19.913994073867798\n",
      "Epoch:  500  Average loss at step  1000 :  65.09765311813355\n",
      "Epoch:  500  Average loss at step  1227 :  63.78357792561185\n",
      "500 3 12.585095405578613\n",
      "Epoch:  500  Average loss at step  1000 :  5.765009886741638\n",
      "Epoch:  500  Average loss at step  2000 :  5.70783203125\n",
      "Epoch:  500  Average loss at step  3000 :  5.849057698249817\n",
      "Epoch:  500  Average loss at step  3222 :  5.769690924505181\n",
      "500 4 33.15653324127197\n",
      "500 5 1.1920928955078125e-06\n",
      "Training time took 98.329273 seconds to run 1 epoch\n",
      "Mean Rank:  160.43156  of  75000\n",
      "Hits @ 10:  0.8546\n",
      "Hits @ 1:  0.61772\n",
      "Testing time took 163.775605 seconds.\n",
      "\n",
      "Epoch:  501  Average loss at step  1000 :  0.06354628372192382\n",
      "Epoch:  501  Average loss at step  2000 :  0.06642419517040253\n",
      "Epoch:  501  Average loss at step  3000 :  0.07271201276779175\n",
      "Epoch:  501  Average loss at step  3222 :  0.07594582927551999\n",
      "501 0 29.362539291381836\n",
      "Training time took 29.474295 seconds to run 1 epoch\n",
      "Epoch:  502  Average loss at step  1000 :  7.70918793296814\n",
      "Epoch:  502  Average loss at step  2000 :  8.43006291103363\n",
      "Epoch:  502  Average loss at step  3000 :  8.255717950820923\n",
      "Epoch:  502  Average loss at step  4000 :  8.611282384872437\n",
      "Epoch:  502  Average loss at step  5000 :  8.099519494056702\n",
      "Epoch:  502  Average loss at step  6000 :  7.843497867584229\n",
      "Epoch:  502  Average loss at step  7000 :  8.173066851615905\n",
      "Epoch:  502  Average loss at step  8000 :  7.865206614494324\n",
      "Epoch:  502  Average loss at step  8472 :  7.3163741321303855\n",
      "502 0 20.742417335510254\n",
      "Epoch:  502  Average loss at step  1000 :  2558.673170532227\n",
      "Epoch:  502  Average loss at step  1491 :  2610.6100366209444\n",
      "502 1 11.709443092346191\n",
      "Epoch:  502  Average loss at step  1000 :  3600.6783071289065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  502  Average loss at step  2000 :  3596.7168485107422\n",
      "Epoch:  502  Average loss at step  2533 :  3574.347544435191\n",
      "502 2 19.91148042678833\n",
      "Epoch:  502  Average loss at step  1000 :  65.17953019332886\n",
      "Epoch:  502  Average loss at step  1227 :  65.75503570399118\n",
      "502 3 12.595705032348633\n",
      "Epoch:  502  Average loss at step  1000 :  5.824303299427032\n",
      "Epoch:  502  Average loss at step  2000 :  5.853138978481293\n",
      "Epoch:  502  Average loss at step  3000 :  5.808525050640106\n",
      "Epoch:  502  Average loss at step  3222 :  5.909766202197649\n",
      "502 4 33.231884717941284\n",
      "502 5 1.1920928955078125e-06\n",
      "Training time took 98.826806 seconds to run 1 epoch\n",
      "Epoch:  503  Average loss at step  1000 :  0.06344490140676498\n",
      "Epoch:  503  Average loss at step  2000 :  0.06623080223798752\n",
      "Epoch:  503  Average loss at step  3000 :  0.07212614166736603\n",
      "Epoch:  503  Average loss at step  3222 :  0.07577366046815986\n",
      "503 0 29.3933002948761\n",
      "Training time took 29.516249 seconds to run 1 epoch\n",
      "Epoch:  504  Average loss at step  1000 :  8.221514702796936\n",
      "Epoch:  504  Average loss at step  2000 :  7.7964187383651735\n",
      "Epoch:  504  Average loss at step  3000 :  7.0417196607589725\n",
      "Epoch:  504  Average loss at step  4000 :  8.839884394168854\n",
      "Epoch:  504  Average loss at step  5000 :  8.367032112121581\n",
      "Epoch:  504  Average loss at step  6000 :  7.981926769256591\n",
      "Epoch:  504  Average loss at step  7000 :  7.743827753067016\n",
      "Epoch:  504  Average loss at step  8000 :  7.787797062873841\n",
      "Epoch:  504  Average loss at step  8472 :  7.682088698359662\n",
      "504 0 20.57684087753296\n",
      "Epoch:  504  Average loss at step  1000 :  2571.177669799805\n",
      "Epoch:  504  Average loss at step  1491 :  2564.983683162967\n",
      "504 1 11.743811130523682\n",
      "Epoch:  504  Average loss at step  1000 :  3560.5833435058594\n",
      "Epoch:  504  Average loss at step  2000 :  3576.3230458984376\n",
      "Epoch:  504  Average loss at step  2533 :  3584.5620277971766\n",
      "504 2 19.905462741851807\n",
      "Epoch:  504  Average loss at step  1000 :  64.21663600158692\n",
      "Epoch:  504  Average loss at step  1227 :  64.41691253846558\n",
      "504 3 12.597299098968506\n",
      "Epoch:  504  Average loss at step  1000 :  5.795460089206696\n",
      "Epoch:  504  Average loss at step  2000 :  5.552613224029541\n",
      "Epoch:  504  Average loss at step  3000 :  5.770292256355286\n",
      "Epoch:  504  Average loss at step  3222 :  5.80506817402231\n",
      "504 4 33.28051042556763\n",
      "504 5 1.1920928955078125e-06\n",
      "Training time took 98.739632 seconds to run 1 epoch\n",
      "Epoch:  505  Average loss at step  1000 :  0.06276764404773712\n",
      "Epoch:  505  Average loss at step  2000 :  0.06585605436563492\n",
      "Epoch:  505  Average loss at step  3000 :  0.07226126742362976\n",
      "Epoch:  505  Average loss at step  3222 :  0.07656329099743305\n",
      "505 0 29.407090663909912\n",
      "Training time took 29.53184 seconds to run 1 epoch\n",
      "Epoch:  506  Average loss at step  1000 :  8.03518042755127\n",
      "Epoch:  506  Average loss at step  2000 :  7.723701186180115\n",
      "Epoch:  506  Average loss at step  3000 :  7.711187260627747\n",
      "Epoch:  506  Average loss at step  4000 :  8.120224619865418\n",
      "Epoch:  506  Average loss at step  5000 :  7.808596592903137\n",
      "Epoch:  506  Average loss at step  6000 :  8.52843181324005\n",
      "Epoch:  506  Average loss at step  7000 :  7.616763934135437\n",
      "Epoch:  506  Average loss at step  8000 :  8.457042329788209\n",
      "Epoch:  506  Average loss at step  8472 :  8.185012961561238\n",
      "506 0 20.37007784843445\n",
      "Epoch:  506  Average loss at step  1000 :  2582.09245690918\n",
      "Epoch:  506  Average loss at step  1491 :  2577.790376337902\n",
      "506 1 11.726306200027466\n",
      "Epoch:  506  Average loss at step  1000 :  3597.3385417480467\n",
      "Epoch:  506  Average loss at step  2000 :  3593.619607543945\n",
      "Epoch:  506  Average loss at step  2533 :  3622.380786269553\n",
      "506 2 19.824003219604492\n",
      "Epoch:  506  Average loss at step  1000 :  64.58227161407471\n",
      "Epoch:  506  Average loss at step  1227 :  64.35540012011758\n",
      "506 3 12.603306293487549\n",
      "Epoch:  506  Average loss at step  1000 :  5.808317812919617\n",
      "Epoch:  506  Average loss at step  2000 :  5.743669240474701\n",
      "Epoch:  506  Average loss at step  3000 :  5.7254893851280215\n",
      "Epoch:  506  Average loss at step  3222 :  5.782063832931256\n",
      "506 4 33.37334656715393\n",
      "506 5 1.1920928955078125e-06\n",
      "Training time took 98.537089 seconds to run 1 epoch\n",
      "Epoch:  507  Average loss at step  1000 :  0.06236722946166992\n",
      "Epoch:  507  Average loss at step  2000 :  0.06615572410821914\n",
      "Epoch:  507  Average loss at step  3000 :  0.07195907336473464\n",
      "Epoch:  507  Average loss at step  3222 :  0.07456711271993303\n",
      "507 0 29.38339066505432\n",
      "Training time took 29.510851 seconds to run 1 epoch\n",
      "Epoch:  508  Average loss at step  1000 :  8.346337842941285\n",
      "Epoch:  508  Average loss at step  2000 :  7.678612615585327\n",
      "Epoch:  508  Average loss at step  3000 :  7.47900895690918\n",
      "Epoch:  508  Average loss at step  4000 :  8.451445065498351\n",
      "Epoch:  508  Average loss at step  5000 :  7.786942150115967\n",
      "Epoch:  508  Average loss at step  6000 :  7.617657563209534\n",
      "Epoch:  508  Average loss at step  7000 :  7.830321495056152\n",
      "Epoch:  508  Average loss at step  8000 :  8.149752773284913\n",
      "Epoch:  508  Average loss at step  8472 :  7.801827202071551\n",
      "508 0 20.43267560005188\n",
      "Epoch:  508  Average loss at step  1000 :  2570.358099121094\n",
      "Epoch:  508  Average loss at step  1491 :  2606.2114441515973\n",
      "508 1 11.722167015075684\n",
      "Epoch:  508  Average loss at step  1000 :  3575.2840617675784\n",
      "Epoch:  508  Average loss at step  2000 :  3585.121382080078\n",
      "Epoch:  508  Average loss at step  2533 :  3588.907256920625\n",
      "508 2 19.8700749874115\n",
      "Epoch:  508  Average loss at step  1000 :  64.54835163879395\n",
      "Epoch:  508  Average loss at step  1227 :  65.04427556057131\n",
      "508 3 12.672507286071777\n",
      "Epoch:  508  Average loss at step  1000 :  5.6804263215065\n",
      "Epoch:  508  Average loss at step  2000 :  5.703677344322204\n",
      "Epoch:  508  Average loss at step  3000 :  5.681753460884094\n",
      "Epoch:  508  Average loss at step  3222 :  5.934221565045482\n",
      "508 4 33.14528703689575\n",
      "508 5 1.6689300537109375e-06\n",
      "Training time took 98.48808 seconds to run 1 epoch\n",
      "Epoch:  509  Average loss at step  1000 :  0.06268662184476853\n",
      "Epoch:  509  Average loss at step  2000 :  0.06567717570066452\n",
      "Epoch:  509  Average loss at step  3000 :  0.07180280083417892\n",
      "Epoch:  509  Average loss at step  3222 :  0.07517811897580515\n",
      "509 0 29.429364442825317\n",
      "Training time took 29.560322 seconds to run 1 epoch\n",
      "Epoch:  510  Average loss at step  1000 :  7.240239019393921\n",
      "Epoch:  510  Average loss at step  2000 :  7.8795105714797975\n",
      "Epoch:  510  Average loss at step  3000 :  7.964429488182068\n",
      "Epoch:  510  Average loss at step  4000 :  7.905612434387207\n",
      "Epoch:  510  Average loss at step  5000 :  8.497290660858154\n",
      "Epoch:  510  Average loss at step  6000 :  7.569412521362304\n",
      "Epoch:  510  Average loss at step  7000 :  8.051441118240357\n",
      "Epoch:  510  Average loss at step  8000 :  8.131748464584351\n",
      "Epoch:  510  Average loss at step  8472 :  7.89209779679717\n",
      "510 0 21.168357372283936\n",
      "Epoch:  510  Average loss at step  1000 :  2575.5624265136717\n",
      "Epoch:  510  Average loss at step  1491 :  2625.9707552522286\n",
      "510 1 11.695688962936401\n",
      "Epoch:  510  Average loss at step  1000 :  3574.4215139160156\n",
      "Epoch:  510  Average loss at step  2000 :  3596.7053371582033\n",
      "Epoch:  510  Average loss at step  2533 :  3635.327268199751\n",
      "510 2 19.948620557785034\n",
      "Epoch:  510  Average loss at step  1000 :  64.74834577560425\n",
      "Epoch:  510  Average loss at step  1227 :  64.12676133292014\n",
      "510 3 12.649955749511719\n",
      "Epoch:  510  Average loss at step  1000 :  5.7258108005523685\n",
      "Epoch:  510  Average loss at step  2000 :  5.661560861587525\n",
      "Epoch:  510  Average loss at step  3000 :  5.743762902259826\n",
      "Epoch:  510  Average loss at step  3222 :  5.724328344189791\n",
      "510 4 33.15984892845154\n",
      "510 5 1.1920928955078125e-06\n",
      "Training time took 99.270386 seconds to run 1 epoch\n",
      "Mean Rank:  158.689  of  75000\n",
      "Hits @ 10:  0.85504\n",
      "Hits @ 1:  0.61724\n",
      "Testing time took 163.56015 seconds.\n",
      "\n",
      "Epoch:  511  Average loss at step  1000 :  0.06231255197525024\n",
      "Epoch:  511  Average loss at step  2000 :  0.0657518990635872\n",
      "Epoch:  511  Average loss at step  3000 :  0.07074364197254181\n",
      "Epoch:  511  Average loss at step  3222 :  0.07485004673582657\n",
      "511 0 29.490102291107178\n",
      "Training time took 29.601525 seconds to run 1 epoch\n",
      "Epoch:  512  Average loss at step  1000 :  7.781731176376343\n",
      "Epoch:  512  Average loss at step  2000 :  8.240114583015442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  512  Average loss at step  3000 :  7.914729573249817\n",
      "Epoch:  512  Average loss at step  4000 :  8.217785199642181\n",
      "Epoch:  512  Average loss at step  5000 :  8.128531394004822\n",
      "Epoch:  512  Average loss at step  6000 :  8.008525489807129\n",
      "Epoch:  512  Average loss at step  7000 :  7.894021241664887\n",
      "Epoch:  512  Average loss at step  8000 :  8.101899047851562\n",
      "Epoch:  512  Average loss at step  8472 :  7.496131093345905\n",
      "512 0 20.635669231414795\n",
      "Epoch:  512  Average loss at step  1000 :  2550.29105078125\n",
      "Epoch:  512  Average loss at step  1491 :  2583.4275727020176\n",
      "512 1 11.782496452331543\n",
      "Epoch:  512  Average loss at step  1000 :  3606.4885249023437\n",
      "Epoch:  512  Average loss at step  2000 :  3598.238948852539\n",
      "Epoch:  512  Average loss at step  2533 :  3619.221428039939\n",
      "512 2 19.89339327812195\n",
      "Epoch:  512  Average loss at step  1000 :  64.55182306289673\n",
      "Epoch:  512  Average loss at step  1227 :  64.10197507363748\n",
      "512 3 12.633460283279419\n",
      "Epoch:  512  Average loss at step  1000 :  5.828557219982147\n",
      "Epoch:  512  Average loss at step  2000 :  5.558195478439331\n",
      "Epoch:  512  Average loss at step  3000 :  5.616229362487793\n",
      "Epoch:  512  Average loss at step  3222 :  5.503942258824164\n",
      "512 4 33.23710584640503\n",
      "512 5 1.430511474609375e-06\n",
      "Training time took 98.813518 seconds to run 1 epoch\n",
      "Epoch:  513  Average loss at step  1000 :  0.062262763500213626\n",
      "Epoch:  513  Average loss at step  2000 :  0.06518696570396423\n",
      "Epoch:  513  Average loss at step  3000 :  0.07115952348709106\n",
      "Epoch:  513  Average loss at step  3222 :  0.07449509295170693\n",
      "513 0 29.418282985687256\n",
      "Training time took 29.546999 seconds to run 1 epoch\n",
      "Epoch:  514  Average loss at step  1000 :  7.824885405540466\n",
      "Epoch:  514  Average loss at step  2000 :  7.893009600639343\n",
      "Epoch:  514  Average loss at step  3000 :  8.017855870246887\n",
      "Epoch:  514  Average loss at step  4000 :  8.16831101989746\n",
      "Epoch:  514  Average loss at step  5000 :  7.743682638168335\n",
      "Epoch:  514  Average loss at step  6000 :  8.329544211387635\n",
      "Epoch:  514  Average loss at step  7000 :  8.026009248733521\n",
      "Epoch:  514  Average loss at step  8000 :  7.5592120218276975\n",
      "Epoch:  514  Average loss at step  8472 :  8.240928806142861\n",
      "514 0 21.50772476196289\n",
      "Epoch:  514  Average loss at step  1000 :  2566.5754516601564\n",
      "Epoch:  514  Average loss at step  1491 :  2590.376116851483\n",
      "514 1 11.692443132400513\n",
      "Epoch:  514  Average loss at step  1000 :  3591.8800541992186\n",
      "Epoch:  514  Average loss at step  2000 :  3600.2794461669923\n",
      "Epoch:  514  Average loss at step  2533 :  3586.8064437285184\n",
      "514 2 19.86905264854431\n",
      "Epoch:  514  Average loss at step  1000 :  64.71347079086304\n",
      "Epoch:  514  Average loss at step  1227 :  63.29547597496628\n",
      "514 3 12.639116764068604\n",
      "Epoch:  514  Average loss at step  1000 :  5.686757390975952\n",
      "Epoch:  514  Average loss at step  2000 :  5.6118312458992\n",
      "Epoch:  514  Average loss at step  3000 :  5.553594951152801\n",
      "Epoch:  514  Average loss at step  3222 :  5.75317474968878\n",
      "514 4 33.17849397659302\n",
      "514 5 1.1920928955078125e-06\n",
      "Training time took 99.514714 seconds to run 1 epoch\n",
      "Epoch:  515  Average loss at step  1000 :  0.062072685480117795\n",
      "Epoch:  515  Average loss at step  2000 :  0.06522208935022354\n",
      "Epoch:  515  Average loss at step  3000 :  0.07067143309116364\n",
      "Epoch:  515  Average loss at step  3222 :  0.07483986799715658\n",
      "515 0 29.411115884780884\n",
      "Training time took 29.539545 seconds to run 1 epoch\n",
      "Epoch:  516  Average loss at step  1000 :  8.052488210678101\n",
      "Epoch:  516  Average loss at step  2000 :  7.968904972553253\n",
      "Epoch:  516  Average loss at step  3000 :  8.14517705631256\n",
      "Epoch:  516  Average loss at step  4000 :  7.704801779747009\n",
      "Epoch:  516  Average loss at step  5000 :  8.650772267341614\n",
      "Epoch:  516  Average loss at step  6000 :  7.727257390975952\n",
      "Epoch:  516  Average loss at step  7000 :  8.402102685928345\n",
      "Epoch:  516  Average loss at step  8000 :  7.96854815196991\n",
      "Epoch:  516  Average loss at step  8472 :  8.205149138420548\n",
      "516 0 20.619555950164795\n",
      "Epoch:  516  Average loss at step  1000 :  2557.9066826171875\n",
      "Epoch:  516  Average loss at step  1491 :  2608.3533918564\n",
      "516 1 11.729935646057129\n",
      "Epoch:  516  Average loss at step  1000 :  3554.1003095703127\n",
      "Epoch:  516  Average loss at step  2000 :  3590.428376586914\n",
      "Epoch:  516  Average loss at step  2533 :  3587.0248356990405\n",
      "516 2 19.951321125030518\n",
      "Epoch:  516  Average loss at step  1000 :  64.34423523712158\n",
      "Epoch:  516  Average loss at step  1227 :  64.6681734716939\n",
      "516 3 12.621618509292603\n",
      "Epoch:  516  Average loss at step  1000 :  5.723476073741913\n",
      "Epoch:  516  Average loss at step  2000 :  5.5271343016624455\n",
      "Epoch:  516  Average loss at step  3000 :  5.617414766788483\n",
      "Epoch:  516  Average loss at step  3222 :  5.688530887845492\n",
      "516 4 33.18697714805603\n",
      "516 5 1.430511474609375e-06\n",
      "Training time took 98.732318 seconds to run 1 epoch\n",
      "Epoch:  517  Average loss at step  1000 :  0.06206276869773865\n",
      "Epoch:  517  Average loss at step  2000 :  0.06486822205781936\n",
      "Epoch:  517  Average loss at step  3000 :  0.07065339797735214\n",
      "Epoch:  517  Average loss at step  3222 :  0.0733974218734401\n",
      "517 0 29.385967254638672\n",
      "Training time took 29.508148 seconds to run 1 epoch\n",
      "Epoch:  518  Average loss at step  1000 :  8.39622002696991\n",
      "Epoch:  518  Average loss at step  2000 :  7.802283699989319\n",
      "Epoch:  518  Average loss at step  3000 :  7.922865567207336\n",
      "Epoch:  518  Average loss at step  4000 :  7.782832215309143\n",
      "Epoch:  518  Average loss at step  5000 :  8.335885667324066\n",
      "Epoch:  518  Average loss at step  6000 :  8.176500703811646\n",
      "Epoch:  518  Average loss at step  7000 :  7.965936532020569\n",
      "Epoch:  518  Average loss at step  8000 :  7.892083288192749\n",
      "Epoch:  518  Average loss at step  8472 :  8.020951843925538\n",
      "518 0 21.134846687316895\n",
      "Epoch:  518  Average loss at step  1000 :  2593.4804677734373\n",
      "Epoch:  518  Average loss at step  1491 :  2574.7511673276676\n",
      "518 1 11.713662385940552\n",
      "Epoch:  518  Average loss at step  1000 :  3615.1131215820315\n",
      "Epoch:  518  Average loss at step  2000 :  3628.0488717041017\n",
      "Epoch:  518  Average loss at step  2533 :  3574.6188091451154\n",
      "518 2 19.8765549659729\n",
      "Epoch:  518  Average loss at step  1000 :  64.47228772354126\n",
      "Epoch:  518  Average loss at step  1227 :  63.70713887808104\n",
      "518 3 12.561238527297974\n",
      "Epoch:  518  Average loss at step  1000 :  5.555755454063416\n",
      "Epoch:  518  Average loss at step  2000 :  5.543029695510865\n",
      "Epoch:  518  Average loss at step  3000 :  5.639599687576294\n",
      "Epoch:  518  Average loss at step  3222 :  5.7405475890901165\n",
      "518 4 32.98200082778931\n",
      "518 5 1.1920928955078125e-06\n",
      "Training time took 98.898919 seconds to run 1 epoch\n",
      "Epoch:  519  Average loss at step  1000 :  0.06144710975885391\n",
      "Epoch:  519  Average loss at step  2000 :  0.06477326226234437\n",
      "Epoch:  519  Average loss at step  3000 :  0.07016968613862991\n",
      "Epoch:  519  Average loss at step  3222 :  0.07330787393844047\n",
      "519 0 29.465048789978027\n",
      "Training time took 29.59398 seconds to run 1 epoch\n",
      "Epoch:  520  Average loss at step  1000 :  7.643234112739563\n",
      "Epoch:  520  Average loss at step  2000 :  8.275008235931397\n",
      "Epoch:  520  Average loss at step  3000 :  8.187199877262115\n",
      "Epoch:  520  Average loss at step  4000 :  8.064939972877502\n",
      "Epoch:  520  Average loss at step  5000 :  7.74725276184082\n",
      "Epoch:  520  Average loss at step  6000 :  8.096227380752563\n",
      "Epoch:  520  Average loss at step  7000 :  7.742907032966614\n",
      "Epoch:  520  Average loss at step  8000 :  8.046129376411438\n",
      "Epoch:  520  Average loss at step  8472 :  8.15587320016492\n",
      "520 0 21.00211524963379\n",
      "Epoch:  520  Average loss at step  1000 :  2585.3423962402344\n",
      "Epoch:  520  Average loss at step  1491 :  2579.223706910545\n",
      "520 1 11.697634220123291\n",
      "Epoch:  520  Average loss at step  1000 :  3600.565927734375\n",
      "Epoch:  520  Average loss at step  2000 :  3583.7123115234376\n",
      "Epoch:  520  Average loss at step  2533 :  3643.861098071353\n",
      "520 2 19.914178609848022\n",
      "Epoch:  520  Average loss at step  1000 :  64.43526964950561\n",
      "Epoch:  520  Average loss at step  1227 :  64.68640236280885\n",
      "520 3 12.642478466033936\n",
      "Epoch:  520  Average loss at step  1000 :  5.5789833841323855\n",
      "Epoch:  520  Average loss at step  2000 :  5.551768478870392\n",
      "Epoch:  520  Average loss at step  3000 :  5.555944950580597\n",
      "Epoch:  520  Average loss at step  3222 :  5.556339741097522\n",
      "520 4 33.11522316932678\n",
      "520 5 1.430511474609375e-06\n",
      "Training time took 98.994886 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank:  159.20716  of  75000\n",
      "Hits @ 10:  0.85448\n",
      "Hits @ 1:  0.61696\n",
      "Testing time took 163.889321 seconds.\n",
      "\n",
      "Epoch:  521  Average loss at step  1000 :  0.061358104646205905\n",
      "Epoch:  521  Average loss at step  2000 :  0.06476954907178879\n",
      "Epoch:  521  Average loss at step  3000 :  0.07005764108896255\n",
      "Epoch:  521  Average loss at step  3222 :  0.0739010703608886\n",
      "521 0 29.429229736328125\n",
      "Training time took 29.537581 seconds to run 1 epoch\n",
      "Epoch:  522  Average loss at step  1000 :  8.561070689678193\n",
      "Epoch:  522  Average loss at step  2000 :  8.61397976589203\n",
      "Epoch:  522  Average loss at step  3000 :  7.94921524143219\n",
      "Epoch:  522  Average loss at step  4000 :  7.758991093635559\n",
      "Epoch:  522  Average loss at step  5000 :  8.104773341178895\n",
      "Epoch:  522  Average loss at step  6000 :  8.241190337181092\n",
      "Epoch:  522  Average loss at step  7000 :  8.166232390403747\n",
      "Epoch:  522  Average loss at step  8000 :  7.900237309455871\n",
      "Epoch:  522  Average loss at step  8472 :  8.171181492376224\n",
      "522 0 21.616698503494263\n",
      "Epoch:  522  Average loss at step  1000 :  2586.6003594970703\n",
      "Epoch:  522  Average loss at step  1491 :  2588.615580378058\n",
      "522 1 11.727237701416016\n",
      "Epoch:  522  Average loss at step  1000 :  3622.1098868408203\n",
      "Epoch:  522  Average loss at step  2000 :  3627.699240966797\n",
      "Epoch:  522  Average loss at step  2533 :  3619.3793474155877\n",
      "522 2 19.906655311584473\n",
      "Epoch:  522  Average loss at step  1000 :  64.29825127792358\n",
      "Epoch:  522  Average loss at step  1227 :  64.47774811605554\n",
      "522 3 12.681065320968628\n",
      "Epoch:  522  Average loss at step  1000 :  5.67575084400177\n",
      "Epoch:  522  Average loss at step  2000 :  5.469663291931153\n",
      "Epoch:  522  Average loss at step  3000 :  5.468302861213684\n",
      "Epoch:  522  Average loss at step  3222 :  5.631541248090131\n",
      "522 4 33.31035614013672\n",
      "522 5 1.1920928955078125e-06\n",
      "Training time took 99.880674 seconds to run 1 epoch\n",
      "Epoch:  523  Average loss at step  1000 :  0.060892020046710967\n",
      "Epoch:  523  Average loss at step  2000 :  0.06438661086559296\n",
      "Epoch:  523  Average loss at step  3000 :  0.06973867070674897\n",
      "Epoch:  523  Average loss at step  3222 :  0.07396097711803122\n",
      "523 0 29.371718168258667\n",
      "Training time took 29.493886 seconds to run 1 epoch\n",
      "Epoch:  524  Average loss at step  1000 :  8.117029756546021\n",
      "Epoch:  524  Average loss at step  2000 :  8.293321355819701\n",
      "Epoch:  524  Average loss at step  3000 :  7.593745497703552\n",
      "Epoch:  524  Average loss at step  4000 :  8.08135630607605\n",
      "Epoch:  524  Average loss at step  5000 :  8.215564392089844\n",
      "Epoch:  524  Average loss at step  6000 :  8.159621415138245\n",
      "Epoch:  524  Average loss at step  7000 :  8.161739261627197\n",
      "Epoch:  524  Average loss at step  8000 :  7.601522506713867\n",
      "Epoch:  524  Average loss at step  8472 :  7.5198263482677925\n",
      "524 0 20.304931163787842\n",
      "Epoch:  524  Average loss at step  1000 :  2590.7757739868166\n",
      "Epoch:  524  Average loss at step  1491 :  2599.920791179337\n",
      "524 1 11.688528537750244\n",
      "Epoch:  524  Average loss at step  1000 :  3591.149733642578\n",
      "Epoch:  524  Average loss at step  2000 :  3624.576280761719\n",
      "Epoch:  524  Average loss at step  2533 :  3643.6242023742334\n",
      "524 2 19.91149067878723\n",
      "Epoch:  524  Average loss at step  1000 :  64.1380873184204\n",
      "Epoch:  524  Average loss at step  1227 :  63.59121174786442\n",
      "524 3 12.53335952758789\n",
      "Epoch:  524  Average loss at step  1000 :  5.5096714701652525\n",
      "Epoch:  524  Average loss at step  2000 :  5.505684386253357\n",
      "Epoch:  524  Average loss at step  3000 :  5.43914506816864\n",
      "Epoch:  524  Average loss at step  3222 :  5.426830499906965\n",
      "524 4 33.276150703430176\n",
      "524 5 1.1920928955078125e-06\n",
      "Training time took 98.34055 seconds to run 1 epoch\n",
      "Epoch:  525  Average loss at step  1000 :  0.0610199174284935\n",
      "Epoch:  525  Average loss at step  2000 :  0.06392605865001678\n",
      "Epoch:  525  Average loss at step  3000 :  0.06960385161638259\n",
      "Epoch:  525  Average loss at step  3222 :  0.07300103349921548\n",
      "525 0 29.310879230499268\n",
      "Training time took 29.430289 seconds to run 1 epoch\n",
      "Epoch:  526  Average loss at step  1000 :  8.218850887775421\n",
      "Epoch:  526  Average loss at step  2000 :  8.054146830558777\n",
      "Epoch:  526  Average loss at step  3000 :  8.099335821151733\n",
      "Epoch:  526  Average loss at step  4000 :  7.920211204528808\n",
      "Epoch:  526  Average loss at step  5000 :  7.621293666362763\n",
      "Epoch:  526  Average loss at step  6000 :  8.351013244628906\n",
      "Epoch:  526  Average loss at step  7000 :  7.979725121498108\n",
      "Epoch:  526  Average loss at step  8000 :  8.52417622089386\n",
      "Epoch:  526  Average loss at step  8472 :  7.775218369099539\n",
      "526 0 20.840245723724365\n",
      "Epoch:  526  Average loss at step  1000 :  2592.889074951172\n",
      "Epoch:  526  Average loss at step  1491 :  2569.274238693812\n",
      "526 1 11.702323913574219\n",
      "Epoch:  526  Average loss at step  1000 :  3609.3156748046877\n",
      "Epoch:  526  Average loss at step  2000 :  3609.782970703125\n",
      "Epoch:  526  Average loss at step  2533 :  3667.835501877432\n",
      "526 2 19.875246286392212\n",
      "Epoch:  526  Average loss at step  1000 :  64.11899873352051\n",
      "Epoch:  526  Average loss at step  1227 :  63.81087126243613\n",
      "526 3 12.634538888931274\n",
      "Epoch:  526  Average loss at step  1000 :  5.59757721710205\n",
      "Epoch:  526  Average loss at step  2000 :  5.4998385891914365\n",
      "Epoch:  526  Average loss at step  3000 :  5.503511641979218\n",
      "Epoch:  526  Average loss at step  3222 :  5.34088477737143\n",
      "526 4 33.13378119468689\n",
      "526 5 1.6689300537109375e-06\n",
      "Training time took 98.818305 seconds to run 1 epoch\n",
      "Epoch:  527  Average loss at step  1000 :  0.06079299229383468\n",
      "Epoch:  527  Average loss at step  2000 :  0.06390469861030579\n",
      "Epoch:  527  Average loss at step  3000 :  0.06946402049064636\n",
      "Epoch:  527  Average loss at step  3222 :  0.07234417422623986\n",
      "527 0 29.36862349510193\n",
      "Training time took 29.488376 seconds to run 1 epoch\n",
      "Epoch:  528  Average loss at step  1000 :  7.863313844680786\n",
      "Epoch:  528  Average loss at step  2000 :  8.634463100433349\n",
      "Epoch:  528  Average loss at step  3000 :  8.223432491302491\n",
      "Epoch:  528  Average loss at step  4000 :  8.031104991436004\n",
      "Epoch:  528  Average loss at step  5000 :  8.633424388885498\n",
      "Epoch:  528  Average loss at step  6000 :  8.287383269309997\n",
      "Epoch:  528  Average loss at step  7000 :  7.601958783149719\n",
      "Epoch:  528  Average loss at step  8000 :  7.709821442604065\n",
      "Epoch:  528  Average loss at step  8472 :  8.212160145324173\n",
      "528 0 20.524289846420288\n",
      "Epoch:  528  Average loss at step  1000 :  2575.6842786865236\n",
      "Epoch:  528  Average loss at step  1491 :  2579.275204305715\n",
      "528 1 11.704658269882202\n",
      "Epoch:  528  Average loss at step  1000 :  3641.2975505371096\n",
      "Epoch:  528  Average loss at step  2000 :  3609.800245239258\n",
      "Epoch:  528  Average loss at step  2533 :  3596.3621174729474\n",
      "528 2 19.94614291191101\n",
      "Epoch:  528  Average loss at step  1000 :  63.18187691497803\n",
      "Epoch:  528  Average loss at step  1227 :  63.276808007433374\n",
      "528 3 12.619465827941895\n",
      "Epoch:  528  Average loss at step  1000 :  5.494368206501007\n",
      "Epoch:  528  Average loss at step  2000 :  5.420106292247772\n",
      "Epoch:  528  Average loss at step  3000 :  5.531979024410248\n",
      "Epoch:  528  Average loss at step  3222 :  5.543560147995681\n",
      "528 4 33.12266135215759\n",
      "528 5 1.430511474609375e-06\n",
      "Training time took 98.53817 seconds to run 1 epoch\n",
      "Epoch:  529  Average loss at step  1000 :  0.060727829933166506\n",
      "Epoch:  529  Average loss at step  2000 :  0.06379964905977249\n",
      "Epoch:  529  Average loss at step  3000 :  0.06929848831892013\n",
      "Epoch:  529  Average loss at step  3222 :  0.07276164993608787\n",
      "529 0 29.329453229904175\n",
      "Training time took 29.448366 seconds to run 1 epoch\n",
      "Epoch:  530  Average loss at step  1000 :  8.083514904022216\n",
      "Epoch:  530  Average loss at step  2000 :  8.240053799629212\n",
      "Epoch:  530  Average loss at step  3000 :  7.7591569652557375\n",
      "Epoch:  530  Average loss at step  4000 :  7.864585977554321\n",
      "Epoch:  530  Average loss at step  5000 :  7.925467204093933\n",
      "Epoch:  530  Average loss at step  6000 :  8.335626039505005\n",
      "Epoch:  530  Average loss at step  7000 :  7.722533326148987\n",
      "Epoch:  530  Average loss at step  8000 :  7.683753636360168\n",
      "Epoch:  530  Average loss at step  8472 :  8.431397601130417\n",
      "530 0 21.261640787124634\n",
      "Epoch:  530  Average loss at step  1000 :  2596.3084835205077\n",
      "Epoch:  530  Average loss at step  1491 :  2630.066394384367\n",
      "530 1 11.717974424362183\n",
      "Epoch:  530  Average loss at step  1000 :  3645.456306640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  530  Average loss at step  2000 :  3612.4519880371095\n",
      "Epoch:  530  Average loss at step  2533 :  3632.6386153068383\n",
      "530 2 19.84649395942688\n",
      "Epoch:  530  Average loss at step  1000 :  63.87611268234253\n",
      "Epoch:  530  Average loss at step  1227 :  64.50361367195902\n",
      "530 3 12.594514846801758\n",
      "Epoch:  530  Average loss at step  1000 :  5.5310495615005495\n",
      "Epoch:  530  Average loss at step  2000 :  5.350157043457031\n",
      "Epoch:  530  Average loss at step  3000 :  5.595975645542145\n",
      "Epoch:  530  Average loss at step  3222 :  5.254128750189695\n",
      "530 4 33.11549234390259\n",
      "530 5 1.1920928955078125e-06\n",
      "Training time took 99.160906 seconds to run 1 epoch\n",
      "Mean Rank:  157.46004  of  75000\n",
      "Hits @ 10:  0.85428\n",
      "Hits @ 1:  0.618\n",
      "Testing time took 163.355628 seconds.\n",
      "\n",
      "Epoch:  531  Average loss at step  1000 :  0.06044271385669708\n",
      "Epoch:  531  Average loss at step  2000 :  0.06337820744514465\n",
      "Epoch:  531  Average loss at step  3000 :  0.06866811794042588\n",
      "Epoch:  531  Average loss at step  3222 :  0.0723848361834698\n",
      "531 0 29.415507555007935\n",
      "Training time took 29.525299 seconds to run 1 epoch\n",
      "Epoch:  532  Average loss at step  1000 :  8.563408495903015\n",
      "Epoch:  532  Average loss at step  2000 :  7.879267139434814\n",
      "Epoch:  532  Average loss at step  3000 :  8.434586050987244\n",
      "Epoch:  532  Average loss at step  4000 :  8.259661056518555\n",
      "Epoch:  532  Average loss at step  5000 :  7.800708393096924\n",
      "Epoch:  532  Average loss at step  6000 :  7.827800609588623\n",
      "Epoch:  532  Average loss at step  7000 :  7.997915509223938\n",
      "Epoch:  532  Average loss at step  8000 :  8.254749128341675\n",
      "Epoch:  532  Average loss at step  8472 :  8.018383755758174\n",
      "532 0 20.71587872505188\n",
      "Epoch:  532  Average loss at step  1000 :  2602.4516241455076\n",
      "Epoch:  532  Average loss at step  1491 :  2580.7566400501187\n",
      "532 1 11.727643251419067\n",
      "Epoch:  532  Average loss at step  1000 :  3638.475357055664\n",
      "Epoch:  532  Average loss at step  2000 :  3650.494784423828\n",
      "Epoch:  532  Average loss at step  2533 :  3658.0343210253104\n",
      "532 2 19.829251766204834\n",
      "Epoch:  532  Average loss at step  1000 :  64.25287083053588\n",
      "Epoch:  532  Average loss at step  1227 :  63.82332413608987\n",
      "532 3 12.612329721450806\n",
      "Epoch:  532  Average loss at step  1000 :  5.509746381759643\n",
      "Epoch:  532  Average loss at step  2000 :  5.376071612834931\n",
      "Epoch:  532  Average loss at step  3000 :  5.485838577270508\n",
      "Epoch:  532  Average loss at step  3222 :  5.2850793836607055\n",
      "532 4 33.23177123069763\n",
      "532 5 1.430511474609375e-06\n",
      "Training time took 98.757315 seconds to run 1 epoch\n",
      "Epoch:  533  Average loss at step  1000 :  0.06021252727508545\n",
      "Epoch:  533  Average loss at step  2000 :  0.06315114516019821\n",
      "Epoch:  533  Average loss at step  3000 :  0.06903816372156144\n",
      "Epoch:  533  Average loss at step  3222 :  0.07218400140513709\n",
      "533 0 29.410902738571167\n",
      "Training time took 29.53253 seconds to run 1 epoch\n",
      "Epoch:  534  Average loss at step  1000 :  8.25417829990387\n",
      "Epoch:  534  Average loss at step  2000 :  8.095267884254456\n",
      "Epoch:  534  Average loss at step  3000 :  8.381784011363983\n",
      "Epoch:  534  Average loss at step  4000 :  8.479949747562408\n",
      "Epoch:  534  Average loss at step  5000 :  7.905172556877136\n",
      "Epoch:  534  Average loss at step  6000 :  8.495670448303223\n",
      "Epoch:  534  Average loss at step  7000 :  7.592215111732483\n",
      "Epoch:  534  Average loss at step  8000 :  8.334555235862732\n",
      "Epoch:  534  Average loss at step  8472 :  7.352187680973473\n",
      "534 0 20.685935020446777\n",
      "Epoch:  534  Average loss at step  1000 :  2587.3234100341797\n",
      "Epoch:  534  Average loss at step  1491 :  2556.286237922317\n",
      "534 1 11.738437175750732\n",
      "Epoch:  534  Average loss at step  1000 :  3658.7793939208987\n",
      "Epoch:  534  Average loss at step  2000 :  3658.345008056641\n",
      "Epoch:  534  Average loss at step  2533 :  3602.121258810831\n",
      "534 2 19.86085534095764\n",
      "Epoch:  534  Average loss at step  1000 :  63.802973094940185\n",
      "Epoch:  534  Average loss at step  1227 :  64.05755110893935\n",
      "534 3 12.64992904663086\n",
      "Epoch:  534  Average loss at step  1000 :  5.481538077354431\n",
      "Epoch:  534  Average loss at step  2000 :  5.340786357402801\n",
      "Epoch:  534  Average loss at step  3000 :  5.34659741449356\n",
      "Epoch:  534  Average loss at step  3222 :  5.301475156879442\n",
      "534 4 33.379592418670654\n",
      "534 5 1.6689300537109375e-06\n",
      "Training time took 98.942144 seconds to run 1 epoch\n",
      "Epoch:  535  Average loss at step  1000 :  0.05985624021291733\n",
      "Epoch:  535  Average loss at step  2000 :  0.06307720029354096\n",
      "Epoch:  535  Average loss at step  3000 :  0.06902454340457917\n",
      "Epoch:  535  Average loss at step  3222 :  0.07194351673255352\n",
      "535 0 29.4522545337677\n",
      "Training time took 29.580338 seconds to run 1 epoch\n",
      "Epoch:  536  Average loss at step  1000 :  8.65851787853241\n",
      "Epoch:  536  Average loss at step  2000 :  7.882172779083252\n",
      "Epoch:  536  Average loss at step  3000 :  8.252962869644165\n",
      "Epoch:  536  Average loss at step  4000 :  8.556916679382324\n",
      "Epoch:  536  Average loss at step  5000 :  8.16701051902771\n",
      "Epoch:  536  Average loss at step  6000 :  7.8909278564453125\n",
      "Epoch:  536  Average loss at step  7000 :  7.5319374647140505\n",
      "Epoch:  536  Average loss at step  8000 :  8.277179598808289\n",
      "Epoch:  536  Average loss at step  8472 :  7.906842926939842\n",
      "536 0 21.365776538848877\n",
      "Epoch:  536  Average loss at step  1000 :  2618.0233595581053\n",
      "Epoch:  536  Average loss at step  1491 :  2567.5920561783723\n",
      "536 1 11.669197082519531\n",
      "Epoch:  536  Average loss at step  1000 :  3661.5815107421877\n",
      "Epoch:  536  Average loss at step  2000 :  3645.224469970703\n",
      "Epoch:  536  Average loss at step  2533 :  3609.040931002187\n",
      "536 2 19.911044120788574\n",
      "Epoch:  536  Average loss at step  1000 :  63.328254112243656\n",
      "Epoch:  536  Average loss at step  1227 :  64.25980912806544\n",
      "536 3 12.684103727340698\n",
      "Epoch:  536  Average loss at step  1000 :  5.494317389965057\n",
      "Epoch:  536  Average loss at step  2000 :  5.4688997941017155\n",
      "Epoch:  536  Average loss at step  3000 :  5.4300127048492435\n",
      "Epoch:  536  Average loss at step  3222 :  5.2612270252608635\n",
      "536 4 33.24083471298218\n",
      "536 5 1.430511474609375e-06\n",
      "Training time took 99.504919 seconds to run 1 epoch\n",
      "Epoch:  537  Average loss at step  1000 :  0.059956838488578794\n",
      "Epoch:  537  Average loss at step  2000 :  0.06269583308696747\n",
      "Epoch:  537  Average loss at step  3000 :  0.06844134467840195\n",
      "Epoch:  537  Average loss at step  3222 :  0.07200710694698204\n",
      "537 0 29.387911319732666\n",
      "Training time took 29.509528 seconds to run 1 epoch\n",
      "Epoch:  538  Average loss at step  1000 :  7.874682286262512\n",
      "Epoch:  538  Average loss at step  2000 :  7.633937273979187\n",
      "Epoch:  538  Average loss at step  3000 :  8.18035111618042\n",
      "Epoch:  538  Average loss at step  4000 :  7.720504851341247\n",
      "Epoch:  538  Average loss at step  5000 :  8.417271873474121\n",
      "Epoch:  538  Average loss at step  6000 :  7.867348306179046\n",
      "Epoch:  538  Average loss at step  7000 :  7.701513072013855\n",
      "Epoch:  538  Average loss at step  8000 :  8.238135272979736\n",
      "Epoch:  538  Average loss at step  8472 :  7.779351256657808\n",
      "538 0 21.443955183029175\n",
      "Epoch:  538  Average loss at step  1000 :  2611.3101802978517\n",
      "Epoch:  538  Average loss at step  1491 :  2623.2615877605704\n",
      "538 1 11.690202474594116\n",
      "Epoch:  538  Average loss at step  1000 :  3640.6792032470703\n",
      "Epoch:  538  Average loss at step  2000 :  3635.9232603759765\n",
      "Epoch:  538  Average loss at step  2533 :  3669.4270015493294\n",
      "538 2 19.885047912597656\n",
      "Epoch:  538  Average loss at step  1000 :  63.56666887664795\n",
      "Epoch:  538  Average loss at step  1227 :  64.10991991655425\n",
      "538 3 12.686299324035645\n",
      "Epoch:  538  Average loss at step  1000 :  5.431317605018616\n",
      "Epoch:  538  Average loss at step  2000 :  5.234915616512299\n",
      "Epoch:  538  Average loss at step  3000 :  5.3325871639251705\n",
      "Epoch:  538  Average loss at step  3222 :  5.4563000736350205\n",
      "538 4 33.24502205848694\n",
      "538 5 1.1920928955078125e-06\n",
      "Training time took 99.587931 seconds to run 1 epoch\n",
      "Epoch:  539  Average loss at step  1000 :  0.059504240572452544\n",
      "Epoch:  539  Average loss at step  2000 :  0.062215526700019834\n",
      "Epoch:  539  Average loss at step  3000 :  0.06839155334234237\n",
      "Epoch:  539  Average loss at step  3222 :  0.07215057454141044\n",
      "539 0 29.413166761398315\n",
      "Training time took 29.533114 seconds to run 1 epoch\n",
      "Epoch:  540  Average loss at step  1000 :  7.808975540161133\n",
      "Epoch:  540  Average loss at step  2000 :  8.008667462348939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  540  Average loss at step  3000 :  8.2259098072052\n",
      "Epoch:  540  Average loss at step  4000 :  7.672721188545227\n",
      "Epoch:  540  Average loss at step  5000 :  8.12134428024292\n",
      "Epoch:  540  Average loss at step  6000 :  7.778673385620118\n",
      "Epoch:  540  Average loss at step  7000 :  7.779882132530212\n",
      "Epoch:  540  Average loss at step  8000 :  7.825732724189758\n",
      "Epoch:  540  Average loss at step  8472 :  7.872339305081911\n",
      "540 0 20.605830907821655\n",
      "Epoch:  540  Average loss at step  1000 :  2600.925025024414\n",
      "Epoch:  540  Average loss at step  1491 :  2618.857853433948\n",
      "540 1 11.730964660644531\n",
      "Epoch:  540  Average loss at step  1000 :  3678.73216418457\n",
      "Epoch:  540  Average loss at step  2000 :  3637.383066894531\n",
      "Epoch:  540  Average loss at step  2533 :  3608.817390172602\n",
      "540 2 19.96187710762024\n",
      "Epoch:  540  Average loss at step  1000 :  64.54554750061035\n",
      "Epoch:  540  Average loss at step  1227 :  63.56183618915861\n",
      "540 3 12.635553121566772\n",
      "Epoch:  540  Average loss at step  1000 :  5.506457900524139\n",
      "Epoch:  540  Average loss at step  2000 :  5.3964753952026365\n",
      "Epoch:  540  Average loss at step  3000 :  5.461332297325134\n",
      "Epoch:  540  Average loss at step  3222 :  5.121847145134285\n",
      "540 4 33.09771943092346\n",
      "540 5 1.1920928955078125e-06\n",
      "Training time took 98.68049 seconds to run 1 epoch\n",
      "Mean Rank:  158.91424  of  75000\n",
      "Hits @ 10:  0.85404\n",
      "Hits @ 1:  0.61764\n",
      "Testing time took 163.690792 seconds.\n",
      "\n",
      "Epoch:  541  Average loss at step  1000 :  0.05961755406856537\n",
      "Epoch:  541  Average loss at step  2000 :  0.0626287470459938\n",
      "Epoch:  541  Average loss at step  3000 :  0.0677623261809349\n",
      "Epoch:  541  Average loss at step  3222 :  0.07018573981670938\n",
      "541 0 29.441234588623047\n",
      "Training time took 29.551951 seconds to run 1 epoch\n",
      "Epoch:  542  Average loss at step  1000 :  8.090251908779145\n",
      "Epoch:  542  Average loss at step  2000 :  8.448400453567505\n",
      "Epoch:  542  Average loss at step  3000 :  7.854608629226685\n",
      "Epoch:  542  Average loss at step  4000 :  7.876212365150452\n",
      "Epoch:  542  Average loss at step  5000 :  7.785568344116211\n",
      "Epoch:  542  Average loss at step  6000 :  8.220127512931823\n",
      "Epoch:  542  Average loss at step  7000 :  8.267874671936035\n",
      "Epoch:  542  Average loss at step  8000 :  7.960948721408844\n",
      "Epoch:  542  Average loss at step  8472 :  8.328494092239335\n",
      "542 0 20.50991940498352\n",
      "Epoch:  542  Average loss at step  1000 :  2599.292541015625\n",
      "Epoch:  542  Average loss at step  1491 :  2587.891749649183\n",
      "542 1 11.71489405632019\n",
      "Epoch:  542  Average loss at step  1000 :  3665.9464635009767\n",
      "Epoch:  542  Average loss at step  2000 :  3640.943860107422\n",
      "Epoch:  542  Average loss at step  2533 :  3642.466048870267\n",
      "542 2 19.948025226593018\n",
      "Epoch:  542  Average loss at step  1000 :  63.74229738616943\n",
      "Epoch:  542  Average loss at step  1227 :  64.04932196867\n",
      "542 3 12.623263835906982\n",
      "Epoch:  542  Average loss at step  1000 :  5.391034184932709\n",
      "Epoch:  542  Average loss at step  2000 :  5.3610120906829835\n",
      "Epoch:  542  Average loss at step  3000 :  5.294752105712891\n",
      "Epoch:  542  Average loss at step  3222 :  5.17734769320828\n",
      "542 4 33.122942209243774\n",
      "542 5 1.1920928955078125e-06\n",
      "Training time took 98.551678 seconds to run 1 epoch\n",
      "Epoch:  543  Average loss at step  1000 :  0.059639390885829924\n",
      "Epoch:  543  Average loss at step  2000 :  0.06175096493959427\n",
      "Epoch:  543  Average loss at step  3000 :  0.06781700563430786\n",
      "Epoch:  543  Average loss at step  3222 :  0.07157349795248345\n",
      "543 0 29.452784538269043\n",
      "Training time took 29.575439 seconds to run 1 epoch\n",
      "Epoch:  544  Average loss at step  1000 :  8.496968439102172\n",
      "Epoch:  544  Average loss at step  2000 :  8.408525651931763\n",
      "Epoch:  544  Average loss at step  3000 :  8.20933955001831\n",
      "Epoch:  544  Average loss at step  4000 :  7.786237856864929\n",
      "Epoch:  544  Average loss at step  5000 :  8.360002894878388\n",
      "Epoch:  544  Average loss at step  6000 :  8.197698843955994\n",
      "Epoch:  544  Average loss at step  7000 :  7.546270898818969\n",
      "Epoch:  544  Average loss at step  8000 :  8.048266949653625\n",
      "Epoch:  544  Average loss at step  8472 :  7.829756281593549\n",
      "544 0 20.856128454208374\n",
      "Epoch:  544  Average loss at step  1000 :  2622.5804375\n",
      "Epoch:  544  Average loss at step  1491 :  2612.9678851415456\n",
      "544 1 11.680040836334229\n",
      "Epoch:  544  Average loss at step  1000 :  3701.03223046875\n",
      "Epoch:  544  Average loss at step  2000 :  3590.7596112060546\n",
      "Epoch:  544  Average loss at step  2533 :  3697.9579306507376\n",
      "544 2 19.951995372772217\n",
      "Epoch:  544  Average loss at step  1000 :  63.77503568649292\n",
      "Epoch:  544  Average loss at step  1227 :  63.64986865485872\n",
      "544 3 12.61300539970398\n",
      "Epoch:  544  Average loss at step  1000 :  5.300245757102966\n",
      "Epoch:  544  Average loss at step  2000 :  5.31823791217804\n",
      "Epoch:  544  Average loss at step  3000 :  5.267348608016968\n",
      "Epoch:  544  Average loss at step  3222 :  5.287605559574092\n",
      "544 4 33.208515644073486\n",
      "544 5 1.1920928955078125e-06\n",
      "Training time took 98.945294 seconds to run 1 epoch\n",
      "Epoch:  545  Average loss at step  1000 :  0.058913042306900025\n",
      "Epoch:  545  Average loss at step  2000 :  0.06224066013097763\n",
      "Epoch:  545  Average loss at step  3000 :  0.06781776803731919\n",
      "Epoch:  545  Average loss at step  3222 :  0.070539881690656\n",
      "545 0 29.386201858520508\n",
      "Training time took 29.51251 seconds to run 1 epoch\n",
      "Epoch:  546  Average loss at step  1000 :  7.953277027606964\n",
      "Epoch:  546  Average loss at step  2000 :  8.052837873458863\n",
      "Epoch:  546  Average loss at step  3000 :  7.849613848686218\n",
      "Epoch:  546  Average loss at step  4000 :  8.242945853233337\n",
      "Epoch:  546  Average loss at step  5000 :  8.585361192703248\n",
      "Epoch:  546  Average loss at step  6000 :  7.4961448602676395\n",
      "Epoch:  546  Average loss at step  7000 :  8.089759683609008\n",
      "Epoch:  546  Average loss at step  8000 :  8.597578741073608\n",
      "Epoch:  546  Average loss at step  8472 :  7.466193222189024\n",
      "546 0 20.600532054901123\n",
      "Epoch:  546  Average loss at step  1000 :  2584.3853690185547\n",
      "Epoch:  546  Average loss at step  1491 :  2648.850294488506\n",
      "546 1 11.724095821380615\n",
      "Epoch:  546  Average loss at step  1000 :  3685.1209724121095\n",
      "Epoch:  546  Average loss at step  2000 :  3634.4372330322267\n",
      "Epoch:  546  Average loss at step  2533 :  3640.1674049588805\n",
      "546 2 19.873725175857544\n",
      "Epoch:  546  Average loss at step  1000 :  64.32348839950562\n",
      "Epoch:  546  Average loss at step  1227 :  63.844305879832966\n",
      "546 3 12.609388828277588\n",
      "Epoch:  546  Average loss at step  1000 :  5.333971613407135\n",
      "Epoch:  546  Average loss at step  2000 :  5.2717010569572444\n",
      "Epoch:  546  Average loss at step  3000 :  5.217180155277252\n",
      "Epoch:  546  Average loss at step  3222 :  5.122853506986663\n",
      "546 4 33.28082227706909\n",
      "546 5 1.6689300537109375e-06\n",
      "Training time took 98.724188 seconds to run 1 epoch\n",
      "Epoch:  547  Average loss at step  1000 :  0.059173541486263276\n",
      "Epoch:  547  Average loss at step  2000 :  0.061908119440078735\n",
      "Epoch:  547  Average loss at step  3000 :  0.06722694462537765\n",
      "Epoch:  547  Average loss at step  3222 :  0.0702409346432091\n",
      "547 0 29.397928714752197\n",
      "Training time took 29.51964 seconds to run 1 epoch\n",
      "Epoch:  548  Average loss at step  1000 :  7.971716739654541\n",
      "Epoch:  548  Average loss at step  2000 :  8.453487632751465\n",
      "Epoch:  548  Average loss at step  3000 :  8.328865892410278\n",
      "Epoch:  548  Average loss at step  4000 :  8.175355648517609\n",
      "Epoch:  548  Average loss at step  5000 :  7.954824110984802\n",
      "Epoch:  548  Average loss at step  6000 :  8.293737273216248\n",
      "Epoch:  548  Average loss at step  7000 :  8.472668862342834\n",
      "Epoch:  548  Average loss at step  8000 :  7.920643755435943\n",
      "Epoch:  548  Average loss at step  8472 :  8.168910582985115\n",
      "548 0 20.6110258102417\n",
      "Epoch:  548  Average loss at step  1000 :  2619.4620072021485\n",
      "Epoch:  548  Average loss at step  1491 :  2631.73986515787\n",
      "548 1 11.735720872879028\n",
      "Epoch:  548  Average loss at step  1000 :  3683.4026918945315\n",
      "Epoch:  548  Average loss at step  2000 :  3688.0113060302733\n",
      "Epoch:  548  Average loss at step  2533 :  3643.617735671553\n",
      "548 2 19.897589206695557\n",
      "Epoch:  548  Average loss at step  1000 :  63.91101942825318\n",
      "Epoch:  548  Average loss at step  1227 :  63.83444078021084\n",
      "548 3 12.576586484909058\n",
      "Epoch:  548  Average loss at step  1000 :  5.2587031602859495\n",
      "Epoch:  548  Average loss at step  2000 :  5.2588678665161135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  548  Average loss at step  3000 :  5.255294511795044\n",
      "Epoch:  548  Average loss at step  3222 :  5.440227217914439\n",
      "548 4 33.229028940200806\n",
      "548 5 9.5367431640625e-07\n",
      "Training time took 98.687775 seconds to run 1 epoch\n",
      "Epoch:  549  Average loss at step  1000 :  0.058766509175300595\n",
      "Epoch:  549  Average loss at step  2000 :  0.061446171641349794\n",
      "Epoch:  549  Average loss at step  3000 :  0.06693046492338181\n",
      "Epoch:  549  Average loss at step  3222 :  0.07062588659816108\n",
      "549 0 29.38126540184021\n",
      "Training time took 29.501196 seconds to run 1 epoch\n",
      "Epoch:  550  Average loss at step  1000 :  7.769097330570221\n",
      "Epoch:  550  Average loss at step  2000 :  7.824553712844849\n",
      "Epoch:  550  Average loss at step  3000 :  8.189984931468963\n",
      "Epoch:  550  Average loss at step  4000 :  8.405395576477051\n",
      "Epoch:  550  Average loss at step  5000 :  7.972904730796814\n",
      "Epoch:  550  Average loss at step  6000 :  8.30742341184616\n",
      "Epoch:  550  Average loss at step  7000 :  7.6424418940544125\n",
      "Epoch:  550  Average loss at step  8000 :  7.958440323829651\n",
      "Epoch:  550  Average loss at step  8472 :  8.052842041555747\n",
      "550 0 20.109296560287476\n",
      "Epoch:  550  Average loss at step  1000 :  2647.216470336914\n",
      "Epoch:  550  Average loss at step  1491 :  2673.4046129006742\n",
      "550 1 11.74599027633667\n",
      "Epoch:  550  Average loss at step  1000 :  3685.0669107666017\n",
      "Epoch:  550  Average loss at step  2000 :  3704.549173828125\n",
      "Epoch:  550  Average loss at step  2533 :  3684.567499693115\n",
      "550 2 19.878899097442627\n",
      "Epoch:  550  Average loss at step  1000 :  63.95354039764404\n",
      "Epoch:  550  Average loss at step  1227 :  63.47783780746941\n",
      "550 3 12.660261392593384\n",
      "Epoch:  550  Average loss at step  1000 :  5.339321345329284\n",
      "Epoch:  550  Average loss at step  2000 :  5.174449127197265\n",
      "Epoch:  550  Average loss at step  3000 :  5.144201374053955\n",
      "Epoch:  550  Average loss at step  3222 :  5.265386056374893\n",
      "550 4 33.318323850631714\n",
      "550 5 1.1920928955078125e-06\n",
      "Training time took 98.349821 seconds to run 1 epoch\n",
      "Mean Rank:  156.84608  of  75000\n",
      "Hits @ 10:  0.85556\n",
      "Hits @ 1:  0.61784\n",
      "Testing time took 163.664912 seconds.\n",
      "\n",
      "Epoch:  551  Average loss at step  1000 :  0.05866588115692139\n",
      "Epoch:  551  Average loss at step  2000 :  0.06167697793245316\n",
      "Epoch:  551  Average loss at step  3000 :  0.06686443334817886\n",
      "Epoch:  551  Average loss at step  3222 :  0.07053810667961508\n",
      "551 0 29.515048265457153\n",
      "Training time took 29.626994 seconds to run 1 epoch\n",
      "Epoch:  552  Average loss at step  1000 :  7.942843305587768\n",
      "Epoch:  552  Average loss at step  2000 :  8.025682831287384\n",
      "Epoch:  552  Average loss at step  3000 :  8.165946795463562\n",
      "Epoch:  552  Average loss at step  4000 :  8.186778680324554\n",
      "Epoch:  552  Average loss at step  5000 :  7.886602281570434\n",
      "Epoch:  552  Average loss at step  6000 :  7.725049838066101\n",
      "Epoch:  552  Average loss at step  7000 :  8.063493560791015\n",
      "Epoch:  552  Average loss at step  8000 :  7.887037274360657\n",
      "Epoch:  552  Average loss at step  8472 :  7.69208995349075\n",
      "552 0 20.59890055656433\n",
      "Epoch:  552  Average loss at step  1000 :  2632.947618774414\n",
      "Epoch:  552  Average loss at step  1491 :  2602.9156608395833\n",
      "552 1 11.714967489242554\n",
      "Epoch:  552  Average loss at step  1000 :  3673.1000524902342\n",
      "Epoch:  552  Average loss at step  2000 :  3667.1264438476564\n",
      "Epoch:  552  Average loss at step  2533 :  3636.874130737135\n",
      "552 2 19.907163858413696\n",
      "Epoch:  552  Average loss at step  1000 :  64.00556299972534\n",
      "Epoch:  552  Average loss at step  1227 :  62.957489758200076\n",
      "552 3 12.675684213638306\n",
      "Epoch:  552  Average loss at step  1000 :  5.28990096616745\n",
      "Epoch:  552  Average loss at step  2000 :  5.184098369121552\n",
      "Epoch:  552  Average loss at step  3000 :  5.268078442573548\n",
      "Epoch:  552  Average loss at step  3222 :  5.227070955361543\n",
      "552 4 33.18637180328369\n",
      "552 5 1.430511474609375e-06\n",
      "Training time took 98.720221 seconds to run 1 epoch\n",
      "Epoch:  553  Average loss at step  1000 :  0.05824969744682312\n",
      "Epoch:  553  Average loss at step  2000 :  0.061330152690410616\n",
      "Epoch:  553  Average loss at step  3000 :  0.06682191222906113\n",
      "Epoch:  553  Average loss at step  3222 :  0.06962017416631214\n",
      "553 0 29.41797161102295\n",
      "Training time took 29.537026 seconds to run 1 epoch\n",
      "Epoch:  554  Average loss at step  1000 :  8.049285313606262\n",
      "Epoch:  554  Average loss at step  2000 :  7.809963588237762\n",
      "Epoch:  554  Average loss at step  3000 :  7.8225697422027585\n",
      "Epoch:  554  Average loss at step  4000 :  8.174235884666443\n",
      "Epoch:  554  Average loss at step  5000 :  8.338360257148743\n",
      "Epoch:  554  Average loss at step  6000 :  8.033877010345458\n",
      "Epoch:  554  Average loss at step  7000 :  7.954167268753052\n",
      "Epoch:  554  Average loss at step  8000 :  8.204996354103088\n",
      "Epoch:  554  Average loss at step  8472 :  8.659444479235798\n",
      "554 0 20.4156277179718\n",
      "Epoch:  554  Average loss at step  1000 :  2634.573006713867\n",
      "Epoch:  554  Average loss at step  1491 :  2659.071131129231\n",
      "554 1 11.753789186477661\n",
      "Epoch:  554  Average loss at step  1000 :  3658.163658447266\n",
      "Epoch:  554  Average loss at step  2000 :  3712.7808431396484\n",
      "Epoch:  554  Average loss at step  2533 :  3655.0315558388334\n",
      "554 2 19.95186948776245\n",
      "Epoch:  554  Average loss at step  1000 :  64.15529663467407\n",
      "Epoch:  554  Average loss at step  1227 :  63.29235506556308\n",
      "554 3 12.674104690551758\n",
      "Epoch:  554  Average loss at step  1000 :  5.338342358112335\n",
      "Epoch:  554  Average loss at step  2000 :  5.17186098241806\n",
      "Epoch:  554  Average loss at step  3000 :  5.1898971714973445\n",
      "Epoch:  554  Average loss at step  3222 :  5.2388518182438055\n",
      "554 4 33.272828340530396\n",
      "554 5 1.430511474609375e-06\n",
      "Training time took 98.686941 seconds to run 1 epoch\n",
      "Epoch:  555  Average loss at step  1000 :  0.05789072877168656\n",
      "Epoch:  555  Average loss at step  2000 :  0.06140128797292709\n",
      "Epoch:  555  Average loss at step  3000 :  0.06638417780399322\n",
      "Epoch:  555  Average loss at step  3222 :  0.0701063716964701\n",
      "555 0 29.324003219604492\n",
      "Training time took 29.440281 seconds to run 1 epoch\n",
      "Epoch:  556  Average loss at step  1000 :  8.074194422721863\n",
      "Epoch:  556  Average loss at step  2000 :  8.731763355255127\n",
      "Epoch:  556  Average loss at step  3000 :  7.671492987632751\n",
      "Epoch:  556  Average loss at step  4000 :  7.948146815776825\n",
      "Epoch:  556  Average loss at step  5000 :  8.26589468574524\n",
      "Epoch:  556  Average loss at step  6000 :  7.9802176823616024\n",
      "Epoch:  556  Average loss at step  7000 :  8.066605093955994\n",
      "Epoch:  556  Average loss at step  8000 :  7.494673341751098\n",
      "Epoch:  556  Average loss at step  8472 :  8.47368637231649\n",
      "556 0 20.688904762268066\n",
      "Epoch:  556  Average loss at step  1000 :  2605.360147583008\n",
      "Epoch:  556  Average loss at step  1491 :  2608.1175740829267\n",
      "556 1 11.750126123428345\n",
      "Epoch:  556  Average loss at step  1000 :  3661.1468381347654\n",
      "Epoch:  556  Average loss at step  2000 :  3654.0572958984376\n",
      "Epoch:  556  Average loss at step  2533 :  3688.327676455957\n",
      "556 2 19.890496730804443\n",
      "Epoch:  556  Average loss at step  1000 :  63.93503843688965\n",
      "Epoch:  556  Average loss at step  1227 :  62.850336599987386\n",
      "556 3 12.70693325996399\n",
      "Epoch:  556  Average loss at step  1000 :  5.14439972448349\n",
      "Epoch:  556  Average loss at step  2000 :  5.133407938480377\n",
      "Epoch:  556  Average loss at step  3000 :  5.079956085681915\n",
      "Epoch:  556  Average loss at step  3222 :  5.181779752119415\n",
      "556 4 33.0127637386322\n",
      "556 5 1.430511474609375e-06\n",
      "Training time took 98.681147 seconds to run 1 epoch\n",
      "Epoch:  557  Average loss at step  1000 :  0.058215746104717254\n",
      "Epoch:  557  Average loss at step  2000 :  0.06087031066417694\n",
      "Epoch:  557  Average loss at step  3000 :  0.06616931974887848\n",
      "Epoch:  557  Average loss at step  3222 :  0.06917831182781163\n",
      "557 0 29.450008630752563\n",
      "Training time took 29.568305 seconds to run 1 epoch\n",
      "Epoch:  558  Average loss at step  1000 :  7.9705228986740115\n",
      "Epoch:  558  Average loss at step  2000 :  8.432074843406678\n",
      "Epoch:  558  Average loss at step  3000 :  8.326384983062745\n",
      "Epoch:  558  Average loss at step  4000 :  8.111521077156066\n",
      "Epoch:  558  Average loss at step  5000 :  8.012382297515869\n",
      "Epoch:  558  Average loss at step  6000 :  8.138720589637757\n",
      "Epoch:  558  Average loss at step  7000 :  8.547321725845338\n",
      "Epoch:  558  Average loss at step  8000 :  7.523151421546936\n",
      "Epoch:  558  Average loss at step  8472 :  8.325951097675487\n",
      "558 0 20.67462682723999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  558  Average loss at step  1000 :  2623.542762207031\n",
      "Epoch:  558  Average loss at step  1491 :  2610.061989827502\n",
      "558 1 11.701984643936157\n",
      "Epoch:  558  Average loss at step  1000 :  3698.274527709961\n",
      "Epoch:  558  Average loss at step  2000 :  3704.2606645507813\n",
      "Epoch:  558  Average loss at step  2533 :  3681.876709663487\n",
      "558 2 19.912684679031372\n",
      "Epoch:  558  Average loss at step  1000 :  63.0516573677063\n",
      "Epoch:  558  Average loss at step  1227 :  63.37645075426065\n",
      "558 3 12.68265414237976\n",
      "Epoch:  558  Average loss at step  1000 :  5.10809983253479\n",
      "Epoch:  558  Average loss at step  2000 :  5.181862570285797\n",
      "Epoch:  558  Average loss at step  3000 :  5.164114535331726\n",
      "Epoch:  558  Average loss at step  3222 :  5.05581767276255\n",
      "558 4 33.26661205291748\n",
      "558 5 1.430511474609375e-06\n",
      "Training time took 98.888889 seconds to run 1 epoch\n",
      "Epoch:  559  Average loss at step  1000 :  0.057864568471908566\n",
      "Epoch:  559  Average loss at step  2000 :  0.061406446218490604\n",
      "Epoch:  559  Average loss at step  3000 :  0.06568632990121842\n",
      "Epoch:  559  Average loss at step  3222 :  0.06959373597139742\n",
      "559 0 29.40322518348694\n",
      "Training time took 29.519132 seconds to run 1 epoch\n",
      "Epoch:  560  Average loss at step  1000 :  8.254829707622529\n",
      "Epoch:  560  Average loss at step  2000 :  7.986588284492493\n",
      "Epoch:  560  Average loss at step  3000 :  8.085571497917176\n",
      "Epoch:  560  Average loss at step  4000 :  8.19366588306427\n",
      "Epoch:  560  Average loss at step  5000 :  8.223554885864258\n",
      "Epoch:  560  Average loss at step  6000 :  8.692676254272461\n",
      "Epoch:  560  Average loss at step  7000 :  8.17650321340561\n",
      "Epoch:  560  Average loss at step  8000 :  8.051569071769714\n",
      "Epoch:  560  Average loss at step  8472 :  8.302688655300358\n",
      "560 0 20.914196491241455\n",
      "Epoch:  560  Average loss at step  1000 :  2643.129687988281\n",
      "Epoch:  560  Average loss at step  1491 :  2644.9771548765702\n",
      "560 1 11.708916187286377\n",
      "Epoch:  560  Average loss at step  1000 :  3718.6304470214845\n",
      "Epoch:  560  Average loss at step  2000 :  3693.3954104003906\n",
      "Epoch:  560  Average loss at step  2533 :  3703.5614090530794\n",
      "560 2 19.913255214691162\n",
      "Epoch:  560  Average loss at step  1000 :  63.58853227233887\n",
      "Epoch:  560  Average loss at step  1227 :  62.45680470878301\n",
      "560 3 12.580599546432495\n",
      "Epoch:  560  Average loss at step  1000 :  5.183866557598114\n",
      "Epoch:  560  Average loss at step  2000 :  5.088395024776458\n",
      "Epoch:  560  Average loss at step  3000 :  5.081857344150543\n",
      "Epoch:  560  Average loss at step  3222 :  5.294047182788701\n",
      "560 4 33.22316575050354\n",
      "560 5 9.5367431640625e-07\n",
      "Training time took 98.983793 seconds to run 1 epoch\n",
      "Mean Rank:  158.11336  of  75000\n",
      "Hits @ 10:  0.8548\n",
      "Hits @ 1:  0.61888\n",
      "Testing time took 164.103156 seconds.\n",
      "\n",
      "Epoch:  561  Average loss at step  1000 :  0.057487699508666994\n",
      "Epoch:  561  Average loss at step  2000 :  0.060556237637996675\n",
      "Epoch:  561  Average loss at step  3000 :  0.06621064829826355\n",
      "Epoch:  561  Average loss at step  3222 :  0.06946526127486566\n",
      "561 0 29.425605535507202\n",
      "Training time took 29.536277 seconds to run 1 epoch\n",
      "Epoch:  562  Average loss at step  1000 :  8.004693461418151\n",
      "Epoch:  562  Average loss at step  2000 :  7.648717449188233\n",
      "Epoch:  562  Average loss at step  3000 :  7.805190237522125\n",
      "Epoch:  562  Average loss at step  4000 :  8.252362114906312\n",
      "Epoch:  562  Average loss at step  5000 :  7.815727783203125\n",
      "Epoch:  562  Average loss at step  6000 :  8.172748093605042\n",
      "Epoch:  562  Average loss at step  7000 :  8.053035957336427\n",
      "Epoch:  562  Average loss at step  8000 :  8.463999849319459\n",
      "Epoch:  562  Average loss at step  8472 :  8.2406216255448\n",
      "562 0 20.59007167816162\n",
      "Epoch:  562  Average loss at step  1000 :  2612.073294921875\n",
      "Epoch:  562  Average loss at step  1491 :  2669.0458642927233\n",
      "562 1 11.631630182266235\n",
      "Epoch:  562  Average loss at step  1000 :  3710.077898681641\n",
      "Epoch:  562  Average loss at step  2000 :  3671.1738098144533\n",
      "Epoch:  562  Average loss at step  2533 :  3699.730640473467\n",
      "562 2 19.938292503356934\n",
      "Epoch:  562  Average loss at step  1000 :  63.40363901901245\n",
      "Epoch:  562  Average loss at step  1227 :  64.10356061240964\n",
      "562 3 12.664967060089111\n",
      "Epoch:  562  Average loss at step  1000 :  5.182884455680847\n",
      "Epoch:  562  Average loss at step  2000 :  5.052905324459076\n",
      "Epoch:  562  Average loss at step  3000 :  5.1283353629112245\n",
      "Epoch:  562  Average loss at step  3222 :  4.884505857304775\n",
      "562 4 33.13552141189575\n",
      "562 5 1.6689300537109375e-06\n",
      "Training time took 98.591301 seconds to run 1 epoch\n",
      "Epoch:  563  Average loss at step  1000 :  0.05780850672721863\n",
      "Epoch:  563  Average loss at step  2000 :  0.060057434916496275\n",
      "Epoch:  563  Average loss at step  3000 :  0.06541831874847412\n",
      "Epoch:  563  Average loss at step  3222 :  0.06931345667041022\n",
      "563 0 29.430582284927368\n",
      "Training time took 29.556793 seconds to run 1 epoch\n",
      "Epoch:  564  Average loss at step  1000 :  8.478761981010438\n",
      "Epoch:  564  Average loss at step  2000 :  8.153738549232482\n",
      "Epoch:  564  Average loss at step  3000 :  8.180492127418518\n",
      "Epoch:  564  Average loss at step  4000 :  7.612260811805725\n",
      "Epoch:  564  Average loss at step  5000 :  8.400260780334472\n",
      "Epoch:  564  Average loss at step  6000 :  7.858141688346863\n",
      "Epoch:  564  Average loss at step  7000 :  8.008175537109375\n",
      "Epoch:  564  Average loss at step  8000 :  8.199970553398133\n",
      "Epoch:  564  Average loss at step  8472 :  8.077941336113064\n",
      "564 0 20.751654386520386\n",
      "Epoch:  564  Average loss at step  1000 :  2638.7515852050783\n",
      "Epoch:  564  Average loss at step  1491 :  2683.2314411451066\n",
      "564 1 11.705965518951416\n",
      "Epoch:  564  Average loss at step  1000 :  3696.533978881836\n",
      "Epoch:  564  Average loss at step  2000 :  3695.0419357910155\n",
      "Epoch:  564  Average loss at step  2533 :  3699.5797237480415\n",
      "564 2 19.870341300964355\n",
      "Epoch:  564  Average loss at step  1000 :  64.09141773605347\n",
      "Epoch:  564  Average loss at step  1227 :  64.00091853103709\n",
      "564 3 12.64248538017273\n",
      "Epoch:  564  Average loss at step  1000 :  5.184731791973114\n",
      "Epoch:  564  Average loss at step  2000 :  5.155430098056793\n",
      "Epoch:  564  Average loss at step  3000 :  5.0277499327659605\n",
      "Epoch:  564  Average loss at step  3222 :  5.183353452481051\n",
      "564 4 33.18906831741333\n",
      "564 5 1.430511474609375e-06\n",
      "Training time took 98.779758 seconds to run 1 epoch\n",
      "Epoch:  565  Average loss at step  1000 :  0.05709172433614731\n",
      "Epoch:  565  Average loss at step  2000 :  0.060092839181423184\n",
      "Epoch:  565  Average loss at step  3000 :  0.0659004567861557\n",
      "Epoch:  565  Average loss at step  3222 :  0.06817547928277584\n",
      "565 0 29.37564992904663\n",
      "Training time took 29.503084 seconds to run 1 epoch\n",
      "Epoch:  566  Average loss at step  1000 :  7.893522123336792\n",
      "Epoch:  566  Average loss at step  2000 :  8.084521003723145\n",
      "Epoch:  566  Average loss at step  3000 :  7.717934824943542\n",
      "Epoch:  566  Average loss at step  4000 :  7.849176032066345\n",
      "Epoch:  566  Average loss at step  5000 :  8.118377596855163\n",
      "Epoch:  566  Average loss at step  6000 :  8.140223252296447\n",
      "Epoch:  566  Average loss at step  7000 :  7.872544169425964\n",
      "Epoch:  566  Average loss at step  8000 :  7.9842331428527835\n",
      "Epoch:  566  Average loss at step  8472 :  8.449455192177016\n",
      "566 0 21.485240697860718\n",
      "Epoch:  566  Average loss at step  1000 :  2654.711297363281\n",
      "Epoch:  566  Average loss at step  1491 :  2610.356215509101\n",
      "566 1 11.742043018341064\n",
      "Epoch:  566  Average loss at step  1000 :  3754.966858276367\n",
      "Epoch:  566  Average loss at step  2000 :  3732.504817626953\n",
      "Epoch:  566  Average loss at step  2533 :  3685.9955622075054\n",
      "566 2 19.89913535118103\n",
      "Epoch:  566  Average loss at step  1000 :  63.021492469787596\n",
      "Epoch:  566  Average loss at step  1227 :  63.90196122473979\n",
      "566 3 12.67193055152893\n",
      "Epoch:  566  Average loss at step  1000 :  5.136608503818512\n",
      "Epoch:  566  Average loss at step  2000 :  5.1202696232795715\n",
      "Epoch:  566  Average loss at step  3000 :  4.9417329730987545\n",
      "Epoch:  566  Average loss at step  3222 :  5.279584438023013\n",
      "566 4 33.20331692695618\n",
      "566 5 1.1920928955078125e-06\n",
      "Training time took 99.63493 seconds to run 1 epoch\n",
      "Epoch:  567  Average loss at step  1000 :  0.05720732009410858\n",
      "Epoch:  567  Average loss at step  2000 :  0.06028626710176468\n",
      "Epoch:  567  Average loss at step  3000 :  0.06525516194105148\n",
      "Epoch:  567  Average loss at step  3222 :  0.06895834550807613\n",
      "567 0 29.392059087753296\n",
      "Training time took 29.51304 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  568  Average loss at step  1000 :  8.116405543804168\n",
      "Epoch:  568  Average loss at step  2000 :  7.433250475883484\n",
      "Epoch:  568  Average loss at step  3000 :  8.075366582870483\n",
      "Epoch:  568  Average loss at step  4000 :  8.63533171749115\n",
      "Epoch:  568  Average loss at step  5000 :  8.671520382404328\n",
      "Epoch:  568  Average loss at step  6000 :  8.099707006454468\n",
      "Epoch:  568  Average loss at step  7000 :  8.026563117027283\n",
      "Epoch:  568  Average loss at step  8000 :  8.037591242790223\n",
      "Epoch:  568  Average loss at step  8472 :  8.932866208657845\n",
      "568 0 20.128634929656982\n",
      "Epoch:  568  Average loss at step  1000 :  2668.2685463867188\n",
      "Epoch:  568  Average loss at step  1491 :  2636.64029409504\n",
      "568 1 11.708629369735718\n",
      "Epoch:  568  Average loss at step  1000 :  3728.5929697265624\n",
      "Epoch:  568  Average loss at step  2000 :  3705.882337890625\n",
      "Epoch:  568  Average loss at step  2533 :  3667.351980373895\n",
      "568 2 19.989546060562134\n",
      "Epoch:  568  Average loss at step  1000 :  63.33948446655273\n",
      "Epoch:  568  Average loss at step  1227 :  63.05949217473666\n",
      "568 3 12.674683570861816\n",
      "Epoch:  568  Average loss at step  1000 :  5.0717078576087955\n",
      "Epoch:  568  Average loss at step  2000 :  4.968021909236908\n",
      "Epoch:  568  Average loss at step  3000 :  5.1413442735672\n",
      "Epoch:  568  Average loss at step  3222 :  4.923941941010778\n",
      "568 4 33.18493962287903\n",
      "568 5 1.1920928955078125e-06\n",
      "Training time took 98.300098 seconds to run 1 epoch\n",
      "Epoch:  569  Average loss at step  1000 :  0.05693378061056137\n",
      "Epoch:  569  Average loss at step  2000 :  0.06000687217712403\n",
      "Epoch:  569  Average loss at step  3000 :  0.06544345653057099\n",
      "Epoch:  569  Average loss at step  3222 :  0.06841175993936417\n",
      "569 0 29.361315727233887\n",
      "Training time took 29.486298 seconds to run 1 epoch\n",
      "Epoch:  570  Average loss at step  1000 :  7.922998309135437\n",
      "Epoch:  570  Average loss at step  2000 :  7.971525472640991\n",
      "Epoch:  570  Average loss at step  3000 :  8.297930621147156\n",
      "Epoch:  570  Average loss at step  4000 :  7.959069314956665\n",
      "Epoch:  570  Average loss at step  5000 :  8.439919003486633\n",
      "Epoch:  570  Average loss at step  6000 :  7.830139410018921\n",
      "Epoch:  570  Average loss at step  7000 :  8.18390273475647\n",
      "Epoch:  570  Average loss at step  8000 :  8.205091605186462\n",
      "Epoch:  570  Average loss at step  8472 :  8.009337966042702\n",
      "570 0 20.464056253433228\n",
      "Epoch:  570  Average loss at step  1000 :  2639.3646247558595\n",
      "Epoch:  570  Average loss at step  1491 :  2635.284511477658\n",
      "570 1 11.709792613983154\n",
      "Epoch:  570  Average loss at step  1000 :  3739.3955646972654\n",
      "Epoch:  570  Average loss at step  2000 :  3699.3963436279296\n",
      "Epoch:  570  Average loss at step  2533 :  3707.087992069592\n",
      "570 2 19.88940715789795\n",
      "Epoch:  570  Average loss at step  1000 :  63.800105823516844\n",
      "Epoch:  570  Average loss at step  1227 :  62.70042108428144\n",
      "570 3 12.683519124984741\n",
      "Epoch:  570  Average loss at step  1000 :  5.052356491088867\n",
      "Epoch:  570  Average loss at step  2000 :  5.0051720457077025\n",
      "Epoch:  570  Average loss at step  3000 :  5.010254465579987\n",
      "Epoch:  570  Average loss at step  3222 :  4.760903478378982\n",
      "570 4 33.359073877334595\n",
      "570 5 1.1920928955078125e-06\n",
      "Training time took 98.74103 seconds to run 1 epoch\n",
      "Mean Rank:  156.23292  of  75000\n",
      "Hits @ 10:  0.85448\n",
      "Hits @ 1:  0.61996\n",
      "Testing time took 163.964646 seconds.\n",
      "\n",
      "Epoch:  571  Average loss at step  1000 :  0.056994184732437135\n",
      "Epoch:  571  Average loss at step  2000 :  0.05935803544521332\n",
      "Epoch:  571  Average loss at step  3000 :  0.06468142038583756\n",
      "Epoch:  571  Average loss at step  3222 :  0.06824684075272713\n",
      "571 0 29.416911125183105\n",
      "Training time took 29.527008 seconds to run 1 epoch\n",
      "Epoch:  572  Average loss at step  1000 :  8.24433467388153\n",
      "Epoch:  572  Average loss at step  2000 :  7.857435146331787\n",
      "Epoch:  572  Average loss at step  3000 :  8.293949144363403\n",
      "Epoch:  572  Average loss at step  4000 :  7.951210129737854\n",
      "Epoch:  572  Average loss at step  5000 :  8.61250534915924\n",
      "Epoch:  572  Average loss at step  6000 :  8.324310012817383\n",
      "Epoch:  572  Average loss at step  7000 :  8.287123387336731\n",
      "Epoch:  572  Average loss at step  8000 :  8.414243490219116\n",
      "Epoch:  572  Average loss at step  8472 :  8.06088680110122\n",
      "572 0 20.34372591972351\n",
      "Epoch:  572  Average loss at step  1000 :  2649.3056220703124\n",
      "Epoch:  572  Average loss at step  1491 :  2690.7213341717984\n",
      "572 1 11.717839002609253\n",
      "Epoch:  572  Average loss at step  1000 :  3731.9202990722656\n",
      "Epoch:  572  Average loss at step  2000 :  3732.037296875\n",
      "Epoch:  572  Average loss at step  2533 :  3758.6209291480286\n",
      "572 2 19.904696464538574\n",
      "Epoch:  572  Average loss at step  1000 :  63.532331100463864\n",
      "Epoch:  572  Average loss at step  1227 :  63.0599226345534\n",
      "572 3 12.633336067199707\n",
      "Epoch:  572  Average loss at step  1000 :  5.08939775800705\n",
      "Epoch:  572  Average loss at step  2000 :  5.02358664560318\n",
      "Epoch:  572  Average loss at step  3000 :  4.9718198347091676\n",
      "Epoch:  572  Average loss at step  3222 :  4.841881365224243\n",
      "572 4 33.32085061073303\n",
      "572 5 1.6689300537109375e-06\n",
      "Training time took 98.552781 seconds to run 1 epoch\n",
      "Epoch:  573  Average loss at step  1000 :  0.05645570629835129\n",
      "Epoch:  573  Average loss at step  2000 :  0.059849434316158294\n",
      "Epoch:  573  Average loss at step  3000 :  0.06464092898368835\n",
      "Epoch:  573  Average loss at step  3222 :  0.06811883630768059\n",
      "573 0 29.30653738975525\n",
      "Training time took 29.425827 seconds to run 1 epoch\n",
      "Epoch:  574  Average loss at step  1000 :  7.798804874897003\n",
      "Epoch:  574  Average loss at step  2000 :  8.076494704246521\n",
      "Epoch:  574  Average loss at step  3000 :  7.822172756671906\n",
      "Epoch:  574  Average loss at step  4000 :  7.7854348621368406\n",
      "Epoch:  574  Average loss at step  5000 :  8.236167422771453\n",
      "Epoch:  574  Average loss at step  6000 :  8.427380958080292\n",
      "Epoch:  574  Average loss at step  7000 :  8.370097414970399\n",
      "Epoch:  574  Average loss at step  8000 :  8.003722506523133\n",
      "Epoch:  574  Average loss at step  8472 :  7.700908012530996\n",
      "574 0 20.873281478881836\n",
      "Epoch:  574  Average loss at step  1000 :  2681.6149942626953\n",
      "Epoch:  574  Average loss at step  1491 :  2667.2141862367725\n",
      "574 1 11.708567142486572\n",
      "Epoch:  574  Average loss at step  1000 :  3721.2484033203127\n",
      "Epoch:  574  Average loss at step  2000 :  3711.735276123047\n",
      "Epoch:  574  Average loss at step  2533 :  3688.5180692970634\n",
      "574 2 19.909608125686646\n",
      "Epoch:  574  Average loss at step  1000 :  63.53632354736328\n",
      "Epoch:  574  Average loss at step  1227 :  64.2531532243505\n",
      "574 3 12.677232265472412\n",
      "Epoch:  574  Average loss at step  1000 :  4.919983035564423\n",
      "Epoch:  574  Average loss at step  2000 :  5.006913662433624\n",
      "Epoch:  574  Average loss at step  3000 :  5.005104017257691\n",
      "Epoch:  574  Average loss at step  3222 :  5.06425594934855\n",
      "574 4 33.18934679031372\n",
      "574 5 1.430511474609375e-06\n",
      "Training time took 99.000533 seconds to run 1 epoch\n",
      "Epoch:  575  Average loss at step  1000 :  0.0570361276268959\n",
      "Epoch:  575  Average loss at step  2000 :  0.05921634638309479\n",
      "Epoch:  575  Average loss at step  3000 :  0.06441044044494629\n",
      "Epoch:  575  Average loss at step  3222 :  0.06741767735402923\n",
      "575 0 29.446886777877808\n",
      "Training time took 29.565411 seconds to run 1 epoch\n",
      "Epoch:  576  Average loss at step  1000 :  8.154593120574951\n",
      "Epoch:  576  Average loss at step  2000 :  7.419953978538513\n",
      "Epoch:  576  Average loss at step  3000 :  8.221187274932861\n",
      "Epoch:  576  Average loss at step  4000 :  7.821349298477172\n",
      "Epoch:  576  Average loss at step  5000 :  7.1208934412002565\n",
      "Epoch:  576  Average loss at step  6000 :  8.60395209312439\n",
      "Epoch:  576  Average loss at step  7000 :  7.7355352306365965\n",
      "Epoch:  576  Average loss at step  8000 :  8.181992426872254\n",
      "Epoch:  576  Average loss at step  8472 :  7.911129409856745\n",
      "576 0 20.87179923057556\n",
      "Epoch:  576  Average loss at step  1000 :  2673.50271862793\n",
      "Epoch:  576  Average loss at step  1491 :  2644.953255273314\n",
      "576 1 11.747898578643799\n",
      "Epoch:  576  Average loss at step  1000 :  3731.882624267578\n",
      "Epoch:  576  Average loss at step  2000 :  3712.6814284667967\n",
      "Epoch:  576  Average loss at step  2533 :  3677.9333592913044\n",
      "576 2 19.887840747833252\n",
      "Epoch:  576  Average loss at step  1000 :  63.84810376358032\n",
      "Epoch:  576  Average loss at step  1227 :  63.37058343785092\n",
      "576 3 12.65311574935913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  576  Average loss at step  1000 :  5.050339244365692\n",
      "Epoch:  576  Average loss at step  2000 :  4.895664205551148\n",
      "Epoch:  576  Average loss at step  3000 :  4.8974093894958495\n",
      "Epoch:  576  Average loss at step  3222 :  5.086198346368198\n",
      "576 4 33.14895796775818\n",
      "576 5 1.1920928955078125e-06\n",
      "Training time took 98.945812 seconds to run 1 epoch\n",
      "Epoch:  577  Average loss at step  1000 :  0.05641030091047287\n",
      "Epoch:  577  Average loss at step  2000 :  0.059223889470100405\n",
      "Epoch:  577  Average loss at step  3000 :  0.0645045741200447\n",
      "Epoch:  577  Average loss at step  3222 :  0.0676416763223709\n",
      "577 0 29.389856815338135\n",
      "Training time took 29.512743 seconds to run 1 epoch\n",
      "Epoch:  578  Average loss at step  1000 :  7.478193972587586\n",
      "Epoch:  578  Average loss at step  2000 :  7.927199656486511\n",
      "Epoch:  578  Average loss at step  3000 :  8.298247263908387\n",
      "Epoch:  578  Average loss at step  4000 :  7.863173565864563\n",
      "Epoch:  578  Average loss at step  5000 :  8.059211024284362\n",
      "Epoch:  578  Average loss at step  6000 :  7.7461189308166505\n",
      "Epoch:  578  Average loss at step  7000 :  7.9995357685089115\n",
      "Epoch:  578  Average loss at step  8000 :  8.434556240081788\n",
      "Epoch:  578  Average loss at step  8472 :  8.650996736534827\n",
      "578 0 20.83964228630066\n",
      "Epoch:  578  Average loss at step  1000 :  2639.960816894531\n",
      "Epoch:  578  Average loss at step  1491 :  2694.1376342238837\n",
      "578 1 11.74703049659729\n",
      "Epoch:  578  Average loss at step  1000 :  3750.080919555664\n",
      "Epoch:  578  Average loss at step  2000 :  3728.235955566406\n",
      "Epoch:  578  Average loss at step  2533 :  3690.180399392515\n",
      "578 2 19.84213352203369\n",
      "Epoch:  578  Average loss at step  1000 :  63.17866703414917\n",
      "Epoch:  578  Average loss at step  1227 :  63.82023750796928\n",
      "578 3 12.624510288238525\n",
      "Epoch:  578  Average loss at step  1000 :  4.953312703609466\n",
      "Epoch:  578  Average loss at step  2000 :  4.991201378822327\n",
      "Epoch:  578  Average loss at step  3000 :  4.832455649852752\n",
      "Epoch:  578  Average loss at step  3222 :  4.880372185336056\n",
      "578 4 33.15737009048462\n",
      "578 5 1.430511474609375e-06\n",
      "Training time took 98.855152 seconds to run 1 epoch\n",
      "Epoch:  579  Average loss at step  1000 :  0.05616550129652023\n",
      "Epoch:  579  Average loss at step  2000 :  0.05891176748275757\n",
      "Epoch:  579  Average loss at step  3000 :  0.06433361148834228\n",
      "Epoch:  579  Average loss at step  3222 :  0.06765988350215855\n",
      "579 0 29.382563591003418\n",
      "Training time took 29.508719 seconds to run 1 epoch\n",
      "Epoch:  580  Average loss at step  1000 :  8.048586559295654\n",
      "Epoch:  580  Average loss at step  2000 :  8.41479818725586\n",
      "Epoch:  580  Average loss at step  3000 :  8.131875855445863\n",
      "Epoch:  580  Average loss at step  4000 :  7.769316820144653\n",
      "Epoch:  580  Average loss at step  5000 :  7.74362361907959\n",
      "Epoch:  580  Average loss at step  6000 :  8.747613391399383\n",
      "Epoch:  580  Average loss at step  7000 :  8.20728972530365\n",
      "Epoch:  580  Average loss at step  8000 :  7.94404927444458\n",
      "Epoch:  580  Average loss at step  8472 :  8.200187163180736\n",
      "580 0 20.8615083694458\n",
      "Epoch:  580  Average loss at step  1000 :  2630.0768828125\n",
      "Epoch:  580  Average loss at step  1491 :  2655.1463737749655\n",
      "580 1 11.711240530014038\n",
      "Epoch:  580  Average loss at step  1000 :  3727.8524921875\n",
      "Epoch:  580  Average loss at step  2000 :  3698.2125200195314\n",
      "Epoch:  580  Average loss at step  2533 :  3707.923844019883\n",
      "580 2 19.93007230758667\n",
      "Epoch:  580  Average loss at step  1000 :  63.09665510177612\n",
      "Epoch:  580  Average loss at step  1227 :  62.302310142697166\n",
      "580 3 12.730636358261108\n",
      "Epoch:  580  Average loss at step  1000 :  5.026327212810516\n",
      "Epoch:  580  Average loss at step  2000 :  5.010965641975403\n",
      "Epoch:  580  Average loss at step  3000 :  4.934409964084625\n",
      "Epoch:  580  Average loss at step  3222 :  4.8088857425552645\n",
      "580 4 33.28705382347107\n",
      "580 5 1.430511474609375e-06\n",
      "Training time took 99.150641 seconds to run 1 epoch\n",
      "Mean Rank:  156.8916  of  75000\n",
      "Hits @ 10:  0.85464\n",
      "Hits @ 1:  0.62008\n",
      "Testing time took 163.633382 seconds.\n",
      "\n",
      "Epoch:  581  Average loss at step  1000 :  0.05615201336145401\n",
      "Epoch:  581  Average loss at step  2000 :  0.05865097653865814\n",
      "Epoch:  581  Average loss at step  3000 :  0.06414608204364777\n",
      "Epoch:  581  Average loss at step  3222 :  0.06680548390147273\n",
      "581 0 29.429039478302002\n",
      "Training time took 29.536882 seconds to run 1 epoch\n",
      "Epoch:  582  Average loss at step  1000 :  8.078684150695802\n",
      "Epoch:  582  Average loss at step  2000 :  8.187198460578918\n",
      "Epoch:  582  Average loss at step  3000 :  8.355902557373048\n",
      "Epoch:  582  Average loss at step  4000 :  7.876052026748657\n",
      "Epoch:  582  Average loss at step  5000 :  7.738048869609833\n",
      "Epoch:  582  Average loss at step  6000 :  7.927169155597687\n",
      "Epoch:  582  Average loss at step  7000 :  7.910577446937561\n",
      "Epoch:  582  Average loss at step  8000 :  7.898784993171692\n",
      "Epoch:  582  Average loss at step  8472 :  7.8881509943276775\n",
      "582 0 20.203765869140625\n",
      "Epoch:  582  Average loss at step  1000 :  2657.7375107421876\n",
      "Epoch:  582  Average loss at step  1491 :  2681.0893243575174\n",
      "582 1 11.721665143966675\n",
      "Epoch:  582  Average loss at step  1000 :  3722.3978348388673\n",
      "Epoch:  582  Average loss at step  2000 :  3735.344116455078\n",
      "Epoch:  582  Average loss at step  2533 :  3704.2153022237567\n",
      "582 2 19.900840997695923\n",
      "Epoch:  582  Average loss at step  1000 :  62.85458748626709\n",
      "Epoch:  582  Average loss at step  1227 :  62.48084108814878\n",
      "582 3 12.612715482711792\n",
      "Epoch:  582  Average loss at step  1000 :  4.970848225593567\n",
      "Epoch:  582  Average loss at step  2000 :  4.928965184688568\n",
      "Epoch:  582  Average loss at step  3000 :  4.895923337459564\n",
      "Epoch:  582  Average loss at step  3222 :  4.8418828997290895\n",
      "582 4 33.22653388977051\n",
      "582 5 1.430511474609375e-06\n",
      "Training time took 98.295497 seconds to run 1 epoch\n",
      "Epoch:  583  Average loss at step  1000 :  0.05602715390920639\n",
      "Epoch:  583  Average loss at step  2000 :  0.05892895883321762\n",
      "Epoch:  583  Average loss at step  3000 :  0.06377175217866897\n",
      "Epoch:  583  Average loss at step  3222 :  0.06657863087248643\n",
      "583 0 29.423452138900757\n",
      "Training time took 29.541461 seconds to run 1 epoch\n",
      "Epoch:  584  Average loss at step  1000 :  7.404586988449097\n",
      "Epoch:  584  Average loss at step  2000 :  8.337211868286133\n",
      "Epoch:  584  Average loss at step  3000 :  8.173061789512634\n",
      "Epoch:  584  Average loss at step  4000 :  8.492074911117554\n",
      "Epoch:  584  Average loss at step  5000 :  8.366873517990113\n",
      "Epoch:  584  Average loss at step  6000 :  8.448578380584717\n",
      "Epoch:  584  Average loss at step  7000 :  8.37581930065155\n",
      "Epoch:  584  Average loss at step  8000 :  8.01875136089325\n",
      "Epoch:  584  Average loss at step  8472 :  8.404299338662023\n",
      "584 0 21.404643535614014\n",
      "Epoch:  584  Average loss at step  1000 :  2661.985852294922\n",
      "Epoch:  584  Average loss at step  1491 :  2693.013929417922\n",
      "584 1 11.715701818466187\n",
      "Epoch:  584  Average loss at step  1000 :  3754.607487426758\n",
      "Epoch:  584  Average loss at step  2000 :  3733.22816015625\n",
      "Epoch:  584  Average loss at step  2533 :  3714.404096353531\n",
      "584 2 19.902288913726807\n",
      "Epoch:  584  Average loss at step  1000 :  63.20420809173584\n",
      "Epoch:  584  Average loss at step  1227 :  64.45607645518885\n",
      "584 3 12.691413164138794\n",
      "Epoch:  584  Average loss at step  1000 :  4.963181970119476\n",
      "Epoch:  584  Average loss at step  2000 :  4.889261235713959\n",
      "Epoch:  584  Average loss at step  3000 :  4.8864226779937745\n",
      "Epoch:  584  Average loss at step  3222 :  4.8308959483325555\n",
      "584 4 33.12328028678894\n",
      "584 5 1.430511474609375e-06\n",
      "Training time took 99.468808 seconds to run 1 epoch\n",
      "Epoch:  585  Average loss at step  1000 :  0.05540643632411957\n",
      "Epoch:  585  Average loss at step  2000 :  0.05835137802362442\n",
      "Epoch:  585  Average loss at step  3000 :  0.06377523076534271\n",
      "Epoch:  585  Average loss at step  3222 :  0.06750556434356557\n",
      "585 0 29.419235229492188\n",
      "Training time took 29.542638 seconds to run 1 epoch\n",
      "Epoch:  586  Average loss at step  1000 :  7.852814192771912\n",
      "Epoch:  586  Average loss at step  2000 :  8.139866727828979\n",
      "Epoch:  586  Average loss at step  3000 :  7.994394315719605\n",
      "Epoch:  586  Average loss at step  4000 :  8.378263451576233\n",
      "Epoch:  586  Average loss at step  5000 :  7.9265287466049195\n",
      "Epoch:  586  Average loss at step  6000 :  8.055726892948151\n",
      "Epoch:  586  Average loss at step  7000 :  8.1224805059433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  586  Average loss at step  8000 :  7.851798471450806\n",
      "Epoch:  586  Average loss at step  8472 :  7.888335067718584\n",
      "586 0 20.315603256225586\n",
      "Epoch:  586  Average loss at step  1000 :  2653.434228393555\n",
      "Epoch:  586  Average loss at step  1491 :  2641.9287936388746\n",
      "586 1 11.71383547782898\n",
      "Epoch:  586  Average loss at step  1000 :  3757.8077163085936\n",
      "Epoch:  586  Average loss at step  2000 :  3744.5352497558592\n",
      "Epoch:  586  Average loss at step  2533 :  3750.3914091903703\n",
      "586 2 19.91673445701599\n",
      "Epoch:  586  Average loss at step  1000 :  63.25789738082886\n",
      "Epoch:  586  Average loss at step  1227 :  62.58750818253994\n",
      "586 3 12.606560230255127\n",
      "Epoch:  586  Average loss at step  1000 :  4.811845821380615\n",
      "Epoch:  586  Average loss at step  2000 :  4.858722150325775\n",
      "Epoch:  586  Average loss at step  3000 :  4.881790963172913\n",
      "Epoch:  586  Average loss at step  3222 :  4.946720180452935\n",
      "586 4 33.32987999916077\n",
      "586 5 1.1920928955078125e-06\n",
      "Training time took 98.524248 seconds to run 1 epoch\n",
      "Epoch:  587  Average loss at step  1000 :  0.05575932443141937\n",
      "Epoch:  587  Average loss at step  2000 :  0.058395098030567166\n",
      "Epoch:  587  Average loss at step  3000 :  0.06368639719486237\n",
      "Epoch:  587  Average loss at step  3222 :  0.06669807636387018\n",
      "587 0 29.390196323394775\n",
      "Training time took 29.509959 seconds to run 1 epoch\n",
      "Epoch:  588  Average loss at step  1000 :  8.436737159729004\n",
      "Epoch:  588  Average loss at step  2000 :  8.418289842128754\n",
      "Epoch:  588  Average loss at step  3000 :  7.704642048835755\n",
      "Epoch:  588  Average loss at step  4000 :  7.863966484069824\n",
      "Epoch:  588  Average loss at step  5000 :  8.119843560218811\n",
      "Epoch:  588  Average loss at step  6000 :  8.079557900905609\n",
      "Epoch:  588  Average loss at step  7000 :  7.61161802482605\n",
      "Epoch:  588  Average loss at step  8000 :  8.2324880027771\n",
      "Epoch:  588  Average loss at step  8472 :  8.129026926128969\n",
      "588 0 20.963658332824707\n",
      "Epoch:  588  Average loss at step  1000 :  2678.762262084961\n",
      "Epoch:  588  Average loss at step  1491 :  2671.4983586437666\n",
      "588 1 11.744369745254517\n",
      "Epoch:  588  Average loss at step  1000 :  3788.0152568359376\n",
      "Epoch:  588  Average loss at step  2000 :  3726.1041905517577\n",
      "Epoch:  588  Average loss at step  2533 :  3742.500973102702\n",
      "588 2 19.909406185150146\n",
      "Epoch:  588  Average loss at step  1000 :  63.58582947921753\n",
      "Epoch:  588  Average loss at step  1227 :  62.580445514661626\n",
      "588 3 12.53584623336792\n",
      "Epoch:  588  Average loss at step  1000 :  5.040362155914306\n",
      "Epoch:  588  Average loss at step  2000 :  4.92797261762619\n",
      "Epoch:  588  Average loss at step  3000 :  4.873175211429596\n",
      "Epoch:  588  Average loss at step  3222 :  5.021136393291379\n",
      "588 4 33.12737250328064\n",
      "588 5 1.1920928955078125e-06\n",
      "Training time took 98.905707 seconds to run 1 epoch\n",
      "Epoch:  589  Average loss at step  1000 :  0.05498888421058655\n",
      "Epoch:  589  Average loss at step  2000 :  0.058220220267772675\n",
      "Epoch:  589  Average loss at step  3000 :  0.06317062866687774\n",
      "Epoch:  589  Average loss at step  3222 :  0.06625209125419626\n",
      "589 0 29.419278383255005\n",
      "Training time took 29.539607 seconds to run 1 epoch\n",
      "Epoch:  590  Average loss at step  1000 :  8.083986476898193\n",
      "Epoch:  590  Average loss at step  2000 :  8.075251909255982\n",
      "Epoch:  590  Average loss at step  3000 :  8.180447709083557\n",
      "Epoch:  590  Average loss at step  4000 :  7.986800003051758\n",
      "Epoch:  590  Average loss at step  5000 :  8.258240153312682\n",
      "Epoch:  590  Average loss at step  6000 :  7.949435180664063\n",
      "Epoch:  590  Average loss at step  7000 :  7.687563401222229\n",
      "Epoch:  590  Average loss at step  8000 :  8.130699531555177\n",
      "Epoch:  590  Average loss at step  8472 :  7.994742152858967\n",
      "590 0 20.833068132400513\n",
      "Epoch:  590  Average loss at step  1000 :  2669.123119506836\n",
      "Epoch:  590  Average loss at step  1491 :  2667.020913422213\n",
      "590 1 11.689878225326538\n",
      "Epoch:  590  Average loss at step  1000 :  3702.855341186523\n",
      "Epoch:  590  Average loss at step  2000 :  3765.208611816406\n",
      "Epoch:  590  Average loss at step  2533 :  3755.1226086461115\n",
      "590 2 19.962021589279175\n",
      "Epoch:  590  Average loss at step  1000 :  63.06334073638916\n",
      "Epoch:  590  Average loss at step  1227 :  64.07692688314097\n",
      "590 3 12.628893613815308\n",
      "Epoch:  590  Average loss at step  1000 :  4.953432271957397\n",
      "Epoch:  590  Average loss at step  2000 :  4.996392244338989\n",
      "Epoch:  590  Average loss at step  3000 :  4.905954021453858\n",
      "Epoch:  590  Average loss at step  3222 :  4.9397702035458\n",
      "590 4 33.20458173751831\n",
      "590 5 1.6689300537109375e-06\n",
      "Training time took 98.970901 seconds to run 1 epoch\n",
      "Mean Rank:  155.8548  of  75000\n",
      "Hits @ 10:  0.85524\n",
      "Hits @ 1:  0.62204\n",
      "Testing time took 164.441394 seconds.\n",
      "\n",
      "Epoch:  591  Average loss at step  1000 :  0.05513299763202667\n",
      "Epoch:  591  Average loss at step  2000 :  0.0580676742196083\n",
      "Epoch:  591  Average loss at step  3000 :  0.06325538980960846\n",
      "Epoch:  591  Average loss at step  3222 :  0.0663796609587393\n",
      "591 0 29.432631492614746\n",
      "Training time took 29.541057 seconds to run 1 epoch\n",
      "Epoch:  592  Average loss at step  1000 :  7.947012257575989\n",
      "Epoch:  592  Average loss at step  2000 :  8.166745098114014\n",
      "Epoch:  592  Average loss at step  3000 :  8.102418144226075\n",
      "Epoch:  592  Average loss at step  4000 :  7.906487771034241\n",
      "Epoch:  592  Average loss at step  5000 :  7.9742576637268066\n",
      "Epoch:  592  Average loss at step  6000 :  8.12614850616455\n",
      "Epoch:  592  Average loss at step  7000 :  8.315409680366516\n",
      "Epoch:  592  Average loss at step  8000 :  7.859298480987549\n",
      "Epoch:  592  Average loss at step  8472 :  8.189568338053755\n",
      "592 0 20.88894534111023\n",
      "Epoch:  592  Average loss at step  1000 :  2706.027192626953\n",
      "Epoch:  592  Average loss at step  1491 :  2678.0230579986583\n",
      "592 1 11.70509123802185\n",
      "Epoch:  592  Average loss at step  1000 :  3745.4466181640623\n",
      "Epoch:  592  Average loss at step  2000 :  3743.7000571289063\n",
      "Epoch:  592  Average loss at step  2533 :  3720.995641314831\n",
      "592 2 19.902782678604126\n",
      "Epoch:  592  Average loss at step  1000 :  62.40500722503662\n",
      "Epoch:  592  Average loss at step  1227 :  62.926761864322096\n",
      "592 3 12.704360961914062\n",
      "Epoch:  592  Average loss at step  1000 :  4.93261648607254\n",
      "Epoch:  592  Average loss at step  2000 :  4.880913193225861\n",
      "Epoch:  592  Average loss at step  3000 :  4.857329897880554\n",
      "Epoch:  592  Average loss at step  3222 :  4.6284247292661345\n",
      "592 4 33.190850496292114\n",
      "592 5 1.430511474609375e-06\n",
      "Training time took 99.023342 seconds to run 1 epoch\n",
      "Epoch:  593  Average loss at step  1000 :  0.05499591565132141\n",
      "Epoch:  593  Average loss at step  2000 :  0.05800099217891693\n",
      "Epoch:  593  Average loss at step  3000 :  0.0631981019973755\n",
      "Epoch:  593  Average loss at step  3222 :  0.06532386351544238\n",
      "593 0 29.472025632858276\n",
      "Training time took 29.597053 seconds to run 1 epoch\n",
      "Epoch:  594  Average loss at step  1000 :  7.672497623443603\n",
      "Epoch:  594  Average loss at step  2000 :  7.884095440864563\n",
      "Epoch:  594  Average loss at step  3000 :  7.942128735542298\n",
      "Epoch:  594  Average loss at step  4000 :  8.535291352272033\n",
      "Epoch:  594  Average loss at step  5000 :  7.657444730758667\n",
      "Epoch:  594  Average loss at step  6000 :  8.115289783477783\n",
      "Epoch:  594  Average loss at step  7000 :  7.41347465133667\n",
      "Epoch:  594  Average loss at step  8000 :  8.208986030101777\n",
      "Epoch:  594  Average loss at step  8472 :  8.034176183098023\n",
      "594 0 20.254802465438843\n",
      "Epoch:  594  Average loss at step  1000 :  2671.6084210205076\n",
      "Epoch:  594  Average loss at step  1491 :  2680.702470152313\n",
      "594 1 11.694098711013794\n",
      "Epoch:  594  Average loss at step  1000 :  3748.73556640625\n",
      "Epoch:  594  Average loss at step  2000 :  3746.261606323242\n",
      "Epoch:  594  Average loss at step  2533 :  3743.8915787113124\n",
      "594 2 19.915443897247314\n",
      "Epoch:  594  Average loss at step  1000 :  63.05248191833496\n",
      "Epoch:  594  Average loss at step  1227 :  62.965936013259316\n",
      "594 3 12.677844762802124\n",
      "Epoch:  594  Average loss at step  1000 :  4.808619563579559\n",
      "Epoch:  594  Average loss at step  2000 :  4.826140131473541\n",
      "Epoch:  594  Average loss at step  3000 :  4.926730140686035\n",
      "Epoch:  594  Average loss at step  3222 :  4.859006480203034\n",
      "594 4 33.23332667350769\n",
      "594 5 1.1920928955078125e-06\n",
      "Training time took 98.425026 seconds to run 1 epoch\n",
      "Epoch:  595  Average loss at step  1000 :  0.05490816777944565\n",
      "Epoch:  595  Average loss at step  2000 :  0.05783036112785339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  595  Average loss at step  3000 :  0.06266556638479233\n",
      "Epoch:  595  Average loss at step  3222 :  0.06618336512952488\n",
      "595 0 29.38297963142395\n",
      "Training time took 29.504306 seconds to run 1 epoch\n",
      "Epoch:  596  Average loss at step  1000 :  8.495949709892272\n",
      "Epoch:  596  Average loss at step  2000 :  7.573076132774353\n",
      "Epoch:  596  Average loss at step  3000 :  7.885729477882386\n",
      "Epoch:  596  Average loss at step  4000 :  8.256913067817688\n",
      "Epoch:  596  Average loss at step  5000 :  7.865751565933228\n",
      "Epoch:  596  Average loss at step  6000 :  7.717222262382507\n",
      "Epoch:  596  Average loss at step  7000 :  7.930520589828491\n",
      "Epoch:  596  Average loss at step  8000 :  7.553346217155457\n",
      "Epoch:  596  Average loss at step  8472 :  7.5222674222031145\n",
      "596 0 20.026487588882446\n",
      "Epoch:  596  Average loss at step  1000 :  2687.3669963378907\n",
      "Epoch:  596  Average loss at step  1491 :  2687.1627616466612\n",
      "596 1 11.735755920410156\n",
      "Epoch:  596  Average loss at step  1000 :  3787.944822631836\n",
      "Epoch:  596  Average loss at step  2000 :  3738.9915666503907\n",
      "Epoch:  596  Average loss at step  2533 :  3745.9013200534837\n",
      "596 2 19.734889268875122\n",
      "Epoch:  596  Average loss at step  1000 :  62.78133092498779\n",
      "Epoch:  596  Average loss at step  1227 :  63.093652185419955\n",
      "596 3 12.617072105407715\n",
      "Epoch:  596  Average loss at step  1000 :  4.756926245689392\n",
      "Epoch:  596  Average loss at step  2000 :  4.801370636463165\n",
      "Epoch:  596  Average loss at step  3000 :  4.8091953735351565\n",
      "Epoch:  596  Average loss at step  3222 :  4.783144684168466\n",
      "596 4 33.023608922958374\n",
      "596 5 1.1920928955078125e-06\n",
      "Training time took 97.774731 seconds to run 1 epoch\n",
      "Epoch:  597  Average loss at step  1000 :  0.054357477843761444\n",
      "Epoch:  597  Average loss at step  2000 :  0.05759842526912689\n",
      "Epoch:  597  Average loss at step  3000 :  0.06266951149702073\n",
      "Epoch:  597  Average loss at step  3222 :  0.06604603367132451\n",
      "597 0 29.38194727897644\n",
      "Training time took 29.503757 seconds to run 1 epoch\n",
      "Epoch:  598  Average loss at step  1000 :  8.007378854751586\n",
      "Epoch:  598  Average loss at step  2000 :  8.475102120399475\n",
      "Epoch:  598  Average loss at step  3000 :  8.313755810737609\n",
      "Epoch:  598  Average loss at step  4000 :  7.569954207420349\n",
      "Epoch:  598  Average loss at step  5000 :  7.838519537448883\n",
      "Epoch:  598  Average loss at step  6000 :  8.559988996505737\n",
      "Epoch:  598  Average loss at step  7000 :  8.083157832145691\n",
      "Epoch:  598  Average loss at step  8000 :  7.529226145744324\n",
      "Epoch:  598  Average loss at step  8472 :  8.28123779542974\n",
      "598 0 20.413705825805664\n",
      "Epoch:  598  Average loss at step  1000 :  2678.1197867431642\n",
      "Epoch:  598  Average loss at step  1491 :  2648.105741918161\n",
      "598 1 11.728063583374023\n",
      "Epoch:  598  Average loss at step  1000 :  3753.590941772461\n",
      "Epoch:  598  Average loss at step  2000 :  3768.4464075927735\n",
      "Epoch:  598  Average loss at step  2533 :  3747.9910304590007\n",
      "598 2 19.92690420150757\n",
      "Epoch:  598  Average loss at step  1000 :  62.968178760528566\n",
      "Epoch:  598  Average loss at step  1227 :  63.27143439534703\n",
      "598 3 12.617460012435913\n",
      "Epoch:  598  Average loss at step  1000 :  4.95175382232666\n",
      "Epoch:  598  Average loss at step  2000 :  4.916453516006469\n",
      "Epoch:  598  Average loss at step  3000 :  4.819508979320526\n",
      "Epoch:  598  Average loss at step  3222 :  4.818034180666828\n",
      "598 4 33.42753481864929\n",
      "598 5 1.430511474609375e-06\n",
      "Training time took 98.738843 seconds to run 1 epoch\n",
      "Epoch:  599  Average loss at step  1000 :  0.054737226009368894\n",
      "Epoch:  599  Average loss at step  2000 :  0.05750048756599426\n",
      "Epoch:  599  Average loss at step  3000 :  0.06255344468355178\n",
      "Epoch:  599  Average loss at step  3222 :  0.06530366180218133\n",
      "599 0 29.38907027244568\n",
      "Training time took 29.512252 seconds to run 1 epoch\n",
      "Epoch:  600  Average loss at step  1000 :  8.274826336860658\n",
      "Epoch:  600  Average loss at step  2000 :  8.002692823410035\n",
      "Epoch:  600  Average loss at step  3000 :  8.175784002304077\n",
      "Epoch:  600  Average loss at step  4000 :  7.898893259048462\n",
      "Epoch:  600  Average loss at step  5000 :  8.140973636627198\n",
      "Epoch:  600  Average loss at step  6000 :  7.893190850257874\n",
      "Epoch:  600  Average loss at step  7000 :  7.805923727989197\n",
      "Epoch:  600  Average loss at step  8000 :  8.241063242912292\n",
      "Epoch:  600  Average loss at step  8472 :  8.082600090399566\n",
      "600 0 20.768054246902466\n",
      "Epoch:  600  Average loss at step  1000 :  2682.5176899414064\n",
      "Epoch:  600  Average loss at step  1491 :  2713.6629618506267\n",
      "600 1 11.695802211761475\n",
      "Epoch:  600  Average loss at step  1000 :  3757.4143208007813\n",
      "Epoch:  600  Average loss at step  2000 :  3781.176771484375\n",
      "Epoch:  600  Average loss at step  2533 :  3737.2410455646454\n",
      "600 2 19.9393208026886\n",
      "Epoch:  600  Average loss at step  1000 :  63.01974048233032\n",
      "Epoch:  600  Average loss at step  1227 :  63.62405700320081\n",
      "600 3 12.671014070510864\n",
      "Epoch:  600  Average loss at step  1000 :  4.7439297647476195\n",
      "Epoch:  600  Average loss at step  2000 :  4.721366807460785\n",
      "Epoch:  600  Average loss at step  3000 :  4.81046839094162\n",
      "Epoch:  600  Average loss at step  3222 :  4.81167583823699\n",
      "600 4 33.16828989982605\n",
      "600 5 1.430511474609375e-06\n",
      "Training time took 98.885644 seconds to run 1 epoch\n",
      "Mean Rank:  156.93404  of  75000\n",
      "Hits @ 10:  0.85428\n",
      "Hits @ 1:  0.62136\n",
      "Testing time took 164.184183 seconds.\n",
      "\n",
      "Epoch:  601  Average loss at step  1000 :  0.05433128088712692\n",
      "Epoch:  601  Average loss at step  2000 :  0.05718047970533371\n",
      "Epoch:  601  Average loss at step  3000 :  0.0622745213508606\n",
      "Epoch:  601  Average loss at step  3222 :  0.06506128859102435\n",
      "601 0 29.444817781448364\n",
      "Training time took 29.553371 seconds to run 1 epoch\n",
      "Epoch:  602  Average loss at step  1000 :  8.235557053565978\n",
      "Epoch:  602  Average loss at step  2000 :  7.798420983314514\n",
      "Epoch:  602  Average loss at step  3000 :  7.834528059959411\n",
      "Epoch:  602  Average loss at step  4000 :  8.544246044158935\n",
      "Epoch:  602  Average loss at step  5000 :  7.66819183921814\n",
      "Epoch:  602  Average loss at step  6000 :  7.610546293258667\n",
      "Epoch:  602  Average loss at step  7000 :  7.866234907150268\n",
      "Epoch:  602  Average loss at step  8000 :  8.087495364189149\n",
      "Epoch:  602  Average loss at step  8472 :  8.51135457099878\n",
      "602 0 21.528931379318237\n",
      "Epoch:  602  Average loss at step  1000 :  2686.0013389282226\n",
      "Epoch:  602  Average loss at step  1491 :  2712.254128016994\n",
      "602 1 11.729146718978882\n",
      "Epoch:  602  Average loss at step  1000 :  3770.5822670898438\n",
      "Epoch:  602  Average loss at step  2000 :  3796.2147302246094\n",
      "Epoch:  602  Average loss at step  2533 :  3815.084019229945\n",
      "602 2 19.901753902435303\n",
      "Epoch:  602  Average loss at step  1000 :  62.967804531097414\n",
      "Epoch:  602  Average loss at step  1227 :  62.70505169963429\n",
      "602 3 12.72300124168396\n",
      "Epoch:  602  Average loss at step  1000 :  4.731806140899658\n",
      "Epoch:  602  Average loss at step  2000 :  4.74954070520401\n",
      "Epoch:  602  Average loss at step  3000 :  4.765304178237915\n",
      "Epoch:  602  Average loss at step  3222 :  4.717235352980529\n",
      "602 4 33.236647844314575\n",
      "602 5 1.6689300537109375e-06\n",
      "Training time took 99.754679 seconds to run 1 epoch\n",
      "Epoch:  603  Average loss at step  1000 :  0.054566716611385346\n",
      "Epoch:  603  Average loss at step  2000 :  0.05687313652038574\n",
      "Epoch:  603  Average loss at step  3000 :  0.062093079149723056\n",
      "Epoch:  603  Average loss at step  3222 :  0.06487684724218558\n",
      "603 0 29.356588125228882\n",
      "Training time took 29.476366 seconds to run 1 epoch\n",
      "Epoch:  604  Average loss at step  1000 :  7.953746245384217\n",
      "Epoch:  604  Average loss at step  2000 :  8.381063277244568\n",
      "Epoch:  604  Average loss at step  3000 :  8.178004068374634\n",
      "Epoch:  604  Average loss at step  4000 :  7.719845799446106\n",
      "Epoch:  604  Average loss at step  5000 :  8.022024104118348\n",
      "Epoch:  604  Average loss at step  6000 :  7.894751063346863\n",
      "Epoch:  604  Average loss at step  7000 :  7.588910172462463\n",
      "Epoch:  604  Average loss at step  8000 :  7.988133395195008\n",
      "Epoch:  604  Average loss at step  8472 :  8.130134768550988\n",
      "604 0 20.74957847595215\n",
      "Epoch:  604  Average loss at step  1000 :  2675.8602908935545\n",
      "Epoch:  604  Average loss at step  1491 :  2709.5349968248242\n",
      "604 1 11.703859806060791\n",
      "Epoch:  604  Average loss at step  1000 :  3754.988819824219\n",
      "Epoch:  604  Average loss at step  2000 :  3750.219591796875\n",
      "Epoch:  604  Average loss at step  2533 :  3782.5684415107967\n",
      "604 2 19.903650045394897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  604  Average loss at step  1000 :  63.060870204925536\n",
      "Epoch:  604  Average loss at step  1227 :  61.87141062685645\n",
      "604 3 12.594807386398315\n",
      "Epoch:  604  Average loss at step  1000 :  4.756387969493866\n",
      "Epoch:  604  Average loss at step  2000 :  4.83539350605011\n",
      "Epoch:  604  Average loss at step  3000 :  4.796322033405304\n",
      "Epoch:  604  Average loss at step  3222 :  4.8132301947984\n",
      "604 4 33.30518651008606\n",
      "604 5 1.430511474609375e-06\n",
      "Training time took 98.902594 seconds to run 1 epoch\n",
      "Epoch:  605  Average loss at step  1000 :  0.05383182632923126\n",
      "Epoch:  605  Average loss at step  2000 :  0.056834415316581725\n",
      "Epoch:  605  Average loss at step  3000 :  0.06213187748193741\n",
      "Epoch:  605  Average loss at step  3222 :  0.06508585842405981\n",
      "605 0 29.339524269104004\n",
      "Training time took 29.460347 seconds to run 1 epoch\n",
      "Epoch:  606  Average loss at step  1000 :  7.915281702041626\n",
      "Epoch:  606  Average loss at step  2000 :  8.100015612602235\n",
      "Epoch:  606  Average loss at step  3000 :  8.136291977882385\n",
      "Epoch:  606  Average loss at step  4000 :  7.969423145294189\n",
      "Epoch:  606  Average loss at step  5000 :  8.363908116340637\n",
      "Epoch:  606  Average loss at step  6000 :  8.506149424552918\n",
      "Epoch:  606  Average loss at step  7000 :  7.762351913452148\n",
      "Epoch:  606  Average loss at step  8000 :  7.987303077697754\n",
      "Epoch:  606  Average loss at step  8472 :  8.11682256634898\n",
      "606 0 20.775063037872314\n",
      "Epoch:  606  Average loss at step  1000 :  2720.4289548339843\n",
      "Epoch:  606  Average loss at step  1491 :  2692.10779536893\n",
      "606 1 11.710581064224243\n",
      "Epoch:  606  Average loss at step  1000 :  3788.939934326172\n",
      "Epoch:  606  Average loss at step  2000 :  3765.7258637695313\n",
      "Epoch:  606  Average loss at step  2533 :  3789.690477262022\n",
      "606 2 19.922667503356934\n",
      "Epoch:  606  Average loss at step  1000 :  62.25434662628174\n",
      "Epoch:  606  Average loss at step  1227 :  62.77691600508582\n",
      "606 3 12.664430856704712\n",
      "Epoch:  606  Average loss at step  1000 :  4.805919645786285\n",
      "Epoch:  606  Average loss at step  2000 :  4.587885921001434\n",
      "Epoch:  606  Average loss at step  3000 :  4.775892103672027\n",
      "Epoch:  606  Average loss at step  3222 :  4.500798424522591\n",
      "606 4 33.2988920211792\n",
      "606 5 1.6689300537109375e-06\n",
      "Training time took 99.011583 seconds to run 1 epoch\n",
      "Epoch:  607  Average loss at step  1000 :  0.054064485251903535\n",
      "Epoch:  607  Average loss at step  2000 :  0.05681064164638519\n",
      "Epoch:  607  Average loss at step  3000 :  0.06159470111131668\n",
      "Epoch:  607  Average loss at step  3222 :  0.0649837003242326\n",
      "607 0 29.420230388641357\n",
      "Training time took 29.541049 seconds to run 1 epoch\n",
      "Epoch:  608  Average loss at step  1000 :  8.383715754508971\n",
      "Epoch:  608  Average loss at step  2000 :  8.306995427131653\n",
      "Epoch:  608  Average loss at step  3000 :  8.362085166931152\n",
      "Epoch:  608  Average loss at step  4000 :  8.218306475639343\n",
      "Epoch:  608  Average loss at step  5000 :  8.563148635864257\n",
      "Epoch:  608  Average loss at step  6000 :  7.895001329421997\n",
      "Epoch:  608  Average loss at step  7000 :  8.001439663887023\n",
      "Epoch:  608  Average loss at step  8000 :  8.133449350357056\n",
      "Epoch:  608  Average loss at step  8472 :  7.692460073517456\n",
      "608 0 20.245347261428833\n",
      "Epoch:  608  Average loss at step  1000 :  2691.3178358154296\n",
      "Epoch:  608  Average loss at step  1491 :  2676.6444290643203\n",
      "608 1 11.691928148269653\n",
      "Epoch:  608  Average loss at step  1000 :  3793.168493408203\n",
      "Epoch:  608  Average loss at step  2000 :  3777.284092163086\n",
      "Epoch:  608  Average loss at step  2533 :  3782.6526357496396\n",
      "608 2 19.8934326171875\n",
      "Epoch:  608  Average loss at step  1000 :  62.66728575515747\n",
      "Epoch:  608  Average loss at step  1227 :  62.401548380487185\n",
      "608 3 12.691508769989014\n",
      "Epoch:  608  Average loss at step  1000 :  4.778754636287689\n",
      "Epoch:  608  Average loss at step  2000 :  4.715644041538239\n",
      "Epoch:  608  Average loss at step  3000 :  4.681641575813294\n",
      "Epoch:  608  Average loss at step  3222 :  4.622398246645303\n",
      "608 4 33.34634470939636\n",
      "608 5 1.1920928955078125e-06\n",
      "Training time took 98.507764 seconds to run 1 epoch\n",
      "Epoch:  609  Average loss at step  1000 :  0.05406276082992554\n",
      "Epoch:  609  Average loss at step  2000 :  0.056536011338233945\n",
      "Epoch:  609  Average loss at step  3000 :  0.06150257563591004\n",
      "Epoch:  609  Average loss at step  3222 :  0.06406664724577246\n",
      "609 0 29.41574788093567\n",
      "Training time took 29.529873 seconds to run 1 epoch\n",
      "Epoch:  610  Average loss at step  1000 :  8.443720331192017\n",
      "Epoch:  610  Average loss at step  2000 :  7.76169722366333\n",
      "Epoch:  610  Average loss at step  3000 :  8.507618463516236\n",
      "Epoch:  610  Average loss at step  4000 :  7.841030699729919\n",
      "Epoch:  610  Average loss at step  5000 :  8.131104743003846\n",
      "Epoch:  610  Average loss at step  6000 :  8.09817069721222\n",
      "Epoch:  610  Average loss at step  7000 :  8.074220997333526\n",
      "Epoch:  610  Average loss at step  8000 :  7.792606273651123\n",
      "Epoch:  610  Average loss at step  8472 :  7.755311655323278\n",
      "610 0 21.420011043548584\n",
      "Epoch:  610  Average loss at step  1000 :  2696.1199567871095\n",
      "Epoch:  610  Average loss at step  1491 :  2698.477491560183\n",
      "610 1 11.721461534500122\n",
      "Epoch:  610  Average loss at step  1000 :  3783.202499633789\n",
      "Epoch:  610  Average loss at step  2000 :  3784.350607421875\n",
      "Epoch:  610  Average loss at step  2533 :  3824.46645045466\n",
      "610 2 19.88971710205078\n",
      "Epoch:  610  Average loss at step  1000 :  62.48295454406738\n",
      "Epoch:  610  Average loss at step  1227 :  61.77461941966825\n",
      "610 3 12.596958637237549\n",
      "Epoch:  610  Average loss at step  1000 :  4.828545558452606\n",
      "Epoch:  610  Average loss at step  2000 :  4.756621282100678\n",
      "Epoch:  610  Average loss at step  3000 :  4.663899903297424\n",
      "Epoch:  610  Average loss at step  3222 :  4.478977055385195\n",
      "610 4 33.23788094520569\n",
      "610 5 1.430511474609375e-06\n",
      "Training time took 99.509133 seconds to run 1 epoch\n",
      "Mean Rank:  154.73164  of  75000\n",
      "Hits @ 10:  0.85468\n",
      "Hits @ 1:  0.62092\n",
      "Testing time took 164.019239 seconds.\n",
      "\n",
      "Epoch:  611  Average loss at step  1000 :  0.05370575231313705\n",
      "Epoch:  611  Average loss at step  2000 :  0.05632695078849793\n",
      "Epoch:  611  Average loss at step  3000 :  0.06125977230072022\n",
      "Epoch:  611  Average loss at step  3222 :  0.06430429265395379\n",
      "611 0 29.406126260757446\n",
      "Training time took 29.524961 seconds to run 1 epoch\n",
      "Epoch:  612  Average loss at step  1000 :  8.336391080856323\n",
      "Epoch:  612  Average loss at step  2000 :  8.07996713924408\n",
      "Epoch:  612  Average loss at step  3000 :  7.957792179107666\n",
      "Epoch:  612  Average loss at step  4000 :  7.787446667671204\n",
      "Epoch:  612  Average loss at step  5000 :  8.172679404258728\n",
      "Epoch:  612  Average loss at step  6000 :  7.8142316551208495\n",
      "Epoch:  612  Average loss at step  7000 :  7.771701790809631\n",
      "Epoch:  612  Average loss at step  8000 :  7.878509132385254\n",
      "Epoch:  612  Average loss at step  8472 :  8.549339620191027\n",
      "612 0 20.363741874694824\n",
      "Epoch:  612  Average loss at step  1000 :  2695.4592087402343\n",
      "Epoch:  612  Average loss at step  1491 :  2707.949401856712\n",
      "612 1 11.707128047943115\n",
      "Epoch:  612  Average loss at step  1000 :  3774.778717529297\n",
      "Epoch:  612  Average loss at step  2000 :  3759.2678865966795\n",
      "Epoch:  612  Average loss at step  2533 :  3800.5057234058427\n",
      "612 2 19.9625301361084\n",
      "Epoch:  612  Average loss at step  1000 :  62.88994502258301\n",
      "Epoch:  612  Average loss at step  1227 :  62.19916059063441\n",
      "612 3 12.71305537223816\n",
      "Epoch:  612  Average loss at step  1000 :  4.822522364616394\n",
      "Epoch:  612  Average loss at step  2000 :  4.754192500591278\n",
      "Epoch:  612  Average loss at step  3000 :  4.760483196258545\n",
      "Epoch:  612  Average loss at step  3222 :  4.640145494654239\n",
      "612 4 33.186707973480225\n",
      "612 5 1.1920928955078125e-06\n",
      "Training time took 98.579584 seconds to run 1 epoch\n",
      "Epoch:  613  Average loss at step  1000 :  0.05337489718198776\n",
      "Epoch:  613  Average loss at step  2000 :  0.05641343194246292\n",
      "Epoch:  613  Average loss at step  3000 :  0.061419283032417296\n",
      "Epoch:  613  Average loss at step  3222 :  0.06451167140675916\n",
      "613 0 29.375771045684814\n",
      "Training time took 29.502 seconds to run 1 epoch\n",
      "Epoch:  614  Average loss at step  1000 :  8.211725227355958\n",
      "Epoch:  614  Average loss at step  2000 :  8.00226994228363\n",
      "Epoch:  614  Average loss at step  3000 :  7.771663509368897\n",
      "Epoch:  614  Average loss at step  4000 :  8.427234524726869\n",
      "Epoch:  614  Average loss at step  5000 :  8.669713936805724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  614  Average loss at step  6000 :  7.8605171413421635\n",
      "Epoch:  614  Average loss at step  7000 :  7.687229659080505\n",
      "Epoch:  614  Average loss at step  8000 :  8.323934533119202\n",
      "Epoch:  614  Average loss at step  8472 :  8.022665160858217\n",
      "614 0 20.26793098449707\n",
      "Epoch:  614  Average loss at step  1000 :  2712.034212768555\n",
      "Epoch:  614  Average loss at step  1491 :  2746.8638039843545\n",
      "614 1 11.686290264129639\n",
      "Epoch:  614  Average loss at step  1000 :  3785.4568751220704\n",
      "Epoch:  614  Average loss at step  2000 :  3769.8409407958984\n",
      "Epoch:  614  Average loss at step  2533 :  3758.459126676415\n",
      "614 2 19.893208980560303\n",
      "Epoch:  614  Average loss at step  1000 :  62.706298904418944\n",
      "Epoch:  614  Average loss at step  1227 :  62.706836278528925\n",
      "614 3 12.661961555480957\n",
      "Epoch:  614  Average loss at step  1000 :  4.6647261328697205\n",
      "Epoch:  614  Average loss at step  2000 :  4.6609094929695125\n",
      "Epoch:  614  Average loss at step  3000 :  4.758356223583221\n",
      "Epoch:  614  Average loss at step  3222 :  4.756385226782575\n",
      "614 4 33.17953681945801\n",
      "614 5 1.9073486328125e-06\n",
      "Training time took 98.317821 seconds to run 1 epoch\n",
      "Epoch:  615  Average loss at step  1000 :  0.05330750340223312\n",
      "Epoch:  615  Average loss at step  2000 :  0.05645043212175369\n",
      "Epoch:  615  Average loss at step  3000 :  0.0609637451171875\n",
      "Epoch:  615  Average loss at step  3222 :  0.06353721213611933\n",
      "615 0 29.429465532302856\n",
      "Training time took 29.551272 seconds to run 1 epoch\n",
      "Epoch:  616  Average loss at step  1000 :  8.262974313735961\n",
      "Epoch:  616  Average loss at step  2000 :  8.455121673583985\n",
      "Epoch:  616  Average loss at step  3000 :  7.6179819688796995\n",
      "Epoch:  616  Average loss at step  4000 :  7.912286927223206\n",
      "Epoch:  616  Average loss at step  5000 :  8.36687947845459\n",
      "Epoch:  616  Average loss at step  6000 :  8.02794709587097\n",
      "Epoch:  616  Average loss at step  7000 :  8.079259880065917\n",
      "Epoch:  616  Average loss at step  8000 :  8.442411675930023\n",
      "Epoch:  616  Average loss at step  8472 :  8.35662419178415\n",
      "616 0 21.023011445999146\n",
      "Epoch:  616  Average loss at step  1000 :  2716.090346557617\n",
      "Epoch:  616  Average loss at step  1491 :  2698.06317184548\n",
      "616 1 11.751370429992676\n",
      "Epoch:  616  Average loss at step  1000 :  3771.5493642578126\n",
      "Epoch:  616  Average loss at step  2000 :  3783.406281494141\n",
      "Epoch:  616  Average loss at step  2533 :  3761.817909931593\n",
      "616 2 19.94056010246277\n",
      "Epoch:  616  Average loss at step  1000 :  62.50371822357178\n",
      "Epoch:  616  Average loss at step  1227 :  61.86785641348493\n",
      "616 3 12.68146562576294\n",
      "Epoch:  616  Average loss at step  1000 :  4.741440202236175\n",
      "Epoch:  616  Average loss at step  2000 :  4.582262149810791\n",
      "Epoch:  616  Average loss at step  3000 :  4.701053667068481\n",
      "Epoch:  616  Average loss at step  3222 :  4.799632021915527\n",
      "616 4 33.16711688041687\n",
      "616 5 1.6689300537109375e-06\n",
      "Training time took 99.200009 seconds to run 1 epoch\n",
      "Epoch:  617  Average loss at step  1000 :  0.05306148117780685\n",
      "Epoch:  617  Average loss at step  2000 :  0.05578699886798859\n",
      "Epoch:  617  Average loss at step  3000 :  0.061026961505413056\n",
      "Epoch:  617  Average loss at step  3222 :  0.06352195344390497\n",
      "617 0 29.446802854537964\n",
      "Training time took 29.569734 seconds to run 1 epoch\n",
      "Epoch:  618  Average loss at step  1000 :  7.708869269371033\n",
      "Epoch:  618  Average loss at step  2000 :  7.936878882408142\n",
      "Epoch:  618  Average loss at step  3000 :  8.237378492355347\n",
      "Epoch:  618  Average loss at step  4000 :  8.05162876701355\n",
      "Epoch:  618  Average loss at step  5000 :  7.795614512443542\n",
      "Epoch:  618  Average loss at step  6000 :  7.974570789337158\n",
      "Epoch:  618  Average loss at step  7000 :  7.764816920280457\n",
      "Epoch:  618  Average loss at step  8000 :  8.163219590187072\n",
      "Epoch:  618  Average loss at step  8472 :  7.6858248827407945\n",
      "618 0 21.18092632293701\n",
      "Epoch:  618  Average loss at step  1000 :  2680.3687362060546\n",
      "Epoch:  618  Average loss at step  1491 :  2726.7294264839184\n",
      "618 1 11.712424516677856\n",
      "Epoch:  618  Average loss at step  1000 :  3792.5746087646485\n",
      "Epoch:  618  Average loss at step  2000 :  3765.406504394531\n",
      "Epoch:  618  Average loss at step  2533 :  3796.3679945415583\n",
      "618 2 19.932344436645508\n",
      "Epoch:  618  Average loss at step  1000 :  62.41510720825195\n",
      "Epoch:  618  Average loss at step  1227 :  62.80682483379761\n",
      "618 3 12.65505576133728\n",
      "Epoch:  618  Average loss at step  1000 :  4.8760734887123105\n",
      "Epoch:  618  Average loss at step  2000 :  4.663959198951721\n",
      "Epoch:  618  Average loss at step  3000 :  4.671047441005706\n",
      "Epoch:  618  Average loss at step  3222 :  4.583707678337393\n",
      "618 4 33.06575846672058\n",
      "618 5 1.430511474609375e-06\n",
      "Training time took 99.172343 seconds to run 1 epoch\n",
      "Epoch:  619  Average loss at step  1000 :  0.05316359412670135\n",
      "Epoch:  619  Average loss at step  2000 :  0.055826844215393065\n",
      "Epoch:  619  Average loss at step  3000 :  0.061111083924770354\n",
      "Epoch:  619  Average loss at step  3222 :  0.06421057567589548\n",
      "619 0 29.37374258041382\n",
      "Training time took 29.494591 seconds to run 1 epoch\n",
      "Epoch:  620  Average loss at step  1000 :  7.67205678653717\n",
      "Epoch:  620  Average loss at step  2000 :  8.114999792098999\n",
      "Epoch:  620  Average loss at step  3000 :  7.829590281486511\n",
      "Epoch:  620  Average loss at step  4000 :  8.023795605659485\n",
      "Epoch:  620  Average loss at step  5000 :  8.287666764259338\n",
      "Epoch:  620  Average loss at step  6000 :  8.0087550034523\n",
      "Epoch:  620  Average loss at step  7000 :  7.988081215858459\n",
      "Epoch:  620  Average loss at step  8000 :  8.072715264320374\n",
      "Epoch:  620  Average loss at step  8472 :  7.617573525392464\n",
      "620 0 20.66299796104431\n",
      "Epoch:  620  Average loss at step  1000 :  2687.838413818359\n",
      "Epoch:  620  Average loss at step  1491 :  2693.848551394165\n",
      "620 1 11.719377994537354\n",
      "Epoch:  620  Average loss at step  1000 :  3793.723167480469\n",
      "Epoch:  620  Average loss at step  2000 :  3816.79998828125\n",
      "Epoch:  620  Average loss at step  2533 :  3800.684150346208\n",
      "620 2 19.941391944885254\n",
      "Epoch:  620  Average loss at step  1000 :  62.569721786499024\n",
      "Epoch:  620  Average loss at step  1227 :  63.79401942873399\n",
      "620 3 12.600618362426758\n",
      "Epoch:  620  Average loss at step  1000 :  4.562175857067108\n",
      "Epoch:  620  Average loss at step  2000 :  4.616696844577789\n",
      "Epoch:  620  Average loss at step  3000 :  4.519829949378967\n",
      "Epoch:  620  Average loss at step  3222 :  4.889046035318259\n",
      "620 4 33.26533579826355\n",
      "620 5 1.1920928955078125e-06\n",
      "Training time took 98.823891 seconds to run 1 epoch\n",
      "Mean Rank:  155.25916  of  75000\n",
      "Hits @ 10:  0.85516\n",
      "Hits @ 1:  0.62136\n",
      "Testing time took 163.631988 seconds.\n",
      "\n",
      "Epoch:  621  Average loss at step  1000 :  0.05282288604974747\n",
      "Epoch:  621  Average loss at step  2000 :  0.05555757075548172\n",
      "Epoch:  621  Average loss at step  3000 :  0.06051642554998398\n",
      "Epoch:  621  Average loss at step  3222 :  0.06392049130861413\n",
      "621 0 29.420336723327637\n",
      "Training time took 29.52889 seconds to run 1 epoch\n",
      "Epoch:  622  Average loss at step  1000 :  8.145173641204835\n",
      "Epoch:  622  Average loss at step  2000 :  7.999357172966003\n",
      "Epoch:  622  Average loss at step  3000 :  8.303262714385987\n",
      "Epoch:  622  Average loss at step  4000 :  7.8218525648117065\n",
      "Epoch:  622  Average loss at step  5000 :  8.093524848937989\n",
      "Epoch:  622  Average loss at step  6000 :  8.10841158771515\n",
      "Epoch:  622  Average loss at step  7000 :  8.11485185432434\n",
      "Epoch:  622  Average loss at step  8000 :  8.00724229812622\n",
      "Epoch:  622  Average loss at step  8472 :  8.516798618061323\n",
      "622 0 20.464982986450195\n",
      "Epoch:  622  Average loss at step  1000 :  2746.052196899414\n",
      "Epoch:  622  Average loss at step  1491 :  2705.314856069173\n",
      "622 1 11.687074899673462\n",
      "Epoch:  622  Average loss at step  1000 :  3788.3428887939453\n",
      "Epoch:  622  Average loss at step  2000 :  3780.0674553222657\n",
      "Epoch:  622  Average loss at step  2533 :  3816.6763345240674\n",
      "622 2 19.92431616783142\n",
      "Epoch:  622  Average loss at step  1000 :  62.633095180511475\n",
      "Epoch:  622  Average loss at step  1227 :  62.41106447410104\n",
      "622 3 12.639477014541626\n",
      "Epoch:  622  Average loss at step  1000 :  4.65669180393219\n",
      "Epoch:  622  Average loss at step  2000 :  4.687483871936798\n",
      "Epoch:  622  Average loss at step  3000 :  4.727537051677704\n",
      "Epoch:  622  Average loss at step  3222 :  4.736550976856023\n",
      "622 4 33.257768869400024\n",
      "622 5 1.430511474609375e-06\n",
      "Training time took 98.597663 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  623  Average loss at step  1000 :  0.05267062574625015\n",
      "Epoch:  623  Average loss at step  2000 :  0.055433609247207645\n",
      "Epoch:  623  Average loss at step  3000 :  0.060371371686458584\n",
      "Epoch:  623  Average loss at step  3222 :  0.06346524966970465\n",
      "623 0 29.38194227218628\n",
      "Training time took 29.503667 seconds to run 1 epoch\n",
      "Epoch:  624  Average loss at step  1000 :  7.782448081970215\n",
      "Epoch:  624  Average loss at step  2000 :  7.819886304855347\n",
      "Epoch:  624  Average loss at step  3000 :  8.274329095840454\n",
      "Epoch:  624  Average loss at step  4000 :  7.585701602935791\n",
      "Epoch:  624  Average loss at step  5000 :  8.308255922317505\n",
      "Epoch:  624  Average loss at step  6000 :  8.469679427146911\n",
      "Epoch:  624  Average loss at step  7000 :  7.719343165397644\n",
      "Epoch:  624  Average loss at step  8000 :  8.52501597070694\n",
      "Epoch:  624  Average loss at step  8472 :  8.322099236619122\n",
      "624 0 20.450453281402588\n",
      "Epoch:  624  Average loss at step  1000 :  2723.7625588378905\n",
      "Epoch:  624  Average loss at step  1491 :  2693.6046487283224\n",
      "624 1 11.73393702507019\n",
      "Epoch:  624  Average loss at step  1000 :  3808.9573516845703\n",
      "Epoch:  624  Average loss at step  2000 :  3831.5917836914064\n",
      "Epoch:  624  Average loss at step  2533 :  3814.880174472584\n",
      "624 2 19.849884033203125\n",
      "Epoch:  624  Average loss at step  1000 :  62.613179164886475\n",
      "Epoch:  624  Average loss at step  1227 :  62.92677765020481\n",
      "624 3 12.657003164291382\n",
      "Epoch:  624  Average loss at step  1000 :  4.61653617143631\n",
      "Epoch:  624  Average loss at step  2000 :  4.561682432174683\n",
      "Epoch:  624  Average loss at step  3000 :  4.483040615558624\n",
      "Epoch:  624  Average loss at step  3222 :  4.580054846583\n",
      "624 4 33.20881223678589\n",
      "624 5 1.6689300537109375e-06\n",
      "Training time took 98.525948 seconds to run 1 epoch\n",
      "Epoch:  625  Average loss at step  1000 :  0.052535229325294495\n",
      "Epoch:  625  Average loss at step  2000 :  0.05524434494972229\n",
      "Epoch:  625  Average loss at step  3000 :  0.060765968143939975\n",
      "Epoch:  625  Average loss at step  3222 :  0.0625184908479662\n",
      "625 0 29.457059621810913\n",
      "Training time took 29.580287 seconds to run 1 epoch\n",
      "Epoch:  626  Average loss at step  1000 :  8.12122928237915\n",
      "Epoch:  626  Average loss at step  2000 :  8.009233080863952\n",
      "Epoch:  626  Average loss at step  3000 :  8.259510261535645\n",
      "Epoch:  626  Average loss at step  4000 :  7.7747724361419674\n",
      "Epoch:  626  Average loss at step  5000 :  7.6606860699653625\n",
      "Epoch:  626  Average loss at step  6000 :  8.03770623922348\n",
      "Epoch:  626  Average loss at step  7000 :  7.6195902976989744\n",
      "Epoch:  626  Average loss at step  8000 :  8.143746772766113\n",
      "Epoch:  626  Average loss at step  8472 :  8.022896896714615\n",
      "626 0 20.447388887405396\n",
      "Epoch:  626  Average loss at step  1000 :  2702.7118753662107\n",
      "Epoch:  626  Average loss at step  1491 :  2712.694387766347\n",
      "626 1 11.716552972793579\n",
      "Epoch:  626  Average loss at step  1000 :  3794.4660614013674\n",
      "Epoch:  626  Average loss at step  2000 :  3804.5272802734376\n",
      "Epoch:  626  Average loss at step  2533 :  3813.2469667938653\n",
      "626 2 19.846755027770996\n",
      "Epoch:  626  Average loss at step  1000 :  62.6900888595581\n",
      "Epoch:  626  Average loss at step  1227 :  62.78027112784697\n",
      "626 3 12.562655210494995\n",
      "Epoch:  626  Average loss at step  1000 :  4.650529625415802\n",
      "Epoch:  626  Average loss at step  2000 :  4.657140161514282\n",
      "Epoch:  626  Average loss at step  3000 :  4.4983651480674745\n",
      "Epoch:  626  Average loss at step  3222 :  4.465535113604453\n",
      "626 4 33.26543831825256\n",
      "626 5 1.6689300537109375e-06\n",
      "Training time took 98.481942 seconds to run 1 epoch\n",
      "Epoch:  627  Average loss at step  1000 :  0.05281725418567657\n",
      "Epoch:  627  Average loss at step  2000 :  0.05545589029788971\n",
      "Epoch:  627  Average loss at step  3000 :  0.059757495105266574\n",
      "Epoch:  627  Average loss at step  3222 :  0.06228733803094305\n",
      "627 0 29.390315055847168\n",
      "Training time took 29.509472 seconds to run 1 epoch\n",
      "Epoch:  628  Average loss at step  1000 :  7.737926474571228\n",
      "Epoch:  628  Average loss at step  2000 :  8.100610467910766\n",
      "Epoch:  628  Average loss at step  3000 :  8.01310903263092\n",
      "Epoch:  628  Average loss at step  4000 :  8.42505073070526\n",
      "Epoch:  628  Average loss at step  5000 :  7.6003674154281615\n",
      "Epoch:  628  Average loss at step  6000 :  8.166784464836121\n",
      "Epoch:  628  Average loss at step  7000 :  8.350247797966004\n",
      "Epoch:  628  Average loss at step  8000 :  7.923018011569977\n",
      "Epoch:  628  Average loss at step  8472 :  7.731686330176559\n",
      "628 0 21.197904109954834\n",
      "Epoch:  628  Average loss at step  1000 :  2747.1616119384767\n",
      "Epoch:  628  Average loss at step  1491 :  2717.312926854468\n",
      "628 1 11.698923826217651\n",
      "Epoch:  628  Average loss at step  1000 :  3774.59323828125\n",
      "Epoch:  628  Average loss at step  2000 :  3812.242291015625\n",
      "Epoch:  628  Average loss at step  2533 :  3815.21967292186\n",
      "628 2 19.917968034744263\n",
      "Epoch:  628  Average loss at step  1000 :  62.305287017822266\n",
      "Epoch:  628  Average loss at step  1227 :  61.53734669706611\n",
      "628 3 12.62634015083313\n",
      "Epoch:  628  Average loss at step  1000 :  4.621639689445495\n",
      "Epoch:  628  Average loss at step  2000 :  4.573946316242218\n",
      "Epoch:  628  Average loss at step  3000 :  4.502444005012512\n",
      "Epoch:  628  Average loss at step  3222 :  4.46102066275918\n",
      "628 4 33.28890013694763\n",
      "628 5 1.6689300537109375e-06\n",
      "Training time took 99.357417 seconds to run 1 epoch\n",
      "Epoch:  629  Average loss at step  1000 :  0.05225910896062851\n",
      "Epoch:  629  Average loss at step  2000 :  0.055190400898456574\n",
      "Epoch:  629  Average loss at step  3000 :  0.05964334881305695\n",
      "Epoch:  629  Average loss at step  3222 :  0.06271350101822872\n",
      "629 0 29.455612659454346\n",
      "Training time took 29.575779 seconds to run 1 epoch\n",
      "Epoch:  630  Average loss at step  1000 :  8.178980390548706\n",
      "Epoch:  630  Average loss at step  2000 :  8.474081887245179\n",
      "Epoch:  630  Average loss at step  3000 :  8.258861003875733\n",
      "Epoch:  630  Average loss at step  4000 :  8.067151840209961\n",
      "Epoch:  630  Average loss at step  5000 :  8.330513301849365\n",
      "Epoch:  630  Average loss at step  6000 :  7.645481300354004\n",
      "Epoch:  630  Average loss at step  7000 :  7.695580131530762\n",
      "Epoch:  630  Average loss at step  8000 :  8.155409141540527\n",
      "Epoch:  630  Average loss at step  8472 :  7.917708916674445\n",
      "630 0 21.08457088470459\n",
      "Epoch:  630  Average loss at step  1000 :  2696.0134072265623\n",
      "Epoch:  630  Average loss at step  1491 :  2744.1127464809297\n",
      "630 1 11.741109132766724\n",
      "Epoch:  630  Average loss at step  1000 :  3793.919005126953\n",
      "Epoch:  630  Average loss at step  2000 :  3784.6052694091795\n",
      "Epoch:  630  Average loss at step  2533 :  3809.41202190726\n",
      "630 2 19.907506704330444\n",
      "Epoch:  630  Average loss at step  1000 :  62.587313152313236\n",
      "Epoch:  630  Average loss at step  1227 :  63.050767748189784\n",
      "630 3 12.627601623535156\n",
      "Epoch:  630  Average loss at step  1000 :  4.581645014286042\n",
      "Epoch:  630  Average loss at step  2000 :  4.490597496509552\n",
      "Epoch:  630  Average loss at step  3000 :  4.568823664188385\n",
      "Epoch:  630  Average loss at step  3222 :  4.445650313257374\n",
      "630 4 33.161710023880005\n",
      "630 5 1.6689300537109375e-06\n",
      "Training time took 99.160972 seconds to run 1 epoch\n",
      "Mean Rank:  154.17  of  75000\n",
      "Hits @ 10:  0.85472\n",
      "Hits @ 1:  0.62248\n",
      "Testing time took 163.676335 seconds.\n",
      "\n",
      "Epoch:  631  Average loss at step  1000 :  0.0520451112985611\n",
      "Epoch:  631  Average loss at step  2000 :  0.0552157147526741\n",
      "Epoch:  631  Average loss at step  3000 :  0.05976678436994553\n",
      "Epoch:  631  Average loss at step  3222 :  0.06316291858711319\n",
      "631 0 29.471851587295532\n",
      "Training time took 29.583501 seconds to run 1 epoch\n",
      "Epoch:  632  Average loss at step  1000 :  8.144136569023132\n",
      "Epoch:  632  Average loss at step  2000 :  7.8903201370239255\n",
      "Epoch:  632  Average loss at step  3000 :  7.9906851072311404\n",
      "Epoch:  632  Average loss at step  4000 :  8.48887815284729\n",
      "Epoch:  632  Average loss at step  5000 :  8.176755036354065\n",
      "Epoch:  632  Average loss at step  6000 :  7.850712497711181\n",
      "Epoch:  632  Average loss at step  7000 :  7.773087062835693\n",
      "Epoch:  632  Average loss at step  8000 :  7.641755981445312\n",
      "Epoch:  632  Average loss at step  8472 :  7.707228736882298\n",
      "632 0 20.52238392829895\n",
      "Epoch:  632  Average loss at step  1000 :  2719.144587890625\n",
      "Epoch:  632  Average loss at step  1491 :  2731.259391056897\n",
      "632 1 11.725402116775513\n",
      "Epoch:  632  Average loss at step  1000 :  3828.984704956055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  632  Average loss at step  2000 :  3794.619338745117\n",
      "Epoch:  632  Average loss at step  2533 :  3809.886485300795\n",
      "632 2 19.9423930644989\n",
      "Epoch:  632  Average loss at step  1000 :  62.07920824050903\n",
      "Epoch:  632  Average loss at step  1227 :  62.22623199948921\n",
      "632 3 12.662624835968018\n",
      "Epoch:  632  Average loss at step  1000 :  4.568992839813232\n",
      "Epoch:  632  Average loss at step  2000 :  4.5445224843025205\n",
      "Epoch:  632  Average loss at step  3000 :  4.512884719371796\n",
      "Epoch:  632  Average loss at step  3222 :  4.477037542411665\n",
      "632 4 33.30451512336731\n",
      "632 5 1.1920928955078125e-06\n",
      "Training time took 98.795074 seconds to run 1 epoch\n",
      "Epoch:  633  Average loss at step  1000 :  0.05226389843225479\n",
      "Epoch:  633  Average loss at step  2000 :  0.05469840061664581\n",
      "Epoch:  633  Average loss at step  3000 :  0.059559646844863895\n",
      "Epoch:  633  Average loss at step  3222 :  0.06230622825908368\n",
      "633 0 29.388939380645752\n",
      "Training time took 29.506352 seconds to run 1 epoch\n",
      "Epoch:  634  Average loss at step  1000 :  8.02165424156189\n",
      "Epoch:  634  Average loss at step  2000 :  8.632841653823853\n",
      "Epoch:  634  Average loss at step  3000 :  8.370027583122253\n",
      "Epoch:  634  Average loss at step  4000 :  7.728058705329895\n",
      "Epoch:  634  Average loss at step  5000 :  8.417917504310608\n",
      "Epoch:  634  Average loss at step  6000 :  8.770784160614014\n",
      "Epoch:  634  Average loss at step  7000 :  8.112621382713318\n",
      "Epoch:  634  Average loss at step  8000 :  7.907982187271118\n",
      "Epoch:  634  Average loss at step  8472 :  7.729212793832946\n",
      "634 0 20.24867844581604\n",
      "Epoch:  634  Average loss at step  1000 :  2740.1364135742188\n",
      "Epoch:  634  Average loss at step  1491 :  2701.851990368965\n",
      "634 1 11.746231317520142\n",
      "Epoch:  634  Average loss at step  1000 :  3768.6128706054687\n",
      "Epoch:  634  Average loss at step  2000 :  3806.3738857421877\n",
      "Epoch:  634  Average loss at step  2533 :  3785.029101951613\n",
      "634 2 19.952046394348145\n",
      "Epoch:  634  Average loss at step  1000 :  61.77162649917602\n",
      "Epoch:  634  Average loss at step  1227 :  63.26674516354482\n",
      "634 3 12.649324893951416\n",
      "Epoch:  634  Average loss at step  1000 :  4.4895609536170955\n",
      "Epoch:  634  Average loss at step  2000 :  4.515261556625366\n",
      "Epoch:  634  Average loss at step  3000 :  4.613872473716736\n",
      "Epoch:  634  Average loss at step  3222 :  4.5479541200230456\n",
      "634 4 33.24643039703369\n",
      "634 5 1.1920928955078125e-06\n",
      "Training time took 98.46805 seconds to run 1 epoch\n",
      "Epoch:  635  Average loss at step  1000 :  0.05209651774168014\n",
      "Epoch:  635  Average loss at step  2000 :  0.05466316705942154\n",
      "Epoch:  635  Average loss at step  3000 :  0.0591860973238945\n",
      "Epoch:  635  Average loss at step  3222 :  0.06258438846913889\n",
      "635 0 29.40010929107666\n",
      "Training time took 29.519888 seconds to run 1 epoch\n",
      "Epoch:  636  Average loss at step  1000 :  8.181217423439026\n",
      "Epoch:  636  Average loss at step  2000 :  7.982851468086243\n",
      "Epoch:  636  Average loss at step  3000 :  7.973959881782532\n",
      "Epoch:  636  Average loss at step  4000 :  8.094926889419556\n",
      "Epoch:  636  Average loss at step  5000 :  8.075801706314087\n",
      "Epoch:  636  Average loss at step  6000 :  8.055273342132569\n",
      "Epoch:  636  Average loss at step  7000 :  7.700801981925965\n",
      "Epoch:  636  Average loss at step  8000 :  7.78780569934845\n",
      "Epoch:  636  Average loss at step  8472 :  7.561512700942987\n",
      "636 0 20.827829360961914\n",
      "Epoch:  636  Average loss at step  1000 :  2736.5861322021483\n",
      "Epoch:  636  Average loss at step  1491 :  2710.634388520655\n",
      "636 1 11.748828887939453\n",
      "Epoch:  636  Average loss at step  1000 :  3801.9271213378906\n",
      "Epoch:  636  Average loss at step  2000 :  3823.2985563964844\n",
      "Epoch:  636  Average loss at step  2533 :  3794.639924377068\n",
      "636 2 19.911465406417847\n",
      "Epoch:  636  Average loss at step  1000 :  62.617445575714115\n",
      "Epoch:  636  Average loss at step  1227 :  61.838389488513386\n",
      "636 3 12.72972297668457\n",
      "Epoch:  636  Average loss at step  1000 :  4.519617309570313\n",
      "Epoch:  636  Average loss at step  2000 :  4.458189022541046\n",
      "Epoch:  636  Average loss at step  3000 :  4.432704487800598\n",
      "Epoch:  636  Average loss at step  3222 :  4.583076095081749\n",
      "636 4 33.20569443702698\n",
      "636 5 1.6689300537109375e-06\n",
      "Training time took 99.041931 seconds to run 1 epoch\n",
      "Epoch:  637  Average loss at step  1000 :  0.05165378314256668\n",
      "Epoch:  637  Average loss at step  2000 :  0.05465592133998871\n",
      "Epoch:  637  Average loss at step  3000 :  0.05942323160171509\n",
      "Epoch:  637  Average loss at step  3222 :  0.06203282867275995\n",
      "637 0 29.40071201324463\n",
      "Training time took 29.520388 seconds to run 1 epoch\n",
      "Epoch:  638  Average loss at step  1000 :  8.215100999832153\n",
      "Epoch:  638  Average loss at step  2000 :  8.511997030258179\n",
      "Epoch:  638  Average loss at step  3000 :  7.907726674079895\n",
      "Epoch:  638  Average loss at step  4000 :  8.182177474975585\n",
      "Epoch:  638  Average loss at step  5000 :  7.985338044166565\n",
      "Epoch:  638  Average loss at step  6000 :  7.880097516059876\n",
      "Epoch:  638  Average loss at step  7000 :  8.121113144874572\n",
      "Epoch:  638  Average loss at step  8000 :  8.328137459754943\n",
      "Epoch:  638  Average loss at step  8472 :  8.074725254561235\n",
      "638 0 20.816341876983643\n",
      "Epoch:  638  Average loss at step  1000 :  2718.1758139648437\n",
      "Epoch:  638  Average loss at step  1491 :  2792.730190847521\n",
      "638 1 11.722625017166138\n",
      "Epoch:  638  Average loss at step  1000 :  3836.6093408203124\n",
      "Epoch:  638  Average loss at step  2000 :  3801.761608886719\n",
      "Epoch:  638  Average loss at step  2533 :  3807.6006378252987\n",
      "638 2 19.957080364227295\n",
      "Epoch:  638  Average loss at step  1000 :  61.75003322219849\n",
      "Epoch:  638  Average loss at step  1227 :  62.70542881057234\n",
      "638 3 12.63463306427002\n",
      "Epoch:  638  Average loss at step  1000 :  4.428250026702881\n",
      "Epoch:  638  Average loss at step  2000 :  4.369701977729798\n",
      "Epoch:  638  Average loss at step  3000 :  4.394585171222687\n",
      "Epoch:  638  Average loss at step  3222 :  4.464664565115807\n",
      "638 4 33.27211332321167\n",
      "638 5 1.6689300537109375e-06\n",
      "Training time took 99.041274 seconds to run 1 epoch\n",
      "Epoch:  639  Average loss at step  1000 :  0.05192713838815689\n",
      "Epoch:  639  Average loss at step  2000 :  0.05464570140838623\n",
      "Epoch:  639  Average loss at step  3000 :  0.05881980580091477\n",
      "Epoch:  639  Average loss at step  3222 :  0.06209845619525348\n",
      "639 0 29.397854328155518\n",
      "Training time took 29.518668 seconds to run 1 epoch\n",
      "Epoch:  640  Average loss at step  1000 :  8.287409350395203\n",
      "Epoch:  640  Average loss at step  2000 :  8.584608428955079\n",
      "Epoch:  640  Average loss at step  3000 :  8.280240339756013\n",
      "Epoch:  640  Average loss at step  4000 :  8.245823720932007\n",
      "Epoch:  640  Average loss at step  5000 :  8.02309281539917\n",
      "Epoch:  640  Average loss at step  6000 :  8.825467963695527\n",
      "Epoch:  640  Average loss at step  7000 :  7.997756839752197\n",
      "Epoch:  640  Average loss at step  8000 :  7.894943593978882\n",
      "Epoch:  640  Average loss at step  8472 :  7.973747248155982\n",
      "640 0 20.25793957710266\n",
      "Epoch:  640  Average loss at step  1000 :  2747.097700317383\n",
      "Epoch:  640  Average loss at step  1491 :  2719.198648990739\n",
      "640 1 11.72648811340332\n",
      "Epoch:  640  Average loss at step  1000 :  3808.243354614258\n",
      "Epoch:  640  Average loss at step  2000 :  3787.3069416503904\n",
      "Epoch:  640  Average loss at step  2533 :  3802.088414587142\n",
      "640 2 19.92913556098938\n",
      "Epoch:  640  Average loss at step  1000 :  62.05868137741089\n",
      "Epoch:  640  Average loss at step  1227 :  62.57047858094961\n",
      "640 3 12.615735054016113\n",
      "Epoch:  640  Average loss at step  1000 :  4.491064154148102\n",
      "Epoch:  640  Average loss at step  2000 :  4.430096632003784\n",
      "Epoch:  640  Average loss at step  3000 :  4.282704285621643\n",
      "Epoch:  640  Average loss at step  3222 :  4.354678600956589\n",
      "640 4 33.19485783576965\n",
      "640 5 1.430511474609375e-06\n",
      "Training time took 98.357275 seconds to run 1 epoch\n",
      "Mean Rank:  155.8148  of  75000\n",
      "Hits @ 10:  0.85544\n",
      "Hits @ 1:  0.6224\n",
      "Testing time took 163.654013 seconds.\n",
      "\n",
      "Epoch:  641  Average loss at step  1000 :  0.051553468346595764\n",
      "Epoch:  641  Average loss at step  2000 :  0.053857337176799774\n",
      "Epoch:  641  Average loss at step  3000 :  0.058827682852745054\n",
      "Epoch:  641  Average loss at step  3222 :  0.06197477575027678\n",
      "641 0 29.40620732307434\n",
      "Training time took 29.515767 seconds to run 1 epoch\n",
      "Epoch:  642  Average loss at step  1000 :  7.984341677665711\n",
      "Epoch:  642  Average loss at step  2000 :  8.34798749923706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  642  Average loss at step  3000 :  8.079383231163025\n",
      "Epoch:  642  Average loss at step  4000 :  8.016612662315369\n",
      "Epoch:  642  Average loss at step  5000 :  7.731168371200561\n",
      "Epoch:  642  Average loss at step  6000 :  7.9387403383255\n",
      "Epoch:  642  Average loss at step  7000 :  7.274161565303802\n",
      "Epoch:  642  Average loss at step  8000 :  7.846512051105499\n",
      "Epoch:  642  Average loss at step  8472 :  8.282580567329122\n",
      "642 0 20.44792866706848\n",
      "Epoch:  642  Average loss at step  1000 :  2735.289130859375\n",
      "Epoch:  642  Average loss at step  1491 :  2700.08542335903\n",
      "642 1 11.710092782974243\n",
      "Epoch:  642  Average loss at step  1000 :  3853.624104980469\n",
      "Epoch:  642  Average loss at step  2000 :  3834.2201811523437\n",
      "Epoch:  642  Average loss at step  2533 :  3803.553234017604\n",
      "642 2 19.930732011795044\n",
      "Epoch:  642  Average loss at step  1000 :  61.892478324890135\n",
      "Epoch:  642  Average loss at step  1227 :  61.20968369027748\n",
      "642 3 12.627790212631226\n",
      "Epoch:  642  Average loss at step  1000 :  4.5311973190307615\n",
      "Epoch:  642  Average loss at step  2000 :  4.411932322025299\n",
      "Epoch:  642  Average loss at step  3000 :  4.311681427001953\n",
      "Epoch:  642  Average loss at step  3222 :  4.370457701227643\n",
      "642 4 33.182414531707764\n",
      "642 5 1.1920928955078125e-06\n",
      "Training time took 98.527569 seconds to run 1 epoch\n",
      "Epoch:  643  Average loss at step  1000 :  0.05122033256292343\n",
      "Epoch:  643  Average loss at step  2000 :  0.05399407082796097\n",
      "Epoch:  643  Average loss at step  3000 :  0.05917557591199875\n",
      "Epoch:  643  Average loss at step  3222 :  0.06180399429240711\n",
      "643 0 29.41433334350586\n",
      "Training time took 29.535064 seconds to run 1 epoch\n",
      "Epoch:  644  Average loss at step  1000 :  8.068460957527162\n",
      "Epoch:  644  Average loss at step  2000 :  7.894618445396423\n",
      "Epoch:  644  Average loss at step  3000 :  7.893659571647644\n",
      "Epoch:  644  Average loss at step  4000 :  7.871165975570679\n",
      "Epoch:  644  Average loss at step  5000 :  8.208859175682068\n",
      "Epoch:  644  Average loss at step  6000 :  8.575190191268922\n",
      "Epoch:  644  Average loss at step  7000 :  8.064592611312866\n",
      "Epoch:  644  Average loss at step  8000 :  8.621896421432496\n",
      "Epoch:  644  Average loss at step  8472 :  8.181452468833859\n",
      "644 0 20.259280920028687\n",
      "Epoch:  644  Average loss at step  1000 :  2743.6947423095703\n",
      "Epoch:  644  Average loss at step  1491 :  2735.140202302979\n",
      "644 1 11.73904013633728\n",
      "Epoch:  644  Average loss at step  1000 :  3842.1077873535155\n",
      "Epoch:  644  Average loss at step  2000 :  3809.2966311035157\n",
      "Epoch:  644  Average loss at step  2533 :  3873.47016113887\n",
      "644 2 19.884299278259277\n",
      "Epoch:  644  Average loss at step  1000 :  62.16662052536011\n",
      "Epoch:  644  Average loss at step  1227 :  62.0349032975539\n",
      "644 3 12.603997945785522\n",
      "Epoch:  644  Average loss at step  1000 :  4.434715986251831\n",
      "Epoch:  644  Average loss at step  2000 :  4.464099572181702\n",
      "Epoch:  644  Average loss at step  3000 :  4.360375494480133\n",
      "Epoch:  644  Average loss at step  3222 :  4.652524876839892\n",
      "644 4 33.20095372200012\n",
      "644 5 1.430511474609375e-06\n",
      "Training time took 98.33691 seconds to run 1 epoch\n",
      "Epoch:  645  Average loss at step  1000 :  0.05173388117551803\n",
      "Epoch:  645  Average loss at step  2000 :  0.053646856129169466\n",
      "Epoch:  645  Average loss at step  3000 :  0.058445108115673064\n",
      "Epoch:  645  Average loss at step  3222 :  0.06159932755631948\n",
      "645 0 29.33782124519348\n",
      "Training time took 29.458457 seconds to run 1 epoch\n",
      "Epoch:  646  Average loss at step  1000 :  8.236677114486694\n",
      "Epoch:  646  Average loss at step  2000 :  7.880222506523133\n",
      "Epoch:  646  Average loss at step  3000 :  7.73620760345459\n",
      "Epoch:  646  Average loss at step  4000 :  8.430879475593567\n",
      "Epoch:  646  Average loss at step  5000 :  7.7855556154251095\n",
      "Epoch:  646  Average loss at step  6000 :  8.021985233306884\n",
      "Epoch:  646  Average loss at step  7000 :  8.702226737499236\n",
      "Epoch:  646  Average loss at step  8000 :  8.190345239639282\n",
      "Epoch:  646  Average loss at step  8472 :  8.014394773408231\n",
      "646 0 20.89949655532837\n",
      "Epoch:  646  Average loss at step  1000 :  2749.54649609375\n",
      "Epoch:  646  Average loss at step  1491 :  2731.6803669144215\n",
      "646 1 11.696563243865967\n",
      "Epoch:  646  Average loss at step  1000 :  3844.163399658203\n",
      "Epoch:  646  Average loss at step  2000 :  3838.928878417969\n",
      "Epoch:  646  Average loss at step  2533 :  3836.531377370137\n",
      "646 2 19.90675663948059\n",
      "Epoch:  646  Average loss at step  1000 :  62.059254245758055\n",
      "Epoch:  646  Average loss at step  1227 :  63.038157924491045\n",
      "646 3 12.582608699798584\n",
      "Epoch:  646  Average loss at step  1000 :  4.473495289325714\n",
      "Epoch:  646  Average loss at step  2000 :  4.4654650664329525\n",
      "Epoch:  646  Average loss at step  3000 :  4.382493741512299\n",
      "Epoch:  646  Average loss at step  3222 :  4.467633991255229\n",
      "646 4 33.15206432342529\n",
      "646 5 1.430511474609375e-06\n",
      "Training time took 98.857252 seconds to run 1 epoch\n",
      "Epoch:  647  Average loss at step  1000 :  0.051342292726039886\n",
      "Epoch:  647  Average loss at step  2000 :  0.05367157757282257\n",
      "Epoch:  647  Average loss at step  3000 :  0.05839523839950562\n",
      "Epoch:  647  Average loss at step  3222 :  0.061310044069284995\n",
      "647 0 29.417455434799194\n",
      "Training time took 29.536984 seconds to run 1 epoch\n",
      "Epoch:  648  Average loss at step  1000 :  7.993785059928894\n",
      "Epoch:  648  Average loss at step  2000 :  7.9601349411010744\n",
      "Epoch:  648  Average loss at step  3000 :  7.681071617126465\n",
      "Epoch:  648  Average loss at step  4000 :  8.229434818267823\n",
      "Epoch:  648  Average loss at step  5000 :  7.738738041877746\n",
      "Epoch:  648  Average loss at step  6000 :  8.096900493621826\n",
      "Epoch:  648  Average loss at step  7000 :  7.590330744743347\n",
      "Epoch:  648  Average loss at step  8000 :  7.886816493988037\n",
      "Epoch:  648  Average loss at step  8472 :  7.888719490229043\n",
      "648 0 20.684373378753662\n",
      "Epoch:  648  Average loss at step  1000 :  2773.3452971191405\n",
      "Epoch:  648  Average loss at step  1491 :  2728.803759971508\n",
      "648 1 11.745551586151123\n",
      "Epoch:  648  Average loss at step  1000 :  3831.4918129882813\n",
      "Epoch:  648  Average loss at step  2000 :  3855.8573500976563\n",
      "Epoch:  648  Average loss at step  2533 :  3805.307270106403\n",
      "648 2 19.89888572692871\n",
      "Epoch:  648  Average loss at step  1000 :  62.4201263923645\n",
      "Epoch:  648  Average loss at step  1227 :  63.44081262541464\n",
      "648 3 12.63160753250122\n",
      "Epoch:  648  Average loss at step  1000 :  4.461151255130768\n",
      "Epoch:  648  Average loss at step  2000 :  4.39893317079544\n",
      "Epoch:  648  Average loss at step  3000 :  4.294537832260132\n",
      "Epoch:  648  Average loss at step  3222 :  4.4701158193328965\n",
      "648 4 33.144442081451416\n",
      "648 5 1.1920928955078125e-06\n",
      "Training time took 98.731982 seconds to run 1 epoch\n",
      "Epoch:  649  Average loss at step  1000 :  0.05074969631433487\n",
      "Epoch:  649  Average loss at step  2000 :  0.05370979768037796\n",
      "Epoch:  649  Average loss at step  3000 :  0.05855825537443161\n",
      "Epoch:  649  Average loss at step  3222 :  0.06184301924718418\n",
      "649 0 29.43040657043457\n",
      "Training time took 29.549238 seconds to run 1 epoch\n",
      "Epoch:  650  Average loss at step  1000 :  8.24009140586853\n",
      "Epoch:  650  Average loss at step  2000 :  7.637163264274597\n",
      "Epoch:  650  Average loss at step  3000 :  8.3662508354187\n",
      "Epoch:  650  Average loss at step  4000 :  8.19726629257202\n",
      "Epoch:  650  Average loss at step  5000 :  8.124615023612977\n",
      "Epoch:  650  Average loss at step  6000 :  7.590928846359253\n",
      "Epoch:  650  Average loss at step  7000 :  8.233792516708373\n",
      "Epoch:  650  Average loss at step  8000 :  8.250900961875915\n",
      "Epoch:  650  Average loss at step  8472 :  7.225438102559289\n",
      "650 0 20.736762285232544\n",
      "Epoch:  650  Average loss at step  1000 :  2750.0980727539063\n",
      "Epoch:  650  Average loss at step  1491 :  2764.5647007417683\n",
      "650 1 11.705183506011963\n",
      "Epoch:  650  Average loss at step  1000 :  3868.1477045898437\n",
      "Epoch:  650  Average loss at step  2000 :  3833.353927246094\n",
      "Epoch:  650  Average loss at step  2533 :  3827.3224190124533\n",
      "650 2 19.938796043395996\n",
      "Epoch:  650  Average loss at step  1000 :  62.87910146331787\n",
      "Epoch:  650  Average loss at step  1227 :  62.773523756890484\n",
      "650 3 12.652225017547607\n",
      "Epoch:  650  Average loss at step  1000 :  4.511460891246796\n",
      "Epoch:  650  Average loss at step  2000 :  4.326150186538697\n",
      "Epoch:  650  Average loss at step  3000 :  4.38001971912384\n",
      "Epoch:  650  Average loss at step  3222 :  4.4735143709363525\n",
      "650 4 33.16913676261902\n",
      "650 5 1.6689300537109375e-06\n",
      "Training time took 98.829855 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank:  153.81976  of  75000\n",
      "Hits @ 10:  0.8546\n",
      "Hits @ 1:  0.62292\n",
      "Testing time took 164.038232 seconds.\n",
      "\n",
      "Epoch:  651  Average loss at step  1000 :  0.05086770820617676\n",
      "Epoch:  651  Average loss at step  2000 :  0.05364987450838089\n",
      "Epoch:  651  Average loss at step  3000 :  0.05818152052164078\n",
      "Epoch:  651  Average loss at step  3222 :  0.06115466684485024\n",
      "651 0 29.35942816734314\n",
      "Training time took 29.468268 seconds to run 1 epoch\n",
      "Epoch:  652  Average loss at step  1000 :  8.121924046516419\n",
      "Epoch:  652  Average loss at step  2000 :  7.748706569671631\n",
      "Epoch:  652  Average loss at step  3000 :  8.478539793968201\n",
      "Epoch:  652  Average loss at step  4000 :  8.372852677345277\n",
      "Epoch:  652  Average loss at step  5000 :  7.716240970611572\n",
      "Epoch:  652  Average loss at step  6000 :  7.453287112236023\n",
      "Epoch:  652  Average loss at step  7000 :  7.811762154579163\n",
      "Epoch:  652  Average loss at step  8000 :  7.699924801826477\n",
      "Epoch:  652  Average loss at step  8472 :  7.930733763824005\n",
      "652 0 20.49493098258972\n",
      "Epoch:  652  Average loss at step  1000 :  2772.787278808594\n",
      "Epoch:  652  Average loss at step  1491 :  2758.6287653045783\n",
      "652 1 11.722374200820923\n",
      "Epoch:  652  Average loss at step  1000 :  3828.408682128906\n",
      "Epoch:  652  Average loss at step  2000 :  3845.8212646484376\n",
      "Epoch:  652  Average loss at step  2533 :  3839.7730177723147\n",
      "652 2 19.916208028793335\n",
      "Epoch:  652  Average loss at step  1000 :  62.26367543411255\n",
      "Epoch:  652  Average loss at step  1227 :  61.66677577213579\n",
      "652 3 12.675304412841797\n",
      "Epoch:  652  Average loss at step  1000 :  4.402851199150086\n",
      "Epoch:  652  Average loss at step  2000 :  4.286991021633148\n",
      "Epoch:  652  Average loss at step  3000 :  4.407670726776123\n",
      "Epoch:  652  Average loss at step  3222 :  4.5901119547601335\n",
      "652 4 33.21553564071655\n",
      "652 5 1.1920928955078125e-06\n",
      "Training time took 98.646302 seconds to run 1 epoch\n",
      "Epoch:  653  Average loss at step  1000 :  0.050517395853996276\n",
      "Epoch:  653  Average loss at step  2000 :  0.05360556906461716\n",
      "Epoch:  653  Average loss at step  3000 :  0.05800080996751785\n",
      "Epoch:  653  Average loss at step  3222 :  0.06109374049209606\n",
      "653 0 29.401057720184326\n",
      "Training time took 29.517076 seconds to run 1 epoch\n",
      "Epoch:  654  Average loss at step  1000 :  8.067208134651183\n",
      "Epoch:  654  Average loss at step  2000 :  8.147962006568909\n",
      "Epoch:  654  Average loss at step  3000 :  8.556194063186645\n",
      "Epoch:  654  Average loss at step  4000 :  8.291310514450073\n",
      "Epoch:  654  Average loss at step  5000 :  8.00627544593811\n",
      "Epoch:  654  Average loss at step  6000 :  8.243366748809814\n",
      "Epoch:  654  Average loss at step  7000 :  7.980637666702271\n",
      "Epoch:  654  Average loss at step  8000 :  7.736213690757752\n",
      "Epoch:  654  Average loss at step  8472 :  8.299631303591566\n",
      "654 0 21.454097986221313\n",
      "Epoch:  654  Average loss at step  1000 :  2780.5232795410157\n",
      "Epoch:  654  Average loss at step  1491 :  2771.1098683139494\n",
      "654 1 11.740035057067871\n",
      "Epoch:  654  Average loss at step  1000 :  3863.8659810791014\n",
      "Epoch:  654  Average loss at step  2000 :  3879.6349318847656\n",
      "Epoch:  654  Average loss at step  2533 :  3834.252931064078\n",
      "654 2 19.89749264717102\n",
      "Epoch:  654  Average loss at step  1000 :  62.16921271896362\n",
      "Epoch:  654  Average loss at step  1227 :  62.58175060999075\n",
      "654 3 12.616586208343506\n",
      "Epoch:  654  Average loss at step  1000 :  4.48431187915802\n",
      "Epoch:  654  Average loss at step  2000 :  4.368940489292145\n",
      "Epoch:  654  Average loss at step  3000 :  4.303304452896118\n",
      "Epoch:  654  Average loss at step  3222 :  4.342218905843366\n",
      "654 4 33.15042018890381\n",
      "654 5 1.430511474609375e-06\n",
      "Training time took 99.499177 seconds to run 1 epoch\n",
      "Epoch:  655  Average loss at step  1000 :  0.05045005738735199\n",
      "Epoch:  655  Average loss at step  2000 :  0.053013292491436007\n",
      "Epoch:  655  Average loss at step  3000 :  0.05810095918178558\n",
      "Epoch:  655  Average loss at step  3222 :  0.06085734065850088\n",
      "655 0 29.43905806541443\n",
      "Training time took 29.558652 seconds to run 1 epoch\n",
      "Epoch:  656  Average loss at step  1000 :  8.067489056587219\n",
      "Epoch:  656  Average loss at step  2000 :  7.801016115665436\n",
      "Epoch:  656  Average loss at step  3000 :  7.992788625717163\n",
      "Epoch:  656  Average loss at step  4000 :  8.124340291976928\n",
      "Epoch:  656  Average loss at step  5000 :  8.08645889377594\n",
      "Epoch:  656  Average loss at step  6000 :  7.923446844100952\n",
      "Epoch:  656  Average loss at step  7000 :  8.295433387756347\n",
      "Epoch:  656  Average loss at step  8000 :  8.367234833717346\n",
      "Epoch:  656  Average loss at step  8472 :  8.320350988192235\n",
      "656 0 20.62576460838318\n",
      "Epoch:  656  Average loss at step  1000 :  2762.51105871582\n",
      "Epoch:  656  Average loss at step  1491 :  2726.732172338645\n",
      "656 1 11.721769332885742\n",
      "Epoch:  656  Average loss at step  1000 :  3867.84633984375\n",
      "Epoch:  656  Average loss at step  2000 :  3867.797202392578\n",
      "Epoch:  656  Average loss at step  2533 :  3816.651336333808\n",
      "656 2 19.87523126602173\n",
      "Epoch:  656  Average loss at step  1000 :  61.86446323776245\n",
      "Epoch:  656  Average loss at step  1227 :  61.89553132101157\n",
      "656 3 12.68634557723999\n",
      "Epoch:  656  Average loss at step  1000 :  4.458600512981414\n",
      "Epoch:  656  Average loss at step  2000 :  4.349272926330566\n",
      "Epoch:  656  Average loss at step  3000 :  4.356060069084167\n",
      "Epoch:  656  Average loss at step  3222 :  4.632402716786622\n",
      "656 4 33.207258224487305\n",
      "656 5 1.6689300537109375e-06\n",
      "Training time took 98.751867 seconds to run 1 epoch\n",
      "Epoch:  657  Average loss at step  1000 :  0.050340630412101746\n",
      "Epoch:  657  Average loss at step  2000 :  0.05322735816240311\n",
      "Epoch:  657  Average loss at step  3000 :  0.05790228497982025\n",
      "Epoch:  657  Average loss at step  3222 :  0.060527685220587185\n",
      "657 0 29.398940086364746\n",
      "Training time took 29.522634 seconds to run 1 epoch\n",
      "Epoch:  658  Average loss at step  1000 :  8.00052615594864\n",
      "Epoch:  658  Average loss at step  2000 :  8.11435296201706\n",
      "Epoch:  658  Average loss at step  3000 :  7.842524055480957\n",
      "Epoch:  658  Average loss at step  4000 :  7.328798845767975\n",
      "Epoch:  658  Average loss at step  5000 :  8.438512482643127\n",
      "Epoch:  658  Average loss at step  6000 :  8.018993975639344\n",
      "Epoch:  658  Average loss at step  7000 :  8.058119771957397\n",
      "Epoch:  658  Average loss at step  8000 :  7.88794544506073\n",
      "Epoch:  658  Average loss at step  8472 :  8.0500789745307\n",
      "658 0 21.333611011505127\n",
      "Epoch:  658  Average loss at step  1000 :  2755.758088012695\n",
      "Epoch:  658  Average loss at step  1491 :  2732.3249152218905\n",
      "658 1 11.717463731765747\n",
      "Epoch:  658  Average loss at step  1000 :  3857.3798391113282\n",
      "Epoch:  658  Average loss at step  2000 :  3882.6609895019533\n",
      "Epoch:  658  Average loss at step  2533 :  3840.234174478531\n",
      "658 2 19.92189931869507\n",
      "Epoch:  658  Average loss at step  1000 :  62.13438679885864\n",
      "Epoch:  658  Average loss at step  1227 :  62.1762208925556\n",
      "658 3 12.57088303565979\n",
      "Epoch:  658  Average loss at step  1000 :  4.48529377412796\n",
      "Epoch:  658  Average loss at step  2000 :  4.329995388031006\n",
      "Epoch:  658  Average loss at step  3000 :  4.3919324865341185\n",
      "Epoch:  658  Average loss at step  3222 :  4.323095258639422\n",
      "658 4 33.21816849708557\n",
      "658 5 1.430511474609375e-06\n",
      "Training time took 99.384369 seconds to run 1 epoch\n",
      "Epoch:  659  Average loss at step  1000 :  0.050343874335289\n",
      "Epoch:  659  Average loss at step  2000 :  0.05333997470140457\n",
      "Epoch:  659  Average loss at step  3000 :  0.057158596158027646\n",
      "Epoch:  659  Average loss at step  3222 :  0.06040144341154248\n",
      "659 0 29.40193271636963\n",
      "Training time took 29.524478 seconds to run 1 epoch\n",
      "Epoch:  660  Average loss at step  1000 :  8.058528421401977\n",
      "Epoch:  660  Average loss at step  2000 :  7.829069975852966\n",
      "Epoch:  660  Average loss at step  3000 :  8.22943201160431\n",
      "Epoch:  660  Average loss at step  4000 :  8.041082320213318\n",
      "Epoch:  660  Average loss at step  5000 :  7.760433568000794\n",
      "Epoch:  660  Average loss at step  6000 :  8.147318929672242\n",
      "Epoch:  660  Average loss at step  7000 :  8.288851301193237\n",
      "Epoch:  660  Average loss at step  8000 :  8.258501098155975\n",
      "Epoch:  660  Average loss at step  8472 :  7.507456059842627\n",
      "660 0 20.80194926261902\n",
      "Epoch:  660  Average loss at step  1000 :  2767.901305175781\n",
      "Epoch:  660  Average loss at step  1491 :  2760.273256780339\n",
      "660 1 11.675885915756226\n",
      "Epoch:  660  Average loss at step  1000 :  3862.31830859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  660  Average loss at step  2000 :  3856.2274213867186\n",
      "Epoch:  660  Average loss at step  2533 :  3855.0535494190626\n",
      "660 2 19.91518998146057\n",
      "Epoch:  660  Average loss at step  1000 :  61.79050112915039\n",
      "Epoch:  660  Average loss at step  1227 :  61.00271654711743\n",
      "660 3 12.684322834014893\n",
      "Epoch:  660  Average loss at step  1000 :  4.429681492328644\n",
      "Epoch:  660  Average loss at step  2000 :  4.34051784992218\n",
      "Epoch:  660  Average loss at step  3000 :  4.3409525671005245\n",
      "Epoch:  660  Average loss at step  3222 :  4.296183439772317\n",
      "660 4 33.12285280227661\n",
      "660 5 1.6689300537109375e-06\n",
      "Training time took 98.843551 seconds to run 1 epoch\n",
      "Mean Rank:  154.5308  of  75000\n",
      "Hits @ 10:  0.8552\n",
      "Hits @ 1:  0.62148\n",
      "Testing time took 163.855818 seconds.\n",
      "\n",
      "Epoch:  661  Average loss at step  1000 :  0.050588278710842136\n",
      "Epoch:  661  Average loss at step  2000 :  0.05252919167280197\n",
      "Epoch:  661  Average loss at step  3000 :  0.05764467138051987\n",
      "Epoch:  661  Average loss at step  3222 :  0.060123731393120224\n",
      "661 0 29.392367839813232\n",
      "Training time took 29.501333 seconds to run 1 epoch\n",
      "Epoch:  662  Average loss at step  1000 :  8.049644654273987\n",
      "Epoch:  662  Average loss at step  2000 :  8.031943657875061\n",
      "Epoch:  662  Average loss at step  3000 :  7.759415091514588\n",
      "Epoch:  662  Average loss at step  4000 :  8.259662576675415\n",
      "Epoch:  662  Average loss at step  5000 :  7.544622763633728\n",
      "Epoch:  662  Average loss at step  6000 :  7.97155721950531\n",
      "Epoch:  662  Average loss at step  7000 :  8.037782505989075\n",
      "Epoch:  662  Average loss at step  8000 :  7.668485028266907\n",
      "Epoch:  662  Average loss at step  8472 :  8.354675670131742\n",
      "662 0 20.36223292350769\n",
      "Epoch:  662  Average loss at step  1000 :  2769.7623973388672\n",
      "Epoch:  662  Average loss at step  1491 :  2763.9672193631536\n",
      "662 1 11.541808605194092\n",
      "Epoch:  662  Average loss at step  1000 :  3890.8095783691406\n",
      "Epoch:  662  Average loss at step  2000 :  3874.0435842285156\n",
      "Epoch:  662  Average loss at step  2533 :  3875.0830402079596\n",
      "662 2 19.90061330795288\n",
      "Epoch:  662  Average loss at step  1000 :  62.12820774841309\n",
      "Epoch:  662  Average loss at step  1227 :  62.43226032018946\n",
      "662 3 12.706660270690918\n",
      "Epoch:  662  Average loss at step  1000 :  4.325300763607025\n",
      "Epoch:  662  Average loss at step  2000 :  4.3404530353546145\n",
      "Epoch:  662  Average loss at step  3000 :  4.4130259509086605\n",
      "Epoch:  662  Average loss at step  3222 :  4.5865250572139855\n",
      "662 4 33.15615153312683\n",
      "662 5 9.5367431640625e-07\n",
      "Training time took 98.291752 seconds to run 1 epoch\n",
      "Epoch:  663  Average loss at step  1000 :  0.05026060461997986\n",
      "Epoch:  663  Average loss at step  2000 :  0.05269553661346436\n",
      "Epoch:  663  Average loss at step  3000 :  0.0572731152176857\n",
      "Epoch:  663  Average loss at step  3222 :  0.05986952576143988\n",
      "663 0 29.410399436950684\n",
      "Training time took 29.532804 seconds to run 1 epoch\n",
      "Epoch:  664  Average loss at step  1000 :  8.541701910972595\n",
      "Epoch:  664  Average loss at step  2000 :  8.2315387134552\n",
      "Epoch:  664  Average loss at step  3000 :  8.225460317611695\n",
      "Epoch:  664  Average loss at step  4000 :  7.980693674087524\n",
      "Epoch:  664  Average loss at step  5000 :  8.246689059257507\n",
      "Epoch:  664  Average loss at step  6000 :  8.011251035690307\n",
      "Epoch:  664  Average loss at step  7000 :  7.768640340805054\n",
      "Epoch:  664  Average loss at step  8000 :  7.4441704015731816\n",
      "Epoch:  664  Average loss at step  8472 :  8.084907860005277\n",
      "664 0 21.10169243812561\n",
      "Epoch:  664  Average loss at step  1000 :  2771.5041151123046\n",
      "Epoch:  664  Average loss at step  1491 :  2779.451170999748\n",
      "664 1 11.717870950698853\n",
      "Epoch:  664  Average loss at step  1000 :  3871.485971557617\n",
      "Epoch:  664  Average loss at step  2000 :  3840.471814941406\n",
      "Epoch:  664  Average loss at step  2533 :  3861.0357119284895\n",
      "664 2 19.922115802764893\n",
      "Epoch:  664  Average loss at step  1000 :  61.96981712341309\n",
      "Epoch:  664  Average loss at step  1227 :  61.28744447731439\n",
      "664 3 12.675097942352295\n",
      "Epoch:  664  Average loss at step  1000 :  4.349656477451324\n",
      "Epoch:  664  Average loss at step  2000 :  4.271846901416779\n",
      "Epoch:  664  Average loss at step  3000 :  4.236799954891205\n",
      "Epoch:  664  Average loss at step  3222 :  4.163396556490616\n",
      "664 4 33.08153557777405\n",
      "664 5 1.430511474609375e-06\n",
      "Training time took 99.1344 seconds to run 1 epoch\n",
      "Epoch:  665  Average loss at step  1000 :  0.050074085950851444\n",
      "Epoch:  665  Average loss at step  2000 :  0.052260762691497806\n",
      "Epoch:  665  Average loss at step  3000 :  0.05698570156097412\n",
      "Epoch:  665  Average loss at step  3222 :  0.060280499464339096\n",
      "665 0 29.366514444351196\n",
      "Training time took 29.492453 seconds to run 1 epoch\n",
      "Epoch:  666  Average loss at step  1000 :  8.319578466415406\n",
      "Epoch:  666  Average loss at step  2000 :  7.965851103782653\n",
      "Epoch:  666  Average loss at step  3000 :  7.82198951625824\n",
      "Epoch:  666  Average loss at step  4000 :  8.024583474159241\n",
      "Epoch:  666  Average loss at step  5000 :  7.629187880516052\n",
      "Epoch:  666  Average loss at step  6000 :  8.29553571510315\n",
      "Epoch:  666  Average loss at step  7000 :  8.027066125869752\n",
      "Epoch:  666  Average loss at step  8000 :  7.805986595153809\n",
      "Epoch:  666  Average loss at step  8472 :  7.921558160904505\n",
      "666 0 20.39320731163025\n",
      "Epoch:  666  Average loss at step  1000 :  2768.9788513183594\n",
      "Epoch:  666  Average loss at step  1491 :  2749.8336595868586\n",
      "666 1 11.701299667358398\n",
      "Epoch:  666  Average loss at step  1000 :  3853.4725993652346\n",
      "Epoch:  666  Average loss at step  2000 :  3898.5762329101562\n",
      "Epoch:  666  Average loss at step  2533 :  3833.377582578871\n",
      "666 2 19.912566423416138\n",
      "Epoch:  666  Average loss at step  1000 :  62.38056217575073\n",
      "Epoch:  666  Average loss at step  1227 :  62.95056320569426\n",
      "666 3 12.692535638809204\n",
      "Epoch:  666  Average loss at step  1000 :  4.351739518642425\n",
      "Epoch:  666  Average loss at step  2000 :  4.240111443519592\n",
      "Epoch:  666  Average loss at step  3000 :  4.330252740383148\n",
      "Epoch:  666  Average loss at step  3222 :  4.327698080176845\n",
      "666 4 33.17055082321167\n",
      "666 5 1.6689300537109375e-06\n",
      "Training time took 98.512537 seconds to run 1 epoch\n",
      "Epoch:  667  Average loss at step  1000 :  0.050176462769508365\n",
      "Epoch:  667  Average loss at step  2000 :  0.05258288037776947\n",
      "Epoch:  667  Average loss at step  3000 :  0.05678909033536911\n",
      "Epoch:  667  Average loss at step  3222 :  0.06038043382344725\n",
      "667 0 29.39616894721985\n",
      "Training time took 29.518799 seconds to run 1 epoch\n",
      "Epoch:  668  Average loss at step  1000 :  7.632244365692139\n",
      "Epoch:  668  Average loss at step  2000 :  8.051865263938904\n",
      "Epoch:  668  Average loss at step  3000 :  8.690086646080017\n",
      "Epoch:  668  Average loss at step  4000 :  8.475834053993225\n",
      "Epoch:  668  Average loss at step  5000 :  8.164133125305176\n",
      "Epoch:  668  Average loss at step  6000 :  8.056130111694335\n",
      "Epoch:  668  Average loss at step  7000 :  8.077716320991517\n",
      "Epoch:  668  Average loss at step  8000 :  8.475729312896728\n",
      "Epoch:  668  Average loss at step  8472 :  8.359939439517017\n",
      "668 0 21.532288312911987\n",
      "Epoch:  668  Average loss at step  1000 :  2765.303015991211\n",
      "Epoch:  668  Average loss at step  1491 :  2809.199999813014\n",
      "668 1 11.708233833312988\n",
      "Epoch:  668  Average loss at step  1000 :  3876.7344418945313\n",
      "Epoch:  668  Average loss at step  2000 :  3867.859280883789\n",
      "Epoch:  668  Average loss at step  2533 :  3867.3301721727817\n",
      "668 2 19.909389972686768\n",
      "Epoch:  668  Average loss at step  1000 :  62.07635461425781\n",
      "Epoch:  668  Average loss at step  1227 :  61.325685912827446\n",
      "668 3 12.63632583618164\n",
      "Epoch:  668  Average loss at step  1000 :  4.311050981521606\n",
      "Epoch:  668  Average loss at step  2000 :  4.298058220386505\n",
      "Epoch:  668  Average loss at step  3000 :  4.303871401786804\n",
      "Epoch:  668  Average loss at step  3222 :  4.6172322187855865\n",
      "668 4 33.33797264099121\n",
      "668 5 1.1920928955078125e-06\n",
      "Training time took 99.768729 seconds to run 1 epoch\n",
      "Epoch:  669  Average loss at step  1000 :  0.04965795475244522\n",
      "Epoch:  669  Average loss at step  2000 :  0.05196306324005127\n",
      "Epoch:  669  Average loss at step  3000 :  0.0565029548406601\n",
      "Epoch:  669  Average loss at step  3222 :  0.06014241420484489\n",
      "669 0 29.345208406448364\n",
      "Training time took 29.468932 seconds to run 1 epoch\n",
      "Epoch:  670  Average loss at step  1000 :  8.023812160491943\n",
      "Epoch:  670  Average loss at step  2000 :  8.146367535591125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  670  Average loss at step  3000 :  7.701624273300171\n",
      "Epoch:  670  Average loss at step  4000 :  7.859106577396393\n",
      "Epoch:  670  Average loss at step  5000 :  8.069076034545898\n",
      "Epoch:  670  Average loss at step  6000 :  8.296773555755616\n",
      "Epoch:  670  Average loss at step  7000 :  8.10037527036667\n",
      "Epoch:  670  Average loss at step  8000 :  8.333793507575988\n",
      "Epoch:  670  Average loss at step  8472 :  7.893951714005961\n",
      "670 0 20.869287729263306\n",
      "Epoch:  670  Average loss at step  1000 :  2773.050300048828\n",
      "Epoch:  670  Average loss at step  1491 :  2819.241869286195\n",
      "670 1 11.719081401824951\n",
      "Epoch:  670  Average loss at step  1000 :  3891.197736694336\n",
      "Epoch:  670  Average loss at step  2000 :  3857.065594970703\n",
      "Epoch:  670  Average loss at step  2533 :  3877.8514015321934\n",
      "670 2 19.96438241004944\n",
      "Epoch:  670  Average loss at step  1000 :  61.72395111083984\n",
      "Epoch:  670  Average loss at step  1227 :  62.34507896264135\n",
      "670 3 12.66504716873169\n",
      "Epoch:  670  Average loss at step  1000 :  4.479198550224305\n",
      "Epoch:  670  Average loss at step  2000 :  4.232371275424957\n",
      "Epoch:  670  Average loss at step  3000 :  4.257520993709564\n",
      "Epoch:  670  Average loss at step  3222 :  4.129127994257742\n",
      "670 4 33.18012976646423\n",
      "670 5 1.430511474609375e-06\n",
      "Training time took 99.020498 seconds to run 1 epoch\n",
      "Mean Rank:  154.50412  of  75000\n",
      "Hits @ 10:  0.85488\n",
      "Hits @ 1:  0.62296\n",
      "Testing time took 164.019757 seconds.\n",
      "\n",
      "Epoch:  671  Average loss at step  1000 :  0.05010318958759308\n",
      "Epoch:  671  Average loss at step  2000 :  0.05202281856536865\n",
      "Epoch:  671  Average loss at step  3000 :  0.05701433324813843\n",
      "Epoch:  671  Average loss at step  3222 :  0.0596950971643338\n",
      "671 0 29.435790061950684\n",
      "Training time took 29.545302 seconds to run 1 epoch\n",
      "Epoch:  672  Average loss at step  1000 :  7.775028381824494\n",
      "Epoch:  672  Average loss at step  2000 :  8.132622217178344\n",
      "Epoch:  672  Average loss at step  3000 :  8.16450806427002\n",
      "Epoch:  672  Average loss at step  4000 :  8.744867272377014\n",
      "Epoch:  672  Average loss at step  5000 :  8.197752813339234\n",
      "Epoch:  672  Average loss at step  6000 :  8.710146601676941\n",
      "Epoch:  672  Average loss at step  7000 :  7.956774773597718\n",
      "Epoch:  672  Average loss at step  8000 :  8.004809803009033\n",
      "Epoch:  672  Average loss at step  8472 :  7.919672414749629\n",
      "672 0 20.325624465942383\n",
      "Epoch:  672  Average loss at step  1000 :  2758.5576782226562\n",
      "Epoch:  672  Average loss at step  1491 :  2741.4493059370416\n",
      "672 1 11.686546325683594\n",
      "Epoch:  672  Average loss at step  1000 :  3878.066159667969\n",
      "Epoch:  672  Average loss at step  2000 :  3865.3407670898437\n",
      "Epoch:  672  Average loss at step  2533 :  3855.3648151795915\n",
      "672 2 19.898653507232666\n",
      "Epoch:  672  Average loss at step  1000 :  62.350792381286624\n",
      "Epoch:  672  Average loss at step  1227 :  61.483078450589055\n",
      "672 3 12.633419036865234\n",
      "Epoch:  672  Average loss at step  1000 :  4.317164112567902\n",
      "Epoch:  672  Average loss at step  2000 :  4.301227920055389\n",
      "Epoch:  672  Average loss at step  3000 :  4.308278396129608\n",
      "Epoch:  672  Average loss at step  3222 :  4.496419918324074\n",
      "672 4 33.10353136062622\n",
      "672 5 1.1920928955078125e-06\n",
      "Training time took 98.283667 seconds to run 1 epoch\n",
      "Epoch:  673  Average loss at step  1000 :  0.04920143085718155\n",
      "Epoch:  673  Average loss at step  2000 :  0.05191516619920731\n",
      "Epoch:  673  Average loss at step  3000 :  0.05678121340274811\n",
      "Epoch:  673  Average loss at step  3222 :  0.05988747091322605\n",
      "673 0 29.45301127433777\n",
      "Training time took 29.572577 seconds to run 1 epoch\n",
      "Epoch:  674  Average loss at step  1000 :  7.53435837841034\n",
      "Epoch:  674  Average loss at step  2000 :  7.861355906486511\n",
      "Epoch:  674  Average loss at step  3000 :  8.222130390167237\n",
      "Epoch:  674  Average loss at step  4000 :  7.803889888763428\n",
      "Epoch:  674  Average loss at step  5000 :  8.120545216560364\n",
      "Epoch:  674  Average loss at step  6000 :  8.036146484375\n",
      "Epoch:  674  Average loss at step  7000 :  8.184377385139465\n",
      "Epoch:  674  Average loss at step  8000 :  7.80698712348938\n",
      "Epoch:  674  Average loss at step  8472 :  7.871654089215322\n",
      "674 0 20.138525247573853\n",
      "Epoch:  674  Average loss at step  1000 :  2790.6730943603516\n",
      "Epoch:  674  Average loss at step  1491 :  2753.4411252592736\n",
      "674 1 11.67112398147583\n",
      "Epoch:  674  Average loss at step  1000 :  3852.8503654785154\n",
      "Epoch:  674  Average loss at step  2000 :  3902.516235839844\n",
      "Epoch:  674  Average loss at step  2533 :  3852.9657487855284\n",
      "674 2 19.86862301826477\n",
      "Epoch:  674  Average loss at step  1000 :  62.094048133850094\n",
      "Epoch:  674  Average loss at step  1227 :  60.7131784329444\n",
      "674 3 12.656475067138672\n",
      "Epoch:  674  Average loss at step  1000 :  4.238422447681427\n",
      "Epoch:  674  Average loss at step  2000 :  4.1906584162712095\n",
      "Epoch:  674  Average loss at step  3000 :  4.209782814025879\n",
      "Epoch:  674  Average loss at step  3222 :  4.281622030434141\n",
      "674 4 33.24906826019287\n",
      "674 5 1.1920928955078125e-06\n",
      "Training time took 98.215317 seconds to run 1 epoch\n",
      "Epoch:  675  Average loss at step  1000 :  0.04943058443069458\n",
      "Epoch:  675  Average loss at step  2000 :  0.05169744300842285\n",
      "Epoch:  675  Average loss at step  3000 :  0.05652660709619522\n",
      "Epoch:  675  Average loss at step  3222 :  0.05927696988177571\n",
      "675 0 29.192720890045166\n",
      "Training time took 29.315587 seconds to run 1 epoch\n",
      "Epoch:  676  Average loss at step  1000 :  8.15552615737915\n",
      "Epoch:  676  Average loss at step  2000 :  8.112871600151061\n",
      "Epoch:  676  Average loss at step  3000 :  8.076320140838623\n",
      "Epoch:  676  Average loss at step  4000 :  8.059086565971375\n",
      "Epoch:  676  Average loss at step  5000 :  8.433098961830138\n",
      "Epoch:  676  Average loss at step  6000 :  8.096618940830231\n",
      "Epoch:  676  Average loss at step  7000 :  7.81126177072525\n",
      "Epoch:  676  Average loss at step  8000 :  7.779025193214417\n",
      "Epoch:  676  Average loss at step  8472 :  8.62455909217053\n",
      "676 0 20.927733659744263\n",
      "Epoch:  676  Average loss at step  1000 :  2765.860192626953\n",
      "Epoch:  676  Average loss at step  1491 :  2778.966392498596\n",
      "676 1 11.69448709487915\n",
      "Epoch:  676  Average loss at step  1000 :  3856.6110173339844\n",
      "Epoch:  676  Average loss at step  2000 :  3912.9246716308594\n",
      "Epoch:  676  Average loss at step  2533 :  3872.3260448260658\n",
      "676 2 19.908999919891357\n",
      "Epoch:  676  Average loss at step  1000 :  62.26518518066406\n",
      "Epoch:  676  Average loss at step  1227 :  60.64997579758277\n",
      "676 3 12.639293193817139\n",
      "Epoch:  676  Average loss at step  1000 :  4.326998629570007\n",
      "Epoch:  676  Average loss at step  2000 :  4.27331213760376\n",
      "Epoch:  676  Average loss at step  3000 :  4.27120157289505\n",
      "Epoch:  676  Average loss at step  3222 :  4.422776461034975\n",
      "676 4 33.12769150733948\n",
      "676 5 1.1920928955078125e-06\n",
      "Training time took 98.93585 seconds to run 1 epoch\n",
      "Epoch:  677  Average loss at step  1000 :  0.048935030043125154\n",
      "Epoch:  677  Average loss at step  2000 :  0.0519502227306366\n",
      "Epoch:  677  Average loss at step  3000 :  0.05668942981958389\n",
      "Epoch:  677  Average loss at step  3222 :  0.05898203369210528\n",
      "677 0 29.42023015022278\n",
      "Training time took 29.543407 seconds to run 1 epoch\n",
      "Epoch:  678  Average loss at step  1000 :  8.00975043296814\n",
      "Epoch:  678  Average loss at step  2000 :  8.469481475830078\n",
      "Epoch:  678  Average loss at step  3000 :  8.364155166625977\n",
      "Epoch:  678  Average loss at step  4000 :  8.16919803237915\n",
      "Epoch:  678  Average loss at step  5000 :  7.927755867004395\n",
      "Epoch:  678  Average loss at step  6000 :  8.210449092864991\n",
      "Epoch:  678  Average loss at step  7000 :  8.365193675994872\n",
      "Epoch:  678  Average loss at step  8000 :  7.981958042144775\n",
      "Epoch:  678  Average loss at step  8472 :  7.856184409857859\n",
      "678 0 20.99053144454956\n",
      "Epoch:  678  Average loss at step  1000 :  2773.3782041015625\n",
      "Epoch:  678  Average loss at step  1491 :  2786.7463087536826\n",
      "678 1 11.684508085250854\n",
      "Epoch:  678  Average loss at step  1000 :  3865.947464477539\n",
      "Epoch:  678  Average loss at step  2000 :  3855.9163469238283\n",
      "Epoch:  678  Average loss at step  2533 :  3864.6005426946094\n",
      "678 2 19.915364980697632\n",
      "Epoch:  678  Average loss at step  1000 :  61.721586780548094\n",
      "Epoch:  678  Average loss at step  1227 :  63.26101859056487\n",
      "678 3 12.620076179504395\n",
      "Epoch:  678  Average loss at step  1000 :  4.365968350887298\n",
      "Epoch:  678  Average loss at step  2000 :  4.248090953350067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  678  Average loss at step  3000 :  4.258066797733307\n",
      "Epoch:  678  Average loss at step  3222 :  4.500268183152239\n",
      "678 4 33.04444479942322\n",
      "678 5 1.6689300537109375e-06\n",
      "Training time took 98.912711 seconds to run 1 epoch\n",
      "Epoch:  679  Average loss at step  1000 :  0.049186425507068636\n",
      "Epoch:  679  Average loss at step  2000 :  0.05147221857309341\n",
      "Epoch:  679  Average loss at step  3000 :  0.05628777253627777\n",
      "Epoch:  679  Average loss at step  3222 :  0.05931044732174905\n",
      "679 0 29.403597593307495\n",
      "Training time took 29.530546 seconds to run 1 epoch\n",
      "Epoch:  680  Average loss at step  1000 :  8.648141512870788\n",
      "Epoch:  680  Average loss at step  2000 :  8.118311873435974\n",
      "Epoch:  680  Average loss at step  3000 :  8.23631907939911\n",
      "Epoch:  680  Average loss at step  4000 :  8.149864685058594\n",
      "Epoch:  680  Average loss at step  5000 :  8.127649244308472\n",
      "Epoch:  680  Average loss at step  6000 :  8.284378442764282\n",
      "Epoch:  680  Average loss at step  7000 :  7.8146985778808595\n",
      "Epoch:  680  Average loss at step  8000 :  7.917115489006043\n",
      "Epoch:  680  Average loss at step  8472 :  8.526390832681049\n",
      "680 0 20.52024269104004\n",
      "Epoch:  680  Average loss at step  1000 :  2763.0001849365235\n",
      "Epoch:  680  Average loss at step  1491 :  2814.3654667643714\n",
      "680 1 11.66825270652771\n",
      "Epoch:  680  Average loss at step  1000 :  3868.323658203125\n",
      "Epoch:  680  Average loss at step  2000 :  3889.529936645508\n",
      "Epoch:  680  Average loss at step  2533 :  3903.673156639627\n",
      "680 2 19.883877277374268\n",
      "Epoch:  680  Average loss at step  1000 :  61.625297679901124\n",
      "Epoch:  680  Average loss at step  1227 :  60.94774707422767\n",
      "680 3 12.63610315322876\n",
      "Epoch:  680  Average loss at step  1000 :  4.209962543964386\n",
      "Epoch:  680  Average loss at step  2000 :  4.228047533988953\n",
      "Epoch:  680  Average loss at step  3000 :  4.203448316574097\n",
      "Epoch:  680  Average loss at step  3222 :  4.2829948785309755\n",
      "680 4 33.260932207107544\n",
      "680 5 1.430511474609375e-06\n",
      "Training time took 98.601669 seconds to run 1 epoch\n",
      "Mean Rank:  154.48376  of  75000\n",
      "Hits @ 10:  0.85576\n",
      "Hits @ 1:  0.62268\n",
      "Testing time took 164.32627 seconds.\n",
      "\n",
      "Epoch:  681  Average loss at step  1000 :  0.04902052998542786\n",
      "Epoch:  681  Average loss at step  2000 :  0.051274976789951326\n",
      "Epoch:  681  Average loss at step  3000 :  0.05621493285894394\n",
      "Epoch:  681  Average loss at step  3222 :  0.05850476878798595\n",
      "681 0 29.464694499969482\n",
      "Training time took 29.572506 seconds to run 1 epoch\n",
      "Epoch:  682  Average loss at step  1000 :  8.199376010894776\n",
      "Epoch:  682  Average loss at step  2000 :  7.835622469902039\n",
      "Epoch:  682  Average loss at step  3000 :  8.149994724273682\n",
      "Epoch:  682  Average loss at step  4000 :  8.19551733493805\n",
      "Epoch:  682  Average loss at step  5000 :  8.023246732711792\n",
      "Epoch:  682  Average loss at step  6000 :  7.860867932319641\n",
      "Epoch:  682  Average loss at step  7000 :  8.271207843780518\n",
      "Epoch:  682  Average loss at step  8000 :  8.102865113258362\n",
      "Epoch:  682  Average loss at step  8472 :  7.750592499504641\n",
      "682 0 20.863143920898438\n",
      "Epoch:  682  Average loss at step  1000 :  2768.0358853759767\n",
      "Epoch:  682  Average loss at step  1491 :  2804.528311042785\n",
      "682 1 11.72136378288269\n",
      "Epoch:  682  Average loss at step  1000 :  3921.1450482177734\n",
      "Epoch:  682  Average loss at step  2000 :  3888.6922158203124\n",
      "Epoch:  682  Average loss at step  2533 :  3855.6379882849214\n",
      "682 2 19.915749073028564\n",
      "Epoch:  682  Average loss at step  1000 :  61.2215761680603\n",
      "Epoch:  682  Average loss at step  1227 :  62.145285863662195\n",
      "682 3 12.710151672363281\n",
      "Epoch:  682  Average loss at step  1000 :  4.298380011558533\n",
      "Epoch:  682  Average loss at step  2000 :  4.084528105258942\n",
      "Epoch:  682  Average loss at step  3000 :  4.148758328437805\n",
      "Epoch:  682  Average loss at step  3222 :  4.126850580303952\n",
      "682 4 33.27889561653137\n",
      "682 5 1.430511474609375e-06\n",
      "Training time took 99.1177 seconds to run 1 epoch\n",
      "Epoch:  683  Average loss at step  1000 :  0.0491003138422966\n",
      "Epoch:  683  Average loss at step  2000 :  0.051274505615234375\n",
      "Epoch:  683  Average loss at step  3000 :  0.05585259222984314\n",
      "Epoch:  683  Average loss at step  3222 :  0.05853029257512131\n",
      "683 0 29.43232822418213\n",
      "Training time took 29.550899 seconds to run 1 epoch\n",
      "Epoch:  684  Average loss at step  1000 :  7.536347416877747\n",
      "Epoch:  684  Average loss at step  2000 :  8.391193664550782\n",
      "Epoch:  684  Average loss at step  3000 :  8.170959334373475\n",
      "Epoch:  684  Average loss at step  4000 :  7.883292428016663\n",
      "Epoch:  684  Average loss at step  5000 :  8.126341032505035\n",
      "Epoch:  684  Average loss at step  6000 :  8.191161443710326\n",
      "Epoch:  684  Average loss at step  7000 :  7.964697243690491\n",
      "Epoch:  684  Average loss at step  8000 :  8.186016879081727\n",
      "Epoch:  684  Average loss at step  8472 :  8.53293361690533\n",
      "684 0 20.635701179504395\n",
      "Epoch:  684  Average loss at step  1000 :  2803.6689340820312\n",
      "Epoch:  684  Average loss at step  1491 :  2743.3303069337944\n",
      "684 1 11.72581148147583\n",
      "Epoch:  684  Average loss at step  1000 :  3875.831443359375\n",
      "Epoch:  684  Average loss at step  2000 :  3900.772555419922\n",
      "Epoch:  684  Average loss at step  2533 :  3924.250286474975\n",
      "684 2 19.942809581756592\n",
      "Epoch:  684  Average loss at step  1000 :  61.87776159286499\n",
      "Epoch:  684  Average loss at step  1227 :  60.93304723668184\n",
      "684 3 12.57424521446228\n",
      "Epoch:  684  Average loss at step  1000 :  4.363835857391358\n",
      "Epoch:  684  Average loss at step  2000 :  4.166619466781616\n",
      "Epoch:  684  Average loss at step  3000 :  4.1676652932167055\n",
      "Epoch:  684  Average loss at step  3222 :  4.306240489840572\n",
      "684 4 33.20157861709595\n",
      "684 5 1.6689300537109375e-06\n",
      "Training time took 98.719115 seconds to run 1 epoch\n",
      "Epoch:  685  Average loss at step  1000 :  0.048605782330036165\n",
      "Epoch:  685  Average loss at step  2000 :  0.05118051338195801\n",
      "Epoch:  685  Average loss at step  3000 :  0.05597674733400345\n",
      "Epoch:  685  Average loss at step  3222 :  0.05827913012696552\n",
      "685 0 29.239518404006958\n",
      "Training time took 29.364373 seconds to run 1 epoch\n",
      "Epoch:  686  Average loss at step  1000 :  7.992438744544983\n",
      "Epoch:  686  Average loss at step  2000 :  7.850905332565308\n",
      "Epoch:  686  Average loss at step  3000 :  8.262330083847045\n",
      "Epoch:  686  Average loss at step  4000 :  7.836111341476441\n",
      "Epoch:  686  Average loss at step  5000 :  7.690125898361206\n",
      "Epoch:  686  Average loss at step  6000 :  8.325195198059083\n",
      "Epoch:  686  Average loss at step  7000 :  8.121922924041748\n",
      "Epoch:  686  Average loss at step  8000 :  8.155107452392578\n",
      "Epoch:  686  Average loss at step  8472 :  8.424590545783175\n",
      "686 0 20.494994401931763\n",
      "Epoch:  686  Average loss at step  1000 :  2837.8206828613284\n",
      "Epoch:  686  Average loss at step  1491 :  2745.0884436749034\n",
      "686 1 11.697110414505005\n",
      "Epoch:  686  Average loss at step  1000 :  3883.5110451660157\n",
      "Epoch:  686  Average loss at step  2000 :  3892.3193237304686\n",
      "Epoch:  686  Average loss at step  2533 :  3840.1961125668986\n",
      "686 2 19.84985899925232\n",
      "Epoch:  686  Average loss at step  1000 :  61.6699178276062\n",
      "Epoch:  686  Average loss at step  1227 :  62.051492223942844\n",
      "686 3 12.69680643081665\n",
      "Epoch:  686  Average loss at step  1000 :  4.229145175933838\n",
      "Epoch:  686  Average loss at step  2000 :  4.2433199400901795\n",
      "Epoch:  686  Average loss at step  3000 :  4.234964912414551\n",
      "Epoch:  686  Average loss at step  3222 :  4.242243364757311\n",
      "686 4 33.24878168106079\n",
      "686 5 1.430511474609375e-06\n",
      "Training time took 98.622617 seconds to run 1 epoch\n",
      "Epoch:  687  Average loss at step  1000 :  0.04856294995546341\n",
      "Epoch:  687  Average loss at step  2000 :  0.05165280520915985\n",
      "Epoch:  687  Average loss at step  3000 :  0.05532803839445114\n",
      "Epoch:  687  Average loss at step  3222 :  0.05903917435898982\n",
      "687 0 29.41926383972168\n",
      "Training time took 29.540961 seconds to run 1 epoch\n",
      "Epoch:  688  Average loss at step  1000 :  8.133492891311645\n",
      "Epoch:  688  Average loss at step  2000 :  7.935637672424316\n",
      "Epoch:  688  Average loss at step  3000 :  7.5429241976737975\n",
      "Epoch:  688  Average loss at step  4000 :  8.227827428817749\n",
      "Epoch:  688  Average loss at step  5000 :  8.096439806938172\n",
      "Epoch:  688  Average loss at step  6000 :  8.435188207626343\n",
      "Epoch:  688  Average loss at step  7000 :  8.218136897087097\n",
      "Epoch:  688  Average loss at step  8000 :  8.458506651878357\n",
      "Epoch:  688  Average loss at step  8472 :  7.697053801795328\n",
      "688 0 20.25463104248047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  688  Average loss at step  1000 :  2778.083072265625\n",
      "Epoch:  688  Average loss at step  1491 :  2804.474004635494\n",
      "688 1 11.738332509994507\n",
      "Epoch:  688  Average loss at step  1000 :  3904.387287109375\n",
      "Epoch:  688  Average loss at step  2000 :  3905.2164051513673\n",
      "Epoch:  688  Average loss at step  2533 :  3923.634508443597\n",
      "688 2 19.927828788757324\n",
      "Epoch:  688  Average loss at step  1000 :  62.1568226852417\n",
      "Epoch:  688  Average loss at step  1227 :  61.92348705905513\n",
      "688 3 12.593859434127808\n",
      "Epoch:  688  Average loss at step  1000 :  4.1017524585723875\n",
      "Epoch:  688  Average loss at step  2000 :  4.202219228744507\n",
      "Epoch:  688  Average loss at step  3000 :  4.232319809913635\n",
      "Epoch:  688  Average loss at step  3222 :  4.433920906863718\n",
      "688 4 33.204763650894165\n",
      "688 5 1.6689300537109375e-06\n",
      "Training time took 98.344638 seconds to run 1 epoch\n",
      "Epoch:  689  Average loss at step  1000 :  0.04820312070846557\n",
      "Epoch:  689  Average loss at step  2000 :  0.050808030426502226\n",
      "Epoch:  689  Average loss at step  3000 :  0.055791255056858065\n",
      "Epoch:  689  Average loss at step  3222 :  0.058090263087518336\n",
      "689 0 29.457961320877075\n",
      "Training time took 29.579112 seconds to run 1 epoch\n",
      "Epoch:  690  Average loss at step  1000 :  8.169078033447265\n",
      "Epoch:  690  Average loss at step  2000 :  8.277464471817016\n",
      "Epoch:  690  Average loss at step  3000 :  8.1851154088974\n",
      "Epoch:  690  Average loss at step  4000 :  8.457592189788818\n",
      "Epoch:  690  Average loss at step  5000 :  8.181784743309022\n",
      "Epoch:  690  Average loss at step  6000 :  8.413317130088807\n",
      "Epoch:  690  Average loss at step  7000 :  7.9246115369796755\n",
      "Epoch:  690  Average loss at step  8000 :  7.902776185035705\n",
      "Epoch:  690  Average loss at step  8472 :  8.575218482078434\n",
      "690 0 21.408355712890625\n",
      "Epoch:  690  Average loss at step  1000 :  2794.856584106445\n",
      "Epoch:  690  Average loss at step  1491 :  2791.394179229584\n",
      "690 1 11.730228424072266\n",
      "Epoch:  690  Average loss at step  1000 :  3875.4851979980467\n",
      "Epoch:  690  Average loss at step  2000 :  3895.7728067626954\n",
      "Epoch:  690  Average loss at step  2533 :  3866.565595739467\n",
      "690 2 19.880396604537964\n",
      "Epoch:  690  Average loss at step  1000 :  62.27224220275879\n",
      "Epoch:  690  Average loss at step  1227 :  61.491324824060854\n",
      "690 3 12.701230525970459\n",
      "Epoch:  690  Average loss at step  1000 :  4.2350932593345645\n",
      "Epoch:  690  Average loss at step  2000 :  4.231323993682861\n",
      "Epoch:  690  Average loss at step  3000 :  4.183664962768555\n",
      "Epoch:  690  Average loss at step  3222 :  4.184883078592179\n",
      "690 4 33.31364893913269\n",
      "690 5 1.430511474609375e-06\n",
      "Training time took 99.665943 seconds to run 1 epoch\n",
      "Mean Rank:  154.7146  of  75000\n",
      "Hits @ 10:  0.85504\n",
      "Hits @ 1:  0.6244\n",
      "Testing time took 163.304059 seconds.\n",
      "\n",
      "Epoch:  691  Average loss at step  1000 :  0.04854348587989807\n",
      "Epoch:  691  Average loss at step  2000 :  0.05086827027797699\n",
      "Epoch:  691  Average loss at step  3000 :  0.05558617025613785\n",
      "Epoch:  691  Average loss at step  3222 :  0.0576105355506211\n",
      "691 0 29.41428303718567\n",
      "Training time took 29.522703 seconds to run 1 epoch\n",
      "Epoch:  692  Average loss at step  1000 :  8.087545105457306\n",
      "Epoch:  692  Average loss at step  2000 :  8.074570594787598\n",
      "Epoch:  692  Average loss at step  3000 :  8.503050443649292\n",
      "Epoch:  692  Average loss at step  4000 :  8.29091452217102\n",
      "Epoch:  692  Average loss at step  5000 :  7.804504611968994\n",
      "Epoch:  692  Average loss at step  6000 :  8.3048222322464\n",
      "Epoch:  692  Average loss at step  7000 :  7.486670716285706\n",
      "Epoch:  692  Average loss at step  8000 :  7.883565066337585\n",
      "Epoch:  692  Average loss at step  8472 :  7.613509424139245\n",
      "692 0 20.150476455688477\n",
      "Epoch:  692  Average loss at step  1000 :  2777.8065584716796\n",
      "Epoch:  692  Average loss at step  1491 :  2812.770401668294\n",
      "692 1 11.73171877861023\n",
      "Epoch:  692  Average loss at step  1000 :  3917.8768088378906\n",
      "Epoch:  692  Average loss at step  2000 :  3902.7892993164064\n",
      "Epoch:  692  Average loss at step  2533 :  3880.8547561233113\n",
      "692 2 19.871971368789673\n",
      "Epoch:  692  Average loss at step  1000 :  61.583118309020996\n",
      "Epoch:  692  Average loss at step  1227 :  62.21759557334822\n",
      "692 3 12.55406379699707\n",
      "Epoch:  692  Average loss at step  1000 :  4.2226748266220095\n",
      "Epoch:  692  Average loss at step  2000 :  4.16405046415329\n",
      "Epoch:  692  Average loss at step  3000 :  4.08621186542511\n",
      "Epoch:  692  Average loss at step  3222 :  4.193901557271544\n",
      "692 4 33.25492262840271\n",
      "692 5 1.430511474609375e-06\n",
      "Training time took 98.209838 seconds to run 1 epoch\n",
      "Epoch:  693  Average loss at step  1000 :  0.04817828190326691\n",
      "Epoch:  693  Average loss at step  2000 :  0.05057536005973816\n",
      "Epoch:  693  Average loss at step  3000 :  0.055353383243083955\n",
      "Epoch:  693  Average loss at step  3222 :  0.05743648116393605\n",
      "693 0 29.386151552200317\n",
      "Training time took 29.50894 seconds to run 1 epoch\n",
      "Epoch:  694  Average loss at step  1000 :  7.910929857254028\n",
      "Epoch:  694  Average loss at step  2000 :  7.710299686431885\n",
      "Epoch:  694  Average loss at step  3000 :  8.107461374282837\n",
      "Epoch:  694  Average loss at step  4000 :  8.15930177116394\n",
      "Epoch:  694  Average loss at step  5000 :  8.319639283180237\n",
      "Epoch:  694  Average loss at step  6000 :  8.418500095367431\n",
      "Epoch:  694  Average loss at step  7000 :  8.177804931640624\n",
      "Epoch:  694  Average loss at step  8000 :  7.610627201080322\n",
      "Epoch:  694  Average loss at step  8472 :  7.766480875118474\n",
      "694 0 20.63972306251526\n",
      "Epoch:  694  Average loss at step  1000 :  2809.598972167969\n",
      "Epoch:  694  Average loss at step  1491 :  2782.7271422848758\n",
      "694 1 11.723159074783325\n",
      "Epoch:  694  Average loss at step  1000 :  3908.5653161621094\n",
      "Epoch:  694  Average loss at step  2000 :  3956.1331826171877\n",
      "Epoch:  694  Average loss at step  2533 :  3895.210490093928\n",
      "694 2 19.930745363235474\n",
      "Epoch:  694  Average loss at step  1000 :  61.512459823608395\n",
      "Epoch:  694  Average loss at step  1227 :  62.18425474563621\n",
      "694 3 12.66652512550354\n",
      "Epoch:  694  Average loss at step  1000 :  4.169648859500885\n",
      "Epoch:  694  Average loss at step  2000 :  4.179346270084381\n",
      "Epoch:  694  Average loss at step  3000 :  4.077995599269867\n",
      "Epoch:  694  Average loss at step  3222 :  3.902552256538541\n",
      "694 4 33.201202392578125\n",
      "694 5 1.6689300537109375e-06\n",
      "Training time took 98.788395 seconds to run 1 epoch\n",
      "Epoch:  695  Average loss at step  1000 :  0.04812822562456131\n",
      "Epoch:  695  Average loss at step  2000 :  0.05071937555074692\n",
      "Epoch:  695  Average loss at step  3000 :  0.05512449544668198\n",
      "Epoch:  695  Average loss at step  3222 :  0.058277573831289294\n",
      "695 0 29.42150592803955\n",
      "Training time took 29.544447 seconds to run 1 epoch\n",
      "Epoch:  696  Average loss at step  1000 :  7.932519061088562\n",
      "Epoch:  696  Average loss at step  2000 :  8.058676040649415\n",
      "Epoch:  696  Average loss at step  3000 :  7.967004908561707\n",
      "Epoch:  696  Average loss at step  4000 :  8.548673120498657\n",
      "Epoch:  696  Average loss at step  5000 :  8.849803339958191\n",
      "Epoch:  696  Average loss at step  6000 :  8.244289044380189\n",
      "Epoch:  696  Average loss at step  7000 :  8.260560070037842\n",
      "Epoch:  696  Average loss at step  8000 :  7.929655425071716\n",
      "Epoch:  696  Average loss at step  8472 :  8.149883189633849\n",
      "696 0 21.65353274345398\n",
      "Epoch:  696  Average loss at step  1000 :  2824.1111087646486\n",
      "Epoch:  696  Average loss at step  1491 :  2793.316578406115\n",
      "696 1 11.708094120025635\n",
      "Epoch:  696  Average loss at step  1000 :  3921.2570703125\n",
      "Epoch:  696  Average loss at step  2000 :  3933.387988769531\n",
      "Epoch:  696  Average loss at step  2533 :  3932.337212265916\n",
      "696 2 19.943759202957153\n",
      "Epoch:  696  Average loss at step  1000 :  61.994789970397946\n",
      "Epoch:  696  Average loss at step  1227 :  61.48921209065975\n",
      "696 3 12.699323892593384\n",
      "Epoch:  696  Average loss at step  1000 :  4.219536000728607\n",
      "Epoch:  696  Average loss at step  2000 :  4.084920563220978\n",
      "Epoch:  696  Average loss at step  3000 :  4.082419077396393\n",
      "Epoch:  696  Average loss at step  3222 :  4.313561892246894\n",
      "696 4 33.185593366622925\n",
      "696 5 1.6689300537109375e-06\n",
      "Training time took 99.824284 seconds to run 1 epoch\n",
      "Epoch:  697  Average loss at step  1000 :  0.04785217851400375\n",
      "Epoch:  697  Average loss at step  2000 :  0.0505329852104187\n",
      "Epoch:  697  Average loss at step  3000 :  0.05512903898954392\n",
      "Epoch:  697  Average loss at step  3222 :  0.05760433215874587\n",
      "697 0 29.380892753601074\n",
      "Training time took 29.502588 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  698  Average loss at step  1000 :  7.453694627761841\n",
      "Epoch:  698  Average loss at step  2000 :  7.915645027637482\n",
      "Epoch:  698  Average loss at step  3000 :  8.137333745002747\n",
      "Epoch:  698  Average loss at step  4000 :  7.855970297813416\n",
      "Epoch:  698  Average loss at step  5000 :  8.603906412124633\n",
      "Epoch:  698  Average loss at step  6000 :  7.928277528762817\n",
      "Epoch:  698  Average loss at step  7000 :  8.361876469135284\n",
      "Epoch:  698  Average loss at step  8000 :  7.894585295677185\n",
      "Epoch:  698  Average loss at step  8472 :  8.029879085135518\n",
      "698 0 20.25089192390442\n",
      "Epoch:  698  Average loss at step  1000 :  2820.7529993896483\n",
      "Epoch:  698  Average loss at step  1491 :  2809.1466989510022\n",
      "698 1 11.690724611282349\n",
      "Epoch:  698  Average loss at step  1000 :  3871.4216381835936\n",
      "Epoch:  698  Average loss at step  2000 :  3896.5765559082033\n",
      "Epoch:  698  Average loss at step  2533 :  3920.779221062284\n",
      "698 2 19.940929889678955\n",
      "Epoch:  698  Average loss at step  1000 :  62.31381578445435\n",
      "Epoch:  698  Average loss at step  1227 :  61.957498164098475\n",
      "698 3 12.623481035232544\n",
      "Epoch:  698  Average loss at step  1000 :  4.267059296607971\n",
      "Epoch:  698  Average loss at step  2000 :  4.049154408454895\n",
      "Epoch:  698  Average loss at step  3000 :  4.043433495044709\n",
      "Epoch:  698  Average loss at step  3222 :  4.077771894121282\n",
      "698 4 33.32236385345459\n",
      "698 5 1.1920928955078125e-06\n",
      "Training time took 98.452734 seconds to run 1 epoch\n",
      "Epoch:  699  Average loss at step  1000 :  0.047900063693523405\n",
      "Epoch:  699  Average loss at step  2000 :  0.05038339197635651\n",
      "Epoch:  699  Average loss at step  3000 :  0.054942214608192444\n",
      "Epoch:  699  Average loss at step  3222 :  0.057684677638050276\n",
      "699 0 29.40213632583618\n",
      "Training time took 29.523102 seconds to run 1 epoch\n",
      "Epoch:  700  Average loss at step  1000 :  7.701740839004517\n",
      "Epoch:  700  Average loss at step  2000 :  8.483928359985352\n",
      "Epoch:  700  Average loss at step  3000 :  7.627305995941162\n",
      "Epoch:  700  Average loss at step  4000 :  8.253252232551574\n",
      "Epoch:  700  Average loss at step  5000 :  8.25661037349701\n",
      "Epoch:  700  Average loss at step  6000 :  8.034885210037231\n",
      "Epoch:  700  Average loss at step  7000 :  7.900418766498566\n",
      "Epoch:  700  Average loss at step  8000 :  8.371381217002869\n",
      "Epoch:  700  Average loss at step  8472 :  7.717221139733219\n",
      "700 0 21.120896816253662\n",
      "Epoch:  700  Average loss at step  1000 :  2823.647596069336\n",
      "Epoch:  700  Average loss at step  1491 :  2746.6054106750357\n",
      "700 1 11.724252700805664\n",
      "Epoch:  700  Average loss at step  1000 :  3910.368692138672\n",
      "Epoch:  700  Average loss at step  2000 :  3920.303574951172\n",
      "Epoch:  700  Average loss at step  2533 :  3941.8481635280214\n",
      "700 2 19.895715713500977\n",
      "Epoch:  700  Average loss at step  1000 :  61.48333380889893\n",
      "Epoch:  700  Average loss at step  1227 :  61.42783987720396\n",
      "700 3 12.616846799850464\n",
      "Epoch:  700  Average loss at step  1000 :  4.29560400056839\n",
      "Epoch:  700  Average loss at step  2000 :  4.066350505828858\n",
      "Epoch:  700  Average loss at step  3000 :  4.030602718830108\n",
      "Epoch:  700  Average loss at step  3222 :  4.081610073830638\n",
      "700 4 33.19750142097473\n",
      "700 5 1.6689300537109375e-06\n",
      "Training time took 99.190934 seconds to run 1 epoch\n",
      "Mean Rank:  154.15076  of  75000\n",
      "Hits @ 10:  0.856\n",
      "Hits @ 1:  0.623\n",
      "Testing time took 164.162291 seconds.\n",
      "\n",
      "Epoch:  701  Average loss at step  1000 :  0.04731576037406921\n",
      "Epoch:  701  Average loss at step  2000 :  0.05040711492300034\n",
      "Epoch:  701  Average loss at step  3000 :  0.05477769464254379\n",
      "Epoch:  701  Average loss at step  3222 :  0.057673809932530365\n",
      "701 0 29.400794982910156\n",
      "Training time took 29.509073 seconds to run 1 epoch\n",
      "Epoch:  702  Average loss at step  1000 :  7.894261660575867\n",
      "Epoch:  702  Average loss at step  2000 :  7.838045674324036\n",
      "Epoch:  702  Average loss at step  3000 :  8.322248446941376\n",
      "Epoch:  702  Average loss at step  4000 :  7.871151681900025\n",
      "Epoch:  702  Average loss at step  5000 :  7.539839842796326\n",
      "Epoch:  702  Average loss at step  6000 :  7.776575336456299\n",
      "Epoch:  702  Average loss at step  7000 :  8.090090173721313\n",
      "Epoch:  702  Average loss at step  8000 :  8.199659531593323\n",
      "Epoch:  702  Average loss at step  8472 :  8.531289861408773\n",
      "702 0 20.646790742874146\n",
      "Epoch:  702  Average loss at step  1000 :  2806.3369794921873\n",
      "Epoch:  702  Average loss at step  1491 :  2811.951507375033\n",
      "702 1 11.695056676864624\n",
      "Epoch:  702  Average loss at step  1000 :  3933.859751220703\n",
      "Epoch:  702  Average loss at step  2000 :  3928.852963623047\n",
      "Epoch:  702  Average loss at step  2533 :  3939.3181671680595\n",
      "702 2 19.965948820114136\n",
      "Epoch:  702  Average loss at step  1000 :  61.626164100646974\n",
      "Epoch:  702  Average loss at step  1227 :  62.45438812238357\n",
      "702 3 12.640140295028687\n",
      "Epoch:  702  Average loss at step  1000 :  4.06708458518982\n",
      "Epoch:  702  Average loss at step  2000 :  4.063820889472962\n",
      "Epoch:  702  Average loss at step  3000 :  4.1323739771842956\n",
      "Epoch:  702  Average loss at step  3222 :  4.078159458823617\n",
      "702 4 33.25447678565979\n",
      "702 5 1.430511474609375e-06\n",
      "Training time took 98.822128 seconds to run 1 epoch\n",
      "Epoch:  703  Average loss at step  1000 :  0.04762833607196808\n",
      "Epoch:  703  Average loss at step  2000 :  0.05077963370084763\n",
      "Epoch:  703  Average loss at step  3000 :  0.05453399354219437\n",
      "Epoch:  703  Average loss at step  3222 :  0.056385506757611205\n",
      "703 0 29.43314838409424\n",
      "Training time took 29.556773 seconds to run 1 epoch\n",
      "Epoch:  704  Average loss at step  1000 :  7.839189098358155\n",
      "Epoch:  704  Average loss at step  2000 :  7.999484169006347\n",
      "Epoch:  704  Average loss at step  3000 :  8.170121233940124\n",
      "Epoch:  704  Average loss at step  4000 :  7.854648987770081\n",
      "Epoch:  704  Average loss at step  5000 :  8.032896869659425\n",
      "Epoch:  704  Average loss at step  6000 :  7.4451620435714725\n",
      "Epoch:  704  Average loss at step  7000 :  8.662740895271302\n",
      "Epoch:  704  Average loss at step  8000 :  7.604761532783508\n",
      "Epoch:  704  Average loss at step  8472 :  8.043105051476099\n",
      "704 0 20.558761835098267\n",
      "Epoch:  704  Average loss at step  1000 :  2815.6953452148437\n",
      "Epoch:  704  Average loss at step  1491 :  2804.263708416774\n",
      "704 1 11.759135961532593\n",
      "Epoch:  704  Average loss at step  1000 :  3942.7226745605467\n",
      "Epoch:  704  Average loss at step  2000 :  3897.1285810546874\n",
      "Epoch:  704  Average loss at step  2533 :  3917.762397806551\n",
      "704 2 19.924126386642456\n",
      "Epoch:  704  Average loss at step  1000 :  61.96565880584717\n",
      "Epoch:  704  Average loss at step  1227 :  61.6553873853195\n",
      "704 3 12.607221841812134\n",
      "Epoch:  704  Average loss at step  1000 :  4.171325844764709\n",
      "Epoch:  704  Average loss at step  2000 :  4.150452569007873\n",
      "Epoch:  704  Average loss at step  3000 :  4.039517108917236\n",
      "Epoch:  704  Average loss at step  3222 :  4.168583768265065\n",
      "704 4 33.19576835632324\n",
      "704 5 1.6689300537109375e-06\n",
      "Training time took 98.687702 seconds to run 1 epoch\n",
      "Epoch:  705  Average loss at step  1000 :  0.047527085542678836\n",
      "Epoch:  705  Average loss at step  2000 :  0.04998597091436386\n",
      "Epoch:  705  Average loss at step  3000 :  0.05425506371259689\n",
      "Epoch:  705  Average loss at step  3222 :  0.05629123075061336\n",
      "705 0 29.45481538772583\n",
      "Training time took 29.575844 seconds to run 1 epoch\n",
      "Epoch:  706  Average loss at step  1000 :  7.9873355875015255\n",
      "Epoch:  706  Average loss at step  2000 :  8.309683094024658\n",
      "Epoch:  706  Average loss at step  3000 :  8.376372177124024\n",
      "Epoch:  706  Average loss at step  4000 :  8.064282508850098\n",
      "Epoch:  706  Average loss at step  5000 :  8.25521706199646\n",
      "Epoch:  706  Average loss at step  6000 :  7.952761580467224\n",
      "Epoch:  706  Average loss at step  7000 :  8.371841917037964\n",
      "Epoch:  706  Average loss at step  8000 :  7.710735867500305\n",
      "Epoch:  706  Average loss at step  8472 :  7.725045138711582\n",
      "706 0 20.799095630645752\n",
      "Epoch:  706  Average loss at step  1000 :  2784.9967689208984\n",
      "Epoch:  706  Average loss at step  1491 :  2797.293213840472\n",
      "706 1 11.704143762588501\n",
      "Epoch:  706  Average loss at step  1000 :  3903.338600830078\n",
      "Epoch:  706  Average loss at step  2000 :  3930.406392211914\n",
      "Epoch:  706  Average loss at step  2533 :  3920.9475244215882\n",
      "706 2 19.918545484542847\n",
      "Epoch:  706  Average loss at step  1000 :  61.840478302001955\n",
      "Epoch:  706  Average loss at step  1227 :  61.45552701963116\n",
      "706 3 12.656875848770142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  706  Average loss at step  1000 :  4.032085009098053\n",
      "Epoch:  706  Average loss at step  2000 :  4.101678460121155\n",
      "Epoch:  706  Average loss at step  3000 :  3.9527107491493223\n",
      "Epoch:  706  Average loss at step  3222 :  3.94761013756549\n",
      "706 4 33.27391338348389\n",
      "706 5 1.430511474609375e-06\n",
      "Training time took 98.985815 seconds to run 1 epoch\n",
      "Epoch:  707  Average loss at step  1000 :  0.04752610582113266\n",
      "Epoch:  707  Average loss at step  2000 :  0.0500712257027626\n",
      "Epoch:  707  Average loss at step  3000 :  0.05442234289646149\n",
      "Epoch:  707  Average loss at step  3222 :  0.05683568431530904\n",
      "707 0 29.464359998703003\n",
      "Training time took 29.587851 seconds to run 1 epoch\n",
      "Epoch:  708  Average loss at step  1000 :  8.033077791213989\n",
      "Epoch:  708  Average loss at step  2000 :  7.878328941345215\n",
      "Epoch:  708  Average loss at step  3000 :  8.259087101936341\n",
      "Epoch:  708  Average loss at step  4000 :  7.927159722328186\n",
      "Epoch:  708  Average loss at step  5000 :  8.177210065841674\n",
      "Epoch:  708  Average loss at step  6000 :  7.8577739505767825\n",
      "Epoch:  708  Average loss at step  7000 :  8.542721734046935\n",
      "Epoch:  708  Average loss at step  8000 :  8.013355367660523\n",
      "Epoch:  708  Average loss at step  8472 :  7.242278652823409\n",
      "708 0 20.65573525428772\n",
      "Epoch:  708  Average loss at step  1000 :  2776.999338378906\n",
      "Epoch:  708  Average loss at step  1491 :  2813.756390036353\n",
      "708 1 11.680699110031128\n",
      "Epoch:  708  Average loss at step  1000 :  3938.568372680664\n",
      "Epoch:  708  Average loss at step  2000 :  3935.4598696289063\n",
      "Epoch:  708  Average loss at step  2533 :  3953.408067027362\n",
      "708 2 19.76305341720581\n",
      "Epoch:  708  Average loss at step  1000 :  61.74049996566772\n",
      "Epoch:  708  Average loss at step  1227 :  61.3031135646931\n",
      "708 3 12.6264066696167\n",
      "Epoch:  708  Average loss at step  1000 :  4.1074904961586\n",
      "Epoch:  708  Average loss at step  2000 :  4.100401513576507\n",
      "Epoch:  708  Average loss at step  3000 :  3.9437896695137025\n",
      "Epoch:  708  Average loss at step  3222 :  4.123934347462968\n",
      "708 4 33.37829041481018\n",
      "708 5 1.430511474609375e-06\n",
      "Training time took 98.742005 seconds to run 1 epoch\n",
      "Epoch:  709  Average loss at step  1000 :  0.047579261541366574\n",
      "Epoch:  709  Average loss at step  2000 :  0.04955885857343674\n",
      "Epoch:  709  Average loss at step  3000 :  0.054360685646533964\n",
      "Epoch:  709  Average loss at step  3222 :  0.05668789756321739\n",
      "709 0 29.389492750167847\n",
      "Training time took 29.509146 seconds to run 1 epoch\n",
      "Epoch:  710  Average loss at step  1000 :  7.678237803459168\n",
      "Epoch:  710  Average loss at step  2000 :  7.640271215438843\n",
      "Epoch:  710  Average loss at step  3000 :  7.840862970352173\n",
      "Epoch:  710  Average loss at step  4000 :  8.002159966468811\n",
      "Epoch:  710  Average loss at step  5000 :  8.011125672340393\n",
      "Epoch:  710  Average loss at step  6000 :  8.238380848884583\n",
      "Epoch:  710  Average loss at step  7000 :  8.605467504501343\n",
      "Epoch:  710  Average loss at step  8000 :  8.127900058746338\n",
      "Epoch:  710  Average loss at step  8472 :  9.757932615444082\n",
      "710 0 20.92132043838501\n",
      "Epoch:  710  Average loss at step  1000 :  2828.7269658203127\n",
      "Epoch:  710  Average loss at step  1491 :  2750.26657318643\n",
      "710 1 11.729994058609009\n",
      "Epoch:  710  Average loss at step  1000 :  3937.021396728516\n",
      "Epoch:  710  Average loss at step  2000 :  3917.241629394531\n",
      "Epoch:  710  Average loss at step  2533 :  3976.7710776605613\n",
      "710 2 19.917563676834106\n",
      "Epoch:  710  Average loss at step  1000 :  62.197133380889895\n",
      "Epoch:  710  Average loss at step  1227 :  62.90445553692132\n",
      "710 3 12.682208776473999\n",
      "Epoch:  710  Average loss at step  1000 :  4.184975347995758\n",
      "Epoch:  710  Average loss at step  2000 :  4.127670564651489\n",
      "Epoch:  710  Average loss at step  3000 :  3.980191180706024\n",
      "Epoch:  710  Average loss at step  3222 :  4.042026983269029\n",
      "710 4 33.235979318618774\n",
      "710 5 1.430511474609375e-06\n",
      "Training time took 99.114052 seconds to run 1 epoch\n",
      "Mean Rank:  154.37852  of  75000\n",
      "Hits @ 10:  0.8542\n",
      "Hits @ 1:  0.6246\n",
      "Testing time took 163.740025 seconds.\n",
      "\n",
      "Epoch:  711  Average loss at step  1000 :  0.04747642606496811\n",
      "Epoch:  711  Average loss at step  2000 :  0.04904639089107513\n",
      "Epoch:  711  Average loss at step  3000 :  0.053981017589569094\n",
      "Epoch:  711  Average loss at step  3222 :  0.056597737063783064\n",
      "711 0 29.41218328475952\n",
      "Training time took 29.521603 seconds to run 1 epoch\n",
      "Epoch:  712  Average loss at step  1000 :  7.98285002040863\n",
      "Epoch:  712  Average loss at step  2000 :  7.958497178077698\n",
      "Epoch:  712  Average loss at step  3000 :  8.129102344512939\n",
      "Epoch:  712  Average loss at step  4000 :  8.445508731842041\n",
      "Epoch:  712  Average loss at step  5000 :  8.00858194732666\n",
      "Epoch:  712  Average loss at step  6000 :  8.275060203075409\n",
      "Epoch:  712  Average loss at step  7000 :  8.166394179344177\n",
      "Epoch:  712  Average loss at step  8000 :  7.686588403701783\n",
      "Epoch:  712  Average loss at step  8472 :  7.730531486073109\n",
      "712 0 20.679666757583618\n",
      "Epoch:  712  Average loss at step  1000 :  2817.369373657227\n",
      "Epoch:  712  Average loss at step  1491 :  2839.082655165483\n",
      "712 1 11.71676778793335\n",
      "Epoch:  712  Average loss at step  1000 :  3944.457193847656\n",
      "Epoch:  712  Average loss at step  2000 :  3926.1884360351564\n",
      "Epoch:  712  Average loss at step  2533 :  3959.6199326159767\n",
      "712 2 19.94661021232605\n",
      "Epoch:  712  Average loss at step  1000 :  61.6004856262207\n",
      "Epoch:  712  Average loss at step  1227 :  62.14175970473256\n",
      "712 3 12.705169916152954\n",
      "Epoch:  712  Average loss at step  1000 :  4.032647346019745\n",
      "Epoch:  712  Average loss at step  2000 :  4.077421325206757\n",
      "Epoch:  712  Average loss at step  3000 :  3.9963442997932432\n",
      "Epoch:  712  Average loss at step  3222 :  4.045117723530736\n",
      "712 4 33.40241765975952\n",
      "712 5 1.6689300537109375e-06\n",
      "Training time took 99.090451 seconds to run 1 epoch\n",
      "Epoch:  713  Average loss at step  1000 :  0.047205329954624176\n",
      "Epoch:  713  Average loss at step  2000 :  0.04987041449546814\n",
      "Epoch:  713  Average loss at step  3000 :  0.05384349447488785\n",
      "Epoch:  713  Average loss at step  3222 :  0.05665589867139211\n",
      "713 0 29.403485536575317\n",
      "Training time took 29.525077 seconds to run 1 epoch\n",
      "Epoch:  714  Average loss at step  1000 :  8.01352129650116\n",
      "Epoch:  714  Average loss at step  2000 :  7.676189560890197\n",
      "Epoch:  714  Average loss at step  3000 :  7.896510347366333\n",
      "Epoch:  714  Average loss at step  4000 :  8.342839966773987\n",
      "Epoch:  714  Average loss at step  5000 :  8.193114915847778\n",
      "Epoch:  714  Average loss at step  6000 :  8.717276458740235\n",
      "Epoch:  714  Average loss at step  7000 :  7.903576418399811\n",
      "Epoch:  714  Average loss at step  8000 :  8.024241273880005\n",
      "Epoch:  714  Average loss at step  8472 :  7.8516335455186645\n",
      "714 0 21.51094150543213\n",
      "Epoch:  714  Average loss at step  1000 :  2827.874591064453\n",
      "Epoch:  714  Average loss at step  1491 :  2837.8983563104243\n",
      "714 1 11.69149923324585\n",
      "Epoch:  714  Average loss at step  1000 :  3940.823385009766\n",
      "Epoch:  714  Average loss at step  2000 :  3951.755077392578\n",
      "Epoch:  714  Average loss at step  2533 :  3968.321676504853\n",
      "714 2 19.922832012176514\n",
      "Epoch:  714  Average loss at step  1000 :  62.0597568359375\n",
      "Epoch:  714  Average loss at step  1227 :  62.06430029678698\n",
      "714 3 12.607114315032959\n",
      "Epoch:  714  Average loss at step  1000 :  4.095859978199005\n",
      "Epoch:  714  Average loss at step  2000 :  3.968717176914215\n",
      "Epoch:  714  Average loss at step  3000 :  4.14413859462738\n",
      "Epoch:  714  Average loss at step  3222 :  3.9853069428869006\n",
      "714 4 33.214388608932495\n",
      "714 5 1.430511474609375e-06\n",
      "Training time took 99.580549 seconds to run 1 epoch\n",
      "Epoch:  715  Average loss at step  1000 :  0.04710505336523056\n",
      "Epoch:  715  Average loss at step  2000 :  0.04922632318735123\n",
      "Epoch:  715  Average loss at step  3000 :  0.053751773178577426\n",
      "Epoch:  715  Average loss at step  3222 :  0.05708057073549063\n",
      "715 0 29.334887266159058\n",
      "Training time took 29.455452 seconds to run 1 epoch\n",
      "Epoch:  716  Average loss at step  1000 :  8.86581792831421\n",
      "Epoch:  716  Average loss at step  2000 :  8.54265860748291\n",
      "Epoch:  716  Average loss at step  3000 :  8.054254762649537\n",
      "Epoch:  716  Average loss at step  4000 :  8.609250844955444\n",
      "Epoch:  716  Average loss at step  5000 :  8.2466809091568\n",
      "Epoch:  716  Average loss at step  6000 :  8.189500893592834\n",
      "Epoch:  716  Average loss at step  7000 :  7.946019021511078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  716  Average loss at step  8000 :  8.149607048034667\n",
      "Epoch:  716  Average loss at step  8472 :  8.292801959684317\n",
      "716 0 20.731687545776367\n",
      "Epoch:  716  Average loss at step  1000 :  2843.9854584960935\n",
      "Epoch:  716  Average loss at step  1491 :  2838.1999147146425\n",
      "716 1 11.697091341018677\n",
      "Epoch:  716  Average loss at step  1000 :  3941.3405588378905\n",
      "Epoch:  716  Average loss at step  2000 :  3905.943900390625\n",
      "Epoch:  716  Average loss at step  2533 :  3989.8559111453305\n",
      "716 2 19.900024890899658\n",
      "Epoch:  716  Average loss at step  1000 :  61.655819862365725\n",
      "Epoch:  716  Average loss at step  1227 :  61.195711644193246\n",
      "716 3 12.845369577407837\n",
      "Epoch:  716  Average loss at step  1000 :  4.0529014644622805\n",
      "Epoch:  716  Average loss at step  2000 :  4.016337316036225\n",
      "Epoch:  716  Average loss at step  3000 :  4.03182275390625\n",
      "Epoch:  716  Average loss at step  3222 :  4.048460006369519\n",
      "716 4 33.09737300872803\n",
      "716 5 1.1920928955078125e-06\n",
      "Training time took 98.904896 seconds to run 1 epoch\n",
      "Epoch:  717  Average loss at step  1000 :  0.046797850251197814\n",
      "Epoch:  717  Average loss at step  2000 :  0.04955005532503128\n",
      "Epoch:  717  Average loss at step  3000 :  0.05363276624679565\n",
      "Epoch:  717  Average loss at step  3222 :  0.05630343926471587\n",
      "717 0 29.432410717010498\n",
      "Training time took 29.549709 seconds to run 1 epoch\n",
      "Epoch:  718  Average loss at step  1000 :  8.740846889495849\n",
      "Epoch:  718  Average loss at step  2000 :  8.240243626594543\n",
      "Epoch:  718  Average loss at step  3000 :  8.08381568145752\n",
      "Epoch:  718  Average loss at step  4000 :  7.8150527982711795\n",
      "Epoch:  718  Average loss at step  5000 :  7.979371994018555\n",
      "Epoch:  718  Average loss at step  6000 :  7.836806717872619\n",
      "Epoch:  718  Average loss at step  7000 :  7.629788869857788\n",
      "Epoch:  718  Average loss at step  8000 :  7.9686301250457765\n",
      "Epoch:  718  Average loss at step  8472 :  7.4601757278983145\n",
      "718 0 20.68141508102417\n",
      "Epoch:  718  Average loss at step  1000 :  2821.000800537109\n",
      "Epoch:  718  Average loss at step  1491 :  2823.7919415322863\n",
      "718 1 11.715275287628174\n",
      "Epoch:  718  Average loss at step  1000 :  3937.9300266113282\n",
      "Epoch:  718  Average loss at step  2000 :  3941.3920834960936\n",
      "Epoch:  718  Average loss at step  2533 :  3941.5913326930354\n",
      "718 2 19.85865807533264\n",
      "Epoch:  718  Average loss at step  1000 :  61.9143981552124\n",
      "Epoch:  718  Average loss at step  1227 :  61.271405296815416\n",
      "718 3 12.672901391983032\n",
      "Epoch:  718  Average loss at step  1000 :  4.037148517131805\n",
      "Epoch:  718  Average loss at step  2000 :  4.017132628917694\n",
      "Epoch:  718  Average loss at step  3000 :  3.8427084527015687\n",
      "Epoch:  718  Average loss at step  3222 :  4.02516555562306\n",
      "718 4 33.10265564918518\n",
      "718 5 1.1920928955078125e-06\n",
      "Training time took 98.648895 seconds to run 1 epoch\n",
      "Epoch:  719  Average loss at step  1000 :  0.04713587123155594\n",
      "Epoch:  719  Average loss at step  2000 :  0.04899647581577301\n",
      "Epoch:  719  Average loss at step  3000 :  0.05360908484458923\n",
      "Epoch:  719  Average loss at step  3222 :  0.05649694882697804\n",
      "719 0 29.37244701385498\n",
      "Training time took 29.49916 seconds to run 1 epoch\n",
      "Epoch:  720  Average loss at step  1000 :  8.559777548789977\n",
      "Epoch:  720  Average loss at step  2000 :  7.807008011817932\n",
      "Epoch:  720  Average loss at step  3000 :  8.358360877037049\n",
      "Epoch:  720  Average loss at step  4000 :  8.446528504371644\n",
      "Epoch:  720  Average loss at step  5000 :  8.117427749633789\n",
      "Epoch:  720  Average loss at step  6000 :  7.562402991294861\n",
      "Epoch:  720  Average loss at step  7000 :  7.636091608047486\n",
      "Epoch:  720  Average loss at step  8000 :  7.741794801712036\n",
      "Epoch:  720  Average loss at step  8472 :  8.569316876966253\n",
      "720 0 20.93684411048889\n",
      "Epoch:  720  Average loss at step  1000 :  2822.324047973633\n",
      "Epoch:  720  Average loss at step  1491 :  2822.5748831359456\n",
      "720 1 11.706988096237183\n",
      "Epoch:  720  Average loss at step  1000 :  3928.2817998046876\n",
      "Epoch:  720  Average loss at step  2000 :  3925.332407470703\n",
      "Epoch:  720  Average loss at step  2533 :  4001.6029388022794\n",
      "720 2 19.936920642852783\n",
      "Epoch:  720  Average loss at step  1000 :  62.03717405700684\n",
      "Epoch:  720  Average loss at step  1227 :  62.155671257900565\n",
      "720 3 12.603599071502686\n",
      "Epoch:  720  Average loss at step  1000 :  4.026561742782593\n",
      "Epoch:  720  Average loss at step  2000 :  3.9588468470573424\n",
      "Epoch:  720  Average loss at step  3000 :  3.8992667002677917\n",
      "Epoch:  720  Average loss at step  3222 :  3.9218601885201765\n",
      "720 4 33.17738962173462\n",
      "720 5 1.430511474609375e-06\n",
      "Training time took 98.991037 seconds to run 1 epoch\n",
      "Mean Rank:  153.71516  of  75000\n",
      "Hits @ 10:  0.8542\n",
      "Hits @ 1:  0.62344\n",
      "Testing time took 163.703555 seconds.\n",
      "\n",
      "Epoch:  721  Average loss at step  1000 :  0.04680914813280106\n",
      "Epoch:  721  Average loss at step  2000 :  0.04888954126834869\n",
      "Epoch:  721  Average loss at step  3000 :  0.05345586329698562\n",
      "Epoch:  721  Average loss at step  3222 :  0.05606926505499787\n",
      "721 0 29.462883472442627\n",
      "Training time took 29.570105 seconds to run 1 epoch\n",
      "Epoch:  722  Average loss at step  1000 :  8.144693284034728\n",
      "Epoch:  722  Average loss at step  2000 :  8.092925358772279\n",
      "Epoch:  722  Average loss at step  3000 :  8.27574141216278\n",
      "Epoch:  722  Average loss at step  4000 :  8.139274660110473\n",
      "Epoch:  722  Average loss at step  5000 :  7.510402879714966\n",
      "Epoch:  722  Average loss at step  6000 :  8.566307836532593\n",
      "Epoch:  722  Average loss at step  7000 :  7.595248787879944\n",
      "Epoch:  722  Average loss at step  8000 :  8.229839681625366\n",
      "Epoch:  722  Average loss at step  8472 :  8.225224766007333\n",
      "722 0 20.053678512573242\n",
      "Epoch:  722  Average loss at step  1000 :  2820.3538333740235\n",
      "Epoch:  722  Average loss at step  1491 :  2843.0963868659514\n",
      "722 1 11.716959476470947\n",
      "Epoch:  722  Average loss at step  1000 :  3939.295840576172\n",
      "Epoch:  722  Average loss at step  2000 :  3961.004748535156\n",
      "Epoch:  722  Average loss at step  2533 :  3944.0875143421035\n",
      "722 2 19.8442702293396\n",
      "Epoch:  722  Average loss at step  1000 :  61.70015944290161\n",
      "Epoch:  722  Average loss at step  1227 :  60.830061770286974\n",
      "722 3 12.625518560409546\n",
      "Epoch:  722  Average loss at step  1000 :  3.9841536746025086\n",
      "Epoch:  722  Average loss at step  2000 :  3.92920148897171\n",
      "Epoch:  722  Average loss at step  3000 :  3.9514192605018614\n",
      "Epoch:  722  Average loss at step  3222 :  3.7321237735228325\n",
      "722 4 33.20403289794922\n",
      "722 5 1.9073486328125e-06\n",
      "Training time took 98.087742 seconds to run 1 epoch\n",
      "Epoch:  723  Average loss at step  1000 :  0.04635881686210632\n",
      "Epoch:  723  Average loss at step  2000 :  0.0489276881814003\n",
      "Epoch:  723  Average loss at step  3000 :  0.05327014702558518\n",
      "Epoch:  723  Average loss at step  3222 :  0.05618753249646524\n",
      "723 0 29.35384440422058\n",
      "Training time took 29.480525 seconds to run 1 epoch\n",
      "Epoch:  724  Average loss at step  1000 :  7.712737737655639\n",
      "Epoch:  724  Average loss at step  2000 :  7.592373898506165\n",
      "Epoch:  724  Average loss at step  3000 :  8.317352498054504\n",
      "Epoch:  724  Average loss at step  4000 :  7.7555582447052\n",
      "Epoch:  724  Average loss at step  5000 :  7.997624674797058\n",
      "Epoch:  724  Average loss at step  6000 :  8.347733206748963\n",
      "Epoch:  724  Average loss at step  7000 :  8.341614263057709\n",
      "Epoch:  724  Average loss at step  8000 :  8.491844672203063\n",
      "Epoch:  724  Average loss at step  8472 :  8.113811538334911\n",
      "724 0 20.793495655059814\n",
      "Epoch:  724  Average loss at step  1000 :  2816.034205200195\n",
      "Epoch:  724  Average loss at step  1491 :  2848.0044324853625\n",
      "724 1 11.746553421020508\n",
      "Epoch:  724  Average loss at step  1000 :  3918.6057244873045\n",
      "Epoch:  724  Average loss at step  2000 :  3953.2270554199217\n",
      "Epoch:  724  Average loss at step  2533 :  3961.5006858843753\n",
      "724 2 19.9275119304657\n",
      "Epoch:  724  Average loss at step  1000 :  62.12962330627441\n",
      "Epoch:  724  Average loss at step  1227 :  62.49342531448333\n",
      "724 3 12.586565494537354\n",
      "Epoch:  724  Average loss at step  1000 :  3.9759053874015806\n",
      "Epoch:  724  Average loss at step  2000 :  3.9679710636138914\n",
      "Epoch:  724  Average loss at step  3000 :  3.939131170272827\n",
      "Epoch:  724  Average loss at step  3222 :  3.871140774459825\n",
      "724 4 33.216816663742065\n",
      "724 5 1.430511474609375e-06\n",
      "Training time took 98.919145 seconds to run 1 epoch\n",
      "Epoch:  725  Average loss at step  1000 :  0.04653463500738144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  725  Average loss at step  2000 :  0.04919780784845352\n",
      "Epoch:  725  Average loss at step  3000 :  0.05322639060020447\n",
      "Epoch:  725  Average loss at step  3222 :  0.05610205379714387\n",
      "725 0 29.440967321395874\n",
      "Training time took 29.561311 seconds to run 1 epoch\n",
      "Epoch:  726  Average loss at step  1000 :  7.710662985801696\n",
      "Epoch:  726  Average loss at step  2000 :  7.741413418769836\n",
      "Epoch:  726  Average loss at step  3000 :  7.930933052062988\n",
      "Epoch:  726  Average loss at step  4000 :  7.912547162532807\n",
      "Epoch:  726  Average loss at step  5000 :  8.055849187850953\n",
      "Epoch:  726  Average loss at step  6000 :  8.08664466571808\n",
      "Epoch:  726  Average loss at step  7000 :  8.115052906036377\n",
      "Epoch:  726  Average loss at step  8000 :  7.5865366039276125\n",
      "Epoch:  726  Average loss at step  8472 :  8.72063479527346\n",
      "726 0 20.273716926574707\n",
      "Epoch:  726  Average loss at step  1000 :  2814.6417917480467\n",
      "Epoch:  726  Average loss at step  1491 :  2839.960216212724\n",
      "726 1 11.702172756195068\n",
      "Epoch:  726  Average loss at step  1000 :  3957.2735959472657\n",
      "Epoch:  726  Average loss at step  2000 :  4005.904841064453\n",
      "Epoch:  726  Average loss at step  2533 :  3937.8518486445964\n",
      "726 2 19.899654626846313\n",
      "Epoch:  726  Average loss at step  1000 :  61.8317519569397\n",
      "Epoch:  726  Average loss at step  1227 :  61.244387825864784\n",
      "726 3 12.629871845245361\n",
      "Epoch:  726  Average loss at step  1000 :  3.8988519716262817\n",
      "Epoch:  726  Average loss at step  2000 :  3.909426676273346\n",
      "Epoch:  726  Average loss at step  3000 :  3.9872943911552428\n",
      "Epoch:  726  Average loss at step  3222 :  4.067800035974269\n",
      "726 4 33.24955701828003\n",
      "726 5 1.6689300537109375e-06\n",
      "Training time took 98.382947 seconds to run 1 epoch\n",
      "Epoch:  727  Average loss at step  1000 :  0.04611711394786835\n",
      "Epoch:  727  Average loss at step  2000 :  0.04838891184329987\n",
      "Epoch:  727  Average loss at step  3000 :  0.05287755483388901\n",
      "Epoch:  727  Average loss at step  3222 :  0.05611001632772729\n",
      "727 0 29.437917232513428\n",
      "Training time took 29.562035 seconds to run 1 epoch\n",
      "Epoch:  728  Average loss at step  1000 :  7.974080694198609\n",
      "Epoch:  728  Average loss at step  2000 :  8.586456816673278\n",
      "Epoch:  728  Average loss at step  3000 :  8.21702269268036\n",
      "Epoch:  728  Average loss at step  4000 :  7.791314383029937\n",
      "Epoch:  728  Average loss at step  5000 :  8.773648149490356\n",
      "Epoch:  728  Average loss at step  6000 :  7.958240371704101\n",
      "Epoch:  728  Average loss at step  7000 :  7.891271757125854\n",
      "Epoch:  728  Average loss at step  8000 :  8.16632340145111\n",
      "Epoch:  728  Average loss at step  8472 :  7.594940163608439\n",
      "728 0 20.458425045013428\n",
      "Epoch:  728  Average loss at step  1000 :  2827.213623046875\n",
      "Epoch:  728  Average loss at step  1491 :  2848.3075668406136\n",
      "728 1 11.702129602432251\n",
      "Epoch:  728  Average loss at step  1000 :  3982.393634765625\n",
      "Epoch:  728  Average loss at step  2000 :  3997.080086669922\n",
      "Epoch:  728  Average loss at step  2533 :  3944.68822481399\n",
      "728 2 19.934503316879272\n",
      "Epoch:  728  Average loss at step  1000 :  61.80664401245117\n",
      "Epoch:  728  Average loss at step  1227 :  62.25259009849443\n",
      "728 3 12.652492046356201\n",
      "Epoch:  728  Average loss at step  1000 :  3.9703866715431215\n",
      "Epoch:  728  Average loss at step  2000 :  3.9482016730308533\n",
      "Epoch:  728  Average loss at step  3000 :  3.8776319828033445\n",
      "Epoch:  728  Average loss at step  3222 :  4.030310279045924\n",
      "728 4 33.24702978134155\n",
      "728 5 1.430511474609375e-06\n",
      "Training time took 98.631078 seconds to run 1 epoch\n",
      "Epoch:  729  Average loss at step  1000 :  0.04648981732130051\n",
      "Epoch:  729  Average loss at step  2000 :  0.04859068763256073\n",
      "Epoch:  729  Average loss at step  3000 :  0.053247160613536834\n",
      "Epoch:  729  Average loss at step  3222 :  0.055679503245180666\n",
      "729 0 29.440297603607178\n",
      "Training time took 29.565159 seconds to run 1 epoch\n",
      "Epoch:  730  Average loss at step  1000 :  8.401887497901917\n",
      "Epoch:  730  Average loss at step  2000 :  8.092258640766143\n",
      "Epoch:  730  Average loss at step  3000 :  7.4261478452682494\n",
      "Epoch:  730  Average loss at step  4000 :  7.870760998725891\n",
      "Epoch:  730  Average loss at step  5000 :  7.816048578262329\n",
      "Epoch:  730  Average loss at step  6000 :  8.534325623512268\n",
      "Epoch:  730  Average loss at step  7000 :  7.746522747039795\n",
      "Epoch:  730  Average loss at step  8000 :  8.013894260883331\n",
      "Epoch:  730  Average loss at step  8472 :  8.12757279440703\n",
      "730 0 20.76978039741516\n",
      "Epoch:  730  Average loss at step  1000 :  2867.405658569336\n",
      "Epoch:  730  Average loss at step  1491 :  2832.3504151439934\n",
      "730 1 11.696882247924805\n",
      "Epoch:  730  Average loss at step  1000 :  3979.184654296875\n",
      "Epoch:  730  Average loss at step  2000 :  3949.933583496094\n",
      "Epoch:  730  Average loss at step  2533 :  4025.2009690867662\n",
      "730 2 19.947678327560425\n",
      "Epoch:  730  Average loss at step  1000 :  61.69436813354492\n",
      "Epoch:  730  Average loss at step  1227 :  61.8910118463511\n",
      "730 3 12.703669309616089\n",
      "Epoch:  730  Average loss at step  1000 :  3.918660970687866\n",
      "Epoch:  730  Average loss at step  2000 :  3.912180540084839\n",
      "Epoch:  730  Average loss at step  3000 :  3.9760506014823913\n",
      "Epoch:  730  Average loss at step  3222 :  4.117514153511693\n",
      "730 4 33.114837408065796\n",
      "730 5 9.5367431640625e-07\n",
      "Training time took 98.868596 seconds to run 1 epoch\n",
      "Mean Rank:  154.40176  of  75000\n",
      "Hits @ 10:  0.85464\n",
      "Hits @ 1:  0.62448\n",
      "Testing time took 164.535138 seconds.\n",
      "\n",
      "Epoch:  731  Average loss at step  1000 :  0.045856057167053224\n",
      "Epoch:  731  Average loss at step  2000 :  0.048731878459453586\n",
      "Epoch:  731  Average loss at step  3000 :  0.052695217013359066\n",
      "Epoch:  731  Average loss at step  3222 :  0.05541126647135867\n",
      "731 0 29.39433240890503\n",
      "Training time took 29.506265 seconds to run 1 epoch\n",
      "Epoch:  732  Average loss at step  1000 :  7.529493017196655\n",
      "Epoch:  732  Average loss at step  2000 :  7.597208961486817\n",
      "Epoch:  732  Average loss at step  3000 :  8.086288878440858\n",
      "Epoch:  732  Average loss at step  4000 :  7.82385489654541\n",
      "Epoch:  732  Average loss at step  5000 :  8.532149375915527\n",
      "Epoch:  732  Average loss at step  6000 :  7.910324201583863\n",
      "Epoch:  732  Average loss at step  7000 :  8.101719725608826\n",
      "Epoch:  732  Average loss at step  8000 :  7.744817484855652\n",
      "Epoch:  732  Average loss at step  8472 :  8.30488287528764\n",
      "732 0 20.68504285812378\n",
      "Epoch:  732  Average loss at step  1000 :  2834.4120806884766\n",
      "Epoch:  732  Average loss at step  1491 :  2846.0946650362575\n",
      "732 1 11.69999623298645\n",
      "Epoch:  732  Average loss at step  1000 :  3976.858534423828\n",
      "Epoch:  732  Average loss at step  2000 :  3960.4559978027346\n",
      "Epoch:  732  Average loss at step  2533 :  3952.241855726446\n",
      "732 2 19.893401861190796\n",
      "Epoch:  732  Average loss at step  1000 :  61.65881593322754\n",
      "Epoch:  732  Average loss at step  1227 :  62.294987293852124\n",
      "732 3 12.63015079498291\n",
      "Epoch:  732  Average loss at step  1000 :  3.919334209442139\n",
      "Epoch:  732  Average loss at step  2000 :  3.8237014169692993\n",
      "Epoch:  732  Average loss at step  3000 :  3.9595486154556276\n",
      "Epoch:  732  Average loss at step  3222 :  3.8464214552565803\n",
      "732 4 33.24862837791443\n",
      "732 5 1.6689300537109375e-06\n",
      "Training time took 98.793785 seconds to run 1 epoch\n",
      "Epoch:  733  Average loss at step  1000 :  0.045966987669467926\n",
      "Epoch:  733  Average loss at step  2000 :  0.04822770094871521\n",
      "Epoch:  733  Average loss at step  3000 :  0.052849370658397676\n",
      "Epoch:  733  Average loss at step  3222 :  0.055622895243021955\n",
      "733 0 29.406933307647705\n",
      "Training time took 29.534457 seconds to run 1 epoch\n",
      "Epoch:  734  Average loss at step  1000 :  7.916109445571899\n",
      "Epoch:  734  Average loss at step  2000 :  8.10608040714264\n",
      "Epoch:  734  Average loss at step  3000 :  8.414565940856933\n",
      "Epoch:  734  Average loss at step  4000 :  7.89319873714447\n",
      "Epoch:  734  Average loss at step  5000 :  8.170288365364074\n",
      "Epoch:  734  Average loss at step  6000 :  8.30809149456024\n",
      "Epoch:  734  Average loss at step  7000 :  8.34479790878296\n",
      "Epoch:  734  Average loss at step  8000 :  8.040581767082214\n",
      "Epoch:  734  Average loss at step  8472 :  8.34178632925071\n",
      "734 0 20.899865865707397\n",
      "Epoch:  734  Average loss at step  1000 :  2860.508269287109\n",
      "Epoch:  734  Average loss at step  1491 :  2818.1311947954646\n",
      "734 1 11.708705425262451\n",
      "Epoch:  734  Average loss at step  1000 :  3925.7201857910154\n",
      "Epoch:  734  Average loss at step  2000 :  3969.5699365234377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  734  Average loss at step  2533 :  3998.964068461499\n",
      "734 2 19.907237768173218\n",
      "Epoch:  734  Average loss at step  1000 :  61.89789476394653\n",
      "Epoch:  734  Average loss at step  1227 :  61.81827389831584\n",
      "734 3 12.610587358474731\n",
      "Epoch:  734  Average loss at step  1000 :  4.069975181102753\n",
      "Epoch:  734  Average loss at step  2000 :  3.849537483692169\n",
      "Epoch:  734  Average loss at step  3000 :  3.852399938583374\n",
      "Epoch:  734  Average loss at step  3222 :  4.026004613403551\n",
      "734 4 33.2183883190155\n",
      "734 5 1.6689300537109375e-06\n",
      "Training time took 98.970044 seconds to run 1 epoch\n",
      "Epoch:  735  Average loss at step  1000 :  0.04565238690376282\n",
      "Epoch:  735  Average loss at step  2000 :  0.04846549993753433\n",
      "Epoch:  735  Average loss at step  3000 :  0.05263459610939026\n",
      "Epoch:  735  Average loss at step  3222 :  0.05532871473780348\n",
      "735 0 29.429574966430664\n",
      "Training time took 29.549084 seconds to run 1 epoch\n",
      "Epoch:  736  Average loss at step  1000 :  8.373799240112305\n",
      "Epoch:  736  Average loss at step  2000 :  8.298716401100158\n",
      "Epoch:  736  Average loss at step  3000 :  7.683612693786621\n",
      "Epoch:  736  Average loss at step  4000 :  7.506168369293213\n",
      "Epoch:  736  Average loss at step  5000 :  8.097471541404724\n",
      "Epoch:  736  Average loss at step  6000 :  8.305854865074158\n",
      "Epoch:  736  Average loss at step  7000 :  8.130296814918518\n",
      "Epoch:  736  Average loss at step  8000 :  7.589887434005737\n",
      "Epoch:  736  Average loss at step  8472 :  8.042712086333134\n",
      "736 0 20.757397413253784\n",
      "Epoch:  736  Average loss at step  1000 :  2838.368635986328\n",
      "Epoch:  736  Average loss at step  1491 :  2889.574492127028\n",
      "736 1 11.73354983329773\n",
      "Epoch:  736  Average loss at step  1000 :  3989.6383845214846\n",
      "Epoch:  736  Average loss at step  2000 :  4009.177104980469\n",
      "Epoch:  736  Average loss at step  2533 :  3990.8671689070256\n",
      "736 2 19.88089370727539\n",
      "Epoch:  736  Average loss at step  1000 :  61.54183252716064\n",
      "Epoch:  736  Average loss at step  1227 :  63.27201714349287\n",
      "736 3 12.606083393096924\n",
      "Epoch:  736  Average loss at step  1000 :  3.9165350613594057\n",
      "Epoch:  736  Average loss at step  2000 :  3.837238784790039\n",
      "Epoch:  736  Average loss at step  3000 :  3.8958913264274595\n",
      "Epoch:  736  Average loss at step  3222 :  3.897714156453673\n",
      "736 4 33.20859670639038\n",
      "736 5 1.6689300537109375e-06\n",
      "Training time took 98.822452 seconds to run 1 epoch\n",
      "Epoch:  737  Average loss at step  1000 :  0.04589668828248978\n",
      "Epoch:  737  Average loss at step  2000 :  0.04810428065061569\n",
      "Epoch:  737  Average loss at step  3000 :  0.052323707938194276\n",
      "Epoch:  737  Average loss at step  3222 :  0.05466882089002616\n",
      "737 0 29.368276596069336\n",
      "Training time took 29.492553 seconds to run 1 epoch\n",
      "Epoch:  738  Average loss at step  1000 :  7.9964532289505\n",
      "Epoch:  738  Average loss at step  2000 :  7.950453442573547\n",
      "Epoch:  738  Average loss at step  3000 :  8.095355522155762\n",
      "Epoch:  738  Average loss at step  4000 :  8.308140564918519\n",
      "Epoch:  738  Average loss at step  5000 :  7.582168386459351\n",
      "Epoch:  738  Average loss at step  6000 :  8.534040204048157\n",
      "Epoch:  738  Average loss at step  7000 :  8.613249994277954\n",
      "Epoch:  738  Average loss at step  8000 :  7.51835808467865\n",
      "Epoch:  738  Average loss at step  8472 :  7.545845355067105\n",
      "738 0 20.702489376068115\n",
      "Epoch:  738  Average loss at step  1000 :  2838.69996472168\n",
      "Epoch:  738  Average loss at step  1491 :  2808.3935345964865\n",
      "738 1 11.728029727935791\n",
      "Epoch:  738  Average loss at step  1000 :  3976.513320678711\n",
      "Epoch:  738  Average loss at step  2000 :  3959.413924560547\n",
      "Epoch:  738  Average loss at step  2533 :  3974.4191558371003\n",
      "738 2 19.920345067977905\n",
      "Epoch:  738  Average loss at step  1000 :  61.62316316223144\n",
      "Epoch:  738  Average loss at step  1227 :  61.25270277873111\n",
      "738 3 12.641950845718384\n",
      "Epoch:  738  Average loss at step  1000 :  3.999810784816742\n",
      "Epoch:  738  Average loss at step  2000 :  3.8508789196014406\n",
      "Epoch:  738  Average loss at step  3000 :  3.9499422554969787\n",
      "Epoch:  738  Average loss at step  3222 :  4.064735240251025\n",
      "738 4 33.23217964172363\n",
      "738 5 1.6689300537109375e-06\n",
      "Training time took 98.856188 seconds to run 1 epoch\n",
      "Epoch:  739  Average loss at step  1000 :  0.04567801880836487\n",
      "Epoch:  739  Average loss at step  2000 :  0.047915869653224946\n",
      "Epoch:  739  Average loss at step  3000 :  0.05265741330385208\n",
      "Epoch:  739  Average loss at step  3222 :  0.054817392919054526\n",
      "739 0 29.412415981292725\n",
      "Training time took 29.536394 seconds to run 1 epoch\n",
      "Epoch:  740  Average loss at step  1000 :  8.330226474761963\n",
      "Epoch:  740  Average loss at step  2000 :  8.323411680221557\n",
      "Epoch:  740  Average loss at step  3000 :  7.988736559867859\n",
      "Epoch:  740  Average loss at step  4000 :  7.874377501487732\n",
      "Epoch:  740  Average loss at step  5000 :  8.23365629863739\n",
      "Epoch:  740  Average loss at step  6000 :  7.932609805107116\n",
      "Epoch:  740  Average loss at step  7000 :  7.8221035537719725\n",
      "Epoch:  740  Average loss at step  8000 :  7.900439018249512\n",
      "Epoch:  740  Average loss at step  8472 :  8.082605431315743\n",
      "740 0 20.696897983551025\n",
      "Epoch:  740  Average loss at step  1000 :  2839.817096191406\n",
      "Epoch:  740  Average loss at step  1491 :  2876.5133038712875\n",
      "740 1 11.716192722320557\n",
      "Epoch:  740  Average loss at step  1000 :  4010.6944267578124\n",
      "Epoch:  740  Average loss at step  2000 :  3924.5615810546874\n",
      "Epoch:  740  Average loss at step  2533 :  3982.3663562490315\n",
      "740 2 19.90428328514099\n",
      "Epoch:  740  Average loss at step  1000 :  61.67394062805176\n",
      "Epoch:  740  Average loss at step  1227 :  61.075377585255026\n",
      "740 3 12.647724628448486\n",
      "Epoch:  740  Average loss at step  1000 :  3.846563581466675\n",
      "Epoch:  740  Average loss at step  2000 :  3.744187933444977\n",
      "Epoch:  740  Average loss at step  3000 :  3.9298416357040407\n",
      "Epoch:  740  Average loss at step  3222 :  3.9907640682529686\n",
      "740 4 33.202282428741455\n",
      "740 5 1.430511474609375e-06\n",
      "Training time took 98.80249 seconds to run 1 epoch\n",
      "Mean Rank:  153.7866  of  75000\n",
      "Hits @ 10:  0.85404\n",
      "Hits @ 1:  0.62368\n",
      "Testing time took 163.81715 seconds.\n",
      "\n",
      "Epoch:  741  Average loss at step  1000 :  0.04562274235486984\n",
      "Epoch:  741  Average loss at step  2000 :  0.047903373062610624\n",
      "Epoch:  741  Average loss at step  3000 :  0.052350503861904145\n",
      "Epoch:  741  Average loss at step  3222 :  0.05447593250092153\n",
      "741 0 29.44778323173523\n",
      "Training time took 29.559303 seconds to run 1 epoch\n",
      "Epoch:  742  Average loss at step  1000 :  8.171018008232117\n",
      "Epoch:  742  Average loss at step  2000 :  8.176072723388671\n",
      "Epoch:  742  Average loss at step  3000 :  7.962056315422058\n",
      "Epoch:  742  Average loss at step  4000 :  8.504134622573853\n",
      "Epoch:  742  Average loss at step  5000 :  8.28960539150238\n",
      "Epoch:  742  Average loss at step  6000 :  8.406929070472717\n",
      "Epoch:  742  Average loss at step  7000 :  8.031671269416808\n",
      "Epoch:  742  Average loss at step  8000 :  7.847565014839172\n",
      "Epoch:  742  Average loss at step  8472 :  8.563955457256785\n",
      "742 0 20.92552351951599\n",
      "Epoch:  742  Average loss at step  1000 :  2831.599524291992\n",
      "Epoch:  742  Average loss at step  1491 :  2835.9045116996535\n",
      "742 1 11.754079103469849\n",
      "Epoch:  742  Average loss at step  1000 :  3978.2100975341796\n",
      "Epoch:  742  Average loss at step  2000 :  3972.0444604492186\n",
      "Epoch:  742  Average loss at step  2533 :  4001.1496680502437\n",
      "742 2 19.929802894592285\n",
      "Epoch:  742  Average loss at step  1000 :  61.27895263671875\n",
      "Epoch:  742  Average loss at step  1227 :  61.604735485986865\n",
      "742 3 12.649168252944946\n",
      "Epoch:  742  Average loss at step  1000 :  3.940140179157257\n",
      "Epoch:  742  Average loss at step  2000 :  3.821746084213257\n",
      "Epoch:  742  Average loss at step  3000 :  3.8442555480003358\n",
      "Epoch:  742  Average loss at step  3222 :  4.046673558640295\n",
      "742 4 33.1643009185791\n",
      "742 5 1.6689300537109375e-06\n",
      "Training time took 99.056081 seconds to run 1 epoch\n",
      "Epoch:  743  Average loss at step  1000 :  0.045464917719364166\n",
      "Epoch:  743  Average loss at step  2000 :  0.04765339207649231\n",
      "Epoch:  743  Average loss at step  3000 :  0.052341117918491366\n",
      "Epoch:  743  Average loss at step  3222 :  0.054551285459022915\n",
      "743 0 29.422898769378662\n",
      "Training time took 29.545856 seconds to run 1 epoch\n",
      "Epoch:  744  Average loss at step  1000 :  8.041903284072877\n",
      "Epoch:  744  Average loss at step  2000 :  8.749039841651916\n",
      "Epoch:  744  Average loss at step  3000 :  8.127159927368163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  744  Average loss at step  4000 :  8.022454951286315\n",
      "Epoch:  744  Average loss at step  5000 :  7.926583286285401\n",
      "Epoch:  744  Average loss at step  6000 :  7.860327589035034\n",
      "Epoch:  744  Average loss at step  7000 :  8.434927236557007\n",
      "Epoch:  744  Average loss at step  8000 :  8.4441085729599\n",
      "Epoch:  744  Average loss at step  8472 :  7.729403986084274\n",
      "744 0 21.42340898513794\n",
      "Epoch:  744  Average loss at step  1000 :  2870.332585205078\n",
      "Epoch:  744  Average loss at step  1491 :  2860.820544441799\n",
      "744 1 11.73591160774231\n",
      "Epoch:  744  Average loss at step  1000 :  3972.0413203125\n",
      "Epoch:  744  Average loss at step  2000 :  3993.450168334961\n",
      "Epoch:  744  Average loss at step  2533 :  3962.793568937832\n",
      "744 2 19.891836166381836\n",
      "Epoch:  744  Average loss at step  1000 :  61.615584838867186\n",
      "Epoch:  744  Average loss at step  1227 :  61.04505308968056\n",
      "744 3 12.62404751777649\n",
      "Epoch:  744  Average loss at step  1000 :  3.8633020873069763\n",
      "Epoch:  744  Average loss at step  2000 :  3.777847025871277\n",
      "Epoch:  744  Average loss at step  3000 :  3.767931097984314\n",
      "Epoch:  744  Average loss at step  3222 :  3.6555122502725204\n",
      "744 4 33.30298829078674\n",
      "744 5 1.430511474609375e-06\n",
      "Training time took 99.624408 seconds to run 1 epoch\n",
      "Epoch:  745  Average loss at step  1000 :  0.045461600720882414\n",
      "Epoch:  745  Average loss at step  2000 :  0.04780106121301651\n",
      "Epoch:  745  Average loss at step  3000 :  0.052015507340431213\n",
      "Epoch:  745  Average loss at step  3222 :  0.05465559089715396\n",
      "745 0 29.37371587753296\n",
      "Training time took 29.491345 seconds to run 1 epoch\n",
      "Epoch:  746  Average loss at step  1000 :  8.153904865264893\n",
      "Epoch:  746  Average loss at step  2000 :  7.790801984786987\n",
      "Epoch:  746  Average loss at step  3000 :  7.710318192481995\n",
      "Epoch:  746  Average loss at step  4000 :  7.441233852386475\n",
      "Epoch:  746  Average loss at step  5000 :  8.146108726501465\n",
      "Epoch:  746  Average loss at step  6000 :  8.144958920478821\n",
      "Epoch:  746  Average loss at step  7000 :  8.137374760627747\n",
      "Epoch:  746  Average loss at step  8000 :  8.024269756317139\n",
      "Epoch:  746  Average loss at step  8472 :  7.740020306708123\n",
      "746 0 21.25097107887268\n",
      "Epoch:  746  Average loss at step  1000 :  2890.3182677001955\n",
      "Epoch:  746  Average loss at step  1491 :  2822.079575501551\n",
      "746 1 11.696462154388428\n",
      "Epoch:  746  Average loss at step  1000 :  3982.1466682128907\n",
      "Epoch:  746  Average loss at step  2000 :  4011.4038659667967\n",
      "Epoch:  746  Average loss at step  2533 :  4000.086940970004\n",
      "746 2 19.94488501548767\n",
      "Epoch:  746  Average loss at step  1000 :  62.15062441253662\n",
      "Epoch:  746  Average loss at step  1227 :  60.908333814606415\n",
      "746 3 12.604054927825928\n",
      "Epoch:  746  Average loss at step  1000 :  3.8420553917884828\n",
      "Epoch:  746  Average loss at step  2000 :  3.8222074036598204\n",
      "Epoch:  746  Average loss at step  3000 :  3.7719056096076966\n",
      "Epoch:  746  Average loss at step  3222 :  3.9171629335975404\n",
      "746 4 33.21073007583618\n",
      "746 5 1.430511474609375e-06\n",
      "Training time took 99.334376 seconds to run 1 epoch\n",
      "Epoch:  747  Average loss at step  1000 :  0.04540204256772995\n",
      "Epoch:  747  Average loss at step  2000 :  0.04756784331798553\n",
      "Epoch:  747  Average loss at step  3000 :  0.05160571700334549\n",
      "Epoch:  747  Average loss at step  3222 :  0.054535547368555294\n",
      "747 0 29.42072868347168\n",
      "Training time took 29.543016 seconds to run 1 epoch\n",
      "Epoch:  748  Average loss at step  1000 :  8.193529361724854\n",
      "Epoch:  748  Average loss at step  2000 :  8.51908409690857\n",
      "Epoch:  748  Average loss at step  3000 :  8.280480744361878\n",
      "Epoch:  748  Average loss at step  4000 :  8.148491048812867\n",
      "Epoch:  748  Average loss at step  5000 :  7.596809714317322\n",
      "Epoch:  748  Average loss at step  6000 :  7.63658021068573\n",
      "Epoch:  748  Average loss at step  7000 :  8.324460136413574\n",
      "Epoch:  748  Average loss at step  8000 :  7.85971501159668\n",
      "Epoch:  748  Average loss at step  8472 :  7.338432763571103\n",
      "748 0 20.425869703292847\n",
      "Epoch:  748  Average loss at step  1000 :  2859.7022080078127\n",
      "Epoch:  748  Average loss at step  1491 :  2862.208642509497\n",
      "748 1 11.72217607498169\n",
      "Epoch:  748  Average loss at step  1000 :  4014.765161254883\n",
      "Epoch:  748  Average loss at step  2000 :  4008.623255126953\n",
      "Epoch:  748  Average loss at step  2533 :  3983.0723528816657\n",
      "748 2 19.96806836128235\n",
      "Epoch:  748  Average loss at step  1000 :  61.90401177215576\n",
      "Epoch:  748  Average loss at step  1227 :  61.18099562527617\n",
      "748 3 12.71301531791687\n",
      "Epoch:  748  Average loss at step  1000 :  3.9116618819236755\n",
      "Epoch:  748  Average loss at step  2000 :  3.9132149991989134\n",
      "Epoch:  748  Average loss at step  3000 :  3.703133342266083\n",
      "Epoch:  748  Average loss at step  3222 :  3.7136446743111335\n",
      "748 4 33.32591915130615\n",
      "748 5 1.430511474609375e-06\n",
      "Training time took 98.793637 seconds to run 1 epoch\n",
      "Epoch:  749  Average loss at step  1000 :  0.045145851790905\n",
      "Epoch:  749  Average loss at step  2000 :  0.04743027567863464\n",
      "Epoch:  749  Average loss at step  3000 :  0.051586371779441836\n",
      "Epoch:  749  Average loss at step  3222 :  0.054874006839710186\n",
      "749 0 29.486278772354126\n",
      "Training time took 29.608291 seconds to run 1 epoch\n",
      "Epoch:  750  Average loss at step  1000 :  7.84376577091217\n",
      "Epoch:  750  Average loss at step  2000 :  8.108919867515564\n",
      "Epoch:  750  Average loss at step  3000 :  8.099160548210143\n",
      "Epoch:  750  Average loss at step  4000 :  8.0384933719635\n",
      "Epoch:  750  Average loss at step  5000 :  7.214610028266907\n",
      "Epoch:  750  Average loss at step  6000 :  8.102500056266784\n",
      "Epoch:  750  Average loss at step  7000 :  7.651067777633667\n",
      "Epoch:  750  Average loss at step  8000 :  8.15656717157364\n",
      "Epoch:  750  Average loss at step  8472 :  8.320937985035332\n",
      "750 0 20.795488834381104\n",
      "Epoch:  750  Average loss at step  1000 :  2908.7019650268553\n",
      "Epoch:  750  Average loss at step  1491 :  2846.292484934525\n",
      "750 1 11.745562314987183\n",
      "Epoch:  750  Average loss at step  1000 :  4001.829324462891\n",
      "Epoch:  750  Average loss at step  2000 :  3976.347965576172\n",
      "Epoch:  750  Average loss at step  2533 :  3997.971356412018\n",
      "750 2 19.90536141395569\n",
      "Epoch:  750  Average loss at step  1000 :  61.63600542068482\n",
      "Epoch:  750  Average loss at step  1227 :  61.38604266319455\n",
      "750 3 12.597259998321533\n",
      "Epoch:  750  Average loss at step  1000 :  3.8246641354560853\n",
      "Epoch:  750  Average loss at step  2000 :  3.7254315843582155\n",
      "Epoch:  750  Average loss at step  3000 :  3.904750294208527\n",
      "Epoch:  750  Average loss at step  3222 :  3.979141844763052\n",
      "750 4 33.22297406196594\n",
      "750 5 1.430511474609375e-06\n",
      "Training time took 98.877857 seconds to run 1 epoch\n",
      "Mean Rank:  153.47612  of  75000\n",
      "Hits @ 10:  0.85436\n",
      "Hits @ 1:  0.62416\n",
      "Testing time took 164.054973 seconds.\n",
      "\n",
      "Epoch:  751  Average loss at step  1000 :  0.04493021416664124\n",
      "Epoch:  751  Average loss at step  2000 :  0.04769248706102371\n",
      "Epoch:  751  Average loss at step  3000 :  0.051722125709056856\n",
      "Epoch:  751  Average loss at step  3222 :  0.05484543664077921\n",
      "751 0 29.4628267288208\n",
      "Training time took 29.573205 seconds to run 1 epoch\n",
      "Epoch:  752  Average loss at step  1000 :  7.727243999481201\n",
      "Epoch:  752  Average loss at step  2000 :  8.209949586868285\n",
      "Epoch:  752  Average loss at step  3000 :  8.494618047714233\n",
      "Epoch:  752  Average loss at step  4000 :  8.30825645160675\n",
      "Epoch:  752  Average loss at step  5000 :  7.782747702598572\n",
      "Epoch:  752  Average loss at step  6000 :  7.765224084854126\n",
      "Epoch:  752  Average loss at step  7000 :  8.01850416278839\n",
      "Epoch:  752  Average loss at step  8000 :  8.041959684371948\n",
      "Epoch:  752  Average loss at step  8472 :  7.83554491185812\n",
      "752 0 20.213518381118774\n",
      "Epoch:  752  Average loss at step  1000 :  2859.085916015625\n",
      "Epoch:  752  Average loss at step  1491 :  2855.3346499445247\n",
      "752 1 11.701808452606201\n",
      "Epoch:  752  Average loss at step  1000 :  3988.924518066406\n",
      "Epoch:  752  Average loss at step  2000 :  3973.848325073242\n",
      "Epoch:  752  Average loss at step  2533 :  3962.2927553254103\n",
      "752 2 19.744728326797485\n",
      "Epoch:  752  Average loss at step  1000 :  61.87876708602905\n",
      "Epoch:  752  Average loss at step  1227 :  61.22702471805081\n",
      "752 3 12.68422269821167\n",
      "Epoch:  752  Average loss at step  1000 :  3.7795168075561523\n",
      "Epoch:  752  Average loss at step  2000 :  3.726430070877075\n",
      "Epoch:  752  Average loss at step  3000 :  3.7839915933609007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  752  Average loss at step  3222 :  3.910178487364147\n",
      "752 4 33.29361414909363\n",
      "752 5 1.430511474609375e-06\n",
      "Training time took 98.275833 seconds to run 1 epoch\n",
      "Epoch:  753  Average loss at step  1000 :  0.04455484229326248\n",
      "Epoch:  753  Average loss at step  2000 :  0.04716330432891846\n",
      "Epoch:  753  Average loss at step  3000 :  0.05162036627531052\n",
      "Epoch:  753  Average loss at step  3222 :  0.054462289289352935\n",
      "753 0 29.343369245529175\n",
      "Training time took 29.46861 seconds to run 1 epoch\n",
      "Epoch:  754  Average loss at step  1000 :  7.754523596763611\n",
      "Epoch:  754  Average loss at step  2000 :  8.474486503601074\n",
      "Epoch:  754  Average loss at step  3000 :  8.053580722808839\n",
      "Epoch:  754  Average loss at step  4000 :  8.200855659484864\n",
      "Epoch:  754  Average loss at step  5000 :  8.552651033401489\n",
      "Epoch:  754  Average loss at step  6000 :  8.0179125289917\n",
      "Epoch:  754  Average loss at step  7000 :  8.781734092712401\n",
      "Epoch:  754  Average loss at step  8000 :  7.679265420913696\n",
      "Epoch:  754  Average loss at step  8472 :  6.8594628696677225\n",
      "754 0 20.7271831035614\n",
      "Epoch:  754  Average loss at step  1000 :  2847.1443697509767\n",
      "Epoch:  754  Average loss at step  1491 :  2860.218262106646\n",
      "754 1 11.70979928970337\n",
      "Epoch:  754  Average loss at step  1000 :  4007.129938232422\n",
      "Epoch:  754  Average loss at step  2000 :  4014.110521484375\n",
      "Epoch:  754  Average loss at step  2533 :  3975.7815946032583\n",
      "754 2 19.950030088424683\n",
      "Epoch:  754  Average loss at step  1000 :  62.0580901260376\n",
      "Epoch:  754  Average loss at step  1227 :  61.15923921205835\n",
      "754 3 12.573638677597046\n",
      "Epoch:  754  Average loss at step  1000 :  3.827883418083191\n",
      "Epoch:  754  Average loss at step  2000 :  3.623827039718628\n",
      "Epoch:  754  Average loss at step  3000 :  3.776752342224121\n",
      "Epoch:  754  Average loss at step  3222 :  3.7383848094062095\n",
      "754 4 33.116703510284424\n",
      "754 5 1.6689300537109375e-06\n",
      "Training time took 98.709045 seconds to run 1 epoch\n",
      "Epoch:  755  Average loss at step  1000 :  0.04463822501897812\n",
      "Epoch:  755  Average loss at step  2000 :  0.047458904504776\n",
      "Epoch:  755  Average loss at step  3000 :  0.05144740581512451\n",
      "Epoch:  755  Average loss at step  3222 :  0.05438180069003128\n",
      "755 0 29.397011280059814\n",
      "Training time took 29.51884 seconds to run 1 epoch\n",
      "Epoch:  756  Average loss at step  1000 :  8.279208236694336\n",
      "Epoch:  756  Average loss at step  2000 :  8.456608104705811\n",
      "Epoch:  756  Average loss at step  3000 :  8.243271500587463\n",
      "Epoch:  756  Average loss at step  4000 :  8.01413848400116\n",
      "Epoch:  756  Average loss at step  5000 :  7.875297945022583\n",
      "Epoch:  756  Average loss at step  6000 :  8.17308906841278\n",
      "Epoch:  756  Average loss at step  7000 :  7.667138231277466\n",
      "Epoch:  756  Average loss at step  8000 :  7.841129755020142\n",
      "Epoch:  756  Average loss at step  8472 :  7.9444750405386015\n",
      "756 0 20.857341051101685\n",
      "Epoch:  756  Average loss at step  1000 :  2858.2693980712893\n",
      "Epoch:  756  Average loss at step  1491 :  2854.105132384661\n",
      "756 1 11.74666690826416\n",
      "Epoch:  756  Average loss at step  1000 :  3988.2491447753905\n",
      "Epoch:  756  Average loss at step  2000 :  4012.0142880859376\n",
      "Epoch:  756  Average loss at step  2533 :  3968.348921269747\n",
      "756 2 19.865710973739624\n",
      "Epoch:  756  Average loss at step  1000 :  61.58962790298462\n",
      "Epoch:  756  Average loss at step  1227 :  61.85052169669883\n",
      "756 3 12.584397554397583\n",
      "Epoch:  756  Average loss at step  1000 :  3.9720903215408323\n",
      "Epoch:  756  Average loss at step  2000 :  3.814704976081848\n",
      "Epoch:  756  Average loss at step  3000 :  3.8134344811439513\n",
      "Epoch:  756  Average loss at step  3222 :  3.9942352408901365\n",
      "756 4 33.30634832382202\n",
      "756 5 1.1920928955078125e-06\n",
      "Training time took 98.998093 seconds to run 1 epoch\n",
      "Epoch:  757  Average loss at step  1000 :  0.0449026226401329\n",
      "Epoch:  757  Average loss at step  2000 :  0.04702910631895065\n",
      "Epoch:  757  Average loss at step  3000 :  0.05112157833576202\n",
      "Epoch:  757  Average loss at step  3222 :  0.053595598584629825\n",
      "757 0 29.38617444038391\n",
      "Training time took 29.509863 seconds to run 1 epoch\n",
      "Epoch:  758  Average loss at step  1000 :  7.858546073913574\n",
      "Epoch:  758  Average loss at step  2000 :  7.6681088333129885\n",
      "Epoch:  758  Average loss at step  3000 :  7.9207243661880495\n",
      "Epoch:  758  Average loss at step  4000 :  7.95348867893219\n",
      "Epoch:  758  Average loss at step  5000 :  8.119115404129028\n",
      "Epoch:  758  Average loss at step  6000 :  7.845145182609558\n",
      "Epoch:  758  Average loss at step  7000 :  7.907857167243957\n",
      "Epoch:  758  Average loss at step  8000 :  7.791972985267639\n",
      "Epoch:  758  Average loss at step  8472 :  7.703298656398374\n",
      "758 0 20.49125385284424\n",
      "Epoch:  758  Average loss at step  1000 :  2864.197375488281\n",
      "Epoch:  758  Average loss at step  1491 :  2894.9429608667638\n",
      "758 1 11.76480770111084\n",
      "Epoch:  758  Average loss at step  1000 :  4026.646059326172\n",
      "Epoch:  758  Average loss at step  2000 :  4033.5861954345705\n",
      "Epoch:  758  Average loss at step  2533 :  4005.706775408466\n",
      "758 2 19.970619678497314\n",
      "Epoch:  758  Average loss at step  1000 :  61.58760103988647\n",
      "Epoch:  758  Average loss at step  1227 :  61.499840634613975\n",
      "758 3 12.622124195098877\n",
      "Epoch:  758  Average loss at step  1000 :  3.8673076729774474\n",
      "Epoch:  758  Average loss at step  2000 :  3.717346076965332\n",
      "Epoch:  758  Average loss at step  3000 :  3.894781382083893\n",
      "Epoch:  758  Average loss at step  3222 :  3.6491774483952932\n",
      "758 4 33.33749794960022\n",
      "758 5 1.430511474609375e-06\n",
      "Training time took 98.812311 seconds to run 1 epoch\n",
      "Epoch:  759  Average loss at step  1000 :  0.04483247309923172\n",
      "Epoch:  759  Average loss at step  2000 :  0.046950182974338533\n",
      "Epoch:  759  Average loss at step  3000 :  0.051059752643108365\n",
      "Epoch:  759  Average loss at step  3222 :  0.05431183706145141\n",
      "759 0 29.42852807044983\n",
      "Training time took 29.548992 seconds to run 1 epoch\n",
      "Epoch:  760  Average loss at step  1000 :  7.726522939682007\n",
      "Epoch:  760  Average loss at step  2000 :  8.38000089073181\n",
      "Epoch:  760  Average loss at step  3000 :  7.8847597208023075\n",
      "Epoch:  760  Average loss at step  4000 :  7.9634416933059695\n",
      "Epoch:  760  Average loss at step  5000 :  7.70329135799408\n",
      "Epoch:  760  Average loss at step  6000 :  7.876654419898987\n",
      "Epoch:  760  Average loss at step  7000 :  7.954301708221435\n",
      "Epoch:  760  Average loss at step  8000 :  7.612392597198486\n",
      "Epoch:  760  Average loss at step  8472 :  7.935180901256655\n",
      "760 0 21.097517013549805\n",
      "Epoch:  760  Average loss at step  1000 :  2871.4637758789063\n",
      "Epoch:  760  Average loss at step  1491 :  2845.393740797918\n",
      "760 1 11.726662635803223\n",
      "Epoch:  760  Average loss at step  1000 :  4020.533612060547\n",
      "Epoch:  760  Average loss at step  2000 :  4019.740700683594\n",
      "Epoch:  760  Average loss at step  2533 :  4042.4503460202154\n",
      "760 2 19.90994906425476\n",
      "Epoch:  760  Average loss at step  1000 :  61.68832434463501\n",
      "Epoch:  760  Average loss at step  1227 :  61.074473161882935\n",
      "760 3 12.651578187942505\n",
      "Epoch:  760  Average loss at step  1000 :  3.8817002444267272\n",
      "Epoch:  760  Average loss at step  2000 :  3.660532494544983\n",
      "Epoch:  760  Average loss at step  3000 :  3.8280492906570434\n",
      "Epoch:  760  Average loss at step  3222 :  3.688799672058761\n",
      "760 4 33.2205605506897\n",
      "760 5 1.430511474609375e-06\n",
      "Training time took 99.236745 seconds to run 1 epoch\n",
      "Mean Rank:  153.53492  of  75000\n",
      "Hits @ 10:  0.85424\n",
      "Hits @ 1:  0.6244\n",
      "Testing time took 163.759266 seconds.\n",
      "\n",
      "Epoch:  761  Average loss at step  1000 :  0.04471713483333588\n",
      "Epoch:  761  Average loss at step  2000 :  0.04679191821813583\n",
      "Epoch:  761  Average loss at step  3000 :  0.05115089386701584\n",
      "Epoch:  761  Average loss at step  3222 :  0.05346565475574059\n",
      "761 0 29.520784616470337\n",
      "Training time took 29.630456 seconds to run 1 epoch\n",
      "Epoch:  762  Average loss at step  1000 :  8.481507827758788\n",
      "Epoch:  762  Average loss at step  2000 :  8.039015580177308\n",
      "Epoch:  762  Average loss at step  3000 :  7.824111482620239\n",
      "Epoch:  762  Average loss at step  4000 :  8.025418354034423\n",
      "Epoch:  762  Average loss at step  5000 :  7.717342056274414\n",
      "Epoch:  762  Average loss at step  6000 :  8.588487917900085\n",
      "Epoch:  762  Average loss at step  7000 :  8.01366854095459\n",
      "Epoch:  762  Average loss at step  8000 :  8.007212996006013\n",
      "Epoch:  762  Average loss at step  8472 :  7.098843063625525\n",
      "762 0 20.712455987930298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  762  Average loss at step  1000 :  2873.219993774414\n",
      "Epoch:  762  Average loss at step  1491 :  2886.6971402252484\n",
      "762 1 11.744513511657715\n",
      "Epoch:  762  Average loss at step  1000 :  4009.1794379882813\n",
      "Epoch:  762  Average loss at step  2000 :  4021.1290986328127\n",
      "Epoch:  762  Average loss at step  2533 :  4034.8640934307814\n",
      "762 2 19.92485523223877\n",
      "Epoch:  762  Average loss at step  1000 :  61.648106269836425\n",
      "Epoch:  762  Average loss at step  1227 :  62.4783217252187\n",
      "762 3 12.613245725631714\n",
      "Epoch:  762  Average loss at step  1000 :  3.7435999102592468\n",
      "Epoch:  762  Average loss at step  2000 :  3.768425471782684\n",
      "Epoch:  762  Average loss at step  3000 :  3.797491699695587\n",
      "Epoch:  762  Average loss at step  3222 :  3.6963303848000764\n",
      "762 4 33.26619100570679\n",
      "762 5 1.430511474609375e-06\n",
      "Training time took 98.890077 seconds to run 1 epoch\n",
      "Epoch:  763  Average loss at step  1000 :  0.04419423234462738\n",
      "Epoch:  763  Average loss at step  2000 :  0.04678126055002212\n",
      "Epoch:  763  Average loss at step  3000 :  0.0509161833524704\n",
      "Epoch:  763  Average loss at step  3222 :  0.053874976121899364\n",
      "763 0 29.436925649642944\n",
      "Training time took 29.559014 seconds to run 1 epoch\n",
      "Epoch:  764  Average loss at step  1000 :  7.982782020568847\n",
      "Epoch:  764  Average loss at step  2000 :  7.8871474146842955\n",
      "Epoch:  764  Average loss at step  3000 :  7.887854524612427\n",
      "Epoch:  764  Average loss at step  4000 :  7.927517691612244\n",
      "Epoch:  764  Average loss at step  5000 :  8.211819131851197\n",
      "Epoch:  764  Average loss at step  6000 :  7.698509819030762\n",
      "Epoch:  764  Average loss at step  7000 :  8.490079544067383\n",
      "Epoch:  764  Average loss at step  8000 :  7.937407594680786\n",
      "Epoch:  764  Average loss at step  8472 :  8.555971431153358\n",
      "764 0 20.28420066833496\n",
      "Epoch:  764  Average loss at step  1000 :  2856.7676290283202\n",
      "Epoch:  764  Average loss at step  1491 :  2907.0029256494054\n",
      "764 1 11.702685594558716\n",
      "Epoch:  764  Average loss at step  1000 :  4023.3664709472655\n",
      "Epoch:  764  Average loss at step  2000 :  3987.1401906738283\n",
      "Epoch:  764  Average loss at step  2533 :  4029.0172858959313\n",
      "764 2 19.909427881240845\n",
      "Epoch:  764  Average loss at step  1000 :  61.63442162704468\n",
      "Epoch:  764  Average loss at step  1227 :  61.72940087643437\n",
      "764 3 12.687175989151001\n",
      "Epoch:  764  Average loss at step  1000 :  3.8518012037277223\n",
      "Epoch:  764  Average loss at step  2000 :  3.686397364616394\n",
      "Epoch:  764  Average loss at step  3000 :  3.768311548233032\n",
      "Epoch:  764  Average loss at step  3222 :  3.599984763352573\n",
      "764 4 33.058993339538574\n",
      "764 5 1.6689300537109375e-06\n",
      "Training time took 98.272721 seconds to run 1 epoch\n",
      "Epoch:  765  Average loss at step  1000 :  0.04440644311904907\n",
      "Epoch:  765  Average loss at step  2000 :  0.04680246156454086\n",
      "Epoch:  765  Average loss at step  3000 :  0.050879800617694856\n",
      "Epoch:  765  Average loss at step  3222 :  0.0538760374160122\n",
      "765 0 29.460911989212036\n",
      "Training time took 29.580838 seconds to run 1 epoch\n",
      "Epoch:  766  Average loss at step  1000 :  8.66113481235504\n",
      "Epoch:  766  Average loss at step  2000 :  8.221418264389039\n",
      "Epoch:  766  Average loss at step  3000 :  7.9833789176940915\n",
      "Epoch:  766  Average loss at step  4000 :  7.722257762908936\n",
      "Epoch:  766  Average loss at step  5000 :  7.799311029434204\n",
      "Epoch:  766  Average loss at step  6000 :  7.75466784954071\n",
      "Epoch:  766  Average loss at step  7000 :  8.246914524078369\n",
      "Epoch:  766  Average loss at step  8000 :  8.251761603355408\n",
      "Epoch:  766  Average loss at step  8472 :  7.891783579304244\n",
      "766 0 20.710994958877563\n",
      "Epoch:  766  Average loss at step  1000 :  2857.15469921875\n",
      "Epoch:  766  Average loss at step  1491 :  2877.035747303746\n",
      "766 1 11.696999549865723\n",
      "Epoch:  766  Average loss at step  1000 :  3980.12734765625\n",
      "Epoch:  766  Average loss at step  2000 :  4025.1755400390625\n",
      "Epoch:  766  Average loss at step  2533 :  4022.066199286148\n",
      "766 2 19.904911756515503\n",
      "Epoch:  766  Average loss at step  1000 :  61.668350605010986\n",
      "Epoch:  766  Average loss at step  1227 :  61.22982795760098\n",
      "766 3 12.669936656951904\n",
      "Epoch:  766  Average loss at step  1000 :  3.8430478076934813\n",
      "Epoch:  766  Average loss at step  2000 :  3.7952013735771177\n",
      "Epoch:  766  Average loss at step  3000 :  3.665410126209259\n",
      "Epoch:  766  Average loss at step  3222 :  3.7221189289020704\n",
      "766 4 33.265082120895386\n",
      "766 5 1.1920928955078125e-06\n",
      "Training time took 98.872642 seconds to run 1 epoch\n",
      "Epoch:  767  Average loss at step  1000 :  0.044200511276721956\n",
      "Epoch:  767  Average loss at step  2000 :  0.04662816703319549\n",
      "Epoch:  767  Average loss at step  3000 :  0.050484932303428647\n",
      "Epoch:  767  Average loss at step  3222 :  0.0536927332256563\n",
      "767 0 29.422616004943848\n",
      "Training time took 29.541655 seconds to run 1 epoch\n",
      "Epoch:  768  Average loss at step  1000 :  8.299848495483399\n",
      "Epoch:  768  Average loss at step  2000 :  8.405764793395996\n",
      "Epoch:  768  Average loss at step  3000 :  7.989389316558838\n",
      "Epoch:  768  Average loss at step  4000 :  8.225186512947083\n",
      "Epoch:  768  Average loss at step  5000 :  8.154833826065063\n",
      "Epoch:  768  Average loss at step  6000 :  8.02130792427063\n",
      "Epoch:  768  Average loss at step  7000 :  8.034938557624816\n",
      "Epoch:  768  Average loss at step  8000 :  8.14124646949768\n",
      "Epoch:  768  Average loss at step  8472 :  8.329448430375562\n",
      "768 0 20.784374952316284\n",
      "Epoch:  768  Average loss at step  1000 :  2879.355374267578\n",
      "Epoch:  768  Average loss at step  1491 :  2925.705112518428\n",
      "768 1 11.691635847091675\n",
      "Epoch:  768  Average loss at step  1000 :  3998.684845947266\n",
      "Epoch:  768  Average loss at step  2000 :  4030.5986010742185\n",
      "Epoch:  768  Average loss at step  2533 :  3998.608734551863\n",
      "768 2 19.88832998275757\n",
      "Epoch:  768  Average loss at step  1000 :  61.50508935546875\n",
      "Epoch:  768  Average loss at step  1227 :  62.42294856792734\n",
      "768 3 12.64276933670044\n",
      "Epoch:  768  Average loss at step  1000 :  3.6789455361366272\n",
      "Epoch:  768  Average loss at step  2000 :  3.7936222281455994\n",
      "Epoch:  768  Average loss at step  3000 :  3.7228092155456545\n",
      "Epoch:  768  Average loss at step  3222 :  3.7203062073507343\n",
      "768 4 33.19114065170288\n",
      "768 5 1.430511474609375e-06\n",
      "Training time took 98.820851 seconds to run 1 epoch\n",
      "Epoch:  769  Average loss at step  1000 :  0.04443363958597183\n",
      "Epoch:  769  Average loss at step  2000 :  0.046426400542259216\n",
      "Epoch:  769  Average loss at step  3000 :  0.050608472168445585\n",
      "Epoch:  769  Average loss at step  3222 :  0.05280541548295924\n",
      "769 0 29.42395830154419\n",
      "Training time took 29.543476 seconds to run 1 epoch\n",
      "Epoch:  770  Average loss at step  1000 :  7.855334671020508\n",
      "Epoch:  770  Average loss at step  2000 :  8.145219450950622\n",
      "Epoch:  770  Average loss at step  3000 :  8.05676482963562\n",
      "Epoch:  770  Average loss at step  4000 :  8.162314049720765\n",
      "Epoch:  770  Average loss at step  5000 :  8.087793597221374\n",
      "Epoch:  770  Average loss at step  6000 :  8.535295682430267\n",
      "Epoch:  770  Average loss at step  7000 :  7.758126211166382\n",
      "Epoch:  770  Average loss at step  8000 :  8.375991937637329\n",
      "Epoch:  770  Average loss at step  8472 :  8.002892433445956\n",
      "770 0 20.611056089401245\n",
      "Epoch:  770  Average loss at step  1000 :  2899.4081447753906\n",
      "Epoch:  770  Average loss at step  1491 :  2906.2084257752026\n",
      "770 1 11.700345754623413\n",
      "Epoch:  770  Average loss at step  1000 :  4011.5972585449217\n",
      "Epoch:  770  Average loss at step  2000 :  4018.1530280761717\n",
      "Epoch:  770  Average loss at step  2533 :  4019.802931354077\n",
      "770 2 19.945472717285156\n",
      "Epoch:  770  Average loss at step  1000 :  61.11690188598633\n",
      "Epoch:  770  Average loss at step  1227 :  60.615453755013576\n",
      "770 3 12.627936601638794\n",
      "Epoch:  770  Average loss at step  1000 :  3.729876916885376\n",
      "Epoch:  770  Average loss at step  2000 :  3.6811460466384887\n",
      "Epoch:  770  Average loss at step  3000 :  3.73533466053009\n",
      "Epoch:  770  Average loss at step  3222 :  3.897282904635097\n",
      "770 4 33.226707458496094\n",
      "770 5 1.430511474609375e-06\n",
      "Training time took 98.726229 seconds to run 1 epoch\n",
      "Mean Rank:  153.62644  of  75000\n",
      "Hits @ 10:  0.85436\n",
      "Hits @ 1:  0.62524\n",
      "Testing time took 165.777223 seconds.\n",
      "\n",
      "Epoch:  771  Average loss at step  1000 :  0.044184143364429475\n",
      "Epoch:  771  Average loss at step  2000 :  0.0461977436542511\n",
      "Epoch:  771  Average loss at step  3000 :  0.05056338059902191\n",
      "Epoch:  771  Average loss at step  3222 :  0.053427060237105604\n",
      "771 0 29.437368869781494\n",
      "Training time took 29.546001 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  772  Average loss at step  1000 :  8.219700881004334\n",
      "Epoch:  772  Average loss at step  2000 :  8.47086789894104\n",
      "Epoch:  772  Average loss at step  3000 :  8.222065152168273\n",
      "Epoch:  772  Average loss at step  4000 :  8.237518676757812\n",
      "Epoch:  772  Average loss at step  5000 :  8.104354712486266\n",
      "Epoch:  772  Average loss at step  6000 :  7.905727842330933\n",
      "Epoch:  772  Average loss at step  7000 :  8.24990202331543\n",
      "Epoch:  772  Average loss at step  8000 :  7.804990560531616\n",
      "Epoch:  772  Average loss at step  8472 :  7.338083412199877\n",
      "772 0 20.389952659606934\n",
      "Epoch:  772  Average loss at step  1000 :  2873.2816450195314\n",
      "Epoch:  772  Average loss at step  1491 :  2866.494764092911\n",
      "772 1 11.718732595443726\n",
      "Epoch:  772  Average loss at step  1000 :  4022.216378417969\n",
      "Epoch:  772  Average loss at step  2000 :  4032.677586303711\n",
      "Epoch:  772  Average loss at step  2533 :  3981.5975890546592\n",
      "772 2 19.982182264328003\n",
      "Epoch:  772  Average loss at step  1000 :  61.249912521362305\n",
      "Epoch:  772  Average loss at step  1227 :  61.12953272201169\n",
      "772 3 12.644019365310669\n",
      "Epoch:  772  Average loss at step  1000 :  3.6913677458763123\n",
      "Epoch:  772  Average loss at step  2000 :  3.793037784576416\n",
      "Epoch:  772  Average loss at step  3000 :  3.7548204698562624\n",
      "Epoch:  772  Average loss at step  3222 :  3.6398256335109553\n",
      "772 4 33.343353033065796\n",
      "772 5 1.430511474609375e-06\n",
      "Training time took 98.706165 seconds to run 1 epoch\n",
      "Epoch:  773  Average loss at step  1000 :  0.04399648797512055\n",
      "Epoch:  773  Average loss at step  2000 :  0.046499697089195255\n",
      "Epoch:  773  Average loss at step  3000 :  0.0502714142203331\n",
      "Epoch:  773  Average loss at step  3222 :  0.05355927999709612\n",
      "773 0 29.42303490638733\n",
      "Training time took 29.5431 seconds to run 1 epoch\n",
      "Epoch:  774  Average loss at step  1000 :  8.374997743606567\n",
      "Epoch:  774  Average loss at step  2000 :  8.502673459053039\n",
      "Epoch:  774  Average loss at step  3000 :  7.65801834487915\n",
      "Epoch:  774  Average loss at step  4000 :  8.294199901103973\n",
      "Epoch:  774  Average loss at step  5000 :  7.8703881397247315\n",
      "Epoch:  774  Average loss at step  6000 :  8.09917730140686\n",
      "Epoch:  774  Average loss at step  7000 :  8.553910656929016\n",
      "Epoch:  774  Average loss at step  8000 :  7.710774774551392\n",
      "Epoch:  774  Average loss at step  8472 :  7.905395026624084\n",
      "774 0 20.5958309173584\n",
      "Epoch:  774  Average loss at step  1000 :  2865.483109741211\n",
      "Epoch:  774  Average loss at step  1491 :  2902.4727559392218\n",
      "774 1 11.72417950630188\n",
      "Epoch:  774  Average loss at step  1000 :  4025.2318869628907\n",
      "Epoch:  774  Average loss at step  2000 :  3999.885764160156\n",
      "Epoch:  774  Average loss at step  2533 :  3999.9724812961654\n",
      "774 2 19.94836139678955\n",
      "Epoch:  774  Average loss at step  1000 :  60.70773488998413\n",
      "Epoch:  774  Average loss at step  1227 :  62.08043940966502\n",
      "774 3 12.562556028366089\n",
      "Epoch:  774  Average loss at step  1000 :  3.78581111907959\n",
      "Epoch:  774  Average loss at step  2000 :  3.689694244861603\n",
      "Epoch:  774  Average loss at step  3000 :  3.7036845712661743\n",
      "Epoch:  774  Average loss at step  3222 :  3.754380423361094\n",
      "774 4 32.95325469970703\n",
      "774 5 1.430511474609375e-06\n",
      "Training time took 98.426717 seconds to run 1 epoch\n",
      "Epoch:  775  Average loss at step  1000 :  0.04420419377088547\n",
      "Epoch:  775  Average loss at step  2000 :  0.0459602981209755\n",
      "Epoch:  775  Average loss at step  3000 :  0.04986461049318314\n",
      "Epoch:  775  Average loss at step  3222 :  0.05292431270630701\n",
      "775 0 29.339674472808838\n",
      "Training time took 29.466821 seconds to run 1 epoch\n",
      "Epoch:  776  Average loss at step  1000 :  7.5627173204422\n",
      "Epoch:  776  Average loss at step  2000 :  8.677163331985474\n",
      "Epoch:  776  Average loss at step  3000 :  8.089332273483276\n",
      "Epoch:  776  Average loss at step  4000 :  8.338069870948791\n",
      "Epoch:  776  Average loss at step  5000 :  8.404742865562438\n",
      "Epoch:  776  Average loss at step  6000 :  8.16108610534668\n",
      "Epoch:  776  Average loss at step  7000 :  7.904009245872498\n",
      "Epoch:  776  Average loss at step  8000 :  8.245509084701538\n",
      "Epoch:  776  Average loss at step  8472 :  7.751026670048654\n",
      "776 0 20.367229223251343\n",
      "Epoch:  776  Average loss at step  1000 :  2910.8270334472654\n",
      "Epoch:  776  Average loss at step  1491 :  2887.810075203647\n",
      "776 1 11.703041791915894\n",
      "Epoch:  776  Average loss at step  1000 :  4023.8927622070314\n",
      "Epoch:  776  Average loss at step  2000 :  4034.092939819336\n",
      "Epoch:  776  Average loss at step  2533 :  4003.2628913187955\n",
      "776 2 19.906277894973755\n",
      "Epoch:  776  Average loss at step  1000 :  61.45067627334595\n",
      "Epoch:  776  Average loss at step  1227 :  62.39959966543677\n",
      "776 3 12.618782758712769\n",
      "Epoch:  776  Average loss at step  1000 :  3.8038619260787963\n",
      "Epoch:  776  Average loss at step  2000 :  3.73068009185791\n",
      "Epoch:  776  Average loss at step  3000 :  3.869745204925537\n",
      "Epoch:  776  Average loss at step  3222 :  3.731771579910474\n",
      "776 4 33.29893708229065\n",
      "776 5 1.430511474609375e-06\n",
      "Training time took 98.525845 seconds to run 1 epoch\n",
      "Epoch:  777  Average loss at step  1000 :  0.043681451618671416\n",
      "Epoch:  777  Average loss at step  2000 :  0.04604945367574692\n",
      "Epoch:  777  Average loss at step  3000 :  0.05037111258506775\n",
      "Epoch:  777  Average loss at step  3222 :  0.05227963289299431\n",
      "777 0 29.407898902893066\n",
      "Training time took 29.53307 seconds to run 1 epoch\n",
      "Epoch:  778  Average loss at step  1000 :  8.058623267650605\n",
      "Epoch:  778  Average loss at step  2000 :  8.243252738952636\n",
      "Epoch:  778  Average loss at step  3000 :  8.211921573638916\n",
      "Epoch:  778  Average loss at step  4000 :  8.358026626110076\n",
      "Epoch:  778  Average loss at step  5000 :  8.350873759269714\n",
      "Epoch:  778  Average loss at step  6000 :  8.057081391334533\n",
      "Epoch:  778  Average loss at step  7000 :  7.733034997940064\n",
      "Epoch:  778  Average loss at step  8000 :  8.182071290969848\n",
      "Epoch:  778  Average loss at step  8472 :  8.952202953176553\n",
      "778 0 21.436269283294678\n",
      "Epoch:  778  Average loss at step  1000 :  2901.029991821289\n",
      "Epoch:  778  Average loss at step  1491 :  2909.6023683585076\n",
      "778 1 11.70580506324768\n",
      "Epoch:  778  Average loss at step  1000 :  3996.126059692383\n",
      "Epoch:  778  Average loss at step  2000 :  4018.22080078125\n",
      "Epoch:  778  Average loss at step  2533 :  3996.1468902543156\n",
      "778 2 19.902072191238403\n",
      "Epoch:  778  Average loss at step  1000 :  61.42313748168945\n",
      "Epoch:  778  Average loss at step  1227 :  61.004668173636624\n",
      "778 3 12.604984998703003\n",
      "Epoch:  778  Average loss at step  1000 :  3.738165777683258\n",
      "Epoch:  778  Average loss at step  2000 :  3.622925036907196\n",
      "Epoch:  778  Average loss at step  3000 :  3.7156607031822206\n",
      "Epoch:  778  Average loss at step  3222 :  3.89365572041823\n",
      "778 4 33.14423418045044\n",
      "778 5 1.1920928955078125e-06\n",
      "Training time took 99.438913 seconds to run 1 epoch\n",
      "Epoch:  779  Average loss at step  1000 :  0.04393747437000275\n",
      "Epoch:  779  Average loss at step  2000 :  0.046182330310344695\n",
      "Epoch:  779  Average loss at step  3000 :  0.05002300035953522\n",
      "Epoch:  779  Average loss at step  3222 :  0.05211466097792987\n",
      "779 0 29.453948974609375\n",
      "Training time took 29.578364 seconds to run 1 epoch\n",
      "Epoch:  780  Average loss at step  1000 :  7.91919868850708\n",
      "Epoch:  780  Average loss at step  2000 :  8.535533651351928\n",
      "Epoch:  780  Average loss at step  3000 :  8.001750638961791\n",
      "Epoch:  780  Average loss at step  4000 :  7.756914547920227\n",
      "Epoch:  780  Average loss at step  5000 :  8.25777344608307\n",
      "Epoch:  780  Average loss at step  6000 :  7.490320413589478\n",
      "Epoch:  780  Average loss at step  7000 :  8.090122730255127\n",
      "Epoch:  780  Average loss at step  8000 :  8.058715445518494\n",
      "Epoch:  780  Average loss at step  8472 :  8.08590750991577\n",
      "780 0 20.316200256347656\n",
      "Epoch:  780  Average loss at step  1000 :  2868.4853416748047\n",
      "Epoch:  780  Average loss at step  1491 :  2890.9009204807235\n",
      "780 1 11.720357418060303\n",
      "Epoch:  780  Average loss at step  1000 :  4035.9724279785155\n",
      "Epoch:  780  Average loss at step  2000 :  4039.017376464844\n",
      "Epoch:  780  Average loss at step  2533 :  4025.806842183492\n",
      "780 2 19.916531085968018\n",
      "Epoch:  780  Average loss at step  1000 :  61.279925506591795\n",
      "Epoch:  780  Average loss at step  1227 :  60.23135275068084\n",
      "780 3 12.714651584625244\n",
      "Epoch:  780  Average loss at step  1000 :  3.6264670991897585\n",
      "Epoch:  780  Average loss at step  2000 :  3.685764753818512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  780  Average loss at step  3000 :  3.792387237071991\n",
      "Epoch:  780  Average loss at step  3222 :  3.650645704815202\n",
      "780 4 33.240840911865234\n",
      "780 5 1.6689300537109375e-06\n",
      "Training time took 98.540583 seconds to run 1 epoch\n",
      "Mean Rank:  153.74632  of  75000\n",
      "Hits @ 10:  0.85396\n",
      "Hits @ 1:  0.6242\n",
      "Testing time took 163.785322 seconds.\n",
      "\n",
      "Epoch:  781  Average loss at step  1000 :  0.043420083820819855\n",
      "Epoch:  781  Average loss at step  2000 :  0.04566032338142395\n",
      "Epoch:  781  Average loss at step  3000 :  0.04992160177230835\n",
      "Epoch:  781  Average loss at step  3222 :  0.052280019478454426\n",
      "781 0 29.36754322052002\n",
      "Training time took 29.48615 seconds to run 1 epoch\n",
      "Epoch:  782  Average loss at step  1000 :  7.840331758499145\n",
      "Epoch:  782  Average loss at step  2000 :  7.67522416305542\n",
      "Epoch:  782  Average loss at step  3000 :  7.93492047214508\n",
      "Epoch:  782  Average loss at step  4000 :  8.111597303390504\n",
      "Epoch:  782  Average loss at step  5000 :  8.225102925300598\n",
      "Epoch:  782  Average loss at step  6000 :  8.023503412246704\n",
      "Epoch:  782  Average loss at step  7000 :  8.164991401672363\n",
      "Epoch:  782  Average loss at step  8000 :  8.145845193862915\n",
      "Epoch:  782  Average loss at step  8472 :  7.402434403096611\n",
      "782 0 21.083325147628784\n",
      "Epoch:  782  Average loss at step  1000 :  2906.068907470703\n",
      "Epoch:  782  Average loss at step  1491 :  2894.0814689005433\n",
      "782 1 11.729705572128296\n",
      "Epoch:  782  Average loss at step  1000 :  4036.5241025390624\n",
      "Epoch:  782  Average loss at step  2000 :  4005.256280517578\n",
      "Epoch:  782  Average loss at step  2533 :  4026.5418423883266\n",
      "782 2 19.893998622894287\n",
      "Epoch:  782  Average loss at step  1000 :  61.68260318374634\n",
      "Epoch:  782  Average loss at step  1227 :  61.146970703378116\n",
      "782 3 12.661459922790527\n",
      "Epoch:  782  Average loss at step  1000 :  3.7109445247650146\n",
      "Epoch:  782  Average loss at step  2000 :  3.7442036752700805\n",
      "Epoch:  782  Average loss at step  3000 :  3.596302562713623\n",
      "Epoch:  782  Average loss at step  3222 :  3.7282314965991383\n",
      "782 4 33.24518299102783\n",
      "782 5 1.1920928955078125e-06\n",
      "Training time took 99.267869 seconds to run 1 epoch\n",
      "Epoch:  783  Average loss at step  1000 :  0.04351376783847809\n",
      "Epoch:  783  Average loss at step  2000 :  0.046164606153965\n",
      "Epoch:  783  Average loss at step  3000 :  0.04999421072006226\n",
      "Epoch:  783  Average loss at step  3222 :  0.051689162745461134\n",
      "783 0 29.388869285583496\n",
      "Training time took 29.507176 seconds to run 1 epoch\n",
      "Epoch:  784  Average loss at step  1000 :  7.900120211601258\n",
      "Epoch:  784  Average loss at step  2000 :  8.07347838115692\n",
      "Epoch:  784  Average loss at step  3000 :  8.472324215888976\n",
      "Epoch:  784  Average loss at step  4000 :  7.522739260673523\n",
      "Epoch:  784  Average loss at step  5000 :  7.802661442756653\n",
      "Epoch:  784  Average loss at step  6000 :  8.581866664886475\n",
      "Epoch:  784  Average loss at step  7000 :  8.02239197254181\n",
      "Epoch:  784  Average loss at step  8000 :  8.256750389099121\n",
      "Epoch:  784  Average loss at step  8472 :  8.082502162809167\n",
      "784 0 20.298187971115112\n",
      "Epoch:  784  Average loss at step  1000 :  2892.3228017578126\n",
      "Epoch:  784  Average loss at step  1491 :  2865.7232559965905\n",
      "784 1 11.684775829315186\n",
      "Epoch:  784  Average loss at step  1000 :  4091.1165517578124\n",
      "Epoch:  784  Average loss at step  2000 :  4039.438672363281\n",
      "Epoch:  784  Average loss at step  2533 :  4030.109268232642\n",
      "784 2 19.919867992401123\n",
      "Epoch:  784  Average loss at step  1000 :  61.088689151763916\n",
      "Epoch:  784  Average loss at step  1227 :  61.40996647137751\n",
      "784 3 12.61739706993103\n",
      "Epoch:  784  Average loss at step  1000 :  3.7264185757637023\n",
      "Epoch:  784  Average loss at step  2000 :  3.754595547199249\n",
      "Epoch:  784  Average loss at step  3000 :  3.666418020248413\n",
      "Epoch:  784  Average loss at step  3222 :  3.476988767798486\n",
      "784 4 33.28193736076355\n",
      "784 5 1.6689300537109375e-06\n",
      "Training time took 98.43205 seconds to run 1 epoch\n",
      "Epoch:  785  Average loss at step  1000 :  0.04330394130945206\n",
      "Epoch:  785  Average loss at step  2000 :  0.04544786012172699\n",
      "Epoch:  785  Average loss at step  3000 :  0.04984101724624634\n",
      "Epoch:  785  Average loss at step  3222 :  0.05204489346681723\n",
      "785 0 29.39544105529785\n",
      "Training time took 29.525783 seconds to run 1 epoch\n",
      "Epoch:  786  Average loss at step  1000 :  7.845220739364624\n",
      "Epoch:  786  Average loss at step  2000 :  8.015431839942933\n",
      "Epoch:  786  Average loss at step  3000 :  8.282679945468903\n",
      "Epoch:  786  Average loss at step  4000 :  8.370456497192382\n",
      "Epoch:  786  Average loss at step  5000 :  7.672711708068848\n",
      "Epoch:  786  Average loss at step  6000 :  8.270458889961242\n",
      "Epoch:  786  Average loss at step  7000 :  7.451214621543884\n",
      "Epoch:  786  Average loss at step  8000 :  8.051558420181275\n",
      "Epoch:  786  Average loss at step  8472 :  8.242637365025548\n",
      "786 0 21.597806692123413\n",
      "Epoch:  786  Average loss at step  1000 :  2895.447308105469\n",
      "Epoch:  786  Average loss at step  1491 :  2864.0804538567904\n",
      "786 1 11.691404104232788\n",
      "Epoch:  786  Average loss at step  1000 :  4062.879916748047\n",
      "Epoch:  786  Average loss at step  2000 :  4019.226499267578\n",
      "Epoch:  786  Average loss at step  2533 :  4038.489916220387\n",
      "786 2 19.877328872680664\n",
      "Epoch:  786  Average loss at step  1000 :  60.91248529815674\n",
      "Epoch:  786  Average loss at step  1227 :  60.21627435487722\n",
      "786 3 12.60369873046875\n",
      "Epoch:  786  Average loss at step  1000 :  3.692427490711212\n",
      "Epoch:  786  Average loss at step  2000 :  3.6469742040634157\n",
      "Epoch:  786  Average loss at step  3000 :  3.78676290512085\n",
      "Epoch:  786  Average loss at step  3222 :  3.6423597251449946\n",
      "786 4 33.12982964515686\n",
      "786 5 1.1920928955078125e-06\n",
      "Training time took 99.523572 seconds to run 1 epoch\n",
      "Epoch:  787  Average loss at step  1000 :  0.04319872123003006\n",
      "Epoch:  787  Average loss at step  2000 :  0.045756729781627654\n",
      "Epoch:  787  Average loss at step  3000 :  0.049731530725955965\n",
      "Epoch:  787  Average loss at step  3222 :  0.05241512531277763\n",
      "787 0 29.412620067596436\n",
      "Training time took 29.537388 seconds to run 1 epoch\n",
      "Epoch:  788  Average loss at step  1000 :  8.387945665359497\n",
      "Epoch:  788  Average loss at step  2000 :  7.858771537780762\n",
      "Epoch:  788  Average loss at step  3000 :  8.166243565559387\n",
      "Epoch:  788  Average loss at step  4000 :  8.421538988113403\n",
      "Epoch:  788  Average loss at step  5000 :  7.8550401182174685\n",
      "Epoch:  788  Average loss at step  6000 :  8.123196008205413\n",
      "Epoch:  788  Average loss at step  7000 :  7.750369018554688\n",
      "Epoch:  788  Average loss at step  8000 :  7.6872866878509525\n",
      "Epoch:  788  Average loss at step  8472 :  8.529134659050507\n",
      "788 0 20.20296359062195\n",
      "Epoch:  788  Average loss at step  1000 :  2875.5710004882812\n",
      "Epoch:  788  Average loss at step  1491 :  2955.6564900776652\n",
      "788 1 11.72793698310852\n",
      "Epoch:  788  Average loss at step  1000 :  4050.7795391845702\n",
      "Epoch:  788  Average loss at step  2000 :  4026.3840778808594\n",
      "Epoch:  788  Average loss at step  2533 :  4024.002642918856\n",
      "788 2 19.905229330062866\n",
      "Epoch:  788  Average loss at step  1000 :  61.429153602600095\n",
      "Epoch:  788  Average loss at step  1227 :  62.11224508552688\n",
      "788 3 12.532910346984863\n",
      "Epoch:  788  Average loss at step  1000 :  3.7468030910491943\n",
      "Epoch:  788  Average loss at step  2000 :  3.6946665081977845\n",
      "Epoch:  788  Average loss at step  3000 :  3.7337547512054443\n",
      "Epoch:  788  Average loss at step  3222 :  3.62887745364992\n",
      "788 4 33.033315896987915\n",
      "788 5 1.1920928955078125e-06\n",
      "Training time took 98.03342 seconds to run 1 epoch\n",
      "Epoch:  789  Average loss at step  1000 :  0.04330993300676346\n",
      "Epoch:  789  Average loss at step  2000 :  0.04530500429868698\n",
      "Epoch:  789  Average loss at step  3000 :  0.04940838605165482\n",
      "Epoch:  789  Average loss at step  3222 :  0.05186621135355957\n",
      "789 0 29.406906843185425\n",
      "Training time took 29.52698 seconds to run 1 epoch\n",
      "Epoch:  790  Average loss at step  1000 :  8.181223257064818\n",
      "Epoch:  790  Average loss at step  2000 :  7.858481359481812\n",
      "Epoch:  790  Average loss at step  3000 :  8.163086144447327\n",
      "Epoch:  790  Average loss at step  4000 :  8.291520220756532\n",
      "Epoch:  790  Average loss at step  5000 :  7.578189931869507\n",
      "Epoch:  790  Average loss at step  6000 :  7.901284874916077\n",
      "Epoch:  790  Average loss at step  7000 :  8.440968260765075\n",
      "Epoch:  790  Average loss at step  8000 :  8.178401462554932\n",
      "Epoch:  790  Average loss at step  8472 :  7.592727348570821\n",
      "790 0 20.962729930877686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  790  Average loss at step  1000 :  2873.2799848632812\n",
      "Epoch:  790  Average loss at step  1491 :  2945.1930832926473\n",
      "790 1 11.726838111877441\n",
      "Epoch:  790  Average loss at step  1000 :  4085.20740234375\n",
      "Epoch:  790  Average loss at step  2000 :  4031.032499633789\n",
      "Epoch:  790  Average loss at step  2533 :  4051.883740900639\n",
      "790 2 19.898136854171753\n",
      "Epoch:  790  Average loss at step  1000 :  60.93144038772583\n",
      "Epoch:  790  Average loss at step  1227 :  60.86468014376519\n",
      "790 3 12.679328441619873\n",
      "Epoch:  790  Average loss at step  1000 :  3.7543160490989687\n",
      "Epoch:  790  Average loss at step  2000 :  3.6975626940727233\n",
      "Epoch:  790  Average loss at step  3000 :  3.620098871707916\n",
      "Epoch:  790  Average loss at step  3222 :  3.8366544825610194\n",
      "790 4 33.22686696052551\n",
      "790 5 1.430511474609375e-06\n",
      "Training time took 99.126641 seconds to run 1 epoch\n",
      "Mean Rank:  153.70844  of  75000\n",
      "Hits @ 10:  0.85312\n",
      "Hits @ 1:  0.62592\n",
      "Testing time took 163.730034 seconds.\n",
      "\n",
      "Epoch:  791  Average loss at step  1000 :  0.0429511815905571\n",
      "Epoch:  791  Average loss at step  2000 :  0.045342972457408905\n",
      "Epoch:  791  Average loss at step  3000 :  0.0495775043964386\n",
      "Epoch:  791  Average loss at step  3222 :  0.05249093238100891\n",
      "791 0 29.413474559783936\n",
      "Training time took 29.521988 seconds to run 1 epoch\n",
      "Epoch:  792  Average loss at step  1000 :  7.81754439163208\n",
      "Epoch:  792  Average loss at step  2000 :  7.901421724319458\n",
      "Epoch:  792  Average loss at step  3000 :  7.979215061187744\n",
      "Epoch:  792  Average loss at step  4000 :  8.183879515647888\n",
      "Epoch:  792  Average loss at step  5000 :  7.6701221160888675\n",
      "Epoch:  792  Average loss at step  6000 :  7.926804392814637\n",
      "Epoch:  792  Average loss at step  7000 :  7.716749045372009\n",
      "Epoch:  792  Average loss at step  8000 :  8.175211565017701\n",
      "Epoch:  792  Average loss at step  8472 :  7.5494015653471065\n",
      "792 0 20.72652578353882\n",
      "Epoch:  792  Average loss at step  1000 :  2905.6549127807616\n",
      "Epoch:  792  Average loss at step  1491 :  2842.6891974718264\n",
      "792 1 11.73481559753418\n",
      "Epoch:  792  Average loss at step  1000 :  4047.6547033691404\n",
      "Epoch:  792  Average loss at step  2000 :  4063.839455810547\n",
      "Epoch:  792  Average loss at step  2533 :  4083.0457785100602\n",
      "792 2 19.88300919532776\n",
      "Epoch:  792  Average loss at step  1000 :  61.116127098083496\n",
      "Epoch:  792  Average loss at step  1227 :  61.55668078509344\n",
      "792 3 12.609425067901611\n",
      "Epoch:  792  Average loss at step  1000 :  3.7885312962532045\n",
      "Epoch:  792  Average loss at step  2000 :  3.6329447484016417\n",
      "Epoch:  792  Average loss at step  3000 :  3.6811361875534057\n",
      "Epoch:  792  Average loss at step  3222 :  3.55899166083762\n",
      "792 4 33.08523511886597\n",
      "792 5 1.6689300537109375e-06\n",
      "Training time took 98.668087 seconds to run 1 epoch\n",
      "Epoch:  793  Average loss at step  1000 :  0.04316364914178848\n",
      "Epoch:  793  Average loss at step  2000 :  0.0452866570353508\n",
      "Epoch:  793  Average loss at step  3000 :  0.04924419057369232\n",
      "Epoch:  793  Average loss at step  3222 :  0.05243385547247792\n",
      "793 0 29.37813448905945\n",
      "Training time took 29.500062 seconds to run 1 epoch\n",
      "Epoch:  794  Average loss at step  1000 :  8.04989625453949\n",
      "Epoch:  794  Average loss at step  2000 :  7.396187024116516\n",
      "Epoch:  794  Average loss at step  3000 :  8.071919306755065\n",
      "Epoch:  794  Average loss at step  4000 :  7.961703667640686\n",
      "Epoch:  794  Average loss at step  5000 :  8.42124870967865\n",
      "Epoch:  794  Average loss at step  6000 :  7.999292899131775\n",
      "Epoch:  794  Average loss at step  7000 :  8.200708820343017\n",
      "Epoch:  794  Average loss at step  8000 :  8.574440506935119\n",
      "Epoch:  794  Average loss at step  8472 :  7.957568360297871\n",
      "794 0 20.71520495414734\n",
      "Epoch:  794  Average loss at step  1000 :  2885.0188162841796\n",
      "Epoch:  794  Average loss at step  1491 :  2925.8877895612345\n",
      "794 1 11.735394954681396\n",
      "Epoch:  794  Average loss at step  1000 :  4065.1631298828124\n",
      "Epoch:  794  Average loss at step  2000 :  4044.7697305908205\n",
      "Epoch:  794  Average loss at step  2533 :  4020.3043515783584\n",
      "794 2 19.94927144050598\n",
      "Epoch:  794  Average loss at step  1000 :  61.41437274169922\n",
      "Epoch:  794  Average loss at step  1227 :  59.59882634809527\n",
      "794 3 12.604164600372314\n",
      "Epoch:  794  Average loss at step  1000 :  3.666606544971466\n",
      "Epoch:  794  Average loss at step  2000 :  3.67241965675354\n",
      "Epoch:  794  Average loss at step  3000 :  3.695613166809082\n",
      "Epoch:  794  Average loss at step  3222 :  3.383377343443116\n",
      "794 4 33.21539354324341\n",
      "794 5 1.430511474609375e-06\n",
      "Training time took 98.843929 seconds to run 1 epoch\n",
      "Epoch:  795  Average loss at step  1000 :  0.04292436707019806\n",
      "Epoch:  795  Average loss at step  2000 :  0.04514009147882461\n",
      "Epoch:  795  Average loss at step  3000 :  0.049183983325958254\n",
      "Epoch:  795  Average loss at step  3222 :  0.05093329293694731\n",
      "795 0 29.400997400283813\n",
      "Training time took 29.519681 seconds to run 1 epoch\n",
      "Epoch:  796  Average loss at step  1000 :  7.964356651306153\n",
      "Epoch:  796  Average loss at step  2000 :  7.645140520095826\n",
      "Epoch:  796  Average loss at step  3000 :  8.071956958770752\n",
      "Epoch:  796  Average loss at step  4000 :  8.129714653968811\n",
      "Epoch:  796  Average loss at step  5000 :  7.630441452980041\n",
      "Epoch:  796  Average loss at step  6000 :  8.439780288696289\n",
      "Epoch:  796  Average loss at step  7000 :  7.9695650806427\n",
      "Epoch:  796  Average loss at step  8000 :  7.901835535049439\n",
      "Epoch:  796  Average loss at step  8472 :  7.539818215150591\n",
      "796 0 20.777921199798584\n",
      "Epoch:  796  Average loss at step  1000 :  2890.7033646240234\n",
      "Epoch:  796  Average loss at step  1491 :  2914.817402177452\n",
      "796 1 11.701828956604004\n",
      "Epoch:  796  Average loss at step  1000 :  4057.8036384277343\n",
      "Epoch:  796  Average loss at step  2000 :  4053.0528614501955\n",
      "Epoch:  796  Average loss at step  2533 :  3980.15533356641\n",
      "796 2 19.93579864501953\n",
      "Epoch:  796  Average loss at step  1000 :  60.86580797958374\n",
      "Epoch:  796  Average loss at step  1227 :  60.850692387530096\n",
      "796 3 12.659531593322754\n",
      "Epoch:  796  Average loss at step  1000 :  3.665562867641449\n",
      "Epoch:  796  Average loss at step  2000 :  3.5842793011665344\n",
      "Epoch:  796  Average loss at step  3000 :  3.611211145401001\n",
      "Epoch:  796  Average loss at step  3222 :  3.518517296287122\n",
      "796 4 33.264363288879395\n",
      "796 5 1.6689300537109375e-06\n",
      "Training time took 98.971044 seconds to run 1 epoch\n",
      "Epoch:  797  Average loss at step  1000 :  0.042871869325637815\n",
      "Epoch:  797  Average loss at step  2000 :  0.0451136389374733\n",
      "Epoch:  797  Average loss at step  3000 :  0.04901485121250153\n",
      "Epoch:  797  Average loss at step  3222 :  0.05059679356437445\n",
      "797 0 29.24216341972351\n",
      "Training time took 29.360971 seconds to run 1 epoch\n",
      "Epoch:  798  Average loss at step  1000 :  8.081365696907044\n",
      "Epoch:  798  Average loss at step  2000 :  7.6993663711547855\n",
      "Epoch:  798  Average loss at step  3000 :  7.680404630661011\n",
      "Epoch:  798  Average loss at step  4000 :  7.8224055280685425\n",
      "Epoch:  798  Average loss at step  5000 :  7.956688344955444\n",
      "Epoch:  798  Average loss at step  6000 :  7.750973794937134\n",
      "Epoch:  798  Average loss at step  7000 :  7.80306787109375\n",
      "Epoch:  798  Average loss at step  8000 :  7.734119244575501\n",
      "Epoch:  798  Average loss at step  8472 :  8.267304960148609\n",
      "798 0 20.220788717269897\n",
      "Epoch:  798  Average loss at step  1000 :  2919.6666998291016\n",
      "Epoch:  798  Average loss at step  1491 :  2946.342664229912\n",
      "798 1 11.687197208404541\n",
      "Epoch:  798  Average loss at step  1000 :  4067.3082399902346\n",
      "Epoch:  798  Average loss at step  2000 :  4033.807505126953\n",
      "Epoch:  798  Average loss at step  2533 :  4085.7660123872897\n",
      "798 2 19.89668345451355\n",
      "Epoch:  798  Average loss at step  1000 :  61.089209320068356\n",
      "Epoch:  798  Average loss at step  1227 :  61.044985705166276\n",
      "798 3 12.597427606582642\n",
      "Epoch:  798  Average loss at step  1000 :  3.54365128993988\n",
      "Epoch:  798  Average loss at step  2000 :  3.6142193870544435\n",
      "Epoch:  798  Average loss at step  3000 :  3.5786674399375915\n",
      "Epoch:  798  Average loss at step  3222 :  3.4381989688945604\n",
      "798 4 33.310182094573975\n",
      "798 5 1.430511474609375e-06\n",
      "Training time took 98.357333 seconds to run 1 epoch\n",
      "Epoch:  799  Average loss at step  1000 :  0.042493607878684996\n",
      "Epoch:  799  Average loss at step  2000 :  0.04510349678993225\n",
      "Epoch:  799  Average loss at step  3000 :  0.04914368540048599\n",
      "Epoch:  799  Average loss at step  3222 :  0.051730733191973466\n",
      "799 0 29.423523664474487\n",
      "Training time took 29.550872 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time took 64888.87807 seconds to run 400 epoch\n"
     ]
    }
   ],
   "source": [
    "start_time = dt.datetime.now()\n",
    "run(tfgraph, 800) \n",
    "end_time = dt.datetime.now()\n",
    "print(\"Training time took {} seconds to run {} epoch\".format((end_time-start_time).total_seconds(), totalEpoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HejbGJdIK0Pf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 0, ' Average loss at step ', 1000, ': ', 928.00448626708987)\n",
      "('Epoch: ', 0, ' Average loss at step ', 2000, ': ', 372.60245579528811)\n",
      "('Epoch: ', 0, ' Average loss at step ', 3000, ': ', 197.10211377716064)\n",
      "('Epoch: ', 0, ' Average loss at step ', 4000, ': ', 152.38899171066285)\n",
      "('Epoch: ', 0, ' Average loss at step ', 4373, ': ', 139.76749172005603)\n",
      "('Epoch: ', 0, ' Average loss at step ', 761, ': ', 936.47003639622733)\n",
      "('Epoch: ', 0, ' Average loss at step ', 782, ': ', 855.07023028619153)\n",
      "('Epoch: ', 0, ' Average loss at step ', 787, ': ', 395.70297674125692)\n",
      "('Epoch: ', 0, ' Average loss at step ', 1000, ': ', 340.98587445068358)\n",
      "('Epoch: ', 0, ' Average loss at step ', 2000, ': ', 299.0904885406494)\n",
      "('Epoch: ', 0, ' Average loss at step ', 2813, ': ', 281.13968872671643)\n",
      "Training time took 97.851513 seconds to run 1 epoch\n",
      "('Epoch: ', 1, ' Average loss at step ', 1000, ': ', 58.942353662490845)\n",
      "('Epoch: ', 1, ' Average loss at step ', 2000, ': ', 22.863810077667235)\n",
      "('Epoch: ', 1, ' Average loss at step ', 2813, ': ', 14.937519058218143)\n",
      "Training time took 44.06458 seconds to run 1 epoch\n",
      "('Epoch: ', 2, ' Average loss at step ', 1000, ': ', 135.02089272689818)\n",
      "('Epoch: ', 2, ' Average loss at step ', 2000, ': ', 135.45963957595825)\n",
      "('Epoch: ', 2, ' Average loss at step ', 3000, ': ', 129.7579079246521)\n",
      "('Epoch: ', 2, ' Average loss at step ', 4000, ': ', 131.55293412399291)\n",
      "('Epoch: ', 2, ' Average loss at step ', 4373, ': ', 127.62619860454272)\n",
      "('Epoch: ', 2, ' Average loss at step ', 761, ': ', 1007.3754033941972)\n",
      "('Epoch: ', 2, ' Average loss at step ', 782, ': ', 1244.54921903134)\n",
      "('Epoch: ', 2, ' Average loss at step ', 787, ': ', 337.1071711144678)\n",
      "('Epoch: ', 2, ' Average loss at step ', 1000, ': ', 246.94895225524903)\n",
      "('Epoch: ', 2, ' Average loss at step ', 2000, ': ', 227.78978689575194)\n",
      "('Epoch: ', 2, ' Average loss at step ', 2813, ': ', 213.63014424140817)\n",
      "Training time took 97.735565 seconds to run 1 epoch\n",
      "('Epoch: ', 3, ' Average loss at step ', 1000, ': ', 8.3989022850990303)\n",
      "('Epoch: ', 3, ' Average loss at step ', 2000, ': ', 6.3614943981170651)\n",
      "('Epoch: ', 3, ' Average loss at step ', 2813, ': ', 4.953263101319374)\n",
      "Training time took 44.036432 seconds to run 1 epoch\n",
      "('Epoch: ', 4, ' Average loss at step ', 1000, ': ', 130.75689513397217)\n",
      "('Epoch: ', 4, ' Average loss at step ', 2000, ': ', 129.97188595199586)\n",
      "('Epoch: ', 4, ' Average loss at step ', 3000, ': ', 129.72721292877196)\n",
      "('Epoch: ', 4, ' Average loss at step ', 4000, ': ', 129.19307060623169)\n",
      "('Epoch: ', 4, ' Average loss at step ', 4373, ': ', 132.95446121051748)\n",
      "('Epoch: ', 4, ' Average loss at step ', 761, ': ', 911.31339271946956)\n",
      "('Epoch: ', 4, ' Average loss at step ', 782, ': ', 1097.5655197163092)\n",
      "('Epoch: ', 4, ' Average loss at step ', 787, ': ', 277.40661904526729)\n",
      "('Epoch: ', 4, ' Average loss at step ', 1000, ': ', 196.17835725402833)\n",
      "('Epoch: ', 4, ' Average loss at step ', 2000, ': ', 186.87439345550538)\n",
      "('Epoch: ', 4, ' Average loss at step ', 2813, ': ', 176.47831406616811)\n",
      "Training time took 97.842156 seconds to run 1 epoch\n",
      "('Epoch: ', 5, ' Average loss at step ', 1000, ': ', 4.9454397542476656)\n",
      "('Epoch: ', 5, ' Average loss at step ', 2000, ': ', 4.1374932215213773)\n",
      "('Epoch: ', 5, ' Average loss at step ', 2813, ': ', 3.5290892024345584)\n",
      "Training time took 44.052272 seconds to run 1 epoch\n",
      "('Epoch: ', 6, ' Average loss at step ', 1000, ': ', 128.12883436965942)\n",
      "('Epoch: ', 6, ' Average loss at step ', 2000, ': ', 128.97259538650513)\n",
      "('Epoch: ', 6, ' Average loss at step ', 3000, ': ', 127.56116570281982)\n",
      "('Epoch: ', 6, ' Average loss at step ', 4000, ': ', 125.99961123275757)\n",
      "('Epoch: ', 6, ' Average loss at step ', 4373, ': ', 131.22654079109111)\n",
      "('Epoch: ', 6, ' Average loss at step ', 761, ': ', 980.70625152587888)\n",
      "('Epoch: ', 6, ' Average loss at step ', 782, ': ', 1122.6832724753172)\n",
      "('Epoch: ', 6, ' Average loss at step ', 787, ': ', 228.51982437987971)\n",
      "('Epoch: ', 6, ' Average loss at step ', 1000, ': ', 164.09157683563234)\n",
      "('Epoch: ', 6, ' Average loss at step ', 2000, ': ', 154.63164253997803)\n",
      "('Epoch: ', 6, ' Average loss at step ', 2813, ': ', 144.74654499298245)\n",
      "Training time took 97.891567 seconds to run 1 epoch\n",
      "('Epoch: ', 7, ' Average loss at step ', 1000, ': ', 3.6350712139606474)\n",
      "('Epoch: ', 7, ' Average loss at step ', 2000, ': ', 3.0439097936153412)\n",
      "('Epoch: ', 7, ' Average loss at step ', 2813, ': ', 2.4746620931061618)\n",
      "Training time took 44.066725 seconds to run 1 epoch\n",
      "('Epoch: ', 8, ' Average loss at step ', 1000, ': ', 128.31712219238281)\n",
      "('Epoch: ', 8, ' Average loss at step ', 2000, ': ', 128.97921263885499)\n",
      "('Epoch: ', 8, ' Average loss at step ', 3000, ': ', 129.31699287223816)\n",
      "('Epoch: ', 8, ' Average loss at step ', 4000, ': ', 129.05414199447631)\n",
      "('Epoch: ', 8, ' Average loss at step ', 4373, ': ', 130.61595808049685)\n",
      "('Epoch: ', 8, ' Average loss at step ', 761, ': ', 1147.0144643683182)\n",
      "('Epoch: ', 8, ' Average loss at step ', 782, ': ', 1262.9507382987556)\n",
      "('Epoch: ', 8, ' Average loss at step ', 787, ': ', 191.15684878128479)\n",
      "('Epoch: ', 8, ' Average loss at step ', 1000, ': ', 135.80889672088622)\n",
      "('Epoch: ', 8, ' Average loss at step ', 2000, ': ', 126.4669063949585)\n",
      "('Epoch: ', 8, ' Average loss at step ', 2813, ': ', 120.15081683285717)\n",
      "Training time took 97.763695 seconds to run 1 epoch\n",
      "('Epoch: ', 9, ' Average loss at step ', 1000, ': ', 2.7578296895027159)\n",
      "('Epoch: ', 9, ' Average loss at step ', 2000, ': ', 2.3296598874330519)\n",
      "('Epoch: ', 9, ' Average loss at step ', 2813, ': ', 1.8970174818790604)\n",
      "Training time took 44.034687 seconds to run 1 epoch\n",
      "Mean Rank:  942  of  28683\n",
      "Hits @ 10:  0.269379586391\n",
      "Hits @ 1:  0.0899933288859\n",
      "Testing time took 78.490039 seconds.\n",
      "\n",
      "('Epoch: ', 10, ' Average loss at step ', 1000, ': ', 129.24480439758301)\n",
      "('Epoch: ', 10, ' Average loss at step ', 2000, ': ', 130.65868249511718)\n",
      "('Epoch: ', 10, ' Average loss at step ', 3000, ': ', 128.6282191181183)\n",
      "('Epoch: ', 10, ' Average loss at step ', 4000, ': ', 129.41771778869628)\n",
      "('Epoch: ', 10, ' Average loss at step ', 4373, ': ', 126.26852877422046)\n",
      "('Epoch: ', 10, ' Average loss at step ', 761, ': ', 1352.596042030736)\n",
      "('Epoch: ', 10, ' Average loss at step ', 782, ': ', 1433.7117702664852)\n",
      "('Epoch: ', 10, ' Average loss at step ', 787, ': ', 161.25280641356801)\n",
      "('Epoch: ', 10, ' Average loss at step ', 1000, ': ', 110.7940703048706)\n",
      "('Epoch: ', 10, ' Average loss at step ', 2000, ': ', 104.98343865585328)\n",
      "('Epoch: ', 10, ' Average loss at step ', 2813, ': ', 98.143983291287725)\n",
      "Training time took 97.859537 seconds to run 1 epoch\n",
      "('Epoch: ', 11, ' Average loss at step ', 1000, ': ', 2.2073240925073625)\n",
      "('Epoch: ', 11, ' Average loss at step ', 2000, ': ', 1.8388665509223938)\n",
      "('Epoch: ', 11, ' Average loss at step ', 2813, ': ', 1.5618642496651616)\n",
      "Training time took 44.029813 seconds to run 1 epoch\n",
      "('Epoch: ', 12, ' Average loss at step ', 1000, ': ', 127.15805787277222)\n",
      "('Epoch: ', 12, ' Average loss at step ', 2000, ': ', 129.76028036117555)\n",
      "('Epoch: ', 12, ' Average loss at step ', 3000, ': ', 129.04439142608643)\n",
      "('Epoch: ', 12, ' Average loss at step ', 4000, ': ', 131.06286734771729)\n",
      "('Epoch: ', 12, ' Average loss at step ', 4373, ': ', 129.16281193558888)\n",
      "('Epoch: ', 12, ' Average loss at step ', 761, ': ', 1539.9367335269326)\n",
      "('Epoch: ', 12, ' Average loss at step ', 782, ': ', 1577.9829623604553)\n",
      "('Epoch: ', 12, ' Average loss at step ', 787, ': ', 132.99333714104185)\n",
      "('Epoch: ', 12, ' Average loss at step ', 1000, ': ', 91.024770797729488)\n",
      "('Epoch: ', 12, ' Average loss at step ', 2000, ': ', 85.975834159851075)\n",
      "('Epoch: ', 12, ' Average loss at step ', 2813, ': ', 81.550155287305714)\n",
      "Training time took 97.777351 seconds to run 1 epoch\n",
      "('Epoch: ', 13, ' Average loss at step ', 1000, ': ', 1.7151369701623917)\n",
      "('Epoch: ', 13, ' Average loss at step ', 2000, ': ', 1.427583988249302)\n",
      "('Epoch: ', 13, ' Average loss at step ', 2813, ': ', 1.2196654264856441)\n",
      "Training time took 44.101502 seconds to run 1 epoch\n",
      "('Epoch: ', 14, ' Average loss at step ', 1000, ': ', 129.06964903259276)\n",
      "('Epoch: ', 14, ' Average loss at step ', 2000, ': ', 128.93977723693848)\n",
      "('Epoch: ', 14, ' Average loss at step ', 3000, ': ', 129.14486025238037)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 14, ' Average loss at step ', 4000, ': ', 128.49696089172363)\n",
      "('Epoch: ', 14, ' Average loss at step ', 4373, ': ', 129.76736573250062)\n",
      "('Epoch: ', 14, ' Average loss at step ', 761, ': ', 1714.4813034860711)\n",
      "('Epoch: ', 14, ' Average loss at step ', 782, ': ', 1701.4092628391086)\n",
      "('Epoch: ', 14, ' Average loss at step ', 787, ': ', 111.50094625846727)\n",
      "('Epoch: ', 14, ' Average loss at step ', 1000, ': ', 74.895015159606928)\n",
      "('Epoch: ', 14, ' Average loss at step ', 2000, ': ', 71.611773151397699)\n",
      "('Epoch: ', 14, ' Average loss at step ', 2813, ': ', 68.748887419113387)\n",
      "Training time took 97.606629 seconds to run 1 epoch\n",
      "('Epoch: ', 15, ' Average loss at step ', 1000, ': ', 1.3925643635392189)\n",
      "('Epoch: ', 15, ' Average loss at step ', 2000, ': ', 1.1268106439113617)\n",
      "('Epoch: ', 15, ' Average loss at step ', 2813, ': ', 0.96808369112719461)\n",
      "Training time took 44.041956 seconds to run 1 epoch\n",
      "('Epoch: ', 16, ' Average loss at step ', 1000, ': ', 126.51732887649536)\n",
      "('Epoch: ', 16, ' Average loss at step ', 2000, ': ', 129.25588304138185)\n",
      "('Epoch: ', 16, ' Average loss at step ', 3000, ': ', 128.86444701385497)\n",
      "('Epoch: ', 16, ' Average loss at step ', 4000, ': ', 128.3548713912964)\n",
      "('Epoch: ', 16, ' Average loss at step ', 4373, ': ', 127.21675284190844)\n",
      "('Epoch: ', 16, ' Average loss at step ', 761, ': ', 1856.1757415771485)\n",
      "('Epoch: ', 16, ' Average loss at step ', 782, ': ', 1836.7582116902408)\n",
      "('Epoch: ', 16, ' Average loss at step ', 787, ': ', 94.496861139933273)\n",
      "('Epoch: ', 16, ' Average loss at step ', 1000, ': ', 65.00633519363403)\n",
      "('Epoch: ', 16, ' Average loss at step ', 2000, ': ', 63.233239746093751)\n",
      "('Epoch: ', 16, ' Average loss at step ', 2813, ': ', 61.624974161533302)\n",
      "Training time took 97.766877 seconds to run 1 epoch\n",
      "('Epoch: ', 17, ' Average loss at step ', 1000, ': ', 1.1641620537042618)\n",
      "('Epoch: ', 17, ' Average loss at step ', 2000, ': ', 0.93733630502223964)\n",
      "('Epoch: ', 17, ' Average loss at step ', 2813, ': ', 0.82157999871693221)\n",
      "Training time took 44.017002 seconds to run 1 epoch\n",
      "('Epoch: ', 18, ' Average loss at step ', 1000, ': ', 128.03122978973389)\n",
      "('Epoch: ', 18, ' Average loss at step ', 2000, ': ', 126.91391199493408)\n",
      "('Epoch: ', 18, ' Average loss at step ', 3000, ': ', 129.6822847518921)\n",
      "('Epoch: ', 18, ' Average loss at step ', 4000, ': ', 129.01236938095093)\n",
      "('Epoch: ', 18, ' Average loss at step ', 4373, ': ', 129.83117108703942)\n",
      "('Epoch: ', 18, ' Average loss at step ', 761, ': ', 2007.5999500475432)\n",
      "('Epoch: ', 18, ' Average loss at step ', 782, ': ', 1956.0528251853093)\n",
      "('Epoch: ', 18, ' Average loss at step ', 787, ': ', 81.190504860331998)\n",
      "('Epoch: ', 18, ' Average loss at step ', 1000, ': ', 57.782035381317137)\n",
      "('Epoch: ', 18, ' Average loss at step ', 2000, ': ', 56.581531494140627)\n",
      "('Epoch: ', 18, ' Average loss at step ', 2813, ': ', 55.19512006919372)\n",
      "Training time took 97.799058 seconds to run 1 epoch\n",
      "('Epoch: ', 19, ' Average loss at step ', 1000, ': ', 0.99179012113809584)\n",
      "('Epoch: ', 19, ' Average loss at step ', 2000, ': ', 0.80434789866209033)\n",
      "('Epoch: ', 19, ' Average loss at step ', 2813, ': ', 0.7060094028711319)\n",
      "Training time took 44.07721 seconds to run 1 epoch\n",
      "Mean Rank:  64  of  28683\n",
      "Hits @ 10:  0.820413609073\n",
      "Hits @ 1:  0.562108072048\n",
      "Testing time took 75.582518 seconds.\n",
      "\n",
      "('Epoch: ', 20, ' Average loss at step ', 1000, ': ', 128.98600724792482)\n",
      "('Epoch: ', 20, ' Average loss at step ', 2000, ': ', 129.44445500564575)\n",
      "('Epoch: ', 20, ' Average loss at step ', 3000, ': ', 128.05525490570068)\n",
      "('Epoch: ', 20, ' Average loss at step ', 4000, ': ', 128.90818540573119)\n",
      "('Epoch: ', 20, ' Average loss at step ', 4373, ': ', 130.92950527642364)\n",
      "('Epoch: ', 20, ' Average loss at step ', 761, ': ', 2124.9173246684827)\n",
      "('Epoch: ', 20, ' Average loss at step ', 782, ': ', 2073.1391410876481)\n",
      "('Epoch: ', 20, ' Average loss at step ', 787, ': ', 73.060012346612282)\n",
      "('Epoch: ', 20, ' Average loss at step ', 1000, ': ', 52.613458148956298)\n",
      "('Epoch: ', 20, ' Average loss at step ', 2000, ': ', 51.174147789001466)\n",
      "('Epoch: ', 20, ' Average loss at step ', 2813, ': ', 50.144432927587353)\n",
      "Training time took 97.838091 seconds to run 1 epoch\n",
      "('Epoch: ', 21, ' Average loss at step ', 1000, ': ', 0.86125423252582545)\n",
      "('Epoch: ', 21, ' Average loss at step ', 2000, ': ', 0.70165404343605042)\n",
      "('Epoch: ', 21, ' Average loss at step ', 2813, ': ', 0.61875911556147589)\n",
      "Training time took 44.055131 seconds to run 1 epoch\n",
      "('Epoch: ', 22, ' Average loss at step ', 1000, ': ', 128.7786149597168)\n",
      "('Epoch: ', 22, ' Average loss at step ', 2000, ': ', 128.16096310424805)\n",
      "('Epoch: ', 22, ' Average loss at step ', 3000, ': ', 128.80927052307129)\n",
      "('Epoch: ', 22, ' Average loss at step ', 4000, ': ', 126.67949967193603)\n",
      "('Epoch: ', 22, ' Average loss at step ', 4373, ': ', 128.49259059659897)\n",
      "('Epoch: ', 22, ' Average loss at step ', 761, ': ', 2255.1680603027344)\n",
      "('Epoch: ', 22, ' Average loss at step ', 782, ': ', 2181.1685792578623)\n",
      "('Epoch: ', 22, ' Average loss at step ', 787, ': ', 67.926874539324345)\n",
      "('Epoch: ', 22, ' Average loss at step ', 1000, ': ', 47.667256786346435)\n",
      "('Epoch: ', 22, ' Average loss at step ', 2000, ': ', 46.300273887634276)\n",
      "('Epoch: ', 22, ' Average loss at step ', 2813, ': ', 45.950831300519368)\n",
      "Training time took 97.779559 seconds to run 1 epoch\n",
      "('Epoch: ', 23, ' Average loss at step ', 1000, ': ', 0.75453010803461074)\n",
      "('Epoch: ', 23, ' Average loss at step ', 2000, ': ', 0.61899927836656565)\n",
      "('Epoch: ', 23, ' Average loss at step ', 2813, ': ', 0.5530487423753504)\n",
      "Training time took 44.039248 seconds to run 1 epoch\n",
      "('Epoch: ', 24, ' Average loss at step ', 1000, ': ', 128.13713571929932)\n",
      "('Epoch: ', 24, ' Average loss at step ', 2000, ': ', 128.62394001770019)\n",
      "('Epoch: ', 24, ' Average loss at step ', 3000, ': ', 128.52880846405029)\n",
      "('Epoch: ', 24, ' Average loss at step ', 4000, ': ', 126.88822816467285)\n",
      "('Epoch: ', 24, ' Average loss at step ', 4373, ': ', 125.88648956052718)\n",
      "('Epoch: ', 24, ' Average loss at step ', 761, ': ', 2357.7578229402243)\n",
      "('Epoch: ', 24, ' Average loss at step ', 782, ': ', 2305.0316423130403)\n",
      "('Epoch: ', 24, ' Average loss at step ', 787, ': ', 64.988354685349009)\n",
      "('Epoch: ', 24, ' Average loss at step ', 1000, ': ', 43.71878192901611)\n",
      "('Epoch: ', 24, ' Average loss at step ', 2000, ': ', 43.208045696258544)\n",
      "('Epoch: ', 24, ' Average loss at step ', 2813, ': ', 42.848136176029449)\n",
      "Training time took 97.752931 seconds to run 1 epoch\n",
      "('Epoch: ', 25, ' Average loss at step ', 1000, ': ', 0.67963139969110486)\n",
      "('Epoch: ', 25, ' Average loss at step ', 2000, ': ', 0.5536159456968307)\n",
      "('Epoch: ', 25, ' Average loss at step ', 2813, ': ', 0.49783341190204244)\n",
      "Training time took 44.017701 seconds to run 1 epoch\n",
      "('Epoch: ', 26, ' Average loss at step ', 1000, ': ', 129.1890974960327)\n",
      "('Epoch: ', 26, ' Average loss at step ', 2000, ': ', 129.04718013381958)\n",
      "('Epoch: ', 26, ' Average loss at step ', 3000, ': ', 126.96214186096191)\n",
      "('Epoch: ', 26, ' Average loss at step ', 4000, ': ', 126.55073457336425)\n",
      "('Epoch: ', 26, ' Average loss at step ', 4373, ': ', 128.81636352949246)\n",
      "('Epoch: ', 26, ' Average loss at step ', 761, ': ', 2446.0771728515624)\n",
      "('Epoch: ', 26, ' Average loss at step ', 782, ': ', 2441.2556641562801)\n",
      "('Epoch: ', 26, ' Average loss at step ', 787, ': ', 62.474741918743412)\n",
      "('Epoch: ', 26, ' Average loss at step ', 1000, ': ', 40.522443754196168)\n",
      "('Epoch: ', 26, ' Average loss at step ', 2000, ': ', 40.377304328918456)\n",
      "('Epoch: ', 26, ' Average loss at step ', 2813, ': ', 40.121796636158606)\n",
      "Training time took 97.826053 seconds to run 1 epoch\n",
      "('Epoch: ', 27, ' Average loss at step ', 1000, ': ', 0.61727244490385058)\n",
      "('Epoch: ', 27, ' Average loss at step ', 2000, ': ', 0.49921472936868666)\n",
      "('Epoch: ', 27, ' Average loss at step ', 2813, ': ', 0.45315300875109404)\n",
      "Training time took 44.043403 seconds to run 1 epoch\n",
      "('Epoch: ', 28, ' Average loss at step ', 1000, ': ', 129.86509075927734)\n",
      "('Epoch: ', 28, ' Average loss at step ', 2000, ': ', 128.6786154937744)\n",
      "('Epoch: ', 28, ' Average loss at step ', 3000, ': ', 127.8881361541748)\n",
      "('Epoch: ', 28, ' Average loss at step ', 4000, ': ', 127.69656059646607)\n",
      "('Epoch: ', 28, ' Average loss at step ', 4373, ': ', 129.95315123117098)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 28, ' Average loss at step ', 761, ': ', 2550.9474962736431)\n",
      "('Epoch: ', 28, ' Average loss at step ', 782, ': ', 2548.2287378836227)\n",
      "('Epoch: ', 28, ' Average loss at step ', 787, ': ', 60.348988826644934)\n",
      "('Epoch: ', 28, ' Average loss at step ', 1000, ': ', 38.559120548248288)\n",
      "('Epoch: ', 28, ' Average loss at step ', 2000, ': ', 38.133591497421264)\n",
      "('Epoch: ', 28, ' Average loss at step ', 2813, ': ', 37.704037128410903)\n",
      "Training time took 97.646669 seconds to run 1 epoch\n",
      "('Epoch: ', 29, ' Average loss at step ', 1000, ': ', 0.55306865197420119)\n",
      "('Epoch: ', 29, ' Average loss at step ', 2000, ': ', 0.46044782757759095)\n",
      "('Epoch: ', 29, ' Average loss at step ', 2813, ': ', 0.41307038846861555)\n",
      "Training time took 44.02296 seconds to run 1 epoch\n",
      "Mean Rank:  24  of  28683\n",
      "Hits @ 10:  0.917611741161\n",
      "Hits @ 1:  0.756037358239\n",
      "Testing time took 73.237164 seconds.\n",
      "\n",
      "('Epoch: ', 30, ' Average loss at step ', 1000, ': ', 126.55667757415772)\n",
      "('Epoch: ', 30, ' Average loss at step ', 2000, ': ', 127.51347779846192)\n",
      "('Epoch: ', 30, ' Average loss at step ', 3000, ': ', 127.66106024169922)\n",
      "('Epoch: ', 30, ' Average loss at step ', 4000, ': ', 128.45085320663452)\n",
      "('Epoch: ', 30, ' Average loss at step ', 4373, ': ', 129.31251082881803)\n",
      "('Epoch: ', 30, ' Average loss at step ', 761, ': ', 2647.9826236122531)\n",
      "('Epoch: ', 30, ' Average loss at step ', 782, ': ', 2669.2562051106356)\n",
      "('Epoch: ', 30, ' Average loss at step ', 787, ': ', 58.388285003545633)\n",
      "('Epoch: ', 30, ' Average loss at step ', 1000, ': ', 36.227521532058717)\n",
      "('Epoch: ', 30, ' Average loss at step ', 2000, ': ', 35.669580993652346)\n",
      "('Epoch: ', 30, ' Average loss at step ', 2813, ': ', 35.341337255656427)\n",
      "Training time took 97.794874 seconds to run 1 epoch\n",
      "('Epoch: ', 31, ' Average loss at step ', 1000, ': ', 0.50998490130901342)\n",
      "('Epoch: ', 31, ' Average loss at step ', 2000, ': ', 0.42186756628751754)\n",
      "('Epoch: ', 31, ' Average loss at step ', 2813, ': ', 0.38412880552519718)\n",
      "Training time took 44.028993 seconds to run 1 epoch\n",
      "('Epoch: ', 32, ' Average loss at step ', 1000, ': ', 129.66439855957032)\n",
      "('Epoch: ', 32, ' Average loss at step ', 2000, ': ', 128.68752536010743)\n",
      "('Epoch: ', 32, ' Average loss at step ', 3000, ': ', 128.54093451690673)\n",
      "('Epoch: ', 32, ' Average loss at step ', 4000, ': ', 127.89811783218384)\n",
      "('Epoch: ', 32, ' Average loss at step ', 4373, ': ', 129.10363656731062)\n",
      "('Epoch: ', 32, ' Average loss at step ', 761, ': ', 2742.5133108038654)\n",
      "('Epoch: ', 32, ' Average loss at step ', 782, ': ', 2779.4895153949265)\n",
      "('Epoch: ', 32, ' Average loss at step ', 787, ': ', 55.975785379191393)\n",
      "('Epoch: ', 32, ' Average loss at step ', 1000, ': ', 33.829532159805296)\n",
      "('Epoch: ', 32, ' Average loss at step ', 2000, ': ', 33.472504627227785)\n",
      "('Epoch: ', 32, ' Average loss at step ', 2813, ': ', 33.316974773782817)\n",
      "Training time took 97.767334 seconds to run 1 epoch\n",
      "('Epoch: ', 33, ' Average loss at step ', 1000, ': ', 0.46844638073444367)\n",
      "('Epoch: ', 33, ' Average loss at step ', 2000, ': ', 0.39323039078712463)\n",
      "('Epoch: ', 33, ' Average loss at step ', 2813, ': ', 0.35478235472892894)\n",
      "Training time took 44.042563 seconds to run 1 epoch\n",
      "('Epoch: ', 34, ' Average loss at step ', 1000, ': ', 129.47924564361571)\n",
      "('Epoch: ', 34, ' Average loss at step ', 2000, ': ', 128.22334399414063)\n",
      "('Epoch: ', 34, ' Average loss at step ', 3000, ': ', 126.6119328918457)\n",
      "('Epoch: ', 34, ' Average loss at step ', 4000, ': ', 128.10331646728517)\n",
      "('Epoch: ', 34, ' Average loss at step ', 4373, ': ', 132.03847189872496)\n",
      "('Epoch: ', 34, ' Average loss at step ', 761, ': ', 2822.5570706016138)\n",
      "('Epoch: ', 34, ' Average loss at step ', 782, ': ', 2896.4626730553778)\n",
      "('Epoch: ', 34, ' Average loss at step ', 787, ': ', 54.539928936169652)\n",
      "('Epoch: ', 34, ' Average loss at step ', 1000, ': ', 31.715390613555908)\n",
      "('Epoch: ', 34, ' Average loss at step ', 2000, ': ', 31.164261550903319)\n",
      "('Epoch: ', 34, ' Average loss at step ', 2813, ': ', 30.944682607509819)\n",
      "Training time took 97.849336 seconds to run 1 epoch\n",
      "('Epoch: ', 35, ' Average loss at step ', 1000, ': ', 0.43059663015604022)\n",
      "('Epoch: ', 35, ' Average loss at step ', 2000, ': ', 0.36586593711376192)\n",
      "('Epoch: ', 35, ' Average loss at step ', 2813, ': ', 0.33111954337270388)\n",
      "Training time took 44.021577 seconds to run 1 epoch\n",
      "('Epoch: ', 36, ' Average loss at step ', 1000, ': ', 127.64986407852173)\n",
      "('Epoch: ', 36, ' Average loss at step ', 2000, ': ', 126.6231919593811)\n",
      "('Epoch: ', 36, ' Average loss at step ', 3000, ': ', 127.94806329727173)\n",
      "('Epoch: ', 36, ' Average loss at step ', 4000, ': ', 127.91060726928711)\n",
      "('Epoch: ', 36, ' Average loss at step ', 4373, ': ', 127.34381257334063)\n",
      "('Epoch: ', 36, ' Average loss at step ', 761, ': ', 2879.618211926912)\n",
      "('Epoch: ', 36, ' Average loss at step ', 782, ': ', 2994.089346715949)\n",
      "('Epoch: ', 36, ' Average loss at step ', 787, ': ', 52.924903762856211)\n",
      "('Epoch: ', 36, ' Average loss at step ', 1000, ': ', 29.35497766304016)\n",
      "('Epoch: ', 36, ' Average loss at step ', 2000, ': ', 29.402101287841798)\n",
      "('Epoch: ', 36, ' Average loss at step ', 2813, ': ', 28.963858503426238)\n",
      "Training time took 97.741444 seconds to run 1 epoch\n",
      "('Epoch: ', 37, ' Average loss at step ', 1000, ': ', 0.40448270678520204)\n",
      "('Epoch: ', 37, ' Average loss at step ', 2000, ': ', 0.33984881818294527)\n",
      "('Epoch: ', 37, ' Average loss at step ', 2813, ': ', 0.31366850076050595)\n",
      "Training time took 44.075182 seconds to run 1 epoch\n",
      "('Epoch: ', 38, ' Average loss at step ', 1000, ': ', 128.13054238891601)\n",
      "('Epoch: ', 38, ' Average loss at step ', 2000, ': ', 129.3203002319336)\n",
      "('Epoch: ', 38, ' Average loss at step ', 3000, ': ', 128.63721964645384)\n",
      "('Epoch: ', 38, ' Average loss at step ', 4000, ': ', 127.18613258361816)\n",
      "('Epoch: ', 38, ' Average loss at step ', 4373, ': ', 130.75024658121089)\n",
      "('Epoch: ', 38, ' Average loss at step ', 761, ': ', 2941.3419342041016)\n",
      "('Epoch: ', 38, ' Average loss at step ', 782, ': ', 3119.286357571923)\n",
      "('Epoch: ', 38, ' Average loss at step ', 787, ': ', 51.234167395050591)\n",
      "('Epoch: ', 38, ' Average loss at step ', 1000, ': ', 27.660376970291139)\n",
      "('Epoch: ', 38, ' Average loss at step ', 2000, ': ', 27.192083855628969)\n",
      "('Epoch: ', 38, ' Average loss at step ', 2813, ': ', 27.010515431465187)\n",
      "Training time took 97.692511 seconds to run 1 epoch\n",
      "('Epoch: ', 39, ' Average loss at step ', 1000, ': ', 0.37448599350452422)\n",
      "('Epoch: ', 39, ' Average loss at step ', 2000, ': ', 0.3197582848072052)\n",
      "('Epoch: ', 39, ' Average loss at step ', 2813, ': ', 0.29374799205751839)\n",
      "Training time took 44.013453 seconds to run 1 epoch\n",
      "Mean Rank:  16  of  28683\n",
      "Hits @ 10:  0.942494996664\n",
      "Hits @ 1:  0.827951967979\n",
      "Testing time took 72.986325 seconds.\n",
      "\n",
      "('Epoch: ', 40, ' Average loss at step ', 1000, ': ', 127.59673018646241)\n",
      "('Epoch: ', 40, ' Average loss at step ', 2000, ': ', 128.71258975982667)\n",
      "('Epoch: ', 40, ' Average loss at step ', 3000, ': ', 126.52124321746827)\n",
      "('Epoch: ', 40, ' Average loss at step ', 4000, ': ', 128.19557289123534)\n",
      "('Epoch: ', 40, ' Average loss at step ', 4373, ': ', 127.56839705026277)\n",
      "('Epoch: ', 40, ' Average loss at step ', 761, ': ', 3037.5229770058081)\n",
      "('Epoch: ', 40, ' Average loss at step ', 782, ': ', 3249.0178625910289)\n",
      "('Epoch: ', 40, ' Average loss at step ', 787, ': ', 49.501680180013331)\n",
      "('Epoch: ', 40, ' Average loss at step ', 1000, ': ', 25.705804785728454)\n",
      "('Epoch: ', 40, ' Average loss at step ', 2000, ': ', 25.518325367927552)\n",
      "('Epoch: ', 40, ' Average loss at step ', 2813, ': ', 25.291863942968433)\n",
      "Training time took 97.737887 seconds to run 1 epoch\n",
      "('Epoch: ', 41, ' Average loss at step ', 1000, ': ', 0.34602408236265181)\n",
      "('Epoch: ', 41, ' Average loss at step ', 2000, ': ', 0.30098159670829772)\n",
      "('Epoch: ', 41, ' Average loss at step ', 2813, ': ', 0.28023526512930547)\n",
      "Training time took 44.013575 seconds to run 1 epoch\n",
      "('Epoch: ', 42, ' Average loss at step ', 1000, ': ', 130.25191189575196)\n",
      "('Epoch: ', 42, ' Average loss at step ', 2000, ': ', 127.31828506088257)\n",
      "('Epoch: ', 42, ' Average loss at step ', 3000, ': ', 126.85975758361816)\n",
      "('Epoch: ', 42, ' Average loss at step ', 4000, ': ', 128.9381395111084)\n",
      "('Epoch: ', 42, ' Average loss at step ', 4373, ': ', 128.83071671762775)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 42, ' Average loss at step ', 761, ': ', 3088.7842972604853)\n",
      "('Epoch: ', 42, ' Average loss at step ', 782, ': ', 3321.030529144326)\n",
      "('Epoch: ', 42, ' Average loss at step ', 787, ': ', 47.863610735983038)\n",
      "('Epoch: ', 42, ' Average loss at step ', 1000, ': ', 23.943683571815491)\n",
      "('Epoch: ', 42, ' Average loss at step ', 2000, ': ', 23.774764961242674)\n",
      "('Epoch: ', 42, ' Average loss at step ', 2813, ': ', 23.550187574818803)\n",
      "Training time took 97.696186 seconds to run 1 epoch\n",
      "('Epoch: ', 43, ' Average loss at step ', 1000, ': ', 0.32733891910314561)\n",
      "('Epoch: ', 43, ' Average loss at step ', 2000, ': ', 0.28636262273788454)\n",
      "('Epoch: ', 43, ' Average loss at step ', 2813, ': ', 0.26216180894175184)\n",
      "Training time took 44.026122 seconds to run 1 epoch\n",
      "('Epoch: ', 44, ' Average loss at step ', 1000, ': ', 127.85125186157227)\n",
      "('Epoch: ', 44, ' Average loss at step ', 2000, ': ', 127.89133874511718)\n",
      "('Epoch: ', 44, ' Average loss at step ', 3000, ': ', 128.08205461502075)\n",
      "('Epoch: ', 44, ' Average loss at step ', 4000, ': ', 128.76528498840332)\n",
      "('Epoch: ', 44, ' Average loss at step ', 4373, ': ', 132.24046905066376)\n",
      "('Epoch: ', 44, ' Average loss at step ', 761, ': ', 3146.0706093236022)\n",
      "('Epoch: ', 44, ' Average loss at step ', 782, ': ', 3434.7619378826225)\n",
      "('Epoch: ', 44, ' Average loss at step ', 787, ': ', 47.15059830760228)\n",
      "('Epoch: ', 44, ' Average loss at step ', 1000, ': ', 22.562566720008849)\n",
      "('Epoch: ', 44, ' Average loss at step ', 2000, ': ', 22.259137237548828)\n",
      "('Epoch: ', 44, ' Average loss at step ', 2813, ': ', 22.359130599815856)\n",
      "Training time took 97.782266 seconds to run 1 epoch\n",
      "('Epoch: ', 45, ' Average loss at step ', 1000, ': ', 0.3112545991539955)\n",
      "('Epoch: ', 45, ' Average loss at step ', 2000, ': ', 0.27231635254621506)\n",
      "('Epoch: ', 45, ' Average loss at step ', 2813, ': ', 0.25029896280448427)\n",
      "Training time took 44.017405 seconds to run 1 epoch\n",
      "('Epoch: ', 46, ' Average loss at step ', 1000, ': ', 128.13072403717041)\n",
      "('Epoch: ', 46, ' Average loss at step ', 2000, ': ', 128.34564564514159)\n",
      "('Epoch: ', 46, ' Average loss at step ', 3000, ': ', 127.55324593734741)\n",
      "('Epoch: ', 46, ' Average loss at step ', 4000, ': ', 127.32283238220215)\n",
      "('Epoch: ', 46, ' Average loss at step ', 4373, ': ', 129.01647832316738)\n",
      "('Epoch: ', 46, ' Average loss at step ', 761, ': ', 3209.5869351035672)\n",
      "('Epoch: ', 46, ' Average loss at step ', 782, ': ', 3525.9576695792653)\n",
      "('Epoch: ', 46, ' Average loss at step ', 787, ': ', 45.808940720012167)\n",
      "('Epoch: ', 46, ' Average loss at step ', 1000, ': ', 21.006928781509398)\n",
      "('Epoch: ', 46, ' Average loss at step ', 2000, ': ', 21.043865311622621)\n",
      "('Epoch: ', 46, ' Average loss at step ', 2813, ': ', 20.787700891494751)\n",
      "Training time took 97.672079 seconds to run 1 epoch\n",
      "('Epoch: ', 47, ' Average loss at step ', 1000, ': ', 0.28925809085369109)\n",
      "('Epoch: ', 47, ' Average loss at step ', 2000, ': ', 0.25883967238664629)\n",
      "('Epoch: ', 47, ' Average loss at step ', 2813, ': ', 0.23900597891196829)\n",
      "Training time took 44.025518 seconds to run 1 epoch\n",
      "('Epoch: ', 48, ' Average loss at step ', 1000, ': ', 128.44027805328369)\n",
      "('Epoch: ', 48, ' Average loss at step ', 2000, ': ', 130.33106600189208)\n",
      "('Epoch: ', 48, ' Average loss at step ', 3000, ': ', 128.10825010681151)\n",
      "('Epoch: ', 48, ' Average loss at step ', 4000, ': ', 129.11137564849852)\n",
      "('Epoch: ', 48, ' Average loss at step ', 4373, ': ', 126.71943738383632)\n",
      "('Epoch: ', 48, ' Average loss at step ', 761, ': ', 3286.107269608347)\n",
      "('Epoch: ', 48, ' Average loss at step ', 782, ': ', 3588.01748059379)\n",
      "('Epoch: ', 48, ' Average loss at step ', 787, ': ', 44.646442180371466)\n",
      "('Epoch: ', 48, ' Average loss at step ', 1000, ': ', 19.889735906600951)\n",
      "('Epoch: ', 48, ' Average loss at step ', 2000, ': ', 19.95851836204529)\n",
      "('Epoch: ', 48, ' Average loss at step ', 2813, ': ', 19.831260731654801)\n",
      "Training time took 97.726722 seconds to run 1 epoch\n",
      "('Epoch: ', 49, ' Average loss at step ', 1000, ': ', 0.27965473836660387)\n",
      "('Epoch: ', 49, ' Average loss at step ', 2000, ': ', 0.24690082001686095)\n",
      "('Epoch: ', 49, ' Average loss at step ', 2813, ': ', 0.22742400725780448)\n",
      "Training time took 44.043314 seconds to run 1 epoch\n",
      "Mean Rank:  12  of  28683\n",
      "Hits @ 10:  0.958372248165\n",
      "Hits @ 1:  0.875517011341\n",
      "Testing time took 73.012402 seconds.\n",
      "\n",
      "('Epoch: ', 50, ' Average loss at step ', 1000, ': ', 128.17028579330443)\n",
      "('Epoch: ', 50, ' Average loss at step ', 2000, ': ', 127.67035453796387)\n",
      "('Epoch: ', 50, ' Average loss at step ', 3000, ': ', 128.28662219238282)\n",
      "('Epoch: ', 50, ' Average loss at step ', 4000, ': ', 129.15772283172606)\n",
      "('Epoch: ', 50, ' Average loss at step ', 4373, ': ', 127.9941445935157)\n",
      "('Epoch: ', 50, ' Average loss at step ', 761, ': ', 3364.7766967773437)\n",
      "('Epoch: ', 50, ' Average loss at step ', 782, ': ', 3667.0139410236275)\n",
      "('Epoch: ', 50, ' Average loss at step ', 787, ': ', 44.19349316604265)\n",
      "('Epoch: ', 50, ' Average loss at step ', 1000, ': ', 18.819802378654479)\n",
      "('Epoch: ', 50, ' Average loss at step ', 2000, ': ', 18.874516859054566)\n",
      "('Epoch: ', 50, ' Average loss at step ', 2813, ': ', 18.902511495674773)\n",
      "Training time took 97.666528 seconds to run 1 epoch\n",
      "('Epoch: ', 51, ' Average loss at step ', 1000, ': ', 0.26549892240762712)\n",
      "('Epoch: ', 51, ' Average loss at step ', 2000, ': ', 0.23619890123605727)\n",
      "('Epoch: ', 51, ' Average loss at step ', 2813, ': ', 0.21838801321137716)\n",
      "Training time took 44.016305 seconds to run 1 epoch\n",
      "('Epoch: ', 52, ' Average loss at step ', 1000, ': ', 127.77610221099853)\n",
      "('Epoch: ', 52, ' Average loss at step ', 2000, ': ', 128.59660142517089)\n",
      "('Epoch: ', 52, ' Average loss at step ', 3000, ': ', 127.66446800994873)\n",
      "('Epoch: ', 52, ' Average loss at step ', 4000, ': ', 125.79299745178223)\n",
      "('Epoch: ', 52, ' Average loss at step ', 4373, ': ', 128.88301285364295)\n",
      "('Epoch: ', 52, ' Average loss at step ', 761, ': ', 3388.3658066598991)\n",
      "('Epoch: ', 52, ' Average loss at step ', 782, ': ', 3760.3037462613038)\n",
      "('Epoch: ', 52, ' Average loss at step ', 787, ': ', 43.228425969907647)\n",
      "('Epoch: ', 52, ' Average loss at step ', 1000, ': ', 18.188930050849915)\n",
      "('Epoch: ', 52, ' Average loss at step ', 2000, ': ', 17.855063476562499)\n",
      "('Epoch: ', 52, ' Average loss at step ', 2813, ': ', 17.998132099071746)\n",
      "Training time took 97.602274 seconds to run 1 epoch\n",
      "('Epoch: ', 53, ' Average loss at step ', 1000, ': ', 0.25036901676654816)\n",
      "('Epoch: ', 53, ' Average loss at step ', 2000, ': ', 0.22478730946779252)\n",
      "('Epoch: ', 53, ' Average loss at step ', 2813, ': ', 0.21130872301280204)\n",
      "Training time took 44.030924 seconds to run 1 epoch\n",
      "('Epoch: ', 54, ' Average loss at step ', 1000, ': ', 127.87105965423584)\n",
      "('Epoch: ', 54, ' Average loss at step ', 2000, ': ', 128.25885789108276)\n",
      "('Epoch: ', 54, ' Average loss at step ', 3000, ': ', 126.50974441528321)\n",
      "('Epoch: ', 54, ' Average loss at step ', 4000, ': ', 127.88263269424438)\n",
      "('Epoch: ', 54, ' Average loss at step ', 4373, ': ', 127.86352410880468)\n",
      "('Epoch: ', 54, ' Average loss at step ', 761, ': ', 3385.4058233963815)\n",
      "('Epoch: ', 54, ' Average loss at step ', 782, ': ', 3840.2493441651327)\n",
      "('Epoch: ', 54, ' Average loss at step ', 787, ': ', 43.032918095285353)\n",
      "('Epoch: ', 54, ' Average loss at step ', 1000, ': ', 17.061343703269959)\n",
      "('Epoch: ', 54, ' Average loss at step ', 2000, ': ', 16.994656828880309)\n",
      "('Epoch: ', 54, ' Average loss at step ', 2813, ': ', 17.19554570743016)\n",
      "Training time took 97.723192 seconds to run 1 epoch\n",
      "('Epoch: ', 55, ' Average loss at step ', 1000, ': ', 0.24479437577724455)\n",
      "('Epoch: ', 55, ' Average loss at step ', 2000, ': ', 0.21767127513885498)\n",
      "('Epoch: ', 55, ' Average loss at step ', 2813, ': ', 0.20230191322089416)\n",
      "Training time took 44.04354 seconds to run 1 epoch\n",
      "('Epoch: ', 56, ' Average loss at step ', 1000, ': ', 126.72521579742431)\n",
      "('Epoch: ', 56, ' Average loss at step ', 2000, ': ', 126.63926699066162)\n",
      "('Epoch: ', 56, ' Average loss at step ', 3000, ': ', 127.80373620605469)\n",
      "('Epoch: ', 56, ' Average loss at step ', 4000, ': ', 128.22868081665038)\n",
      "('Epoch: ', 56, ' Average loss at step ', 4373, ': ', 128.37633500047909)\n",
      "('Epoch: ', 56, ' Average loss at step ', 761, ': ', 3514.343033961246)\n",
      "('Epoch: ', 56, ' Average loss at step ', 782, ': ', 3914.7840649632881)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 56, ' Average loss at step ', 787, ': ', 41.531173485229338)\n",
      "('Epoch: ', 56, ' Average loss at step ', 1000, ': ', 16.397149035930635)\n",
      "('Epoch: ', 56, ' Average loss at step ', 2000, ': ', 16.19907328224182)\n",
      "('Epoch: ', 56, ' Average loss at step ', 2813, ': ', 16.374747639806401)\n",
      "Training time took 97.761896 seconds to run 1 epoch\n",
      "('Epoch: ', 57, ' Average loss at step ', 1000, ': ', 0.22975632899999618)\n",
      "('Epoch: ', 57, ' Average loss at step ', 2000, ': ', 0.20936752998828889)\n",
      "('Epoch: ', 57, ' Average loss at step ', 2813, ': ', 0.19411724622320073)\n",
      "Training time took 44.044488 seconds to run 1 epoch\n",
      "('Epoch: ', 58, ' Average loss at step ', 1000, ': ', 127.23785108566284)\n",
      "('Epoch: ', 58, ' Average loss at step ', 2000, ': ', 128.79525581741333)\n",
      "('Epoch: ', 58, ' Average loss at step ', 3000, ': ', 130.51867180633545)\n",
      "('Epoch: ', 58, ' Average loss at step ', 4000, ': ', 128.39502011871338)\n",
      "('Epoch: ', 58, ' Average loss at step ', 4373, ': ', 128.76710729701546)\n",
      "('Epoch: ', 58, ' Average loss at step ', 761, ': ', 3546.8465760883532)\n",
      "('Epoch: ', 58, ' Average loss at step ', 782, ': ', 3967.0968800641203)\n",
      "('Epoch: ', 58, ' Average loss at step ', 787, ': ', 41.402764019468663)\n",
      "('Epoch: ', 58, ' Average loss at step ', 1000, ': ', 15.598057869434356)\n",
      "('Epoch: ', 58, ' Average loss at step ', 2000, ': ', 15.636253252983094)\n",
      "('Epoch: ', 58, ' Average loss at step ', 2813, ': ', 15.868054099858101)\n",
      "Training time took 97.72275 seconds to run 1 epoch\n",
      "('Epoch: ', 59, ' Average loss at step ', 1000, ': ', 0.22092730766534804)\n",
      "('Epoch: ', 59, ' Average loss at step ', 2000, ': ', 0.20202690106630325)\n",
      "('Epoch: ', 59, ' Average loss at step ', 2813, ': ', 0.18932577358384436)\n",
      "Training time took 44.009475 seconds to run 1 epoch\n",
      "Mean Rank:  10  of  28683\n",
      "Hits @ 10:  0.964843228819\n",
      "Hits @ 1:  0.901000667111\n",
      "Testing time took 73.02592 seconds.\n",
      "\n",
      "('Epoch: ', 60, ' Average loss at step ', 1000, ': ', 127.59145233154297)\n",
      "('Epoch: ', 60, ' Average loss at step ', 2000, ': ', 129.34174913787842)\n",
      "('Epoch: ', 60, ' Average loss at step ', 3000, ': ', 126.88870471191406)\n",
      "('Epoch: ', 60, ' Average loss at step ', 4000, ': ', 128.15635671234131)\n",
      "('Epoch: ', 60, ' Average loss at step ', 4373, ': ', 128.33135762778662)\n",
      "('Epoch: ', 60, ' Average loss at step ', 761, ': ', 3562.0107140792043)\n",
      "('Epoch: ', 60, ' Average loss at step ', 782, ': ', 4003.0907171544895)\n",
      "('Epoch: ', 60, ' Average loss at step ', 787, ': ', 40.597634689195161)\n",
      "('Epoch: ', 60, ' Average loss at step ', 1000, ': ', 15.190543571472167)\n",
      "('Epoch: ', 60, ' Average loss at step ', 2000, ': ', 15.00715732049942)\n",
      "('Epoch: ', 60, ' Average loss at step ', 2813, ': ', 15.038159275289827)\n",
      "Training time took 97.728155 seconds to run 1 epoch\n",
      "('Epoch: ', 61, ' Average loss at step ', 1000, ': ', 0.21333243650197983)\n",
      "('Epoch: ', 61, ' Average loss at step ', 2000, ': ', 0.19450458890199662)\n",
      "('Epoch: ', 61, ' Average loss at step ', 2813, ': ', 0.180721983166751)\n",
      "Training time took 44.039666 seconds to run 1 epoch\n",
      "('Epoch: ', 62, ' Average loss at step ', 1000, ': ', 128.19796588897705)\n",
      "('Epoch: ', 62, ' Average loss at step ', 2000, ': ', 127.22488259887696)\n",
      "('Epoch: ', 62, ' Average loss at step ', 3000, ': ', 128.25238187408448)\n",
      "('Epoch: ', 62, ' Average loss at step ', 4000, ': ', 129.02698651504517)\n",
      "('Epoch: ', 62, ' Average loss at step ', 4373, ': ', 130.46175136361072)\n",
      "('Epoch: ', 62, ' Average loss at step ', 761, ': ', 3615.4667496530633)\n",
      "('Epoch: ', 62, ' Average loss at step ', 782, ': ', 4048.3384511168574)\n",
      "('Epoch: ', 62, ' Average loss at step ', 787, ': ', 40.318226673524194)\n",
      "('Epoch: ', 62, ' Average loss at step ', 1000, ': ', 14.623814617633819)\n",
      "('Epoch: ', 62, ' Average loss at step ', 2000, ': ', 14.509314610481262)\n",
      "('Epoch: ', 62, ' Average loss at step ', 2813, ': ', 14.558935934686895)\n",
      "Training time took 97.689602 seconds to run 1 epoch\n",
      "('Epoch: ', 63, ' Average loss at step ', 1000, ': ', 0.20695893913507463)\n",
      "('Epoch: ', 63, ' Average loss at step ', 2000, ': ', 0.18649868714809417)\n",
      "('Epoch: ', 63, ' Average loss at step ', 2813, ': ', 0.17492178508213588)\n",
      "Training time took 44.025083 seconds to run 1 epoch\n",
      "('Epoch: ', 64, ' Average loss at step ', 1000, ': ', 128.86789444732665)\n",
      "('Epoch: ', 64, ' Average loss at step ', 2000, ': ', 128.26176624298097)\n",
      "('Epoch: ', 64, ' Average loss at step ', 3000, ': ', 129.27924338912965)\n",
      "('Epoch: ', 64, ' Average loss at step ', 4000, ': ', 126.600959690094)\n",
      "('Epoch: ', 64, ' Average loss at step ', 4373, ': ', 128.44582502303584)\n",
      "('Epoch: ', 64, ' Average loss at step ', 761, ': ', 3676.0737041272614)\n",
      "('Epoch: ', 64, ' Average loss at step ', 782, ': ', 4106.7499828069986)\n",
      "('Epoch: ', 64, ' Average loss at step ', 787, ': ', 39.801495690382161)\n",
      "('Epoch: ', 64, ' Average loss at step ', 1000, ': ', 13.935804078102112)\n",
      "('Epoch: ', 64, ' Average loss at step ', 2000, ': ', 13.854485390663147)\n",
      "('Epoch: ', 64, ' Average loss at step ', 2813, ': ', 13.907890527706428)\n",
      "Training time took 97.829356 seconds to run 1 epoch\n",
      "('Epoch: ', 65, ' Average loss at step ', 1000, ': ', 0.19844653379917146)\n",
      "('Epoch: ', 65, ' Average loss at step ', 2000, ': ', 0.18179658490419387)\n",
      "('Epoch: ', 65, ' Average loss at step ', 2813, ': ', 0.17093674089814642)\n",
      "Training time took 44.005532 seconds to run 1 epoch\n",
      "('Epoch: ', 66, ' Average loss at step ', 1000, ': ', 128.22239740753173)\n",
      "('Epoch: ', 66, ' Average loss at step ', 2000, ': ', 128.01465924835205)\n",
      "('Epoch: ', 66, ' Average loss at step ', 3000, ': ', 126.25589521026612)\n",
      "('Epoch: ', 66, ' Average loss at step ', 4000, ': ', 127.28079680633545)\n",
      "('Epoch: ', 66, ' Average loss at step ', 4373, ': ', 130.02743226738386)\n",
      "('Epoch: ', 66, ' Average loss at step ', 761, ': ', 3714.8650430779708)\n",
      "('Epoch: ', 66, ' Average loss at step ', 782, ': ', 4190.7491537917131)\n",
      "('Epoch: ', 66, ' Average loss at step ', 787, ': ', 39.295654804045313)\n",
      "('Epoch: ', 66, ' Average loss at step ', 1000, ': ', 13.608426222324372)\n",
      "('Epoch: ', 66, ' Average loss at step ', 2000, ': ', 13.490915405273437)\n",
      "('Epoch: ', 66, ' Average loss at step ', 2813, ': ', 13.457586199779229)\n",
      "Training time took 97.823495 seconds to run 1 epoch\n",
      "('Epoch: ', 67, ' Average loss at step ', 1000, ': ', 0.19314749455451966)\n",
      "('Epoch: ', 67, ' Average loss at step ', 2000, ': ', 0.17661759746074676)\n",
      "('Epoch: ', 67, ' Average loss at step ', 2813, ': ', 0.1631269716276911)\n",
      "Training time took 44.045501 seconds to run 1 epoch\n",
      "('Epoch: ', 68, ' Average loss at step ', 1000, ': ', 128.98750511550904)\n",
      "('Epoch: ', 68, ' Average loss at step ', 2000, ': ', 129.17571561431885)\n",
      "('Epoch: ', 68, ' Average loss at step ', 3000, ': ', 128.70974206542968)\n",
      "('Epoch: ', 68, ' Average loss at step ', 4000, ': ', 128.13874307250975)\n",
      "('Epoch: ', 68, ' Average loss at step ', 4373, ': ', 129.69617097095778)\n",
      "('Epoch: ', 68, ' Average loss at step ', 761, ': ', 3791.1232152035363)\n",
      "('Epoch: ', 68, ' Average loss at step ', 782, ': ', 4267.487946455366)\n",
      "('Epoch: ', 68, ' Average loss at step ', 787, ': ', 38.767772732800196)\n",
      "('Epoch: ', 68, ' Average loss at step ', 1000, ': ', 13.119588686466217)\n",
      "('Epoch: ', 68, ' Average loss at step ', 2000, ': ', 13.38806808423996)\n",
      "('Epoch: ', 68, ' Average loss at step ', 2813, ': ', 13.01661482526751)\n",
      "Training time took 97.793996 seconds to run 1 epoch\n",
      "('Epoch: ', 69, ' Average loss at step ', 1000, ': ', 0.18725213837623597)\n",
      "('Epoch: ', 69, ' Average loss at step ', 2000, ': ', 0.17030297833681107)\n",
      "('Epoch: ', 69, ' Average loss at step ', 2813, ': ', 0.15995945792480054)\n",
      "Training time took 44.055819 seconds to run 1 epoch\n",
      "Mean Rank:  8  of  28683\n",
      "Hits @ 10:  0.969112741828\n",
      "Hits @ 1:  0.912408272181\n",
      "Testing time took 73.029716 seconds.\n",
      "\n",
      "('Epoch: ', 70, ' Average loss at step ', 1000, ': ', 129.08431326293945)\n",
      "('Epoch: ', 70, ' Average loss at step ', 2000, ': ', 127.94524374008179)\n",
      "('Epoch: ', 70, ' Average loss at step ', 3000, ': ', 130.06445527267456)\n",
      "('Epoch: ', 70, ' Average loss at step ', 4000, ': ', 128.75548041915894)\n",
      "('Epoch: ', 70, ' Average loss at step ', 4373, ': ', 128.12908480244297)\n",
      "('Epoch: ', 70, ' Average loss at step ', 761, ': ', 3823.7700734991777)\n",
      "('Epoch: ', 70, ' Average loss at step ', 782, ': ', 4316.5555821612916)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 70, ' Average loss at step ', 787, ': ', 37.895871970489736)\n",
      "('Epoch: ', 70, ' Average loss at step ', 1000, ': ', 12.779837658882141)\n",
      "('Epoch: ', 70, ' Average loss at step ', 2000, ': ', 12.728679244995117)\n",
      "('Epoch: ', 70, ' Average loss at step ', 2813, ': ', 12.706481302900267)\n",
      "Training time took 97.799208 seconds to run 1 epoch\n",
      "('Epoch: ', 71, ' Average loss at step ', 1000, ': ', 0.18065641015768052)\n",
      "('Epoch: ', 71, ' Average loss at step ', 2000, ': ', 0.16535442525148392)\n",
      "('Epoch: ', 71, ' Average loss at step ', 2813, ': ', 0.15632597279959712)\n",
      "Training time took 44.042284 seconds to run 1 epoch\n",
      "('Epoch: ', 72, ' Average loss at step ', 1000, ': ', 130.02124299621582)\n",
      "('Epoch: ', 72, ' Average loss at step ', 2000, ': ', 128.40466687393189)\n",
      "('Epoch: ', 72, ' Average loss at step ', 3000, ': ', 126.02797996139526)\n",
      "('Epoch: ', 72, ' Average loss at step ', 4000, ': ', 129.00782164001464)\n",
      "('Epoch: ', 72, ' Average loss at step ', 4373, ': ', 127.88820032919607)\n",
      "('Epoch: ', 72, ' Average loss at step ', 761, ': ', 3866.0621633429278)\n",
      "('Epoch: ', 72, ' Average loss at step ', 782, ': ', 4362.204763649368)\n",
      "('Epoch: ', 72, ' Average loss at step ', 787, ': ', 37.789659005085021)\n",
      "('Epoch: ', 72, ' Average loss at step ', 1000, ': ', 12.312962821960449)\n",
      "('Epoch: ', 72, ' Average loss at step ', 2000, ': ', 12.560133771896362)\n",
      "('Epoch: ', 72, ' Average loss at step ', 2813, ': ', 12.41169596481793)\n",
      "Training time took 97.741726 seconds to run 1 epoch\n",
      "('Epoch: ', 73, ' Average loss at step ', 1000, ': ', 0.17513271123170854)\n",
      "('Epoch: ', 73, ' Average loss at step ', 2000, ': ', 0.159534874022007)\n",
      "('Epoch: ', 73, ' Average loss at step ', 2813, ': ', 0.15094503077673796)\n",
      "Training time took 44.03306 seconds to run 1 epoch\n",
      "('Epoch: ', 74, ' Average loss at step ', 1000, ': ', 128.8678296585083)\n",
      "('Epoch: ', 74, ' Average loss at step ', 2000, ': ', 127.55249430084228)\n",
      "('Epoch: ', 74, ' Average loss at step ', 3000, ': ', 128.09777487182618)\n",
      "('Epoch: ', 74, ' Average loss at step ', 4000, ': ', 129.24068790435791)\n",
      "('Epoch: ', 74, ' Average loss at step ', 4373, ': ', 129.02252605397214)\n",
      "('Epoch: ', 74, ' Average loss at step ', 761, ': ', 3901.8655067845393)\n",
      "('Epoch: ', 74, ' Average loss at step ', 782, ': ', 4407.3392566871398)\n",
      "('Epoch: ', 74, ' Average loss at step ', 787, ': ', 36.809897507723356)\n",
      "('Epoch: ', 74, ' Average loss at step ', 1000, ': ', 12.164847661495209)\n",
      "('Epoch: ', 74, ' Average loss at step ', 2000, ': ', 11.86502314376831)\n",
      "('Epoch: ', 74, ' Average loss at step ', 2813, ': ', 12.034695658190497)\n",
      "Training time took 97.700429 seconds to run 1 epoch\n",
      "('Epoch: ', 75, ' Average loss at step ', 1000, ': ', 0.17070191019773484)\n",
      "('Epoch: ', 75, ' Average loss at step ', 2000, ': ', 0.15685330605506898)\n",
      "('Epoch: ', 75, ' Average loss at step ', 2813, ': ', 0.14631630318799041)\n",
      "Training time took 44.058243 seconds to run 1 epoch\n",
      "('Epoch: ', 76, ' Average loss at step ', 1000, ': ', 128.60222850799562)\n",
      "('Epoch: ', 76, ' Average loss at step ', 2000, ': ', 128.47260176849366)\n",
      "('Epoch: ', 76, ' Average loss at step ', 3000, ': ', 128.08052593231201)\n",
      "('Epoch: ', 76, ' Average loss at step ', 4000, ': ', 127.33816794586181)\n",
      "('Epoch: ', 76, ' Average loss at step ', 4373, ': ', 126.87148348490398)\n",
      "('Epoch: ', 76, ' Average loss at step ', 761, ': ', 3942.6710609837583)\n",
      "('Epoch: ', 76, ' Average loss at step ', 782, ': ', 4414.7843603703186)\n",
      "('Epoch: ', 76, ' Average loss at step ', 787, ': ', 36.549989850769819)\n",
      "('Epoch: ', 76, ' Average loss at step ', 1000, ': ', 11.85772368478775)\n",
      "('Epoch: ', 76, ' Average loss at step ', 2000, ': ', 11.809061961650848)\n",
      "('Epoch: ', 76, ' Average loss at step ', 2813, ': ', 11.90603224338569)\n",
      "Training time took 97.748318 seconds to run 1 epoch\n",
      "('Epoch: ', 77, ' Average loss at step ', 1000, ': ', 0.16539566606283188)\n",
      "('Epoch: ', 77, ' Average loss at step ', 2000, ': ', 0.1515705491900444)\n",
      "('Epoch: ', 77, ' Average loss at step ', 2813, ': ', 0.14401269193940561)\n",
      "Training time took 44.039821 seconds to run 1 epoch\n",
      "('Epoch: ', 78, ' Average loss at step ', 1000, ': ', 127.66560916137695)\n",
      "('Epoch: ', 78, ' Average loss at step ', 2000, ': ', 129.83379821777345)\n",
      "('Epoch: ', 78, ' Average loss at step ', 3000, ': ', 126.55552955627441)\n",
      "('Epoch: ', 78, ' Average loss at step ', 4000, ': ', 127.44791262817382)\n",
      "('Epoch: ', 78, ' Average loss at step ', 4373, ': ', 128.80785179138184)\n",
      "('Epoch: ', 78, ' Average loss at step ', 761, ': ', 3971.6328638980262)\n",
      "('Epoch: ', 78, ' Average loss at step ', 782, ': ', 4497.8514224551855)\n",
      "('Epoch: ', 78, ' Average loss at step ', 787, ': ', 36.126325786872066)\n",
      "('Epoch: ', 78, ' Average loss at step ', 1000, ': ', 11.62641566991806)\n",
      "('Epoch: ', 78, ' Average loss at step ', 2000, ': ', 11.653786267280578)\n",
      "('Epoch: ', 78, ' Average loss at step ', 2813, ': ', 11.425043529477612)\n",
      "Training time took 97.780468 seconds to run 1 epoch\n",
      "('Epoch: ', 79, ' Average loss at step ', 1000, ': ', 0.1618320473432541)\n",
      "('Epoch: ', 79, ' Average loss at step ', 2000, ': ', 0.14883129274845122)\n",
      "('Epoch: ', 79, ' Average loss at step ', 2813, ': ', 0.13893253147014845)\n",
      "Training time took 44.014018 seconds to run 1 epoch\n",
      "Mean Rank:  7  of  28683\n",
      "Hits @ 10:  0.971847898599\n",
      "Hits @ 1:  0.918212141428\n",
      "Testing time took 72.946656 seconds.\n",
      "\n",
      "('Epoch: ', 80, ' Average loss at step ', 1000, ': ', 127.62691218566894)\n",
      "('Epoch: ', 80, ' Average loss at step ', 2000, ': ', 128.97429428863526)\n",
      "('Epoch: ', 80, ' Average loss at step ', 3000, ': ', 127.66010066986084)\n",
      "('Epoch: ', 80, ' Average loss at step ', 4000, ': ', 129.35117042541503)\n",
      "('Epoch: ', 80, ' Average loss at step ', 4373, ': ', 127.90302622190086)\n",
      "('Epoch: ', 80, ' Average loss at step ', 761, ': ', 4036.8503324809826)\n",
      "('Epoch: ', 80, ' Average loss at step ', 782, ': ', 4542.7686984835145)\n",
      "('Epoch: ', 80, ' Average loss at step ', 787, ': ', 35.936080447286749)\n",
      "('Epoch: ', 80, ' Average loss at step ', 1000, ': ', 11.478459680080414)\n",
      "('Epoch: ', 80, ' Average loss at step ', 2000, ': ', 11.220895030498504)\n",
      "('Epoch: ', 80, ' Average loss at step ', 2813, ': ', 11.507441669262102)\n",
      "Training time took 97.762858 seconds to run 1 epoch\n",
      "('Epoch: ', 81, ' Average loss at step ', 1000, ': ', 0.15639265984296799)\n",
      "('Epoch: ', 81, ' Average loss at step ', 2000, ': ', 0.14472327166795732)\n",
      "('Epoch: ', 81, ' Average loss at step ', 2813, ': ', 0.13702309197686577)\n",
      "Training time took 44.004143 seconds to run 1 epoch\n",
      "('Epoch: ', 82, ' Average loss at step ', 1000, ': ', 127.69544588470458)\n",
      "('Epoch: ', 82, ' Average loss at step ', 2000, ': ', 129.02630785751342)\n",
      "('Epoch: ', 82, ' Average loss at step ', 3000, ': ', 129.27872479629517)\n",
      "('Epoch: ', 82, ' Average loss at step ', 4000, ': ', 128.63156598663329)\n",
      "('Epoch: ', 82, ' Average loss at step ', 4373, ': ', 131.65642510690998)\n",
      "('Epoch: ', 82, ' Average loss at step ', 761, ': ', 4056.8735884817024)\n",
      "('Epoch: ', 82, ' Average loss at step ', 782, ': ', 4570.6794380451747)\n",
      "('Epoch: ', 82, ' Average loss at step ', 787, ': ', 35.536052310739763)\n",
      "('Epoch: ', 82, ' Average loss at step ', 1000, ': ', 10.947406208992005)\n",
      "('Epoch: ', 82, ' Average loss at step ', 2000, ': ', 11.047198437213897)\n",
      "('Epoch: ', 82, ' Average loss at step ', 2813, ': ', 11.049071488122047)\n",
      "Training time took 97.684444 seconds to run 1 epoch\n",
      "('Epoch: ', 83, ' Average loss at step ', 1000, ': ', 0.15302232867479323)\n",
      "('Epoch: ', 83, ' Average loss at step ', 2000, ': ', 0.14224854421615601)\n",
      "('Epoch: ', 83, ' Average loss at step ', 2813, ': ', 0.13296641027692505)\n",
      "Training time took 44.046925 seconds to run 1 epoch\n",
      "('Epoch: ', 84, ' Average loss at step ', 1000, ': ', 129.62048017883302)\n",
      "('Epoch: ', 84, ' Average loss at step ', 2000, ': ', 127.44632722473145)\n",
      "('Epoch: ', 84, ' Average loss at step ', 3000, ': ', 129.64616825103761)\n",
      "('Epoch: ', 84, ' Average loss at step ', 4000, ': ', 128.62429319763183)\n",
      "('Epoch: ', 84, ' Average loss at step ', 4373, ': ', 129.90533344720001)\n",
      "('Epoch: ', 84, ' Average loss at step ', 761, ': ', 4047.9825249922901)\n",
      "('Epoch: ', 84, ' Average loss at step ', 782, ': ', 4628.2935386198587)\n",
      "('Epoch: ', 84, ' Average loss at step ', 787, ': ', 35.21422799185639)\n",
      "('Epoch: ', 84, ' Average loss at step ', 1000, ': ', 10.799640864372254)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 84, ' Average loss at step ', 2000, ': ', 11.009416621685029)\n",
      "('Epoch: ', 84, ' Average loss at step ', 2813, ': ', 10.920253730759832)\n",
      "Training time took 97.740923 seconds to run 1 epoch\n",
      "('Epoch: ', 85, ' Average loss at step ', 1000, ': ', 0.14998801934719086)\n",
      "('Epoch: ', 85, ' Average loss at step ', 2000, ': ', 0.13794540846347808)\n",
      "('Epoch: ', 85, ' Average loss at step ', 2813, ': ', 0.1301312208762897)\n",
      "Training time took 44.018632 seconds to run 1 epoch\n",
      "('Epoch: ', 86, ' Average loss at step ', 1000, ': ', 128.32538751983643)\n",
      "('Epoch: ', 86, ' Average loss at step ', 2000, ': ', 127.23463803863525)\n",
      "('Epoch: ', 86, ' Average loss at step ', 3000, ': ', 128.1183127593994)\n",
      "('Epoch: ', 86, ' Average loss at step ', 4000, ': ', 127.64704537200927)\n",
      "('Epoch: ', 86, ' Average loss at step ', 4373, ': ', 126.36319570643927)\n",
      "('Epoch: ', 86, ' Average loss at step ', 761, ': ', 4168.5514664499387)\n",
      "('Epoch: ', 86, ' Average loss at step ', 782, ': ', 4663.750750865277)\n",
      "('Epoch: ', 86, ' Average loss at step ', 787, ': ', 34.754925992349328)\n",
      "('Epoch: ', 86, ' Average loss at step ', 1000, ': ', 10.666453803062439)\n",
      "('Epoch: ', 86, ' Average loss at step ', 2000, ': ', 10.734477484703064)\n",
      "('Epoch: ', 86, ' Average loss at step ', 2813, ': ', 10.712578604374025)\n",
      "Training time took 97.871369 seconds to run 1 epoch\n",
      "('Epoch: ', 87, ' Average loss at step ', 1000, ': ', 0.14664870023727417)\n",
      "('Epoch: ', 87, ' Average loss at step ', 2000, ': ', 0.13420964872837066)\n",
      "('Epoch: ', 87, ' Average loss at step ', 2813, ': ', 0.12815358082355538)\n",
      "Training time took 44.041736 seconds to run 1 epoch\n",
      "('Epoch: ', 88, ' Average loss at step ', 1000, ': ', 128.07115053558348)\n",
      "('Epoch: ', 88, ' Average loss at step ', 2000, ': ', 128.46036524963378)\n",
      "('Epoch: ', 88, ' Average loss at step ', 3000, ': ', 129.48512621307373)\n",
      "('Epoch: ', 88, ' Average loss at step ', 4000, ': ', 128.65344228363037)\n",
      "('Epoch: ', 88, ' Average loss at step ', 4373, ': ', 131.64312206801549)\n",
      "('Epoch: ', 88, ' Average loss at step ', 761, ': ', 4172.8747783460112)\n",
      "('Epoch: ', 88, ' Average loss at step ', 782, ': ', 4725.4741976807582)\n",
      "('Epoch: ', 88, ' Average loss at step ', 787, ': ', 34.743253821938396)\n",
      "('Epoch: ', 88, ' Average loss at step ', 1000, ': ', 10.392168822765351)\n",
      "('Epoch: ', 88, ' Average loss at step ', 2000, ': ', 10.313106522083283)\n",
      "('Epoch: ', 88, ' Average loss at step ', 2813, ': ', 10.377731716691567)\n",
      "Training time took 97.724402 seconds to run 1 epoch\n",
      "('Epoch: ', 89, ' Average loss at step ', 1000, ': ', 0.14249039500951766)\n",
      "('Epoch: ', 89, ' Average loss at step ', 2000, ': ', 0.13195274430513382)\n",
      "('Epoch: ', 89, ' Average loss at step ', 2813, ': ', 0.12511132782315973)\n",
      "Training time took 44.022356 seconds to run 1 epoch\n",
      "Mean Rank:  6  of  28683\n",
      "Hits @ 10:  0.972381587725\n",
      "Hits @ 1:  0.920947298199\n",
      "Testing time took 73.043143 seconds.\n",
      "\n",
      "('Epoch: ', 90, ' Average loss at step ', 1000, ': ', 127.86051770782471)\n",
      "('Epoch: ', 90, ' Average loss at step ', 2000, ': ', 125.82060961151123)\n",
      "('Epoch: ', 90, ' Average loss at step ', 3000, ': ', 128.7020811843872)\n",
      "('Epoch: ', 90, ' Average loss at step ', 4000, ': ', 127.72581350708008)\n",
      "('Epoch: ', 90, ' Average loss at step ', 4373, ': ', 129.28418918322492)\n",
      "('Epoch: ', 90, ' Average loss at step ', 761, ': ', 4139.1981393914475)\n",
      "('Epoch: ', 90, ' Average loss at step ', 782, ': ', 4801.3959392005445)\n",
      "('Epoch: ', 90, ' Average loss at step ', 787, ': ', 34.006879032416499)\n",
      "('Epoch: ', 90, ' Average loss at step ', 1000, ': ', 10.311627301216125)\n",
      "('Epoch: ', 90, ' Average loss at step ', 2000, ': ', 10.252808413028717)\n",
      "('Epoch: ', 90, ' Average loss at step ', 2813, ': ', 10.346289260046822)\n",
      "Training time took 97.754431 seconds to run 1 epoch\n",
      "('Epoch: ', 91, ' Average loss at step ', 1000, ': ', 0.13789662808179856)\n",
      "('Epoch: ', 91, ' Average loss at step ', 2000, ': ', 0.12858532261848449)\n",
      "('Epoch: ', 91, ' Average loss at step ', 2813, ': ', 0.12252924572951689)\n",
      "Training time took 44.044931 seconds to run 1 epoch\n",
      "('Epoch: ', 92, ' Average loss at step ', 1000, ': ', 127.34582076263428)\n",
      "('Epoch: ', 92, ' Average loss at step ', 2000, ': ', 128.73593829345702)\n",
      "('Epoch: ', 92, ' Average loss at step ', 3000, ': ', 128.39376897430421)\n",
      "('Epoch: ', 92, ' Average loss at step ', 4000, ': ', 128.04871715545653)\n",
      "('Epoch: ', 92, ' Average loss at step ', 4373, ': ', 128.50397601178898)\n",
      "('Epoch: ', 92, ' Average loss at step ', 761, ': ', 4208.1245618318253)\n",
      "('Epoch: ', 92, ' Average loss at step ', 782, ': ', 4766.2920962833105)\n",
      "('Epoch: ', 92, ' Average loss at step ', 787, ': ', 33.922883320097398)\n",
      "('Epoch: ', 92, ' Average loss at step ', 1000, ': ', 10.060716648101806)\n",
      "('Epoch: ', 92, ' Average loss at step ', 2000, ': ', 10.157654269218444)\n",
      "('Epoch: ', 92, ' Average loss at step ', 2813, ': ', 10.246592367223919)\n",
      "Training time took 97.732721 seconds to run 1 epoch\n",
      "('Epoch: ', 93, ' Average loss at step ', 1000, ': ', 0.13840689253807067)\n",
      "('Epoch: ', 93, ' Average loss at step ', 2000, ': ', 0.12597915822267533)\n",
      "('Epoch: ', 93, ' Average loss at step ', 2813, ': ', 0.11915443022850111)\n",
      "Training time took 44.021855 seconds to run 1 epoch\n",
      "('Epoch: ', 94, ' Average loss at step ', 1000, ': ', 128.78048707580567)\n",
      "('Epoch: ', 94, ' Average loss at step ', 2000, ': ', 126.51683164596558)\n",
      "('Epoch: ', 94, ' Average loss at step ', 3000, ': ', 127.51687272644043)\n",
      "('Epoch: ', 94, ' Average loss at step ', 4000, ': ', 126.33267136383057)\n",
      "('Epoch: ', 94, ' Average loss at step ', 4373, ': ', 129.37354820005356)\n",
      "('Epoch: ', 94, ' Average loss at step ', 761, ': ', 4321.3779971474096)\n",
      "('Epoch: ', 94, ' Average loss at step ', 782, ': ', 4861.3524899842951)\n",
      "('Epoch: ', 94, ' Average loss at step ', 787, ': ', 33.432479838985223)\n",
      "('Epoch: ', 94, ' Average loss at step ', 1000, ': ', 9.9504315314292899)\n",
      "('Epoch: ', 94, ' Average loss at step ', 2000, ': ', 9.942934978008271)\n",
      "('Epoch: ', 94, ' Average loss at step ', 2813, ': ', 9.839944002663561)\n",
      "Training time took 97.662833 seconds to run 1 epoch\n",
      "('Epoch: ', 95, ' Average loss at step ', 1000, ': ', 0.13442046213150025)\n",
      "('Epoch: ', 95, ' Average loss at step ', 2000, ': ', 0.1231343954205513)\n",
      "('Epoch: ', 95, ' Average loss at step ', 2813, ': ', 0.11686064780052072)\n",
      "Training time took 44.015969 seconds to run 1 epoch\n",
      "('Epoch: ', 96, ' Average loss at step ', 1000, ': ', 126.51584120941162)\n",
      "('Epoch: ', 96, ' Average loss at step ', 2000, ': ', 129.28612187194824)\n",
      "('Epoch: ', 96, ' Average loss at step ', 3000, ': ', 128.05826300048827)\n",
      "('Epoch: ', 96, ' Average loss at step ', 4000, ': ', 127.2269285697937)\n",
      "('Epoch: ', 96, ' Average loss at step ', 4373, ': ', 129.70655094679967)\n",
      "('Epoch: ', 96, ' Average loss at step ', 761, ': ', 4371.3828773900086)\n",
      "('Epoch: ', 96, ' Average loss at step ', 782, ': ', 4899.7766722851311)\n",
      "('Epoch: ', 96, ' Average loss at step ', 787, ': ', 33.175108686354932)\n",
      "('Epoch: ', 96, ' Average loss at step ', 1000, ': ', 9.7253633866310114)\n",
      "('Epoch: ', 96, ' Average loss at step ', 2000, ': ', 9.7335291867256171)\n",
      "('Epoch: ', 96, ' Average loss at step ', 2813, ': ', 9.8424578658465673)\n",
      "Training time took 97.729635 seconds to run 1 epoch\n",
      "('Epoch: ', 97, ' Average loss at step ', 1000, ': ', 0.13091953182220459)\n",
      "('Epoch: ', 97, ' Average loss at step ', 2000, ': ', 0.1211700833439827)\n",
      "('Epoch: ', 97, ' Average loss at step ', 2813, ': ', 0.11522615425692403)\n",
      "Training time took 44.020963 seconds to run 1 epoch\n",
      "('Epoch: ', 98, ' Average loss at step ', 1000, ': ', 128.36503504180908)\n",
      "('Epoch: ', 98, ' Average loss at step ', 2000, ': ', 129.89768379211426)\n",
      "('Epoch: ', 98, ' Average loss at step ', 3000, ': ', 128.68232260894774)\n",
      "('Epoch: ', 98, ' Average loss at step ', 4000, ': ', 128.95162336730957)\n",
      "('Epoch: ', 98, ' Average loss at step ', 4373, ': ', 129.87148463341498)\n",
      "('Epoch: ', 98, ' Average loss at step ', 761, ': ', 4378.4255364668998)\n",
      "('Epoch: ', 98, ' Average loss at step ', 782, ': ', 4918.4070899562857)\n",
      "('Epoch: ', 98, ' Average loss at step ', 787, ': ', 32.886737687593808)\n",
      "('Epoch: ', 98, ' Average loss at step ', 1000, ': ', 9.5959648346900934)\n",
      "('Epoch: ', 98, ' Average loss at step ', 2000, ': ', 9.5440602145195008)\n",
      "('Epoch: ', 98, ' Average loss at step ', 2813, ': ', 9.5598168425959322)\n",
      "Training time took 97.691495 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 99, ' Average loss at step ', 1000, ': ', 0.12824196493625642)\n",
      "('Epoch: ', 99, ' Average loss at step ', 2000, ': ', 0.11901458024978638)\n",
      "('Epoch: ', 99, ' Average loss at step ', 2813, ': ', 0.11298294247958461)\n",
      "Training time took 44.010355 seconds to run 1 epoch\n",
      "Mean Rank:  6  of  28683\n",
      "Hits @ 10:  0.972581721147\n",
      "Hits @ 1:  0.923282188125\n",
      "Testing time took 73.053877 seconds.\n",
      "\n",
      "('Epoch: ', 100, ' Average loss at step ', 1000, ': ', 129.91687604904175)\n",
      "('Epoch: ', 100, ' Average loss at step ', 2000, ': ', 127.63942826843262)\n",
      "('Epoch: ', 100, ' Average loss at step ', 3000, ': ', 127.4356870803833)\n",
      "('Epoch: ', 100, ' Average loss at step ', 4000, ': ', 128.95690196990967)\n",
      "('Epoch: ', 100, ' Average loss at step ', 4373, ': ', 128.46917640521963)\n",
      "('Epoch: ', 100, ' Average loss at step ', 761, ': ', 4412.5197927374593)\n",
      "('Epoch: ', 100, ' Average loss at step ', 782, ': ', 5020.7063410291294)\n",
      "('Epoch: ', 100, ' Average loss at step ', 787, ': ', 32.782883920742357)\n",
      "('Epoch: ', 100, ' Average loss at step ', 1000, ': ', 9.5479688072204585)\n",
      "('Epoch: ', 100, ' Average loss at step ', 2000, ': ', 9.4604426097869876)\n",
      "('Epoch: ', 100, ' Average loss at step ', 2813, ': ', 9.3952603545682187)\n",
      "Training time took 97.693163 seconds to run 1 epoch\n",
      "('Epoch: ', 101, ' Average loss at step ', 1000, ': ', 0.12568267095088959)\n",
      "('Epoch: ', 101, ' Average loss at step ', 2000, ': ', 0.11597267615795136)\n",
      "('Epoch: ', 101, ' Average loss at step ', 2813, ': ', 0.11118694038813924)\n",
      "Training time took 44.013062 seconds to run 1 epoch\n",
      "('Epoch: ', 102, ' Average loss at step ', 1000, ': ', 127.35425693511962)\n",
      "('Epoch: ', 102, ' Average loss at step ', 2000, ': ', 129.55746630096436)\n",
      "('Epoch: ', 102, ' Average loss at step ', 3000, ': ', 128.9600652999878)\n",
      "('Epoch: ', 102, ' Average loss at step ', 4000, ': ', 128.31703469085693)\n",
      "('Epoch: ', 102, ' Average loss at step ', 4373, ': ', 125.78386118078744)\n",
      "('Epoch: ', 102, ' Average loss at step ', 761, ': ', 4407.5791002775495)\n",
      "('Epoch: ', 102, ' Average loss at step ', 782, ': ', 5007.8269777578826)\n",
      "('Epoch: ', 102, ' Average loss at step ', 787, ': ', 32.233413150292314)\n",
      "('Epoch: ', 102, ' Average loss at step ', 1000, ': ', 9.3178191385269162)\n",
      "('Epoch: ', 102, ' Average loss at step ', 2000, ': ', 9.3791603569984439)\n",
      "('Epoch: ', 102, ' Average loss at step ', 2813, ': ', 9.2554791167451835)\n",
      "Training time took 97.749905 seconds to run 1 epoch\n",
      "('Epoch: ', 103, ' Average loss at step ', 1000, ': ', 0.12449328327178955)\n",
      "('Epoch: ', 103, ' Average loss at step ', 2000, ': ', 0.11405864673852921)\n",
      "('Epoch: ', 103, ' Average loss at step ', 2813, ': ', 0.10834596060179724)\n",
      "Training time took 44.047349 seconds to run 1 epoch\n",
      "('Epoch: ', 104, ' Average loss at step ', 1000, ': ', 129.702662940979)\n",
      "('Epoch: ', 104, ' Average loss at step ', 2000, ': ', 128.90745582199096)\n",
      "('Epoch: ', 104, ' Average loss at step ', 3000, ': ', 130.34726513671876)\n",
      "('Epoch: ', 104, ' Average loss at step ', 4000, ': ', 128.41059107208252)\n",
      "('Epoch: ', 104, ' Average loss at step ', 4373, ': ', 125.70405642191569)\n",
      "('Epoch: ', 104, ' Average loss at step ', 761, ': ', 4464.9826721191403)\n",
      "('Epoch: ', 104, ' Average loss at step ', 782, ': ', 5065.8196554147326)\n",
      "('Epoch: ', 104, ' Average loss at step ', 787, ': ', 32.31789683082328)\n",
      "('Epoch: ', 104, ' Average loss at step ', 1000, ': ', 9.3489816284179685)\n",
      "('Epoch: ', 104, ' Average loss at step ', 2000, ': ', 9.1154111423492434)\n",
      "('Epoch: ', 104, ' Average loss at step ', 2813, ': ', 9.1909810022767537)\n",
      "Training time took 97.84402 seconds to run 1 epoch\n",
      "('Epoch: ', 105, ' Average loss at step ', 1000, ': ', 0.12016219711303711)\n",
      "('Epoch: ', 105, ' Average loss at step ', 2000, ': ', 0.11139086955785751)\n",
      "('Epoch: ', 105, ' Average loss at step ', 2813, ': ', 0.10691523794176544)\n",
      "Training time took 44.034036 seconds to run 1 epoch\n",
      "('Epoch: ', 106, ' Average loss at step ', 1000, ': ', 128.34419563674928)\n",
      "('Epoch: ', 106, ' Average loss at step ', 2000, ': ', 128.31555642700195)\n",
      "('Epoch: ', 106, ' Average loss at step ', 3000, ': ', 128.42619512176515)\n",
      "('Epoch: ', 106, ' Average loss at step ', 4000, ': ', 128.63739569854735)\n",
      "('Epoch: ', 106, ' Average loss at step ', 4373, ': ', 127.8754524723176)\n",
      "('Epoch: ', 106, ' Average loss at step ', 761, ': ', 4454.1872282329359)\n",
      "('Epoch: ', 106, ' Average loss at step ', 782, ': ', 5108.962713068182)\n",
      "('Epoch: ', 106, ' Average loss at step ', 787, ': ', 32.190119275003291)\n",
      "('Epoch: ', 106, ' Average loss at step ', 1000, ': ', 9.2680737957954413)\n",
      "('Epoch: ', 106, ' Average loss at step ', 2000, ': ', 9.0870415706634518)\n",
      "('Epoch: ', 106, ' Average loss at step ', 2813, ': ', 9.1674431204208595)\n",
      "Training time took 97.750937 seconds to run 1 epoch\n",
      "('Epoch: ', 107, ' Average loss at step ', 1000, ': ', 0.11900361222028732)\n",
      "('Epoch: ', 107, ' Average loss at step ', 2000, ': ', 0.1101652255654335)\n",
      "('Epoch: ', 107, ' Average loss at step ', 2813, ': ', 0.10459052907128639)\n",
      "Training time took 44.018066 seconds to run 1 epoch\n",
      "('Epoch: ', 108, ' Average loss at step ', 1000, ': ', 128.01954648971557)\n",
      "('Epoch: ', 108, ' Average loss at step ', 2000, ': ', 128.66627519989012)\n",
      "('Epoch: ', 108, ' Average loss at step ', 3000, ': ', 127.88947854614258)\n",
      "('Epoch: ', 108, ' Average loss at step ', 4000, ': ', 128.78227616119383)\n",
      "('Epoch: ', 108, ' Average loss at step ', 4373, ': ', 129.39530774598481)\n",
      "('Epoch: ', 108, ' Average loss at step ', 761, ': ', 4573.7550498560859)\n",
      "('Epoch: ', 108, ' Average loss at step ', 782, ': ', 5150.1020157700468)\n",
      "('Epoch: ', 108, ' Average loss at step ', 787, ': ', 31.761824100678812)\n",
      "('Epoch: ', 108, ' Average loss at step ', 1000, ': ', 9.0261777944564816)\n",
      "('Epoch: ', 108, ' Average loss at step ', 2000, ': ', 8.9804770579338076)\n",
      "('Epoch: ', 108, ' Average loss at step ', 2813, ': ', 8.973093978877138)\n",
      "Training time took 97.84785 seconds to run 1 epoch\n",
      "('Epoch: ', 109, ' Average loss at step ', 1000, ': ', 0.11671898311376572)\n",
      "('Epoch: ', 109, ' Average loss at step ', 2000, ': ', 0.10852935922145844)\n",
      "('Epoch: ', 109, ' Average loss at step ', 2813, ': ', 0.10249026956522993)\n",
      "Training time took 44.018459 seconds to run 1 epoch\n",
      "Mean Rank:  5  of  28683\n",
      "Hits @ 10:  0.973982655103\n",
      "Hits @ 1:  0.923348899266\n",
      "Testing time took 72.968081 seconds.\n",
      "\n",
      "('Epoch: ', 110, ' Average loss at step ', 1000, ': ', 127.54862805938721)\n",
      "('Epoch: ', 110, ' Average loss at step ', 2000, ': ', 127.73436219024659)\n",
      "('Epoch: ', 110, ' Average loss at step ', 3000, ': ', 128.61858849334718)\n",
      "('Epoch: ', 110, ' Average loss at step ', 4000, ': ', 129.51778193664552)\n",
      "('Epoch: ', 110, ' Average loss at step ', 4373, ': ', 126.56363171403126)\n",
      "('Epoch: ', 110, ' Average loss at step ', 761, ': ', 4566.8477690044201)\n",
      "('Epoch: ', 110, ' Average loss at step ', 782, ': ', 5160.485992392566)\n",
      "('Epoch: ', 110, ' Average loss at step ', 787, ': ', 31.70218005192492)\n",
      "('Epoch: ', 110, ' Average loss at step ', 1000, ': ', 9.0107437510490414)\n",
      "('Epoch: ', 110, ' Average loss at step ', 2000, ': ', 9.0428348703384405)\n",
      "('Epoch: ', 110, ' Average loss at step ', 2813, ': ', 8.8949694680462912)\n",
      "Training time took 97.743216 seconds to run 1 epoch\n",
      "('Epoch: ', 111, ' Average loss at step ', 1000, ': ', 0.11437706649303436)\n",
      "('Epoch: ', 111, ' Average loss at step ', 2000, ': ', 0.10627849024534225)\n",
      "('Epoch: ', 111, ' Average loss at step ', 2813, ': ', 0.10116814664138361)\n",
      "Training time took 44.030445 seconds to run 1 epoch\n",
      "('Epoch: ', 112, ' Average loss at step ', 1000, ': ', 126.58472510910035)\n",
      "('Epoch: ', 112, ' Average loss at step ', 2000, ': ', 129.09734986114501)\n",
      "('Epoch: ', 112, ' Average loss at step ', 3000, ': ', 127.8139309387207)\n",
      "('Epoch: ', 112, ' Average loss at step ', 4000, ': ', 127.1398572845459)\n",
      "('Epoch: ', 112, ' Average loss at step ', 4373, ': ', 128.40327293642105)\n",
      "('Epoch: ', 112, ' Average loss at step ', 761, ': ', 4645.5846091822577)\n",
      "('Epoch: ', 112, ' Average loss at step ', 782, ': ', 5217.0272605983919)\n",
      "('Epoch: ', 112, ' Average loss at step ', 787, ': ', 31.206862228820647)\n",
      "('Epoch: ', 112, ' Average loss at step ', 1000, ': ', 8.770114161491394)\n",
      "('Epoch: ', 112, ' Average loss at step ', 2000, ': ', 8.721248244285583)\n",
      "('Epoch: ', 112, ' Average loss at step ', 2813, ': ', 8.6713970811496228)\n",
      "Training time took 97.761396 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 113, ' Average loss at step ', 1000, ': ', 0.1125668398141861)\n",
      "('Epoch: ', 113, ' Average loss at step ', 2000, ': ', 0.10532530277967453)\n",
      "('Epoch: ', 113, ' Average loss at step ', 2813, ': ', 0.099342584536580611)\n",
      "Training time took 44.044909 seconds to run 1 epoch\n",
      "('Epoch: ', 114, ' Average loss at step ', 1000, ': ', 129.37100593566893)\n",
      "('Epoch: ', 114, ' Average loss at step ', 2000, ': ', 128.30942427825929)\n",
      "('Epoch: ', 114, ' Average loss at step ', 3000, ': ', 128.00772581481934)\n",
      "('Epoch: ', 114, ' Average loss at step ', 4000, ': ', 127.8576813659668)\n",
      "('Epoch: ', 114, ' Average loss at step ', 4373, ': ', 127.69736413032778)\n",
      "('Epoch: ', 114, ' Average loss at step ', 761, ': ', 4665.2305223966896)\n",
      "('Epoch: ', 114, ' Average loss at step ', 782, ': ', 5263.5862319692305)\n",
      "('Epoch: ', 114, ' Average loss at step ', 787, ': ', 31.346961057823123)\n",
      "('Epoch: ', 114, ' Average loss at step ', 1000, ': ', 8.6122938427925106)\n",
      "('Epoch: ', 114, ' Average loss at step ', 2000, ': ', 8.6185995121002197)\n",
      "('Epoch: ', 114, ' Average loss at step ', 2813, ': ', 8.5162265506283994)\n",
      "Training time took 97.823683 seconds to run 1 epoch\n",
      "('Epoch: ', 115, ' Average loss at step ', 1000, ': ', 0.11076833641529084)\n",
      "('Epoch: ', 115, ' Average loss at step ', 2000, ': ', 0.10201137429475785)\n",
      "('Epoch: ', 115, ' Average loss at step ', 2813, ': ', 0.097999618558460858)\n",
      "Training time took 44.035128 seconds to run 1 epoch\n",
      "('Epoch: ', 116, ' Average loss at step ', 1000, ': ', 126.12571765136718)\n",
      "('Epoch: ', 116, ' Average loss at step ', 2000, ': ', 127.65963789367676)\n",
      "('Epoch: ', 116, ' Average loss at step ', 3000, ': ', 127.85138118743896)\n",
      "('Epoch: ', 116, ' Average loss at step ', 4000, ': ', 127.50912373352051)\n",
      "('Epoch: ', 116, ' Average loss at step ', 4373, ': ', 130.21810632110925)\n",
      "('Epoch: ', 116, ' Average loss at step ', 761, ': ', 4688.3364347759043)\n",
      "('Epoch: ', 116, ' Average loss at step ', 782, ': ', 5327.5016592809698)\n",
      "('Epoch: ', 116, ' Average loss at step ', 787, ': ', 30.82164156770585)\n",
      "('Epoch: ', 116, ' Average loss at step ', 1000, ': ', 8.5783943371772757)\n",
      "('Epoch: ', 116, ' Average loss at step ', 2000, ': ', 8.6138555865287785)\n",
      "('Epoch: ', 116, ' Average loss at step ', 2813, ': ', 8.5142320470856916)\n",
      "Training time took 97.713774 seconds to run 1 epoch\n",
      "('Epoch: ', 117, ' Average loss at step ', 1000, ': ', 0.10944545423984528)\n",
      "('Epoch: ', 117, ' Average loss at step ', 2000, ': ', 0.10100644719600678)\n",
      "('Epoch: ', 117, ' Average loss at step ', 2813, ': ', 0.096526712693017103)\n",
      "Training time took 44.001045 seconds to run 1 epoch\n",
      "('Epoch: ', 118, ' Average loss at step ', 1000, ': ', 128.7922629776001)\n",
      "('Epoch: ', 118, ' Average loss at step ', 2000, ': ', 128.15878836059571)\n",
      "('Epoch: ', 118, ' Average loss at step ', 3000, ': ', 129.16570239257811)\n",
      "('Epoch: ', 118, ' Average loss at step ', 4000, ': ', 130.53157965850829)\n",
      "('Epoch: ', 118, ' Average loss at step ', 4373, ': ', 131.85584763557679)\n",
      "('Epoch: ', 118, ' Average loss at step ', 761, ': ', 4712.7394412392068)\n",
      "('Epoch: ', 118, ' Average loss at step ', 782, ': ', 5316.3558385558381)\n",
      "('Epoch: ', 118, ' Average loss at step ', 787, ': ', 30.68741076229183)\n",
      "('Epoch: ', 118, ' Average loss at step ', 1000, ': ', 8.5096749429702765)\n",
      "('Epoch: ', 118, ' Average loss at step ', 2000, ': ', 8.4743149123191834)\n",
      "('Epoch: ', 118, ' Average loss at step ', 2813, ': ', 8.4443760000426202)\n",
      "Training time took 97.74847 seconds to run 1 epoch\n",
      "('Epoch: ', 119, ' Average loss at step ', 1000, ': ', 0.10680267709493638)\n",
      "('Epoch: ', 119, ' Average loss at step ', 2000, ': ', 0.099149739742279058)\n",
      "('Epoch: ', 119, ' Average loss at step ', 2813, ': ', 0.094942499777953618)\n",
      "Training time took 44.01699 seconds to run 1 epoch\n",
      "Mean Rank:  5  of  28683\n",
      "Hits @ 10:  0.975116744496\n",
      "Hits @ 1:  0.925150100067\n",
      "Testing time took 73.671501 seconds.\n",
      "\n",
      "('Epoch: ', 120, ' Average loss at step ', 1000, ': ', 127.54246227264404)\n",
      "('Epoch: ', 120, ' Average loss at step ', 2000, ': ', 128.10028869628906)\n",
      "('Epoch: ', 120, ' Average loss at step ', 3000, ': ', 129.10311093902587)\n",
      "('Epoch: ', 120, ' Average loss at step ', 4000, ': ', 127.6232017288208)\n",
      "('Epoch: ', 120, ' Average loss at step ', 4373, ': ', 124.07959739110802)\n",
      "('Epoch: ', 120, ' Average loss at step ', 761, ': ', 4749.4879400956006)\n",
      "('Epoch: ', 120, ' Average loss at step ', 782, ': ', 5403.2604755396724)\n",
      "('Epoch: ', 120, ' Average loss at step ', 787, ': ', 30.213605045968947)\n",
      "('Epoch: ', 120, ' Average loss at step ', 1000, ': ', 8.1867013130187996)\n",
      "('Epoch: ', 120, ' Average loss at step ', 2000, ': ', 8.4939805717468264)\n",
      "('Epoch: ', 120, ' Average loss at step ', 2813, ': ', 8.213002901359145)\n",
      "Training time took 97.741447 seconds to run 1 epoch\n",
      "('Epoch: ', 121, ' Average loss at step ', 1000, ': ', 0.10621306174993515)\n",
      "('Epoch: ', 121, ' Average loss at step ', 2000, ': ', 0.097658977150917051)\n",
      "('Epoch: ', 121, ' Average loss at step ', 2813, ': ', 0.093576423199893219)\n",
      "Training time took 44.000491 seconds to run 1 epoch\n",
      "('Epoch: ', 122, ' Average loss at step ', 1000, ': ', 129.26655183410645)\n",
      "('Epoch: ', 122, ' Average loss at step ', 2000, ': ', 128.8017886352539)\n",
      "('Epoch: ', 122, ' Average loss at step ', 3000, ': ', 127.90448329925538)\n",
      "('Epoch: ', 122, ' Average loss at step ', 4000, ': ', 128.76507746887208)\n",
      "('Epoch: ', 122, ' Average loss at step ', 4373, ': ', 130.11476373159758)\n",
      "('Epoch: ', 122, ' Average loss at step ', 761, ': ', 4773.9322419819082)\n",
      "('Epoch: ', 122, ' Average loss at step ', 782, ': ', 5428.3852238966465)\n",
      "('Epoch: ', 122, ' Average loss at step ', 787, ': ', 29.934146114281418)\n",
      "('Epoch: ', 122, ' Average loss at step ', 1000, ': ', 8.3615485515594479)\n",
      "('Epoch: ', 122, ' Average loss at step ', 2000, ': ', 8.3224542198181144)\n",
      "('Epoch: ', 122, ' Average loss at step ', 2813, ': ', 8.4538296731234777)\n",
      "Training time took 97.804345 seconds to run 1 epoch\n",
      "('Epoch: ', 123, ' Average loss at step ', 1000, ': ', 0.10438628464937211)\n",
      "('Epoch: ', 123, ' Average loss at step ', 2000, ': ', 0.096964903473854058)\n",
      "('Epoch: ', 123, ' Average loss at step ', 2813, ': ', 0.090877430192355446)\n",
      "Training time took 44.052385 seconds to run 1 epoch\n",
      "('Epoch: ', 124, ' Average loss at step ', 1000, ': ', 130.81174703598023)\n",
      "('Epoch: ', 124, ' Average loss at step ', 2000, ': ', 128.69492990875244)\n",
      "('Epoch: ', 124, ' Average loss at step ', 3000, ': ', 127.10075889587402)\n",
      "('Epoch: ', 124, ' Average loss at step ', 4000, ': ', 128.15455609130859)\n",
      "('Epoch: ', 124, ' Average loss at step ', 4373, ': ', 131.53573645314862)\n",
      "('Epoch: ', 124, ' Average loss at step ', 761, ': ', 4787.2951162237869)\n",
      "('Epoch: ', 124, ' Average loss at step ', 782, ': ', 5465.9987880496756)\n",
      "('Epoch: ', 124, ' Average loss at step ', 787, ': ', 29.935199439070608)\n",
      "('Epoch: ', 124, ' Average loss at step ', 1000, ': ', 8.3067427000999459)\n",
      "('Epoch: ', 124, ' Average loss at step ', 2000, ': ', 8.320740118026734)\n",
      "('Epoch: ', 124, ' Average loss at step ', 2813, ': ', 8.2446839451202614)\n",
      "Training time took 97.75352 seconds to run 1 epoch\n",
      "('Epoch: ', 125, ' Average loss at step ', 1000, ': ', 0.10195134907960891)\n",
      "('Epoch: ', 125, ' Average loss at step ', 2000, ': ', 0.095213133394718166)\n",
      "('Epoch: ', 125, ' Average loss at step ', 2813, ': ', 0.090301134022585869)\n",
      "Training time took 44.045124 seconds to run 1 epoch\n",
      "('Epoch: ', 126, ' Average loss at step ', 1000, ': ', 129.03269058227539)\n",
      "('Epoch: ', 126, ' Average loss at step ', 2000, ': ', 128.50591331481934)\n",
      "('Epoch: ', 126, ' Average loss at step ', 3000, ': ', 128.24409914016724)\n",
      "('Epoch: ', 126, ' Average loss at step ', 4000, ': ', 128.83156125640869)\n",
      "('Epoch: ', 126, ' Average loss at step ', 4373, ': ', 126.18249378409438)\n",
      "('Epoch: ', 126, ' Average loss at step ', 761, ': ', 4807.3369821648848)\n",
      "('Epoch: ', 126, ' Average loss at step ', 782, ': ', 5462.2508640264887)\n",
      "('Epoch: ', 126, ' Average loss at step ', 787, ': ', 29.507212985866246)\n",
      "('Epoch: ', 126, ' Average loss at step ', 1000, ': ', 8.054491947174073)\n",
      "('Epoch: ', 126, ' Average loss at step ', 2000, ': ', 8.1869392957687381)\n",
      "('Epoch: ', 126, ' Average loss at step ', 2813, ': ', 8.3977545370609299)\n",
      "Training time took 97.772606 seconds to run 1 epoch\n",
      "('Epoch: ', 127, ' Average loss at step ', 1000, ': ', 0.10185957396030426)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 127, ' Average loss at step ', 2000, ': ', 0.093096027076244356)\n",
      "('Epoch: ', 127, ' Average loss at step ', 2813, ': ', 0.089031623502083018)\n",
      "Training time took 44.021039 seconds to run 1 epoch\n",
      "('Epoch: ', 128, ' Average loss at step ', 1000, ': ', 127.66172908020019)\n",
      "('Epoch: ', 128, ' Average loss at step ', 2000, ': ', 127.15789566421509)\n",
      "('Epoch: ', 128, ' Average loss at step ', 3000, ': ', 128.86540992736818)\n",
      "('Epoch: ', 128, ' Average loss at step ', 4000, ': ', 128.1925850830078)\n",
      "('Epoch: ', 128, ' Average loss at step ', 4373, ': ', 127.70165705937211)\n",
      "('Epoch: ', 128, ' Average loss at step ', 761, ': ', 4822.6520870811064)\n",
      "('Epoch: ', 128, ' Average loss at step ', 782, ': ', 5556.8889597796297)\n",
      "('Epoch: ', 128, ' Average loss at step ', 787, ': ', 29.36998296087328)\n",
      "('Epoch: ', 128, ' Average loss at step ', 1000, ': ', 8.1404947595596315)\n",
      "('Epoch: ', 128, ' Average loss at step ', 2000, ': ', 8.0674271402359015)\n",
      "('Epoch: ', 128, ' Average loss at step ', 2813, ': ', 7.9482862391495352)\n",
      "Training time took 97.741917 seconds to run 1 epoch\n",
      "('Epoch: ', 129, ' Average loss at step ', 1000, ': ', 0.098377542972564694)\n",
      "('Epoch: ', 129, ' Average loss at step ', 2000, ': ', 0.092307735562324522)\n",
      "('Epoch: ', 129, ' Average loss at step ', 2813, ': ', 0.088731299259979732)\n",
      "Training time took 44.053843 seconds to run 1 epoch\n",
      "Mean Rank:  5  of  28683\n",
      "Hits @ 10:  0.975517011341\n",
      "Hits @ 1:  0.925150100067\n",
      "Testing time took 73.00543 seconds.\n",
      "\n",
      "('Epoch: ', 130, ' Average loss at step ', 1000, ': ', 128.39775758361816)\n",
      "('Epoch: ', 130, ' Average loss at step ', 2000, ': ', 128.60751127624511)\n",
      "('Epoch: ', 130, ' Average loss at step ', 3000, ': ', 126.37034013366699)\n",
      "('Epoch: ', 130, ' Average loss at step ', 4000, ': ', 128.59750526046753)\n",
      "('Epoch: ', 130, ' Average loss at step ', 4373, ': ', 128.50739952825731)\n",
      "('Epoch: ', 130, ' Average loss at step ', 761, ': ', 4874.0833046361022)\n",
      "('Epoch: ', 130, ' Average loss at step ', 782, ': ', 5582.464334211948)\n",
      "('Epoch: ', 130, ' Average loss at step ', 787, ': ', 29.350791135210422)\n",
      "('Epoch: ', 130, ' Average loss at step ', 1000, ': ', 8.005979293823243)\n",
      "('Epoch: ', 130, ' Average loss at step ', 2000, ': ', 8.0481117534637452)\n",
      "('Epoch: ', 130, ' Average loss at step ', 2813, ': ', 8.0310834164689915)\n",
      "Training time took 97.726091 seconds to run 1 epoch\n",
      "('Epoch: ', 131, ' Average loss at step ', 1000, ': ', 0.09770624899864197)\n",
      "('Epoch: ', 131, ' Average loss at step ', 2000, ': ', 0.090271146774291988)\n",
      "('Epoch: ', 131, ' Average loss at step ', 2813, ': ', 0.087138557448762977)\n",
      "Training time took 44.07295 seconds to run 1 epoch\n",
      "('Epoch: ', 132, ' Average loss at step ', 1000, ': ', 128.01112829208375)\n",
      "('Epoch: ', 132, ' Average loss at step ', 2000, ': ', 130.31519066619873)\n",
      "('Epoch: ', 132, ' Average loss at step ', 3000, ': ', 128.18704525756837)\n",
      "('Epoch: ', 132, ' Average loss at step ', 4000, ': ', 127.06171504974365)\n",
      "('Epoch: ', 132, ' Average loss at step ', 4373, ': ', 127.39559263824135)\n",
      "('Epoch: ', 132, ' Average loss at step ', 761, ': ', 4904.9322175678453)\n",
      "('Epoch: ', 132, ' Average loss at step ', 782, ': ', 5639.8560501860593)\n",
      "('Epoch: ', 132, ' Average loss at step ', 787, ': ', 28.986863073198545)\n",
      "('Epoch: ', 132, ' Average loss at step ', 1000, ': ', 7.789662933349609)\n",
      "('Epoch: ', 132, ' Average loss at step ', 2000, ': ', 7.7781680159568785)\n",
      "('Epoch: ', 132, ' Average loss at step ', 2813, ': ', 8.0751701340886761)\n",
      "Training time took 97.696611 seconds to run 1 epoch\n",
      "('Epoch: ', 133, ' Average loss at step ', 1000, ': ', 0.096648100078105925)\n",
      "('Epoch: ', 133, ' Average loss at step ', 2000, ': ', 0.089562506675720216)\n",
      "('Epoch: ', 133, ' Average loss at step ', 2813, ': ', 0.08532810269905429)\n",
      "Training time took 44.009278 seconds to run 1 epoch\n",
      "('Epoch: ', 134, ' Average loss at step ', 1000, ': ', 127.08385106658936)\n",
      "('Epoch: ', 134, ' Average loss at step ', 2000, ': ', 127.50289084625244)\n",
      "('Epoch: ', 134, ' Average loss at step ', 3000, ': ', 128.51276566314698)\n",
      "('Epoch: ', 134, ' Average loss at step ', 4000, ': ', 127.26146865081787)\n",
      "('Epoch: ', 134, ' Average loss at step ', 4373, ': ', 129.46821136884793)\n",
      "('Epoch: ', 134, ' Average loss at step ', 761, ': ', 4957.1402321263367)\n",
      "('Epoch: ', 134, ' Average loss at step ', 782, ': ', 5629.6290050316102)\n",
      "('Epoch: ', 134, ' Average loss at step ', 787, ': ', 28.599007007123252)\n",
      "('Epoch: ', 134, ' Average loss at step ', 1000, ': ', 7.8585085625648494)\n",
      "('Epoch: ', 134, ' Average loss at step ', 2000, ': ', 7.9414855775833129)\n",
      "('Epoch: ', 134, ' Average loss at step ', 2813, ': ', 7.820321420730628)\n",
      "Training time took 97.616271 seconds to run 1 epoch\n",
      "('Epoch: ', 135, ' Average loss at step ', 1000, ': ', 0.096028521120548244)\n",
      "('Epoch: ', 135, ' Average loss at step ', 2000, ': ', 0.08814463514089585)\n",
      "('Epoch: ', 135, ' Average loss at step ', 2813, ': ', 0.083959106007233039)\n",
      "Training time took 44.006612 seconds to run 1 epoch\n",
      "('Epoch: ', 136, ' Average loss at step ', 1000, ': ', 128.3308881225586)\n",
      "('Epoch: ', 136, ' Average loss at step ', 2000, ': ', 128.97884551239014)\n",
      "('Epoch: ', 136, ' Average loss at step ', 3000, ': ', 130.38066388702393)\n",
      "('Epoch: ', 136, ' Average loss at step ', 4000, ': ', 128.60922370147705)\n",
      "('Epoch: ', 136, ' Average loss at step ', 4373, ': ', 126.98939071163055)\n",
      "('Epoch: ', 136, ' Average loss at step ', 761, ': ', 5031.0002977873146)\n",
      "('Epoch: ', 136, ' Average loss at step ', 782, ': ', 5676.8189129896564)\n",
      "('Epoch: ', 136, ' Average loss at step ', 787, ': ', 28.385929874488113)\n",
      "('Epoch: ', 136, ' Average loss at step ', 1000, ': ', 7.941754185676575)\n",
      "('Epoch: ', 136, ' Average loss at step ', 2000, ': ', 7.6593975710868838)\n",
      "('Epoch: ', 136, ' Average loss at step ', 2813, ': ', 7.712130378032553)\n",
      "Training time took 97.780958 seconds to run 1 epoch\n",
      "('Epoch: ', 137, ' Average loss at step ', 1000, ': ', 0.094035229325294498)\n",
      "('Epoch: ', 137, ' Average loss at step ', 2000, ': ', 0.087338427543640143)\n",
      "('Epoch: ', 137, ' Average loss at step ', 2813, ': ', 0.083181556589497718)\n",
      "Training time took 44.060977 seconds to run 1 epoch\n",
      "('Epoch: ', 138, ' Average loss at step ', 1000, ': ', 127.45151821517945)\n",
      "('Epoch: ', 138, ' Average loss at step ', 2000, ': ', 128.8334379196167)\n",
      "('Epoch: ', 138, ' Average loss at step ', 3000, ': ', 128.402224609375)\n",
      "('Epoch: ', 138, ' Average loss at step ', 4000, ': ', 127.91015410614014)\n",
      "('Epoch: ', 138, ' Average loss at step ', 4373, ': ', 130.309234352522)\n",
      "('Epoch: ', 138, ' Average loss at step ', 761, ': ', 5018.3634386564554)\n",
      "('Epoch: ', 138, ' Average loss at step ', 782, ': ', 5754.6082524532849)\n",
      "('Epoch: ', 138, ' Average loss at step ', 787, ': ', 28.448140919663523)\n",
      "('Epoch: ', 138, ' Average loss at step ', 1000, ': ', 7.6718657302856448)\n",
      "('Epoch: ', 138, ' Average loss at step ', 2000, ': ', 7.7370252685546879)\n",
      "('Epoch: ', 138, ' Average loss at step ', 2813, ': ', 7.79877869366425)\n",
      "Training time took 97.78099 seconds to run 1 epoch\n",
      "('Epoch: ', 139, ' Average loss at step ', 1000, ': ', 0.093397131204605105)\n",
      "('Epoch: ', 139, ' Average loss at step ', 2000, ': ', 0.085470055937767034)\n",
      "('Epoch: ', 139, ' Average loss at step ', 2813, ': ', 0.081668157295640462)\n",
      "Training time took 44.002389 seconds to run 1 epoch\n",
      "Mean Rank:  4  of  28683\n",
      "Hits @ 10:  0.976584389593\n",
      "Hits @ 1:  0.926217478319\n",
      "Testing time took 73.135703 seconds.\n",
      "\n",
      "('Epoch: ', 140, ' Average loss at step ', 1000, ': ', 126.17983917999267)\n",
      "('Epoch: ', 140, ' Average loss at step ', 2000, ': ', 127.55434093856812)\n",
      "('Epoch: ', 140, ' Average loss at step ', 3000, ': ', 128.22714605712892)\n",
      "('Epoch: ', 140, ' Average loss at step ', 4000, ': ', 126.9948267326355)\n",
      "('Epoch: ', 140, ' Average loss at step ', 4373, ': ', 125.39474794941563)\n",
      "('Epoch: ', 140, ' Average loss at step ', 761, ': ', 5022.2263427734379)\n",
      "('Epoch: ', 140, ' Average loss at step ', 782, ': ', 5733.2202604833547)\n",
      "('Epoch: ', 140, ' Average loss at step ', 787, ': ', 28.50542596520965)\n",
      "('Epoch: ', 140, ' Average loss at step ', 1000, ': ', 7.7708801956176758)\n",
      "('Epoch: ', 140, ' Average loss at step ', 2000, ': ', 7.6979225010871888)\n",
      "('Epoch: ', 140, ' Average loss at step ', 2813, ': ', 7.4484160034527331)\n",
      "Training time took 97.723227 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 141, ' Average loss at step ', 1000, ': ', 0.091886800527572629)\n",
      "('Epoch: ', 141, ' Average loss at step ', 2000, ': ', 0.08437288218736648)\n",
      "('Epoch: ', 141, ' Average loss at step ', 2813, ': ', 0.080999586382522956)\n",
      "Training time took 44.04092 seconds to run 1 epoch\n",
      "('Epoch: ', 142, ' Average loss at step ', 1000, ': ', 127.60193456268311)\n",
      "('Epoch: ', 142, ' Average loss at step ', 2000, ': ', 128.18487651824952)\n",
      "('Epoch: ', 142, ' Average loss at step ', 3000, ': ', 128.7047088394165)\n",
      "('Epoch: ', 142, ' Average loss at step ', 4000, ': ', 128.26902034759522)\n",
      "('Epoch: ', 142, ' Average loss at step ', 4373, ': ', 128.88878315751271)\n",
      "('Epoch: ', 142, ' Average loss at step ', 761, ': ', 5055.9857405813118)\n",
      "('Epoch: ', 142, ' Average loss at step ', 782, ': ', 5773.8185216144166)\n",
      "('Epoch: ', 142, ' Average loss at step ', 787, ': ', 28.042292343751164)\n",
      "('Epoch: ', 142, ' Average loss at step ', 1000, ': ', 7.6018704609870911)\n",
      "('Epoch: ', 142, ' Average loss at step ', 2000, ': ', 7.5628588442802434)\n",
      "('Epoch: ', 142, ' Average loss at step ', 2813, ': ', 7.6614971877318885)\n",
      "Training time took 97.728134 seconds to run 1 epoch\n",
      "('Epoch: ', 143, ' Average loss at step ', 1000, ': ', 0.090410754621028905)\n",
      "('Epoch: ', 143, ' Average loss at step ', 2000, ': ', 0.083694572031497952)\n",
      "('Epoch: ', 143, ' Average loss at step ', 2813, ': ', 0.079579486708922925)\n",
      "Training time took 44.014981 seconds to run 1 epoch\n",
      "('Epoch: ', 144, ' Average loss at step ', 1000, ': ', 128.29869467163087)\n",
      "('Epoch: ', 144, ' Average loss at step ', 2000, ': ', 127.06169383239747)\n",
      "('Epoch: ', 144, ' Average loss at step ', 3000, ': ', 127.84737552642822)\n",
      "('Epoch: ', 144, ' Average loss at step ', 4000, ': ', 128.47322593688966)\n",
      "('Epoch: ', 144, ' Average loss at step ', 4373, ': ', 128.88660621643066)\n",
      "('Epoch: ', 144, ' Average loss at step ', 761, ': ', 5090.6591205797695)\n",
      "('Epoch: ', 144, ' Average loss at step ', 782, ': ', 5792.0233977997959)\n",
      "('Epoch: ', 144, ' Average loss at step ', 787, ': ', 28.559802867074048)\n",
      "('Epoch: ', 144, ' Average loss at step ', 1000, ': ', 7.5147721190452579)\n",
      "('Epoch: ', 144, ' Average loss at step ', 2000, ': ', 7.4690761079788208)\n",
      "('Epoch: ', 144, ' Average loss at step ', 2813, ': ', 7.6019332884567712)\n",
      "Training time took 97.810408 seconds to run 1 epoch\n",
      "('Epoch: ', 145, ' Average loss at step ', 1000, ': ', 0.088587495982646938)\n",
      "('Epoch: ', 145, ' Average loss at step ', 2000, ': ', 0.082231742262840274)\n",
      "('Epoch: ', 145, ' Average loss at step ', 2813, ': ', 0.078907570815438713)\n",
      "Training time took 44.059641 seconds to run 1 epoch\n",
      "('Epoch: ', 146, ' Average loss at step ', 1000, ': ', 128.71270366668702)\n",
      "('Epoch: ', 146, ' Average loss at step ', 2000, ': ', 127.75148144531251)\n",
      "('Epoch: ', 146, ' Average loss at step ', 3000, ': ', 128.15030641174317)\n",
      "('Epoch: ', 146, ' Average loss at step ', 4000, ': ', 129.73427378845216)\n",
      "('Epoch: ', 146, ' Average loss at step ', 4373, ': ', 129.86219399975192)\n",
      "('Epoch: ', 146, ' Average loss at step ', 761, ': ', 5123.5853868986433)\n",
      "('Epoch: ', 146, ' Average loss at step ', 782, ': ', 5863.2626996889003)\n",
      "('Epoch: ', 146, ' Average loss at step ', 787, ': ', 27.966842163610096)\n",
      "('Epoch: ', 146, ' Average loss at step ', 1000, ': ', 7.5791690492630002)\n",
      "('Epoch: ', 146, ' Average loss at step ', 2000, ': ', 7.3804595584869386)\n",
      "('Epoch: ', 146, ' Average loss at step ', 2813, ': ', 7.5667847653327902)\n",
      "Training time took 97.801805 seconds to run 1 epoch\n",
      "('Epoch: ', 147, ' Average loss at step ', 1000, ': ', 0.087797016382217402)\n",
      "('Epoch: ', 147, ' Average loss at step ', 2000, ': ', 0.082105500221252445)\n",
      "('Epoch: ', 147, ' Average loss at step ', 2813, ': ', 0.078144205541446285)\n",
      "Training time took 44.023136 seconds to run 1 epoch\n",
      "('Epoch: ', 148, ' Average loss at step ', 1000, ': ', 125.17069608306885)\n",
      "('Epoch: ', 148, ' Average loss at step ', 2000, ': ', 126.81851502227784)\n",
      "('Epoch: ', 148, ' Average loss at step ', 3000, ': ', 127.51739542388916)\n",
      "('Epoch: ', 148, ' Average loss at step ', 4000, ': ', 127.78932680511474)\n",
      "('Epoch: ', 148, ' Average loss at step ', 4373, ': ', 130.54283884520171)\n",
      "('Epoch: ', 148, ' Average loss at step ', 761, ': ', 5160.1025654039886)\n",
      "('Epoch: ', 148, ' Average loss at step ', 782, ': ', 5909.6456550471148)\n",
      "('Epoch: ', 148, ' Average loss at step ', 787, ': ', 27.74646703341535)\n",
      "('Epoch: ', 148, ' Average loss at step ', 1000, ': ', 7.468308185577393)\n",
      "('Epoch: ', 148, ' Average loss at step ', 2000, ': ', 7.4526450800895692)\n",
      "('Epoch: ', 148, ' Average loss at step ', 2813, ': ', 7.4234222713949647)\n",
      "Training time took 97.671162 seconds to run 1 epoch\n",
      "('Epoch: ', 149, ' Average loss at step ', 1000, ': ', 0.087407591938972476)\n",
      "('Epoch: ', 149, ' Average loss at step ', 2000, ': ', 0.080418212950229648)\n",
      "('Epoch: ', 149, ' Average loss at step ', 2813, ': ', 0.076437815877017132)\n",
      "Training time took 44.030673 seconds to run 1 epoch\n",
      "Mean Rank:  4  of  28683\n",
      "Hits @ 10:  0.977118078719\n",
      "Hits @ 1:  0.925483655771\n",
      "Testing time took 73.032035 seconds.\n",
      "\n",
      "('Epoch: ', 150, ' Average loss at step ', 1000, ': ', 127.70549435424805)\n",
      "('Epoch: ', 150, ' Average loss at step ', 2000, ': ', 125.8602049331665)\n",
      "('Epoch: ', 150, ' Average loss at step ', 3000, ': ', 127.18390361022949)\n",
      "('Epoch: ', 150, ' Average loss at step ', 4000, ': ', 126.17367838287353)\n",
      "('Epoch: ', 150, ' Average loss at step ', 4373, ': ', 125.84929552385884)\n",
      "('Epoch: ', 150, ' Average loss at step ', 761, ': ', 5199.4736010099714)\n",
      "('Epoch: ', 150, ' Average loss at step ', 782, ': ', 5929.793924055698)\n",
      "('Epoch: ', 150, ' Average loss at step ', 787, ': ', 27.353120722540158)\n",
      "('Epoch: ', 150, ' Average loss at step ', 1000, ': ', 7.2610237874984742)\n",
      "('Epoch: ', 150, ' Average loss at step ', 2000, ': ', 7.3024370017051696)\n",
      "('Epoch: ', 150, ' Average loss at step ', 2813, ': ', 7.5258565741806782)\n",
      "Training time took 97.726589 seconds to run 1 epoch\n",
      "('Epoch: ', 151, ' Average loss at step ', 1000, ': ', 0.085535222887992854)\n",
      "('Epoch: ', 151, ' Average loss at step ', 2000, ': ', 0.079409680247306824)\n",
      "('Epoch: ', 151, ' Average loss at step ', 2813, ': ', 0.076327827983889082)\n",
      "Training time took 44.02977 seconds to run 1 epoch\n",
      "('Epoch: ', 152, ' Average loss at step ', 1000, ': ', 128.60354402923585)\n",
      "('Epoch: ', 152, ' Average loss at step ', 2000, ': ', 127.52402436828613)\n",
      "('Epoch: ', 152, ' Average loss at step ', 3000, ': ', 126.99989228057861)\n",
      "('Epoch: ', 152, ' Average loss at step ', 4000, ': ', 128.70539487457276)\n",
      "('Epoch: ', 152, ' Average loss at step ', 4373, ': ', 131.32231700035834)\n",
      "('Epoch: ', 152, ' Average loss at step ', 761, ': ', 5235.8337906686884)\n",
      "('Epoch: ', 152, ' Average loss at step ', 782, ': ', 6024.2007267325544)\n",
      "('Epoch: ', 152, ' Average loss at step ', 787, ': ', 27.184519163524833)\n",
      "('Epoch: ', 152, ' Average loss at step ', 1000, ': ', 7.2053289427757266)\n",
      "('Epoch: ', 152, ' Average loss at step ', 2000, ': ', 7.3238446388244629)\n",
      "('Epoch: ', 152, ' Average loss at step ', 2813, ': ', 7.3611217960348272)\n",
      "Training time took 97.707176 seconds to run 1 epoch\n",
      "('Epoch: ', 153, ' Average loss at step ', 1000, ': ', 0.083654490470886231)\n",
      "('Epoch: ', 153, ' Average loss at step ', 2000, ': ', 0.079014335334300995)\n",
      "('Epoch: ', 153, ' Average loss at step ', 2813, ': ', 0.075319792616543507)\n",
      "Training time took 44.005498 seconds to run 1 epoch\n",
      "('Epoch: ', 154, ' Average loss at step ', 1000, ': ', 130.93371614074707)\n",
      "('Epoch: ', 154, ' Average loss at step ', 2000, ': ', 127.11438120269776)\n",
      "('Epoch: ', 154, ' Average loss at step ', 3000, ': ', 128.19097700119019)\n",
      "('Epoch: ', 154, ' Average loss at step ', 4000, ': ', 127.5316968536377)\n",
      "('Epoch: ', 154, ' Average loss at step ', 4373, ': ', 130.07078043619791)\n",
      "('Epoch: ', 154, ' Average loss at step ', 761, ': ', 5244.9644483064349)\n",
      "('Epoch: ', 154, ' Average loss at step ', 782, ': ', 6001.7580838368276)\n",
      "('Epoch: ', 154, ' Average loss at step ', 787, ': ', 27.160331693314415)\n",
      "('Epoch: ', 154, ' Average loss at step ', 1000, ': ', 7.2396755681037899)\n",
      "('Epoch: ', 154, ' Average loss at step ', 2000, ': ', 7.2277323913574216)\n",
      "('Epoch: ', 154, ' Average loss at step ', 2813, ': ', 7.2970671313149591)\n",
      "Training time took 97.674112 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 155, ' Average loss at step ', 1000, ': ', 0.083914546132087708)\n",
      "('Epoch: ', 155, ' Average loss at step ', 2000, ': ', 0.077325702071189883)\n",
      "('Epoch: ', 155, ' Average loss at step ', 2813, ': ', 0.074062710765547352)\n",
      "Training time took 44.039276 seconds to run 1 epoch\n",
      "('Epoch: ', 156, ' Average loss at step ', 1000, ': ', 130.54336351013183)\n",
      "('Epoch: ', 156, ' Average loss at step ', 2000, ': ', 129.46658517456055)\n",
      "('Epoch: ', 156, ' Average loss at step ', 3000, ': ', 127.29761413574219)\n",
      "('Epoch: ', 156, ' Average loss at step ', 4000, ': ', 127.93791451263428)\n",
      "('Epoch: ', 156, ' Average loss at step ', 4373, ': ', 128.8726982403827)\n",
      "('Epoch: ', 156, ' Average loss at step ', 761, ': ', 5260.2104842336557)\n",
      "('Epoch: ', 156, ' Average loss at step ', 782, ': ', 6046.5185478102994)\n",
      "('Epoch: ', 156, ' Average loss at step ', 787, ': ', 27.043824433673734)\n",
      "('Epoch: ', 156, ' Average loss at step ', 1000, ': ', 7.2665954303741458)\n",
      "('Epoch: ', 156, ' Average loss at step ', 2000, ': ', 7.1762381138801574)\n",
      "('Epoch: ', 156, ' Average loss at step ', 2813, ': ', 7.2428160289238237)\n",
      "Training time took 97.678112 seconds to run 1 epoch\n",
      "('Epoch: ', 157, ' Average loss at step ', 1000, ': ', 0.082914600789546961)\n",
      "('Epoch: ', 157, ' Average loss at step ', 2000, ': ', 0.076464910268783576)\n",
      "('Epoch: ', 157, ' Average loss at step ', 2813, ': ', 0.073246722884953319)\n",
      "Training time took 44.063253 seconds to run 1 epoch\n",
      "('Epoch: ', 158, ' Average loss at step ', 1000, ': ', 127.15986659240723)\n",
      "('Epoch: ', 158, ' Average loss at step ', 2000, ': ', 127.13631076049805)\n",
      "('Epoch: ', 158, ' Average loss at step ', 3000, ': ', 128.66480437469482)\n",
      "('Epoch: ', 158, ' Average loss at step ', 4000, ': ', 128.29862745666503)\n",
      "('Epoch: ', 158, ' Average loss at step ', 4373, ': ', 128.15265885219779)\n",
      "('Epoch: ', 158, ' Average loss at step ', 761, ': ', 5312.820010536595)\n",
      "('Epoch: ', 158, ' Average loss at step ', 782, ': ', 6055.1090580235677)\n",
      "('Epoch: ', 158, ' Average loss at step ', 787, ': ', 26.838437196862607)\n",
      "('Epoch: ', 158, ' Average loss at step ', 1000, ': ', 7.1863637094497683)\n",
      "('Epoch: ', 158, ' Average loss at step ', 2000, ': ', 7.1998596601486202)\n",
      "('Epoch: ', 158, ' Average loss at step ', 2813, ': ', 7.0186832462038309)\n",
      "Training time took 97.816885 seconds to run 1 epoch\n",
      "('Epoch: ', 159, ' Average loss at step ', 1000, ': ', 0.08154406082630157)\n",
      "('Epoch: ', 159, ' Average loss at step ', 2000, ': ', 0.075222440838813784)\n",
      "('Epoch: ', 159, ' Average loss at step ', 2813, ': ', 0.073063143735448713)\n",
      "Training time took 44.028347 seconds to run 1 epoch\n",
      "Mean Rank:  4  of  28683\n",
      "Hits @ 10:  0.977585056704\n",
      "Hits @ 1:  0.926817878586\n",
      "Testing time took 73.154515 seconds.\n",
      "\n",
      "('Epoch: ', 160, ' Average loss at step ', 1000, ': ', 126.65037332153321)\n",
      "('Epoch: ', 160, ' Average loss at step ', 2000, ': ', 129.11273165130615)\n",
      "('Epoch: ', 160, ' Average loss at step ', 3000, ': ', 130.01444709014893)\n",
      "('Epoch: ', 160, ' Average loss at step ', 4000, ': ', 128.99682748413085)\n",
      "('Epoch: ', 160, ' Average loss at step ', 4373, ': ', 126.59010567203644)\n",
      "('Epoch: ', 160, ' Average loss at step ', 761, ': ', 5312.9500231291122)\n",
      "('Epoch: ', 160, ' Average loss at step ', 782, ': ', 6119.780096818482)\n",
      "('Epoch: ', 160, ' Average loss at step ', 787, ': ', 26.597760323046426)\n",
      "('Epoch: ', 160, ' Average loss at step ', 1000, ': ', 7.0547534365653988)\n",
      "('Epoch: ', 160, ' Average loss at step ', 2000, ': ', 7.029385576725006)\n",
      "('Epoch: ', 160, ' Average loss at step ', 2813, ': ', 7.0805064974160032)\n",
      "Training time took 97.822508 seconds to run 1 epoch\n",
      "('Epoch: ', 161, ' Average loss at step ', 1000, ': ', 0.080876905083656317)\n",
      "('Epoch: ', 161, ' Average loss at step ', 2000, ': ', 0.074780425429344183)\n",
      "('Epoch: ', 161, ' Average loss at step ', 2813, ': ', 0.07138876411421545)\n",
      "Training time took 44.014757 seconds to run 1 epoch\n",
      "('Epoch: ', 162, ' Average loss at step ', 1000, ': ', 130.59432161712647)\n",
      "('Epoch: ', 162, ' Average loss at step ', 2000, ': ', 128.3881627883911)\n",
      "('Epoch: ', 162, ' Average loss at step ', 3000, ': ', 130.25069532012938)\n",
      "('Epoch: ', 162, ' Average loss at step ', 4000, ': ', 129.20736534881593)\n",
      "('Epoch: ', 162, ' Average loss at step ', 4373, ': ', 127.93537383951167)\n",
      "('Epoch: ', 162, ' Average loss at step ', 761, ': ', 5332.1775107935855)\n",
      "('Epoch: ', 162, ' Average loss at step ', 782, ': ', 6104.9564019861355)\n",
      "('Epoch: ', 162, ' Average loss at step ', 787, ': ', 26.444053094198988)\n",
      "('Epoch: ', 162, ' Average loss at step ', 1000, ': ', 7.1219383573532102)\n",
      "('Epoch: ', 162, ' Average loss at step ', 2000, ': ', 6.9242099294662474)\n",
      "('Epoch: ', 162, ' Average loss at step ', 2813, ': ', 6.9828652225691696)\n",
      "Training time took 97.847127 seconds to run 1 epoch\n",
      "('Epoch: ', 163, ' Average loss at step ', 1000, ': ', 0.080255994141101836)\n",
      "('Epoch: ', 163, ' Average loss at step ', 2000, ': ', 0.073352061688899989)\n",
      "('Epoch: ', 163, ' Average loss at step ', 2813, ': ', 0.071059840579925496)\n",
      "Training time took 44.005699 seconds to run 1 epoch\n",
      "('Epoch: ', 164, ' Average loss at step ', 1000, ': ', 129.61888757324218)\n",
      "('Epoch: ', 164, ' Average loss at step ', 2000, ': ', 127.69819303131104)\n",
      "('Epoch: ', 164, ' Average loss at step ', 3000, ': ', 128.73164424133302)\n",
      "('Epoch: ', 164, ' Average loss at step ', 4000, ': ', 127.91350993347167)\n",
      "('Epoch: ', 164, ' Average loss at step ', 4373, ': ', 129.12121052895822)\n",
      "('Epoch: ', 164, ' Average loss at step ', 761, ': ', 5380.5703719289677)\n",
      "('Epoch: ', 164, ' Average loss at step ', 782, ': ', 6170.8523371228794)\n",
      "('Epoch: ', 164, ' Average loss at step ', 787, ': ', 26.579877972299514)\n",
      "('Epoch: ', 164, ' Average loss at step ', 1000, ': ', 6.927930220603943)\n",
      "('Epoch: ', 164, ' Average loss at step ', 2000, ': ', 6.9071663150787357)\n",
      "('Epoch: ', 164, ' Average loss at step ', 2813, ': ', 7.0552037408199215)\n",
      "Training time took 97.809681 seconds to run 1 epoch\n",
      "('Epoch: ', 165, ' Average loss at step ', 1000, ': ', 0.07824950253963471)\n",
      "('Epoch: ', 165, ' Average loss at step ', 2000, ': ', 0.073061309635639185)\n",
      "('Epoch: ', 165, ' Average loss at step ', 2813, ': ', 0.070762701883104628)\n",
      "Training time took 44.022567 seconds to run 1 epoch\n",
      "('Epoch: ', 166, ' Average loss at step ', 1000, ': ', 128.99261679077148)\n",
      "('Epoch: ', 166, ' Average loss at step ', 2000, ': ', 129.10465859985351)\n",
      "('Epoch: ', 166, ' Average loss at step ', 3000, ': ', 127.99937550735474)\n",
      "('Epoch: ', 166, ' Average loss at step ', 4000, ': ', 126.9682109451294)\n",
      "('Epoch: ', 166, ' Average loss at step ', 4373, ': ', 128.72485491024551)\n",
      "('Epoch: ', 166, ' Average loss at step ', 761, ': ', 5464.1555301063936)\n",
      "('Epoch: ', 166, ' Average loss at step ', 782, ': ', 6191.7850899787936)\n",
      "('Epoch: ', 166, ' Average loss at step ', 787, ': ', 26.029172617060539)\n",
      "('Epoch: ', 166, ' Average loss at step ', 1000, ': ', 6.7743411669731142)\n",
      "('Epoch: ', 166, ' Average loss at step ', 2000, ': ', 7.0941311998367311)\n",
      "('Epoch: ', 166, ' Average loss at step ', 2813, ': ', 6.9768351292962514)\n",
      "Training time took 97.825114 seconds to run 1 epoch\n",
      "('Epoch: ', 167, ' Average loss at step ', 1000, ': ', 0.077933178007602688)\n",
      "('Epoch: ', 167, ' Average loss at step ', 2000, ': ', 0.072485704660415651)\n",
      "('Epoch: ', 167, ' Average loss at step ', 2813, ': ', 0.06934615976998372)\n",
      "Training time took 44.031919 seconds to run 1 epoch\n",
      "('Epoch: ', 168, ' Average loss at step ', 1000, ': ', 127.30587884902954)\n",
      "('Epoch: ', 168, ' Average loss at step ', 2000, ': ', 128.82311981964111)\n",
      "('Epoch: ', 168, ' Average loss at step ', 3000, ': ', 129.47676470184325)\n",
      "('Epoch: ', 168, ' Average loss at step ', 4000, ': ', 127.32736812591553)\n",
      "('Epoch: ', 168, ' Average loss at step ', 4373, ': ', 129.17291815562913)\n",
      "('Epoch: ', 168, ' Average loss at step ', 761, ': ', 5389.5701393528989)\n",
      "('Epoch: ', 168, ' Average loss at step ', 782, ': ', 6229.3462060984511)\n",
      "('Epoch: ', 168, ' Average loss at step ', 787, ': ', 26.080072013476421)\n",
      "('Epoch: ', 168, ' Average loss at step ', 1000, ': ', 6.8596689085960385)\n",
      "('Epoch: ', 168, ' Average loss at step ', 2000, ': ', 6.7526223869323729)\n",
      "('Epoch: ', 168, ' Average loss at step ', 2813, ': ', 6.7178712472539814)\n",
      "Training time took 97.781707 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 169, ' Average loss at step ', 1000, ': ', 0.077365588963031764)\n",
      "('Epoch: ', 169, ' Average loss at step ', 2000, ': ', 0.070994966387748715)\n",
      "('Epoch: ', 169, ' Average loss at step ', 2813, ': ', 0.068647095649113213)\n",
      "Training time took 44.03235 seconds to run 1 epoch\n",
      "Mean Rank:  4  of  28683\n",
      "Hits @ 10:  0.977851901268\n",
      "Hits @ 1:  0.926884589726\n",
      "Testing time took 73.054437 seconds.\n",
      "\n",
      "('Epoch: ', 170, ' Average loss at step ', 1000, ': ', 128.89921515655519)\n",
      "('Epoch: ', 170, ' Average loss at step ', 2000, ': ', 126.8269561920166)\n",
      "('Epoch: ', 170, ' Average loss at step ', 3000, ': ', 128.79308880615235)\n",
      "('Epoch: ', 170, ' Average loss at step ', 4000, ': ', 128.99027139282228)\n",
      "('Epoch: ', 170, ' Average loss at step ', 4373, ': ', 130.2453084350914)\n",
      "('Epoch: ', 170, ' Average loss at step ', 761, ': ', 5474.4580042788857)\n",
      "('Epoch: ', 170, ' Average loss at step ', 782, ': ', 6251.2923841879401)\n",
      "('Epoch: ', 170, ' Average loss at step ', 787, ': ', 25.739403422552211)\n",
      "('Epoch: ', 170, ' Average loss at step ', 1000, ': ', 6.782670329093933)\n",
      "('Epoch: ', 170, ' Average loss at step ', 2000, ': ', 6.8203847427368167)\n",
      "('Epoch: ', 170, ' Average loss at step ', 2813, ': ', 6.975567676750897)\n",
      "Training time took 97.755397 seconds to run 1 epoch\n",
      "('Epoch: ', 171, ' Average loss at step ', 1000, ': ', 0.076281223833560938)\n",
      "('Epoch: ', 171, ' Average loss at step ', 2000, ': ', 0.070351080060005192)\n",
      "('Epoch: ', 171, ' Average loss at step ', 2813, ': ', 0.067645654596131422)\n",
      "Training time took 44.055148 seconds to run 1 epoch\n",
      "('Epoch: ', 172, ' Average loss at step ', 1000, ': ', 130.77720516967773)\n",
      "('Epoch: ', 172, ' Average loss at step ', 2000, ': ', 127.44712479400634)\n",
      "('Epoch: ', 172, ' Average loss at step ', 3000, ': ', 127.0008098526001)\n",
      "('Epoch: ', 172, ' Average loss at step ', 4000, ': ', 127.98260029602051)\n",
      "('Epoch: ', 172, ' Average loss at step ', 4373, ': ', 128.51173569053731)\n",
      "('Epoch: ', 172, ' Average loss at step ', 761, ': ', 5475.0085715846008)\n",
      "('Epoch: ', 172, ' Average loss at step ', 782, ': ', 6244.234618202825)\n",
      "('Epoch: ', 172, ' Average loss at step ', 787, ': ', 26.072803698726585)\n",
      "('Epoch: ', 172, ' Average loss at step ', 1000, ': ', 6.8105320758819579)\n",
      "('Epoch: ', 172, ' Average loss at step ', 2000, ': ', 6.7910676660537721)\n",
      "('Epoch: ', 172, ' Average loss at step ', 2813, ': ', 6.8846721208741508)\n",
      "Training time took 97.815063 seconds to run 1 epoch\n",
      "('Epoch: ', 173, ' Average loss at step ', 1000, ': ', 0.075226103425025934)\n",
      "('Epoch: ', 173, ' Average loss at step ', 2000, ': ', 0.070034624338150026)\n",
      "('Epoch: ', 173, ' Average loss at step ', 2813, ': ', 0.066965975858307825)\n",
      "Training time took 44.013406 seconds to run 1 epoch\n",
      "('Epoch: ', 174, ' Average loss at step ', 1000, ': ', 128.95059824752806)\n",
      "('Epoch: ', 174, ' Average loss at step ', 2000, ': ', 129.66119859313966)\n",
      "('Epoch: ', 174, ' Average loss at step ', 3000, ': ', 129.88876987457274)\n",
      "('Epoch: ', 174, ' Average loss at step ', 4000, ': ', 127.6614141921997)\n",
      "('Epoch: ', 174, ' Average loss at step ', 4373, ': ', 126.08371566444315)\n",
      "('Epoch: ', 174, ' Average loss at step ', 761, ': ', 5505.5250469006987)\n",
      "('Epoch: ', 174, ' Average loss at step ', 782, ': ', 6289.4983719790334)\n",
      "('Epoch: ', 174, ' Average loss at step ', 787, ': ', 25.88221828931464)\n",
      "('Epoch: ', 174, ' Average loss at step ', 1000, ': ', 6.7378177657127383)\n",
      "('Epoch: ', 174, ' Average loss at step ', 2000, ': ', 6.7245843787193298)\n",
      "('Epoch: ', 174, ' Average loss at step ', 2813, ': ', 6.6501770559790101)\n",
      "Training time took 97.845396 seconds to run 1 epoch\n",
      "('Epoch: ', 175, ' Average loss at step ', 1000, ': ', 0.07506204348802567)\n",
      "('Epoch: ', 175, ' Average loss at step ', 2000, ': ', 0.068905188560485844)\n",
      "('Epoch: ', 175, ' Average loss at step ', 2813, ': ', 0.066690794132613196)\n",
      "Training time took 44.029795 seconds to run 1 epoch\n",
      "('Epoch: ', 176, ' Average loss at step ', 1000, ': ', 129.28394750976562)\n",
      "('Epoch: ', 176, ' Average loss at step ', 2000, ': ', 129.45167152404784)\n",
      "('Epoch: ', 176, ' Average loss at step ', 3000, ': ', 127.56323682403564)\n",
      "('Epoch: ', 176, ' Average loss at step ', 4000, ': ', 128.66839509582519)\n",
      "('Epoch: ', 176, ' Average loss at step ', 4373, ': ', 128.69047892990932)\n",
      "('Epoch: ', 176, ' Average loss at step ', 761, ': ', 5536.8318609940379)\n",
      "('Epoch: ', 176, ' Average loss at step ', 782, ': ', 6331.3239261563704)\n",
      "('Epoch: ', 176, ' Average loss at step ', 787, ': ', 25.770330646262522)\n",
      "('Epoch: ', 176, ' Average loss at step ', 1000, ': ', 6.6952266674041745)\n",
      "('Epoch: ', 176, ' Average loss at step ', 2000, ': ', 6.8030819315910342)\n",
      "('Epoch: ', 176, ' Average loss at step ', 2813, ': ', 6.6602331916686941)\n",
      "Training time took 97.785117 seconds to run 1 epoch\n",
      "('Epoch: ', 177, ' Average loss at step ', 1000, ': ', 0.073307747483253485)\n",
      "('Epoch: ', 177, ' Average loss at step ', 2000, ': ', 0.06866850060224533)\n",
      "('Epoch: ', 177, ' Average loss at step ', 2813, ': ', 0.066025150967348969)\n",
      "Training time took 44.025253 seconds to run 1 epoch\n",
      "('Epoch: ', 178, ' Average loss at step ', 1000, ': ', 129.5397853012085)\n",
      "('Epoch: ', 178, ' Average loss at step ', 2000, ': ', 127.63042976379394)\n",
      "('Epoch: ', 178, ' Average loss at step ', 3000, ': ', 129.18237757873536)\n",
      "('Epoch: ', 178, ' Average loss at step ', 4000, ': ', 127.83393663787842)\n",
      "('Epoch: ', 178, ' Average loss at step ', 4373, ': ', 126.95743433634441)\n",
      "('Epoch: ', 178, ' Average loss at step ', 761, ': ', 5544.4330595317642)\n",
      "('Epoch: ', 178, ' Average loss at step ', 782, ': ', 6329.1506572728276)\n",
      "('Epoch: ', 178, ' Average loss at step ', 787, ': ', 25.478909858917159)\n",
      "('Epoch: ', 178, ' Average loss at step ', 1000, ': ', 6.5665718626976011)\n",
      "('Epoch: ', 178, ' Average loss at step ', 2000, ': ', 6.628375299930573)\n",
      "('Epoch: ', 178, ' Average loss at step ', 2813, ': ', 6.4343568996842855)\n",
      "Training time took 97.702195 seconds to run 1 epoch\n",
      "('Epoch: ', 179, ' Average loss at step ', 1000, ': ', 0.073160383164882659)\n",
      "('Epoch: ', 179, ' Average loss at step ', 2000, ': ', 0.067219097197055822)\n",
      "('Epoch: ', 179, ' Average loss at step ', 2813, ': ', 0.0648436349600994)\n",
      "Training time took 44.046004 seconds to run 1 epoch\n",
      "Mean Rank:  4  of  28683\n",
      "Hits @ 10:  0.978318879253\n",
      "Hits @ 1:  0.927951967979\n",
      "Testing time took 73.166576 seconds.\n",
      "\n",
      "('Epoch: ', 180, ' Average loss at step ', 1000, ': ', 128.61830246734618)\n",
      "('Epoch: ', 180, ' Average loss at step ', 2000, ': ', 128.581719039917)\n",
      "('Epoch: ', 180, ' Average loss at step ', 3000, ': ', 128.95499297332765)\n",
      "('Epoch: ', 180, ' Average loss at step ', 4000, ': ', 127.40888291168213)\n",
      "('Epoch: ', 180, ' Average loss at step ', 4373, ': ', 131.3537502083727)\n",
      "('Epoch: ', 180, ' Average loss at step ', 761, ': ', 5598.8744262695309)\n",
      "('Epoch: ', 180, ' Average loss at step ', 782, ': ', 6432.2120484805137)\n",
      "('Epoch: ', 180, ' Average loss at step ', 787, ': ', 25.206913510048359)\n",
      "('Epoch: ', 180, ' Average loss at step ', 1000, ': ', 6.6525770173072818)\n",
      "('Epoch: ', 180, ' Average loss at step ', 2000, ': ', 6.6590205645561218)\n",
      "('Epoch: ', 180, ' Average loss at step ', 2813, ': ', 6.5476662190676906)\n",
      "Training time took 97.797585 seconds to run 1 epoch\n",
      "('Epoch: ', 181, ' Average loss at step ', 1000, ': ', 0.072666056752204888)\n",
      "('Epoch: ', 181, ' Average loss at step ', 2000, ': ', 0.067265414237976079)\n",
      "('Epoch: ', 181, ' Average loss at step ', 2813, ': ', 0.064391700651845324)\n",
      "Training time took 44.027693 seconds to run 1 epoch\n",
      "('Epoch: ', 182, ' Average loss at step ', 1000, ': ', 128.4791679840088)\n",
      "('Epoch: ', 182, ' Average loss at step ', 2000, ': ', 126.36606066131591)\n",
      "('Epoch: ', 182, ' Average loss at step ', 3000, ': ', 127.84766021728515)\n",
      "('Epoch: ', 182, ' Average loss at step ', 4000, ': ', 127.65209201812745)\n",
      "('Epoch: ', 182, ' Average loss at step ', 4373, ': ', 128.15739147637481)\n",
      "('Epoch: ', 182, ' Average loss at step ', 761, ': ', 5670.325230969881)\n",
      "('Epoch: ', 182, ' Average loss at step ', 782, ': ', 6365.0683675026012)\n",
      "('Epoch: ', 182, ' Average loss at step ', 787, ': ', 25.147623210159573)\n",
      "('Epoch: ', 182, ' Average loss at step ', 1000, ': ', 6.5954693164825438)\n",
      "('Epoch: ', 182, ' Average loss at step ', 2000, ': ', 6.7111535234451294)\n",
      "('Epoch: ', 182, ' Average loss at step ', 2813, ': ', 6.6434401179769358)\n",
      "Training time took 97.768625 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 183, ' Average loss at step ', 1000, ': ', 0.072036265373229977)\n",
      "('Epoch: ', 183, ' Average loss at step ', 2000, ': ', 0.066035610616207122)\n",
      "('Epoch: ', 183, ' Average loss at step ', 2813, ': ', 0.063825573680436079)\n",
      "Training time took 44.03005 seconds to run 1 epoch\n",
      "('Epoch: ', 184, ' Average loss at step ', 1000, ': ', 127.80575832366944)\n",
      "('Epoch: ', 184, ' Average loss at step ', 2000, ': ', 126.80653193664551)\n",
      "('Epoch: ', 184, ' Average loss at step ', 3000, ': ', 128.30828251266479)\n",
      "('Epoch: ', 184, ' Average loss at step ', 4000, ': ', 127.30811975097656)\n",
      "('Epoch: ', 184, ' Average loss at step ', 4373, ': ', 130.39232064318912)\n",
      "('Epoch: ', 184, ' Average loss at step ', 761, ': ', 5675.8076136538857)\n",
      "('Epoch: ', 184, ' Average loss at step ', 782, ': ', 6406.6929964463625)\n",
      "('Epoch: ', 184, ' Average loss at step ', 787, ': ', 24.831113816520944)\n",
      "('Epoch: ', 184, ' Average loss at step ', 1000, ': ', 6.6075793652534482)\n",
      "('Epoch: ', 184, ' Average loss at step ', 2000, ': ', 6.6069850625991817)\n",
      "('Epoch: ', 184, ' Average loss at step ', 2813, ': ', 6.6233471027148765)\n",
      "Training time took 97.764277 seconds to run 1 epoch\n",
      "('Epoch: ', 185, ' Average loss at step ', 1000, ': ', 0.070530784547328945)\n",
      "('Epoch: ', 185, ' Average loss at step ', 2000, ': ', 0.065539110302925113)\n",
      "('Epoch: ', 185, ' Average loss at step ', 2813, ': ', 0.062841834986738385)\n",
      "Training time took 44.036679 seconds to run 1 epoch\n",
      "('Epoch: ', 186, ' Average loss at step ', 1000, ': ', 127.43305571746826)\n",
      "('Epoch: ', 186, ' Average loss at step ', 2000, ': ', 128.31938211822509)\n",
      "('Epoch: ', 186, ' Average loss at step ', 3000, ': ', 127.55549542999267)\n",
      "('Epoch: ', 186, ' Average loss at step ', 4000, ': ', 127.76673653411865)\n",
      "('Epoch: ', 186, ' Average loss at step ', 4373, ': ', 130.05591913448868)\n",
      "('Epoch: ', 186, ' Average loss at step ', 761, ': ', 5711.322177927118)\n",
      "('Epoch: ', 186, ' Average loss at step ', 782, ': ', 6483.5963899072703)\n",
      "('Epoch: ', 186, ' Average loss at step ', 787, ': ', 24.755879072135944)\n",
      "('Epoch: ', 186, ' Average loss at step ', 1000, ': ', 6.4386505408287045)\n",
      "('Epoch: ', 186, ' Average loss at step ', 2000, ': ', 6.5787236895561216)\n",
      "('Epoch: ', 186, ' Average loss at step ', 2813, ': ', 6.5160895891377493)\n",
      "Training time took 97.879686 seconds to run 1 epoch\n",
      "('Epoch: ', 187, ' Average loss at step ', 1000, ': ', 0.070712096989154816)\n",
      "('Epoch: ', 187, ' Average loss at step ', 2000, ': ', 0.064576601147651666)\n",
      "('Epoch: ', 187, ' Average loss at step ', 2813, ': ', 0.062832514053495062)\n",
      "Training time took 44.021087 seconds to run 1 epoch\n",
      "('Epoch: ', 188, ' Average loss at step ', 1000, ': ', 131.04317067718506)\n",
      "('Epoch: ', 188, ' Average loss at step ', 2000, ': ', 127.85594759368897)\n",
      "('Epoch: ', 188, ' Average loss at step ', 3000, ': ', 128.36959329223632)\n",
      "('Epoch: ', 188, ' Average loss at step ', 4000, ': ', 129.179533203125)\n",
      "('Epoch: ', 188, ' Average loss at step ', 4373, ': ', 130.65188723738476)\n",
      "('Epoch: ', 188, ' Average loss at step ', 761, ': ', 5695.0379182514389)\n",
      "('Epoch: ', 188, ' Average loss at step ', 782, ': ', 6499.6160965258887)\n",
      "('Epoch: ', 188, ' Average loss at step ', 787, ': ', 24.648192433607186)\n",
      "('Epoch: ', 188, ' Average loss at step ', 1000, ': ', 6.4835108785629272)\n",
      "('Epoch: ', 188, ' Average loss at step ', 2000, ': ', 6.621504827976227)\n",
      "('Epoch: ', 188, ' Average loss at step ', 2813, ': ', 6.3843979624104614)\n",
      "Training time took 97.784074 seconds to run 1 epoch\n",
      "('Epoch: ', 189, ' Average loss at step ', 1000, ': ', 0.069111125171184534)\n",
      "('Epoch: ', 189, ' Average loss at step ', 2000, ': ', 0.064798235237598423)\n",
      "('Epoch: ', 189, ' Average loss at step ', 2813, ': ', 0.061936481392442302)\n",
      "Training time took 44.014872 seconds to run 1 epoch\n",
      "Mean Rank:  4  of  28683\n",
      "Hits @ 10:  0.978652434957\n",
      "Hits @ 1:  0.929486324216\n",
      "Testing time took 73.122962 seconds.\n",
      "\n",
      "('Epoch: ', 190, ' Average loss at step ', 1000, ': ', 128.01035793304445)\n",
      "('Epoch: ', 190, ' Average loss at step ', 2000, ': ', 129.00120826721192)\n",
      "('Epoch: ', 190, ' Average loss at step ', 3000, ': ', 127.49415051269531)\n",
      "('Epoch: ', 190, ' Average loss at step ', 4000, ': ', 128.3056414489746)\n",
      "('Epoch: ', 190, ' Average loss at step ', 4373, ': ', 128.23620970531175)\n",
      "('Epoch: ', 190, ' Average loss at step ', 761, ': ', 5738.7637406198601)\n",
      "('Epoch: ', 190, ' Average loss at step ', 782, ': ', 6539.0447280629805)\n",
      "('Epoch: ', 190, ' Average loss at step ', 787, ': ', 24.632769447549911)\n",
      "('Epoch: ', 190, ' Average loss at step ', 1000, ': ', 6.3767208189964295)\n",
      "('Epoch: ', 190, ' Average loss at step ', 2000, ': ', 6.5359417486190798)\n",
      "('Epoch: ', 190, ' Average loss at step ', 2813, ': ', 6.338239514769004)\n",
      "Training time took 97.834446 seconds to run 1 epoch\n",
      "('Epoch: ', 191, ' Average loss at step ', 1000, ': ', 0.068043517827987676)\n",
      "('Epoch: ', 191, ' Average loss at step ', 2000, ': ', 0.063528907895088194)\n",
      "('Epoch: ', 191, ' Average loss at step ', 2813, ': ', 0.061264538779634559)\n",
      "Training time took 44.030753 seconds to run 1 epoch\n",
      "('Epoch: ', 192, ' Average loss at step ', 1000, ': ', 127.85458365631104)\n",
      "('Epoch: ', 192, ' Average loss at step ', 2000, ': ', 128.54779902648926)\n",
      "('Epoch: ', 192, ' Average loss at step ', 3000, ': ', 128.36718557739258)\n",
      "('Epoch: ', 192, ' Average loss at step ', 4000, ': ', 128.35832659912109)\n",
      "('Epoch: ', 192, ' Average loss at step ', 4373, ': ', 126.83107650920908)\n",
      "('Epoch: ', 192, ' Average loss at step ', 761, ': ', 5740.5172334369863)\n",
      "('Epoch: ', 192, ' Average loss at step ', 782, ': ', 6542.8362294684302)\n",
      "('Epoch: ', 192, ' Average loss at step ', 787, ': ', 24.034752723218222)\n",
      "('Epoch: ', 192, ' Average loss at step ', 1000, ': ', 6.3638185329437258)\n",
      "('Epoch: ', 192, ' Average loss at step ', 2000, ': ', 6.3449091091156005)\n",
      "('Epoch: ', 192, ' Average loss at step ', 2813, ': ', 6.5348457902523096)\n",
      "Training time took 97.884636 seconds to run 1 epoch\n",
      "('Epoch: ', 193, ' Average loss at step ', 1000, ': ', 0.068932151019573215)\n",
      "('Epoch: ', 193, ' Average loss at step ', 2000, ': ', 0.063400557041168218)\n",
      "('Epoch: ', 193, ' Average loss at step ', 2813, ': ', 0.060090259231370069)\n",
      "Training time took 44.047993 seconds to run 1 epoch\n",
      "('Epoch: ', 194, ' Average loss at step ', 1000, ': ', 129.38276103973388)\n",
      "('Epoch: ', 194, ' Average loss at step ', 2000, ': ', 129.79567497253419)\n",
      "('Epoch: ', 194, ' Average loss at step ', 3000, ': ', 128.05928627777101)\n",
      "('Epoch: ', 194, ' Average loss at step ', 4000, ': ', 127.26746537017823)\n",
      "('Epoch: ', 194, ' Average loss at step ', 4373, ': ', 129.34412055887202)\n",
      "('Epoch: ', 194, ' Average loss at step ', 761, ': ', 5766.8308898925779)\n",
      "('Epoch: ', 194, ' Average loss at step ', 782, ': ', 6565.3877034401012)\n",
      "('Epoch: ', 194, ' Average loss at step ', 787, ': ', 24.505351226748402)\n",
      "('Epoch: ', 194, ' Average loss at step ', 1000, ': ', 6.4414265809059144)\n",
      "('Epoch: ', 194, ' Average loss at step ', 2000, ': ', 6.3356881837844847)\n",
      "('Epoch: ', 194, ' Average loss at step ', 2813, ': ', 6.3705780406303596)\n",
      "Training time took 97.775473 seconds to run 1 epoch\n",
      "('Epoch: ', 195, ' Average loss at step ', 1000, ': ', 0.067726083099842072)\n",
      "('Epoch: ', 195, ' Average loss at step ', 2000, ': ', 0.062425492227077481)\n",
      "('Epoch: ', 195, ' Average loss at step ', 2813, ': ', 0.059656800087449585)\n",
      "Training time took 44.019838 seconds to run 1 epoch\n",
      "('Epoch: ', 196, ' Average loss at step ', 1000, ': ', 128.45734328460694)\n",
      "('Epoch: ', 196, ' Average loss at step ', 2000, ': ', 129.35864498138429)\n",
      "('Epoch: ', 196, ' Average loss at step ', 3000, ': ', 128.51002645111083)\n",
      "('Epoch: ', 196, ' Average loss at step ', 4000, ': ', 128.37992566680907)\n",
      "('Epoch: ', 196, ' Average loss at step ', 4373, ': ', 130.67671550217494)\n",
      "('Epoch: ', 196, ' Average loss at step ', 761, ': ', 5790.3322403757193)\n",
      "('Epoch: ', 196, ' Average loss at step ', 782, ': ', 6635.3102649097709)\n",
      "('Epoch: ', 196, ' Average loss at step ', 787, ': ', 24.274882425788704)\n",
      "('Epoch: ', 196, ' Average loss at step ', 1000, ': ', 6.3723593807220462)\n",
      "('Epoch: ', 196, ' Average loss at step ', 2000, ': ', 6.4015741696357731)\n",
      "('Epoch: ', 196, ' Average loss at step ', 2813, ': ', 6.2804237615885992)\n",
      "Training time took 97.798044 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 197, ' Average loss at step ', 1000, ': ', 0.067013303637504573)\n",
      "('Epoch: ', 197, ' Average loss at step ', 2000, ': ', 0.061239157795906066)\n",
      "('Epoch: ', 197, ' Average loss at step ', 2813, ': ', 0.059908396284568483)\n",
      "Training time took 44.038489 seconds to run 1 epoch\n",
      "('Epoch: ', 198, ' Average loss at step ', 1000, ': ', 127.43352895355224)\n",
      "('Epoch: ', 198, ' Average loss at step ', 2000, ': ', 127.60948269653321)\n",
      "('Epoch: ', 198, ' Average loss at step ', 3000, ': ', 129.75067555236816)\n",
      "('Epoch: ', 198, ' Average loss at step ', 4000, ': ', 127.59928866195679)\n",
      "('Epoch: ', 198, ' Average loss at step ', 4373, ': ', 127.3830218981671)\n",
      "('Epoch: ', 198, ' Average loss at step ', 761, ': ', 5832.126486687911)\n",
      "('Epoch: ', 198, ' Average loss at step ', 782, ': ', 6628.6329869308174)\n",
      "('Epoch: ', 198, ' Average loss at step ', 787, ': ', 24.222496926936181)\n",
      "('Epoch: ', 198, ' Average loss at step ', 1000, ': ', 6.1819494137763975)\n",
      "('Epoch: ', 198, ' Average loss at step ', 2000, ': ', 6.163720425128937)\n",
      "('Epoch: ', 198, ' Average loss at step ', 2813, ': ', 6.4028715453124398)\n",
      "Training time took 97.831514 seconds to run 1 epoch\n",
      "('Epoch: ', 199, ' Average loss at step ', 1000, ': ', 0.06676089876890183)\n",
      "('Epoch: ', 199, ' Average loss at step ', 2000, ': ', 0.060955929756164554)\n",
      "('Epoch: ', 199, ' Average loss at step ', 2813, ': ', 0.059078583429599631)\n",
      "Training time took 44.045355 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.979653102068\n",
      "Hits @ 1:  0.930086724483\n",
      "Testing time took 73.749105 seconds.\n",
      "\n",
      "('Epoch: ', 200, ' Average loss at step ', 1000, ': ', 129.3158755569458)\n",
      "('Epoch: ', 200, ' Average loss at step ', 2000, ': ', 129.44033767700196)\n",
      "('Epoch: ', 200, ' Average loss at step ', 3000, ': ', 127.30765394592285)\n",
      "('Epoch: ', 200, ' Average loss at step ', 4000, ': ', 127.74261851119995)\n",
      "('Epoch: ', 200, ' Average loss at step ', 4373, ': ', 128.9645776030838)\n",
      "('Epoch: ', 200, ' Average loss at step ', 761, ': ', 5900.6881546823606)\n",
      "('Epoch: ', 200, ' Average loss at step ', 782, ': ', 6711.1157789242561)\n",
      "('Epoch: ', 200, ' Average loss at step ', 787, ': ', 24.321706438185906)\n",
      "('Epoch: ', 200, ' Average loss at step ', 1000, ': ', 6.262081263542175)\n",
      "('Epoch: ', 200, ' Average loss at step ', 2000, ': ', 6.3027301359176633)\n",
      "('Epoch: ', 200, ' Average loss at step ', 2813, ': ', 6.2091152227570854)\n",
      "Training time took 97.79586 seconds to run 1 epoch\n",
      "('Epoch: ', 201, ' Average loss at step ', 1000, ': ', 0.065604889988899226)\n",
      "('Epoch: ', 201, ' Average loss at step ', 2000, ': ', 0.061318095684051513)\n",
      "('Epoch: ', 201, ' Average loss at step ', 2813, ': ', 0.058152826915820834)\n",
      "Training time took 44.04082 seconds to run 1 epoch\n",
      "('Epoch: ', 202, ' Average loss at step ', 1000, ': ', 126.32987394714355)\n",
      "('Epoch: ', 202, ' Average loss at step ', 2000, ': ', 128.18282594299316)\n",
      "('Epoch: ', 202, ' Average loss at step ', 3000, ': ', 127.21456740570068)\n",
      "('Epoch: ', 202, ' Average loss at step ', 4000, ': ', 128.44600054931641)\n",
      "('Epoch: ', 202, ' Average loss at step ', 4373, ': ', 125.48060230542255)\n",
      "('Epoch: ', 202, ' Average loss at step ', 761, ': ', 5870.0802580180925)\n",
      "('Epoch: ', 202, ' Average loss at step ', 782, ': ', 6727.5774341539291)\n",
      "('Epoch: ', 202, ' Average loss at step ', 787, ': ', 23.630022892211837)\n",
      "('Epoch: ', 202, ' Average loss at step ', 1000, ': ', 6.2680292429924007)\n",
      "('Epoch: ', 202, ' Average loss at step ', 2000, ': ', 6.3227747392654416)\n",
      "('Epoch: ', 202, ' Average loss at step ', 2813, ': ', 6.354104195322309)\n",
      "Training time took 97.797517 seconds to run 1 epoch\n",
      "('Epoch: ', 203, ' Average loss at step ', 1000, ': ', 0.064997037172317501)\n",
      "('Epoch: ', 203, ' Average loss at step ', 2000, ': ', 0.060050821244716647)\n",
      "('Epoch: ', 203, ' Average loss at step ', 2813, ': ', 0.057640878070751432)\n",
      "Training time took 44.023977 seconds to run 1 epoch\n",
      "('Epoch: ', 204, ' Average loss at step ', 1000, ': ', 127.39239704132081)\n",
      "('Epoch: ', 204, ' Average loss at step ', 2000, ': ', 128.81600596618654)\n",
      "('Epoch: ', 204, ' Average loss at step ', 3000, ': ', 128.18222783660889)\n",
      "('Epoch: ', 204, ' Average loss at step ', 4000, ': ', 129.38166039276123)\n",
      "('Epoch: ', 204, ' Average loss at step ', 4373, ': ', 128.83033826274257)\n",
      "('Epoch: ', 204, ' Average loss at step ', 761, ': ', 5941.2688338430307)\n",
      "('Epoch: ', 204, ' Average loss at step ', 782, ': ', 6756.6351551246398)\n",
      "('Epoch: ', 204, ' Average loss at step ', 787, ': ', 24.274381717652766)\n",
      "('Epoch: ', 204, ' Average loss at step ', 1000, ': ', 6.2136363239288332)\n",
      "('Epoch: ', 204, ' Average loss at step ', 2000, ': ', 6.1638615555763243)\n",
      "('Epoch: ', 204, ' Average loss at step ', 2813, ': ', 6.1881425345472518)\n",
      "Training time took 97.79664 seconds to run 1 epoch\n",
      "('Epoch: ', 205, ' Average loss at step ', 1000, ': ', 0.06430101776123047)\n",
      "('Epoch: ', 205, ' Average loss at step ', 2000, ': ', 0.059164321899414063)\n",
      "('Epoch: ', 205, ' Average loss at step ', 2813, ': ', 0.058132434419810482)\n",
      "Training time took 44.033367 seconds to run 1 epoch\n",
      "('Epoch: ', 206, ' Average loss at step ', 1000, ': ', 126.38259834289551)\n",
      "('Epoch: ', 206, ' Average loss at step ', 2000, ': ', 129.69488505172728)\n",
      "('Epoch: ', 206, ' Average loss at step ', 3000, ': ', 129.48447903442383)\n",
      "('Epoch: ', 206, ' Average loss at step ', 4000, ': ', 128.25269782257081)\n",
      "('Epoch: ', 206, ' Average loss at step ', 4373, ': ', 129.82491296337497)\n",
      "('Epoch: ', 206, ' Average loss at step ', 761, ': ', 5959.2185045744245)\n",
      "('Epoch: ', 206, ' Average loss at step ', 782, ': ', 6780.8863355023605)\n",
      "('Epoch: ', 206, ' Average loss at step ', 787, ': ', 24.075675802983096)\n",
      "('Epoch: ', 206, ' Average loss at step ', 1000, ': ', 6.253669488430023)\n",
      "('Epoch: ', 206, ' Average loss at step ', 2000, ': ', 6.1707163686752322)\n",
      "('Epoch: ', 206, ' Average loss at step ', 2813, ': ', 6.2377387907704698)\n",
      "Training time took 97.871154 seconds to run 1 epoch\n",
      "('Epoch: ', 207, ' Average loss at step ', 1000, ': ', 0.064159274160861965)\n",
      "('Epoch: ', 207, ' Average loss at step ', 2000, ': ', 0.05868178403377533)\n",
      "('Epoch: ', 207, ' Average loss at step ', 2813, ': ', 0.057235559219210017)\n",
      "Training time took 44.041442 seconds to run 1 epoch\n",
      "('Epoch: ', 208, ' Average loss at step ', 1000, ': ', 128.18536953735352)\n",
      "('Epoch: ', 208, ' Average loss at step ', 2000, ': ', 126.9657978515625)\n",
      "('Epoch: ', 208, ' Average loss at step ', 3000, ': ', 128.7705400238037)\n",
      "('Epoch: ', 208, ' Average loss at step ', 4000, ': ', 127.83300127410888)\n",
      "('Epoch: ', 208, ' Average loss at step ', 4373, ': ', 124.47170204244634)\n",
      "('Epoch: ', 208, ' Average loss at step ', 761, ': ', 5924.375768079256)\n",
      "('Epoch: ', 208, ' Average loss at step ', 782, ': ', 6823.0207979053293)\n",
      "('Epoch: ', 208, ' Average loss at step ', 787, ': ', 23.925194745148715)\n",
      "('Epoch: ', 208, ' Average loss at step ', 1000, ': ', 6.2604701743125917)\n",
      "('Epoch: ', 208, ' Average loss at step ', 2000, ': ', 6.1254117603302003)\n",
      "('Epoch: ', 208, ' Average loss at step ', 2813, ': ', 6.0815917153663825)\n",
      "Training time took 97.720498 seconds to run 1 epoch\n",
      "('Epoch: ', 209, ' Average loss at step ', 1000, ': ', 0.062889677345752709)\n",
      "('Epoch: ', 209, ' Average loss at step ', 2000, ': ', 0.058243893623352049)\n",
      "('Epoch: ', 209, ' Average loss at step ', 2813, ': ', 0.05638597700102576)\n",
      "Training time took 44.020846 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.979386257505\n",
      "Hits @ 1:  0.929419613075\n",
      "Testing time took 73.236851 seconds.\n",
      "\n",
      "('Epoch: ', 210, ' Average loss at step ', 1000, ': ', 127.16263745880127)\n",
      "('Epoch: ', 210, ' Average loss at step ', 2000, ': ', 128.81418332672118)\n",
      "('Epoch: ', 210, ' Average loss at step ', 3000, ': ', 129.31905897521972)\n",
      "('Epoch: ', 210, ' Average loss at step ', 4000, ': ', 127.47314110183716)\n",
      "('Epoch: ', 210, ' Average loss at step ', 4373, ': ', 131.19000502555602)\n",
      "('Epoch: ', 210, ' Average loss at step ', 761, ': ', 6040.1580299778989)\n",
      "('Epoch: ', 210, ' Average loss at step ', 782, ': ', 6854.515092329545)\n",
      "('Epoch: ', 210, ' Average loss at step ', 787, ': ', 23.704468205381591)\n",
      "('Epoch: ', 210, ' Average loss at step ', 1000, ': ', 6.1405750622749329)\n",
      "('Epoch: ', 210, ' Average loss at step ', 2000, ': ', 6.1193696947097775)\n",
      "('Epoch: ', 210, ' Average loss at step ', 2813, ': ', 6.2721567811637087)\n",
      "Training time took 97.643939 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 211, ' Average loss at step ', 1000, ': ', 0.062278363645076752)\n",
      "('Epoch: ', 211, ' Average loss at step ', 2000, ': ', 0.058254193127155303)\n",
      "('Epoch: ', 211, ' Average loss at step ', 2813, ': ', 0.056143500975200107)\n",
      "Training time took 44.020248 seconds to run 1 epoch\n",
      "('Epoch: ', 212, ' Average loss at step ', 1000, ': ', 130.46220319366455)\n",
      "('Epoch: ', 212, ' Average loss at step ', 2000, ': ', 127.67675734710693)\n",
      "('Epoch: ', 212, ' Average loss at step ', 3000, ': ', 128.93222584533692)\n",
      "('Epoch: ', 212, ' Average loss at step ', 4000, ': ', 127.80210129547119)\n",
      "('Epoch: ', 212, ' Average loss at step ', 4373, ': ', 131.25006437814363)\n",
      "('Epoch: ', 212, ' Average loss at step ', 761, ': ', 5969.1123162520562)\n",
      "('Epoch: ', 212, ' Average loss at step ', 782, ': ', 6837.0095280489759)\n",
      "('Epoch: ', 212, ' Average loss at step ', 787, ': ', 23.566929877866013)\n",
      "('Epoch: ', 212, ' Average loss at step ', 1000, ': ', 6.1987893633842468)\n",
      "('Epoch: ', 212, ' Average loss at step ', 2000, ': ', 6.2408568601608279)\n",
      "('Epoch: ', 212, ' Average loss at step ', 2813, ': ', 6.3396420337883708)\n",
      "Training time took 97.91266 seconds to run 1 epoch\n",
      "('Epoch: ', 213, ' Average loss at step ', 1000, ': ', 0.062363793909549714)\n",
      "('Epoch: ', 213, ' Average loss at step ', 2000, ': ', 0.057381805062294004)\n",
      "('Epoch: ', 213, ' Average loss at step ', 2813, ': ', 0.055364059844040518)\n",
      "Training time took 44.000464 seconds to run 1 epoch\n",
      "('Epoch: ', 214, ' Average loss at step ', 1000, ': ', 129.49431154632569)\n",
      "('Epoch: ', 214, ' Average loss at step ', 2000, ': ', 127.89278681945801)\n",
      "('Epoch: ', 214, ' Average loss at step ', 3000, ': ', 127.71223812866211)\n",
      "('Epoch: ', 214, ' Average loss at step ', 4000, ': ', 128.01313787841798)\n",
      "('Epoch: ', 214, ' Average loss at step ', 4373, ': ', 127.32550417992377)\n",
      "('Epoch: ', 214, ' Average loss at step ', 761, ': ', 6034.9144762541118)\n",
      "('Epoch: ', 214, ' Average loss at step ', 782, ': ', 6830.8217892225512)\n",
      "('Epoch: ', 214, ' Average loss at step ', 787, ': ', 23.741602753258238)\n",
      "('Epoch: ', 214, ' Average loss at step ', 1000, ': ', 6.2716675858497624)\n",
      "('Epoch: ', 214, ' Average loss at step ', 2000, ': ', 6.0603644170761104)\n",
      "('Epoch: ', 214, ' Average loss at step ', 2813, ': ', 6.2036352750703028)\n",
      "Training time took 97.789551 seconds to run 1 epoch\n",
      "('Epoch: ', 215, ' Average loss at step ', 1000, ': ', 0.0611828835606575)\n",
      "('Epoch: ', 215, ' Average loss at step ', 2000, ': ', 0.056738014519214633)\n",
      "('Epoch: ', 215, ' Average loss at step ', 2813, ': ', 0.055276179181531146)\n",
      "Training time took 44.045932 seconds to run 1 epoch\n",
      "('Epoch: ', 216, ' Average loss at step ', 1000, ': ', 127.6221177520752)\n",
      "('Epoch: ', 216, ' Average loss at step ', 2000, ': ', 129.61626839447021)\n",
      "('Epoch: ', 216, ' Average loss at step ', 3000, ': ', 129.66345693969726)\n",
      "('Epoch: ', 216, ' Average loss at step ', 4000, ': ', 127.19318832397461)\n",
      "('Epoch: ', 216, ' Average loss at step ', 4373, ': ', 128.59147412289855)\n",
      "('Epoch: ', 216, ' Average loss at step ', 761, ': ', 6033.1910075940586)\n",
      "('Epoch: ', 216, ' Average loss at step ', 782, ': ', 6910.9034603573145)\n",
      "('Epoch: ', 216, ' Average loss at step ', 787, ': ', 23.01292681512032)\n",
      "('Epoch: ', 216, ' Average loss at step ', 1000, ': ', 6.2096897978782657)\n",
      "('Epoch: ', 216, ' Average loss at step ', 2000, ': ', 6.1175656843185422)\n",
      "('Epoch: ', 216, ' Average loss at step ', 2813, ': ', 6.2540436213826895)\n",
      "Training time took 97.733111 seconds to run 1 epoch\n",
      "('Epoch: ', 217, ' Average loss at step ', 1000, ': ', 0.06106507450342178)\n",
      "('Epoch: ', 217, ' Average loss at step ', 2000, ': ', 0.056861107289791109)\n",
      "('Epoch: ', 217, ' Average loss at step ', 2813, ': ', 0.054501300521672062)\n",
      "Training time took 44.025716 seconds to run 1 epoch\n",
      "('Epoch: ', 218, ' Average loss at step ', 1000, ': ', 127.40975608825684)\n",
      "('Epoch: ', 218, ' Average loss at step ', 2000, ': ', 127.84139307403565)\n",
      "('Epoch: ', 218, ' Average loss at step ', 3000, ': ', 127.92999919128418)\n",
      "('Epoch: ', 218, ' Average loss at step ', 4000, ': ', 129.02422351074219)\n",
      "('Epoch: ', 218, ' Average loss at step ', 4373, ': ', 129.24351759879821)\n",
      "('Epoch: ', 218, ' Average loss at step ', 761, ': ', 5977.5641334935235)\n",
      "('Epoch: ', 218, ' Average loss at step ', 782, ': ', 6917.8590974111712)\n",
      "('Epoch: ', 218, ' Average loss at step ', 787, ': ', 23.16549097915339)\n",
      "('Epoch: ', 218, ' Average loss at step ', 1000, ': ', 5.8764541754722597)\n",
      "('Epoch: ', 218, ' Average loss at step ', 2000, ': ', 6.0657661156654354)\n",
      "('Epoch: ', 218, ' Average loss at step ', 2813, ': ', 6.0934783255525407)\n",
      "Training time took 97.83165 seconds to run 1 epoch\n",
      "('Epoch: ', 219, ' Average loss at step ', 1000, ': ', 0.060625977694988252)\n",
      "('Epoch: ', 219, ' Average loss at step ', 2000, ': ', 0.056129661321640018)\n",
      "('Epoch: ', 219, ' Average loss at step ', 2813, ': ', 0.053589610190227115)\n",
      "Training time took 44.025095 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.97985323549\n",
      "Hits @ 1:  0.929219479653\n",
      "Testing time took 73.163502 seconds.\n",
      "\n",
      "('Epoch: ', 220, ' Average loss at step ', 1000, ': ', 127.83681105804443)\n",
      "('Epoch: ', 220, ' Average loss at step ', 2000, ': ', 128.51435537719726)\n",
      "('Epoch: ', 220, ' Average loss at step ', 3000, ': ', 128.30382943725587)\n",
      "('Epoch: ', 220, ' Average loss at step ', 4000, ': ', 128.76271530151368)\n",
      "('Epoch: ', 220, ' Average loss at step ', 4373, ': ', 128.47702762644778)\n",
      "('Epoch: ', 220, ' Average loss at step ', 761, ': ', 6056.655188309519)\n",
      "('Epoch: ', 220, ' Average loss at step ', 782, ': ', 6899.8745929947581)\n",
      "('Epoch: ', 220, ' Average loss at step ', 787, ': ', 23.012222698929961)\n",
      "('Epoch: ', 220, ' Average loss at step ', 1000, ': ', 6.0172410593032835)\n",
      "('Epoch: ', 220, ' Average loss at step ', 2000, ': ', 5.9033113651275633)\n",
      "('Epoch: ', 220, ' Average loss at step ', 2813, ': ', 6.3156066181624464)\n",
      "Training time took 97.774913 seconds to run 1 epoch\n",
      "('Epoch: ', 221, ' Average loss at step ', 1000, ': ', 0.060114844262599942)\n",
      "('Epoch: ', 221, ' Average loss at step ', 2000, ': ', 0.055459584116935731)\n",
      "('Epoch: ', 221, ' Average loss at step ', 2813, ': ', 0.053835128255078357)\n",
      "Training time took 44.053411 seconds to run 1 epoch\n",
      "('Epoch: ', 222, ' Average loss at step ', 1000, ': ', 128.02047866058351)\n",
      "('Epoch: ', 222, ' Average loss at step ', 2000, ': ', 128.48273546600342)\n",
      "('Epoch: ', 222, ' Average loss at step ', 3000, ': ', 128.47964669799805)\n",
      "('Epoch: ', 222, ' Average loss at step ', 4000, ': ', 127.38557502746582)\n",
      "('Epoch: ', 222, ' Average loss at step ', 4373, ': ', 125.82920103175665)\n",
      "('Epoch: ', 222, ' Average loss at step ', 761, ': ', 6130.6612166555306)\n",
      "('Epoch: ', 222, ' Average loss at step ', 782, ': ', 7034.4725349611872)\n",
      "('Epoch: ', 222, ' Average loss at step ', 787, ': ', 22.726034415587215)\n",
      "('Epoch: ', 222, ' Average loss at step ', 1000, ': ', 5.9859344058036807)\n",
      "('Epoch: ', 222, ' Average loss at step ', 2000, ': ', 5.939764674663544)\n",
      "('Epoch: ', 222, ' Average loss at step ', 2813, ': ', 6.1164444796557493)\n",
      "Training time took 97.797432 seconds to run 1 epoch\n",
      "('Epoch: ', 223, ' Average loss at step ', 1000, ': ', 0.05950560563802719)\n",
      "('Epoch: ', 223, ' Average loss at step ', 2000, ': ', 0.054634643077850341)\n",
      "('Epoch: ', 223, ' Average loss at step ', 2813, ': ', 0.053175151494923481)\n",
      "Training time took 44.013523 seconds to run 1 epoch\n",
      "('Epoch: ', 224, ' Average loss at step ', 1000, ': ', 128.90857868194581)\n",
      "('Epoch: ', 224, ' Average loss at step ', 2000, ': ', 128.47818775177001)\n",
      "('Epoch: ', 224, ' Average loss at step ', 3000, ': ', 126.83871736145019)\n",
      "('Epoch: ', 224, ' Average loss at step ', 4000, ': ', 128.73444994354247)\n",
      "('Epoch: ', 224, ' Average loss at step ', 4373, ': ', 129.96773879758774)\n",
      "('Epoch: ', 224, ' Average loss at step ', 761, ': ', 6184.4868045204566)\n",
      "('Epoch: ', 224, ' Average loss at step ', 782, ': ', 7011.7079340388927)\n",
      "('Epoch: ', 224, ' Average loss at step ', 787, ': ', 22.628031315694329)\n",
      "('Epoch: ', 224, ' Average loss at step ', 1000, ': ', 6.1098590879440309)\n",
      "('Epoch: ', 224, ' Average loss at step ', 2000, ': ', 5.977659949302673)\n",
      "('Epoch: ', 224, ' Average loss at step ', 2813, ': ', 6.1615143186353114)\n",
      "Training time took 97.782496 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 225, ' Average loss at step ', 1000, ': ', 0.059119882166385654)\n",
      "('Epoch: ', 225, ' Average loss at step ', 2000, ': ', 0.054559736609458925)\n",
      "('Epoch: ', 225, ' Average loss at step ', 2813, ': ', 0.052843162652306958)\n",
      "Training time took 44.046659 seconds to run 1 epoch\n",
      "('Epoch: ', 226, ' Average loss at step ', 1000, ': ', 129.19307706069947)\n",
      "('Epoch: ', 226, ' Average loss at step ', 2000, ': ', 128.82651027679444)\n",
      "('Epoch: ', 226, ' Average loss at step ', 3000, ': ', 127.42926331329346)\n",
      "('Epoch: ', 226, ' Average loss at step ', 4000, ': ', 128.95171591949463)\n",
      "('Epoch: ', 226, ' Average loss at step ', 4373, ': ', 132.60131196052797)\n",
      "('Epoch: ', 226, ' Average loss at step ', 761, ': ', 6189.5026868318255)\n",
      "('Epoch: ', 226, ' Average loss at step ', 782, ': ', 7028.0316351232395)\n",
      "('Epoch: ', 226, ' Average loss at step ', 787, ': ', 22.324018124102334)\n",
      "('Epoch: ', 226, ' Average loss at step ', 1000, ': ', 5.9089797849655152)\n",
      "('Epoch: ', 226, ' Average loss at step ', 2000, ': ', 5.9205762772560115)\n",
      "('Epoch: ', 226, ' Average loss at step ', 2813, ': ', 6.0433025794663449)\n",
      "Training time took 97.691505 seconds to run 1 epoch\n",
      "('Epoch: ', 227, ' Average loss at step ', 1000, ': ', 0.058174561440944669)\n",
      "('Epoch: ', 227, ' Average loss at step ', 2000, ': ', 0.054350010752677917)\n",
      "('Epoch: ', 227, ' Average loss at step ', 2813, ': ', 0.052378985902358746)\n",
      "Training time took 44.050469 seconds to run 1 epoch\n",
      "('Epoch: ', 228, ' Average loss at step ', 1000, ': ', 127.8055812072754)\n",
      "('Epoch: ', 228, ' Average loss at step ', 2000, ': ', 127.55402714538575)\n",
      "('Epoch: ', 228, ' Average loss at step ', 3000, ': ', 126.96732012176514)\n",
      "('Epoch: ', 228, ' Average loss at step ', 4000, ': ', 127.56103479766846)\n",
      "('Epoch: ', 228, ' Average loss at step ', 4373, ': ', 128.27983735197333)\n",
      "('Epoch: ', 228, ' Average loss at step ', 761, ': ', 6152.9836184853002)\n",
      "('Epoch: ', 228, ' Average loss at step ', 782, ': ', 7016.8572055557779)\n",
      "('Epoch: ', 228, ' Average loss at step ', 787, ': ', 22.192433897168886)\n",
      "('Epoch: ', 228, ' Average loss at step ', 1000, ': ', 5.8648639359474179)\n",
      "('Epoch: ', 228, ' Average loss at step ', 2000, ': ', 5.9564245495796202)\n",
      "('Epoch: ', 228, ' Average loss at step ', 2813, ': ', 5.9445799272048649)\n",
      "Training time took 97.768832 seconds to run 1 epoch\n",
      "('Epoch: ', 229, ' Average loss at step ', 1000, ': ', 0.058181874752044678)\n",
      "('Epoch: ', 229, ' Average loss at step ', 2000, ': ', 0.053015745222568515)\n",
      "('Epoch: ', 229, ' Average loss at step ', 2813, ': ', 0.052156779272802947)\n",
      "Training time took 44.027392 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.980520346898\n",
      "Hits @ 1:  0.930220146765\n",
      "Testing time took 73.208433 seconds.\n",
      "\n",
      "('Epoch: ', 230, ' Average loss at step ', 1000, ': ', 127.7971051864624)\n",
      "('Epoch: ', 230, ' Average loss at step ', 2000, ': ', 127.42238255310059)\n",
      "('Epoch: ', 230, ' Average loss at step ', 3000, ': ', 128.42044876861573)\n",
      "('Epoch: ', 230, ' Average loss at step ', 4000, ': ', 129.16645604705812)\n",
      "('Epoch: ', 230, ' Average loss at step ', 4373, ': ', 127.77164596639653)\n",
      "('Epoch: ', 230, ' Average loss at step ', 761, ': ', 6169.4474612587373)\n",
      "('Epoch: ', 230, ' Average loss at step ', 782, ': ', 7128.8565966109154)\n",
      "('Epoch: ', 230, ' Average loss at step ', 787, ': ', 22.150488849814611)\n",
      "('Epoch: ', 230, ' Average loss at step ', 1000, ': ', 5.9613921213150025)\n",
      "('Epoch: ', 230, ' Average loss at step ', 2000, ': ', 5.9310463633537296)\n",
      "('Epoch: ', 230, ' Average loss at step ', 2813, ': ', 5.9165925556802987)\n",
      "Training time took 97.790853 seconds to run 1 epoch\n",
      "('Epoch: ', 231, ' Average loss at step ', 1000, ': ', 0.058017292857170104)\n",
      "('Epoch: ', 231, ' Average loss at step ', 2000, ': ', 0.05336699187755585)\n",
      "('Epoch: ', 231, ' Average loss at step ', 2813, ': ', 0.050986633879210562)\n",
      "Training time took 44.032043 seconds to run 1 epoch\n",
      "('Epoch: ', 232, ' Average loss at step ', 1000, ': ', 129.70555082702637)\n",
      "('Epoch: ', 232, ' Average loss at step ', 2000, ': ', 129.68506729125977)\n",
      "('Epoch: ', 232, ' Average loss at step ', 3000, ': ', 128.26961206054688)\n",
      "('Epoch: ', 232, ' Average loss at step ', 4000, ': ', 129.37870574951171)\n",
      "('Epoch: ', 232, ' Average loss at step ', 4373, ': ', 128.36941466792936)\n",
      "('Epoch: ', 232, ' Average loss at step ', 761, ': ', 6229.9419793379939)\n",
      "('Epoch: ', 232, ' Average loss at step ', 782, ': ', 7163.361258727793)\n",
      "('Epoch: ', 232, ' Average loss at step ', 787, ': ', 21.957353492426204)\n",
      "('Epoch: ', 232, ' Average loss at step ', 1000, ': ', 5.7981078910827639)\n",
      "('Epoch: ', 232, ' Average loss at step ', 2000, ': ', 5.7195496406555177)\n",
      "('Epoch: ', 232, ' Average loss at step ', 2813, ': ', 5.7703940398587381)\n",
      "Training time took 97.78743 seconds to run 1 epoch\n",
      "('Epoch: ', 233, ' Average loss at step ', 1000, ': ', 0.056938724696636203)\n",
      "('Epoch: ', 233, ' Average loss at step ', 2000, ': ', 0.052890326738357543)\n",
      "('Epoch: ', 233, ' Average loss at step ', 2813, ': ', 0.051138656039543338)\n",
      "Training time took 44.037468 seconds to run 1 epoch\n",
      "('Epoch: ', 234, ' Average loss at step ', 1000, ': ', 128.11341986846924)\n",
      "('Epoch: ', 234, ' Average loss at step ', 2000, ': ', 125.42288282775878)\n",
      "('Epoch: ', 234, ' Average loss at step ', 3000, ': ', 127.96296269989014)\n",
      "('Epoch: ', 234, ' Average loss at step ', 4000, ': ', 127.01113899993896)\n",
      "('Epoch: ', 234, ' Average loss at step ', 4373, ': ', 125.77527684037403)\n",
      "('Epoch: ', 234, ' Average loss at step ', 761, ': ', 6263.3313964843746)\n",
      "('Epoch: ', 234, ' Average loss at step ', 782, ': ', 7172.2371202534814)\n",
      "('Epoch: ', 234, ' Average loss at step ', 787, ': ', 22.00660136031134)\n",
      "('Epoch: ', 234, ' Average loss at step ', 1000, ': ', 5.9112848834991452)\n",
      "('Epoch: ', 234, ' Average loss at step ', 2000, ': ', 5.7299982085227965)\n",
      "('Epoch: ', 234, ' Average loss at step ', 2813, ': ', 5.7617886324821432)\n",
      "Training time took 97.656749 seconds to run 1 epoch\n",
      "('Epoch: ', 235, ' Average loss at step ', 1000, ': ', 0.056913705527782438)\n",
      "('Epoch: ', 235, ' Average loss at step ', 2000, ': ', 0.052267586112022403)\n",
      "('Epoch: ', 235, ' Average loss at step ', 2813, ': ', 0.050621821008292323)\n",
      "Training time took 44.033361 seconds to run 1 epoch\n",
      "('Epoch: ', 236, ' Average loss at step ', 1000, ': ', 128.26764069366456)\n",
      "('Epoch: ', 236, ' Average loss at step ', 2000, ': ', 128.83685722351075)\n",
      "('Epoch: ', 236, ' Average loss at step ', 3000, ': ', 127.62212635040284)\n",
      "('Epoch: ', 236, ' Average loss at step ', 4000, ': ', 129.54922320556642)\n",
      "('Epoch: ', 236, ' Average loss at step ', 4373, ': ', 127.73237556539556)\n",
      "('Epoch: ', 236, ' Average loss at step ', 761, ': ', 6231.9603904322576)\n",
      "('Epoch: ', 236, ' Average loss at step ', 782, ': ', 7241.8436868547933)\n",
      "('Epoch: ', 236, ' Average loss at step ', 787, ': ', 21.836974816164595)\n",
      "('Epoch: ', 236, ' Average loss at step ', 1000, ': ', 5.9736861333847049)\n",
      "('Epoch: ', 236, ' Average loss at step ', 2000, ': ', 5.80047186756134)\n",
      "('Epoch: ', 236, ' Average loss at step ', 2813, ': ', 5.852682415487731)\n",
      "Training time took 97.878142 seconds to run 1 epoch\n",
      "('Epoch: ', 237, ' Average loss at step ', 1000, ': ', 0.055703096449375156)\n",
      "('Epoch: ', 237, ' Average loss at step ', 2000, ': ', 0.052652913749217989)\n",
      "('Epoch: ', 237, ' Average loss at step ', 2813, ': ', 0.050325595025945767)\n",
      "Training time took 44.042126 seconds to run 1 epoch\n",
      "('Epoch: ', 238, ' Average loss at step ', 1000, ': ', 128.48759642791748)\n",
      "('Epoch: ', 238, ' Average loss at step ', 2000, ': ', 128.24725296020509)\n",
      "('Epoch: ', 238, ' Average loss at step ', 3000, ': ', 129.58036666107176)\n",
      "('Epoch: ', 238, ' Average loss at step ', 4000, ': ', 128.61545725250244)\n",
      "('Epoch: ', 238, ' Average loss at step ', 4373, ': ', 128.90854529924289)\n",
      "('Epoch: ', 238, ' Average loss at step ', 761, ': ', 6317.7046396355881)\n",
      "('Epoch: ', 238, ' Average loss at step ', 782, ': ', 7160.7552660601395)\n",
      "('Epoch: ', 238, ' Average loss at step ', 787, ': ', 21.583359857855257)\n",
      "('Epoch: ', 238, ' Average loss at step ', 1000, ': ', 5.7040062932968141)\n",
      "('Epoch: ', 238, ' Average loss at step ', 2000, ': ', 5.8175559315681458)\n",
      "('Epoch: ', 238, ' Average loss at step ', 2813, ': ', 5.7451099210184786)\n",
      "Training time took 97.838481 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 239, ' Average loss at step ', 1000, ': ', 0.056068094134330747)\n",
      "('Epoch: ', 239, ' Average loss at step ', 2000, ': ', 0.051313559353351593)\n",
      "('Epoch: ', 239, ' Average loss at step ', 2813, ': ', 0.04970198465979158)\n",
      "Training time took 44.033054 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.980453635757\n",
      "Hits @ 1:  0.930620413609\n",
      "Testing time took 73.254016 seconds.\n",
      "\n",
      "('Epoch: ', 240, ' Average loss at step ', 1000, ': ', 128.27347818756104)\n",
      "('Epoch: ', 240, ' Average loss at step ', 2000, ': ', 126.82784304046631)\n",
      "('Epoch: ', 240, ' Average loss at step ', 3000, ': ', 129.09642481231688)\n",
      "('Epoch: ', 240, ' Average loss at step ', 4000, ': ', 128.21295233154297)\n",
      "('Epoch: ', 240, ' Average loss at step ', 4373, ': ', 128.01177080215948)\n",
      "('Epoch: ', 240, ' Average loss at step ', 761, ': ', 6349.7501876027964)\n",
      "('Epoch: ', 240, ' Average loss at step ', 782, ': ', 7198.5496190030808)\n",
      "('Epoch: ', 240, ' Average loss at step ', 787, ': ', 21.415744933159903)\n",
      "('Epoch: ', 240, ' Average loss at step ', 1000, ': ', 5.610634265899658)\n",
      "('Epoch: ', 240, ' Average loss at step ', 2000, ': ', 5.7201121330261229)\n",
      "('Epoch: ', 240, ' Average loss at step ', 2813, ': ', 5.8410642100085175)\n",
      "Training time took 97.742286 seconds to run 1 epoch\n",
      "('Epoch: ', 241, ' Average loss at step ', 1000, ': ', 0.055617144882678986)\n",
      "('Epoch: ', 241, ' Average loss at step ', 2000, ': ', 0.050906249284744264)\n",
      "('Epoch: ', 241, ' Average loss at step ', 2813, ': ', 0.049067996772639268)\n",
      "Training time took 44.011145 seconds to run 1 epoch\n",
      "('Epoch: ', 242, ' Average loss at step ', 1000, ': ', 128.41886991882325)\n",
      "('Epoch: ', 242, ' Average loss at step ', 2000, ': ', 126.32188341140747)\n",
      "('Epoch: ', 242, ' Average loss at step ', 3000, ': ', 127.44950106048584)\n",
      "('Epoch: ', 242, ' Average loss at step ', 4000, ': ', 129.85750157165526)\n",
      "('Epoch: ', 242, ' Average loss at step ', 4373, ': ', 128.51845062419932)\n",
      "('Epoch: ', 242, ' Average loss at step ', 761, ': ', 6325.7832734760486)\n",
      "('Epoch: ', 242, ' Average loss at step ', 782, ': ', 7325.684255836868)\n",
      "('Epoch: ', 242, ' Average loss at step ', 787, ': ', 21.747463703155518)\n",
      "('Epoch: ', 242, ' Average loss at step ', 1000, ': ', 5.6911673207283018)\n",
      "('Epoch: ', 242, ' Average loss at step ', 2000, ': ', 5.6802762064933781)\n",
      "('Epoch: ', 242, ' Average loss at step ', 2813, ': ', 5.6376274137074134)\n",
      "Training time took 97.783723 seconds to run 1 epoch\n",
      "('Epoch: ', 243, ' Average loss at step ', 1000, ': ', 0.055408765017986299)\n",
      "('Epoch: ', 243, ' Average loss at step ', 2000, ': ', 0.050619179368019102)\n",
      "('Epoch: ', 243, ' Average loss at step ', 2813, ': ', 0.049177795721979563)\n",
      "Training time took 44.012586 seconds to run 1 epoch\n",
      "('Epoch: ', 244, ' Average loss at step ', 1000, ': ', 129.09546600341798)\n",
      "('Epoch: ', 244, ' Average loss at step ', 2000, ': ', 128.20749095153809)\n",
      "('Epoch: ', 244, ' Average loss at step ', 3000, ': ', 129.37019676971437)\n",
      "('Epoch: ', 244, ' Average loss at step ', 4000, ': ', 127.1729651260376)\n",
      "('Epoch: ', 244, ' Average loss at step ', 4373, ': ', 128.28679394465621)\n",
      "('Epoch: ', 244, ' Average loss at step ', 761, ': ', 6406.4932019685448)\n",
      "('Epoch: ', 244, ' Average loss at step ', 782, ': ', 7329.2854982344352)\n",
      "('Epoch: ', 244, ' Average loss at step ', 787, ': ', 21.636038974344579)\n",
      "('Epoch: ', 244, ' Average loss at step ', 1000, ': ', 5.5916890821456908)\n",
      "('Epoch: ', 244, ' Average loss at step ', 2000, ': ', 5.703447033405304)\n",
      "('Epoch: ', 244, ' Average loss at step ', 2813, ': ', 5.555638848267165)\n",
      "Training time took 97.825707 seconds to run 1 epoch\n",
      "('Epoch: ', 245, ' Average loss at step ', 1000, ': ', 0.054098189294338225)\n",
      "('Epoch: ', 245, ' Average loss at step ', 2000, ': ', 0.050684653997421267)\n",
      "('Epoch: ', 245, ' Average loss at step ', 2813, ': ', 0.048790500375437619)\n",
      "Training time took 44.009983 seconds to run 1 epoch\n",
      "('Epoch: ', 246, ' Average loss at step ', 1000, ': ', 127.96350158691406)\n",
      "('Epoch: ', 246, ' Average loss at step ', 2000, ': ', 128.14111852264404)\n",
      "('Epoch: ', 246, ' Average loss at step ', 3000, ': ', 127.51878581237793)\n",
      "('Epoch: ', 246, ' Average loss at step ', 4000, ': ', 127.7084593887329)\n",
      "('Epoch: ', 246, ' Average loss at step ', 4373, ': ', 126.55490709120228)\n",
      "('Epoch: ', 246, ' Average loss at step ', 761, ': ', 6393.9510424162208)\n",
      "('Epoch: ', 246, ' Average loss at step ', 782, ': ', 7285.392112976152)\n",
      "('Epoch: ', 246, ' Average loss at step ', 787, ': ', 21.613196802503278)\n",
      "('Epoch: ', 246, ' Average loss at step ', 1000, ': ', 5.5793707747459411)\n",
      "('Epoch: ', 246, ' Average loss at step ', 2000, ': ', 5.7127053122520444)\n",
      "('Epoch: ', 246, ' Average loss at step ', 2813, ': ', 5.593012809753418)\n",
      "Training time took 97.779273 seconds to run 1 epoch\n",
      "('Epoch: ', 247, ' Average loss at step ', 1000, ': ', 0.053621054053306583)\n",
      "('Epoch: ', 247, ' Average loss at step ', 2000, ': ', 0.049991440653800963)\n",
      "('Epoch: ', 247, ' Average loss at step ', 2813, ': ', 0.048376405033571969)\n",
      "Training time took 44.01101 seconds to run 1 epoch\n",
      "('Epoch: ', 248, ' Average loss at step ', 1000, ': ', 128.82404161071779)\n",
      "('Epoch: ', 248, ' Average loss at step ', 2000, ': ', 128.42150748062133)\n",
      "('Epoch: ', 248, ' Average loss at step ', 3000, ': ', 128.27720993804931)\n",
      "('Epoch: ', 248, ' Average loss at step ', 4000, ': ', 129.37895150375365)\n",
      "('Epoch: ', 248, ' Average loss at step ', 4373, ': ', 127.88041092247092)\n",
      "('Epoch: ', 248, ' Average loss at step ', 761, ': ', 6432.2432594700867)\n",
      "('Epoch: ', 248, ' Average loss at step ', 782, ': ', 7299.823064630682)\n",
      "('Epoch: ', 248, ' Average loss at step ', 787, ': ', 21.465057522285985)\n",
      "('Epoch: ', 248, ' Average loss at step ', 1000, ': ', 5.7192119965553285)\n",
      "('Epoch: ', 248, ' Average loss at step ', 2000, ': ', 5.573272441864014)\n",
      "('Epoch: ', 248, ' Average loss at step ', 2813, ': ', 5.6243143122771695)\n",
      "Training time took 97.861671 seconds to run 1 epoch\n",
      "('Epoch: ', 249, ' Average loss at step ', 1000, ': ', 0.053426995217800137)\n",
      "('Epoch: ', 249, ' Average loss at step ', 2000, ': ', 0.049785043895244602)\n",
      "('Epoch: ', 249, ' Average loss at step ', 2813, ': ', 0.047700190558809363)\n",
      "Training time took 44.029499 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.980987324883\n",
      "Hits @ 1:  0.930286857905\n",
      "Testing time took 73.129858 seconds.\n",
      "\n",
      "('Epoch: ', 250, ' Average loss at step ', 1000, ': ', 128.42776365661621)\n",
      "('Epoch: ', 250, ' Average loss at step ', 2000, ': ', 126.0585576057434)\n",
      "('Epoch: ', 250, ' Average loss at step ', 3000, ': ', 128.45364672088624)\n",
      "('Epoch: ', 250, ' Average loss at step ', 4000, ': ', 129.79058158874511)\n",
      "('Epoch: ', 250, ' Average loss at step ', 4373, ': ', 129.52514901725195)\n",
      "('Epoch: ', 250, ' Average loss at step ', 761, ': ', 6506.3029727333469)\n",
      "('Epoch: ', 250, ' Average loss at step ', 782, ': ', 7340.2680764094512)\n",
      "('Epoch: ', 250, ' Average loss at step ', 787, ': ', 21.539350324004662)\n",
      "('Epoch: ', 250, ' Average loss at step ', 1000, ': ', 5.6159556088447573)\n",
      "('Epoch: ', 250, ' Average loss at step ', 2000, ': ', 5.7566976995468142)\n",
      "('Epoch: ', 250, ' Average loss at step ', 2813, ': ', 5.7493248995888999)\n",
      "Training time took 97.808779 seconds to run 1 epoch\n",
      "('Epoch: ', 251, ' Average loss at step ', 1000, ': ', 0.053443103492259982)\n",
      "('Epoch: ', 251, ' Average loss at step ', 2000, ': ', 0.049465681314468386)\n",
      "('Epoch: ', 251, ' Average loss at step ', 2813, ': ', 0.04746157943908804)\n",
      "Training time took 44.035294 seconds to run 1 epoch\n",
      "('Epoch: ', 252, ' Average loss at step ', 1000, ': ', 128.06661441802979)\n",
      "('Epoch: ', 252, ' Average loss at step ', 2000, ': ', 127.11962338256836)\n",
      "('Epoch: ', 252, ' Average loss at step ', 3000, ': ', 128.79385682678222)\n",
      "('Epoch: ', 252, ' Average loss at step ', 4000, ': ', 128.11155624389647)\n",
      "('Epoch: ', 252, ' Average loss at step ', 4373, ': ', 127.7538199065834)\n",
      "('Epoch: ', 252, ' Average loss at step ', 761, ': ', 6359.5921210038032)\n",
      "('Epoch: ', 252, ' Average loss at step ', 782, ': ', 7358.5943214328581)\n",
      "('Epoch: ', 252, ' Average loss at step ', 787, ': ', 20.81833426885629)\n",
      "('Epoch: ', 252, ' Average loss at step ', 1000, ': ', 5.5733684220314021)\n",
      "('Epoch: ', 252, ' Average loss at step ', 2000, ': ', 5.4683490910530086)\n",
      "('Epoch: ', 252, ' Average loss at step ', 2813, ': ', 5.5209897885768875)\n",
      "Training time took 97.76524 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 253, ' Average loss at step ', 1000, ': ', 0.053304447054862973)\n",
      "('Epoch: ', 253, ' Average loss at step ', 2000, ': ', 0.048334123134613036)\n",
      "('Epoch: ', 253, ' Average loss at step ', 2813, ': ', 0.047470968785544333)\n",
      "Training time took 44.02332 seconds to run 1 epoch\n",
      "('Epoch: ', 254, ' Average loss at step ', 1000, ': ', 128.53758836364747)\n",
      "('Epoch: ', 254, ' Average loss at step ', 2000, ': ', 128.62805096435548)\n",
      "('Epoch: ', 254, ' Average loss at step ', 3000, ': ', 127.43126422882079)\n",
      "('Epoch: ', 254, ' Average loss at step ', 4000, ': ', 128.42593951416015)\n",
      "('Epoch: ', 254, ' Average loss at step ', 4373, ': ', 128.23337241142028)\n",
      "('Epoch: ', 254, ' Average loss at step ', 761, ': ', 6503.43548905222)\n",
      "('Epoch: ', 254, ' Average loss at step ', 782, ': ', 7344.7544001580509)\n",
      "('Epoch: ', 254, ' Average loss at step ', 787, ': ', 21.207910530439769)\n",
      "('Epoch: ', 254, ' Average loss at step ', 1000, ': ', 5.5348867983818053)\n",
      "('Epoch: ', 254, ' Average loss at step ', 2000, ': ', 5.7174606218338013)\n",
      "('Epoch: ', 254, ' Average loss at step ', 2813, ': ', 5.5826648920040416)\n",
      "Training time took 97.880103 seconds to run 1 epoch\n",
      "('Epoch: ', 255, ' Average loss at step ', 1000, ': ', 0.052483357548713687)\n",
      "('Epoch: ', 255, ' Average loss at step ', 2000, ': ', 0.048460641980171207)\n",
      "('Epoch: ', 255, ' Average loss at step ', 2813, ': ', 0.046948774547999714)\n",
      "Training time took 44.01526 seconds to run 1 epoch\n",
      "('Epoch: ', 256, ' Average loss at step ', 1000, ': ', 128.25705684661864)\n",
      "('Epoch: ', 256, ' Average loss at step ', 2000, ': ', 130.41254608154296)\n",
      "('Epoch: ', 256, ' Average loss at step ', 3000, ': ', 128.98802294921876)\n",
      "('Epoch: ', 256, ' Average loss at step ', 4000, ': ', 127.59343641662598)\n",
      "('Epoch: ', 256, ' Average loss at step ', 4373, ': ', 126.76488285679972)\n",
      "('Epoch: ', 256, ' Average loss at step ', 761, ': ', 6490.1368494937296)\n",
      "('Epoch: ', 256, ' Average loss at step ', 782, ': ', 7405.7079277868916)\n",
      "('Epoch: ', 256, ' Average loss at step ', 787, ': ', 20.827454377676695)\n",
      "('Epoch: ', 256, ' Average loss at step ', 1000, ': ', 5.6000967020988464)\n",
      "('Epoch: ', 256, ' Average loss at step ', 2000, ': ', 5.4841972904205321)\n",
      "('Epoch: ', 256, ' Average loss at step ', 2813, ': ', 5.5423202714309321)\n",
      "Training time took 97.76053 seconds to run 1 epoch\n",
      "('Epoch: ', 257, ' Average loss at step ', 1000, ': ', 0.052086320817470548)\n",
      "('Epoch: ', 257, ' Average loss at step ', 2000, ': ', 0.048396293163299561)\n",
      "('Epoch: ', 257, ' Average loss at step ', 2813, ': ', 0.046431601341134811)\n",
      "Training time took 44.026732 seconds to run 1 epoch\n",
      "('Epoch: ', 258, ' Average loss at step ', 1000, ': ', 128.10882455444337)\n",
      "('Epoch: ', 258, ' Average loss at step ', 2000, ': ', 129.54793020629882)\n",
      "('Epoch: ', 258, ' Average loss at step ', 3000, ': ', 129.33188054656983)\n",
      "('Epoch: ', 258, ' Average loss at step ', 4000, ': ', 128.66091295623778)\n",
      "('Epoch: ', 258, ' Average loss at step ', 4373, ': ', 126.33837152296498)\n",
      "('Epoch: ', 258, ' Average loss at step ', 761, ': ', 6524.6953577945105)\n",
      "('Epoch: ', 258, ' Average loss at step ', 782, ': ', 7435.7392177996962)\n",
      "('Epoch: ', 258, ' Average loss at step ', 787, ': ', 20.872612364722876)\n",
      "('Epoch: ', 258, ' Average loss at step ', 1000, ': ', 5.670686288356781)\n",
      "('Epoch: ', 258, ' Average loss at step ', 2000, ': ', 5.4669386167526248)\n",
      "('Epoch: ', 258, ' Average loss at step ', 2813, ': ', 5.518397756985256)\n",
      "Training time took 97.767096 seconds to run 1 epoch\n",
      "('Epoch: ', 259, ' Average loss at step ', 1000, ': ', 0.052110129356384274)\n",
      "('Epoch: ', 259, ' Average loss at step ', 2000, ': ', 0.047671109437942505)\n",
      "('Epoch: ', 259, ' Average loss at step ', 2813, ': ', 0.046413097842573532)\n",
      "Training time took 44.049045 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.981187458306\n",
      "Hits @ 1:  0.932888592395\n",
      "Testing time took 73.17236 seconds.\n",
      "\n",
      "('Epoch: ', 260, ' Average loss at step ', 1000, ': ', 129.82772242736817)\n",
      "('Epoch: ', 260, ' Average loss at step ', 2000, ': ', 128.37466275024414)\n",
      "('Epoch: ', 260, ' Average loss at step ', 3000, ': ', 127.17510977935791)\n",
      "('Epoch: ', 260, ' Average loss at step ', 4000, ': ', 127.70070481109619)\n",
      "('Epoch: ', 260, ' Average loss at step ', 4373, ': ', 128.69964773936937)\n",
      "('Epoch: ', 260, ' Average loss at step ', 761, ': ', 6543.6787131861638)\n",
      "('Epoch: ', 260, ' Average loss at step ', 782, ': ', 7461.0246278809218)\n",
      "('Epoch: ', 260, ' Average loss at step ', 787, ': ', 20.85857917698285)\n",
      "('Epoch: ', 260, ' Average loss at step ', 1000, ': ', 5.4786930723190306)\n",
      "('Epoch: ', 260, ' Average loss at step ', 2000, ': ', 5.5520261783599851)\n",
      "('Epoch: ', 260, ' Average loss at step ', 2813, ': ', 5.4891823054534461)\n",
      "Training time took 97.823231 seconds to run 1 epoch\n",
      "('Epoch: ', 261, ' Average loss at step ', 1000, ': ', 0.051304219186305997)\n",
      "('Epoch: ', 261, ' Average loss at step ', 2000, ': ', 0.047221054017543791)\n",
      "('Epoch: ', 261, ' Average loss at step ', 2813, ': ', 0.04625676865941785)\n",
      "Training time took 44.022835 seconds to run 1 epoch\n",
      "('Epoch: ', 262, ' Average loss at step ', 1000, ': ', 129.34934464645386)\n",
      "('Epoch: ', 262, ' Average loss at step ', 2000, ': ', 127.95664154815674)\n",
      "('Epoch: ', 262, ' Average loss at step ', 3000, ': ', 129.08764752960204)\n",
      "('Epoch: ', 262, ' Average loss at step ', 4000, ': ', 128.77674020385743)\n",
      "('Epoch: ', 262, ' Average loss at step ', 4373, ': ', 127.32623028498824)\n",
      "('Epoch: ', 262, ' Average loss at step ', 761, ': ', 6609.2985306589226)\n",
      "('Epoch: ', 262, ' Average loss at step ', 782, ': ', 7560.4677796895003)\n",
      "('Epoch: ', 262, ' Average loss at step ', 787, ': ', 20.475644670976635)\n",
      "('Epoch: ', 262, ' Average loss at step ', 1000, ': ', 5.4410986838340758)\n",
      "('Epoch: ', 262, ' Average loss at step ', 2000, ': ', 5.4073254642486575)\n",
      "('Epoch: ', 262, ' Average loss at step ', 2813, ': ', 5.4567843252802133)\n",
      "Training time took 97.750028 seconds to run 1 epoch\n",
      "('Epoch: ', 263, ' Average loss at step ', 1000, ': ', 0.050830406665802005)\n",
      "('Epoch: ', 263, ' Average loss at step ', 2000, ': ', 0.047083462953567502)\n",
      "('Epoch: ', 263, ' Average loss at step ', 2813, ': ', 0.045818619319958051)\n",
      "Training time took 44.048323 seconds to run 1 epoch\n",
      "('Epoch: ', 264, ' Average loss at step ', 1000, ': ', 127.70362544250489)\n",
      "('Epoch: ', 264, ' Average loss at step ', 2000, ': ', 130.90524726104735)\n",
      "('Epoch: ', 264, ' Average loss at step ', 3000, ': ', 126.46953491973876)\n",
      "('Epoch: ', 264, ' Average loss at step ', 4000, ': ', 130.19370190429689)\n",
      "('Epoch: ', 264, ' Average loss at step ', 4373, ': ', 129.93986273324617)\n",
      "('Epoch: ', 264, ' Average loss at step ', 761, ': ', 6557.8684085243631)\n",
      "('Epoch: ', 264, ' Average loss at step ', 782, ': ', 7571.5726463718393)\n",
      "('Epoch: ', 264, ' Average loss at step ', 787, ': ', 20.559395793740077)\n",
      "('Epoch: ', 264, ' Average loss at step ', 1000, ': ', 5.3170299530029297)\n",
      "('Epoch: ', 264, ' Average loss at step ', 2000, ': ', 5.4570144176483151)\n",
      "('Epoch: ', 264, ' Average loss at step ', 2813, ': ', 5.3004299748707284)\n",
      "Training time took 97.840024 seconds to run 1 epoch\n",
      "('Epoch: ', 265, ' Average loss at step ', 1000, ': ', 0.050649972438812259)\n",
      "('Epoch: ', 265, ' Average loss at step ', 2000, ': ', 0.047037111222743989)\n",
      "('Epoch: ', 265, ' Average loss at step ', 2813, ': ', 0.045119737830068091)\n",
      "Training time took 44.030366 seconds to run 1 epoch\n",
      "('Epoch: ', 266, ' Average loss at step ', 1000, ': ', 128.99252807617188)\n",
      "('Epoch: ', 266, ' Average loss at step ', 2000, ': ', 129.76462236404419)\n",
      "('Epoch: ', 266, ' Average loss at step ', 3000, ': ', 127.09922979736328)\n",
      "('Epoch: ', 266, ' Average loss at step ', 4000, ': ', 127.40092389678955)\n",
      "('Epoch: ', 266, ' Average loss at step ', 4373, ': ', 128.79530994866485)\n",
      "('Epoch: ', 266, ' Average loss at step ', 761, ': ', 6618.6787398488896)\n",
      "('Epoch: ', 266, ' Average loss at step ', 782, ': ', 7526.3115709527046)\n",
      "('Epoch: ', 266, ' Average loss at step ', 787, ': ', 20.583387685489413)\n",
      "('Epoch: ', 266, ' Average loss at step ', 1000, ': ', 5.4889384150505069)\n",
      "('Epoch: ', 266, ' Average loss at step ', 2000, ': ', 5.395398077487946)\n",
      "('Epoch: ', 266, ' Average loss at step ', 2813, ': ', 5.4086868686629046)\n",
      "Training time took 97.672706 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 267, ' Average loss at step ', 1000, ': ', 0.050137458026409149)\n",
      "('Epoch: ', 267, ' Average loss at step ', 2000, ': ', 0.046374094367027281)\n",
      "('Epoch: ', 267, ' Average loss at step ', 2813, ': ', 0.045023173387414718)\n",
      "Training time took 44.035331 seconds to run 1 epoch\n",
      "('Epoch: ', 268, ' Average loss at step ', 1000, ': ', 126.92052604675293)\n",
      "('Epoch: ', 268, ' Average loss at step ', 2000, ': ', 128.01090161132814)\n",
      "('Epoch: ', 268, ' Average loss at step ', 3000, ': ', 127.8841587753296)\n",
      "('Epoch: ', 268, ' Average loss at step ', 4000, ': ', 128.30770718383789)\n",
      "('Epoch: ', 268, ' Average loss at step ', 4373, ': ', 127.74048737556704)\n",
      "('Epoch: ', 268, ' Average loss at step ', 761, ': ', 6684.4780540064758)\n",
      "('Epoch: ', 268, ' Average loss at step ', 782, ': ', 7605.8715257632439)\n",
      "('Epoch: ', 268, ' Average loss at step ', 787, ': ', 20.597961903831735)\n",
      "('Epoch: ', 268, ' Average loss at step ', 1000, ': ', 5.4178108487129215)\n",
      "('Epoch: ', 268, ' Average loss at step ', 2000, ': ', 5.4047755961418149)\n",
      "('Epoch: ', 268, ' Average loss at step ', 2813, ': ', 5.65558342099777)\n",
      "Training time took 97.779989 seconds to run 1 epoch\n",
      "('Epoch: ', 269, ' Average loss at step ', 1000, ': ', 0.049718505799770357)\n",
      "('Epoch: ', 269, ' Average loss at step ', 2000, ': ', 0.045968507289886475)\n",
      "('Epoch: ', 269, ' Average loss at step ', 2813, ': ', 0.045054900235143198)\n",
      "Training time took 44.02839 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.981654436291\n",
      "Hits @ 1:  0.932621747832\n",
      "Testing time took 73.299922 seconds.\n",
      "\n",
      "('Epoch: ', 270, ' Average loss at step ', 1000, ': ', 126.77264246368408)\n",
      "('Epoch: ', 270, ' Average loss at step ', 2000, ': ', 128.63595138549806)\n",
      "('Epoch: ', 270, ' Average loss at step ', 3000, ': ', 127.47760886383057)\n",
      "('Epoch: ', 270, ' Average loss at step ', 4000, ': ', 126.97959628295898)\n",
      "('Epoch: ', 270, ' Average loss at step ', 4373, ': ', 128.17127274954191)\n",
      "('Epoch: ', 270, ' Average loss at step ', 761, ': ', 6591.5698611610815)\n",
      "('Epoch: ', 270, ' Average loss at step ', 782, ': ', 7616.1052568071782)\n",
      "('Epoch: ', 270, ' Average loss at step ', 787, ': ', 20.115259153545662)\n",
      "('Epoch: ', 270, ' Average loss at step ', 1000, ': ', 5.2686586179733279)\n",
      "('Epoch: ', 270, ' Average loss at step ', 2000, ': ', 5.3856449975967404)\n",
      "('Epoch: ', 270, ' Average loss at step ', 2813, ': ', 5.510140140068355)\n",
      "Training time took 97.776747 seconds to run 1 epoch\n",
      "('Epoch: ', 271, ' Average loss at step ', 1000, ': ', 0.049919425427913666)\n",
      "('Epoch: ', 271, ' Average loss at step ', 2000, ': ', 0.045664182662963869)\n",
      "('Epoch: ', 271, ' Average loss at step ', 2813, ': ', 0.044305206593034302)\n",
      "Training time took 44.014059 seconds to run 1 epoch\n",
      "('Epoch: ', 272, ' Average loss at step ', 1000, ': ', 128.67678284454345)\n",
      "('Epoch: ', 272, ' Average loss at step ', 2000, ': ', 129.54604593658448)\n",
      "('Epoch: ', 272, ' Average loss at step ', 3000, ': ', 128.0899037322998)\n",
      "('Epoch: ', 272, ' Average loss at step ', 4000, ': ', 127.75459983062744)\n",
      "('Epoch: ', 272, ' Average loss at step ', 4373, ': ', 128.89935374516313)\n",
      "('Epoch: ', 272, ' Average loss at step ', 761, ': ', 6664.3756093878492)\n",
      "('Epoch: ', 272, ' Average loss at step ', 782, ': ', 7663.2901197133078)\n",
      "('Epoch: ', 272, ' Average loss at step ', 787, ': ', 19.82205667932525)\n",
      "('Epoch: ', 272, ' Average loss at step ', 1000, ': ', 5.3343433432579044)\n",
      "('Epoch: ', 272, ' Average loss at step ', 2000, ': ', 5.2858317971229551)\n",
      "('Epoch: ', 272, ' Average loss at step ', 2813, ': ', 5.4257499361273105)\n",
      "Training time took 97.802504 seconds to run 1 epoch\n",
      "('Epoch: ', 273, ' Average loss at step ', 1000, ': ', 0.048969133853912356)\n",
      "('Epoch: ', 273, ' Average loss at step ', 2000, ': ', 0.045842514693737027)\n",
      "('Epoch: ', 273, ' Average loss at step ', 2813, ': ', 0.043655267710168963)\n",
      "Training time took 44.018234 seconds to run 1 epoch\n",
      "('Epoch: ', 274, ' Average loss at step ', 1000, ': ', 126.80079950714111)\n",
      "('Epoch: ', 274, ' Average loss at step ', 2000, ': ', 128.97452131652832)\n",
      "('Epoch: ', 274, ' Average loss at step ', 3000, ': ', 127.60093695068359)\n",
      "('Epoch: ', 274, ' Average loss at step ', 4000, ': ', 127.21114008331298)\n",
      "('Epoch: ', 274, ' Average loss at step ', 4373, ': ', 128.2366477392053)\n",
      "('Epoch: ', 274, ' Average loss at step ', 761, ': ', 6712.6285737690168)\n",
      "('Epoch: ', 274, ' Average loss at step ', 782, ': ', 7702.9769632532407)\n",
      "('Epoch: ', 274, ' Average loss at step ', 787, ': ', 20.247069975195345)\n",
      "('Epoch: ', 274, ' Average loss at step ', 1000, ': ', 5.3423052725791935)\n",
      "('Epoch: ', 274, ' Average loss at step ', 2000, ': ', 5.412292960643768)\n",
      "('Epoch: ', 274, ' Average loss at step ', 2813, ': ', 5.4945595452350933)\n",
      "Training time took 97.706218 seconds to run 1 epoch\n",
      "('Epoch: ', 275, ' Average loss at step ', 1000, ': ', 0.048818214654922483)\n",
      "('Epoch: ', 275, ' Average loss at step ', 2000, ': ', 0.045542971789836885)\n",
      "('Epoch: ', 275, ' Average loss at step ', 2813, ': ', 0.044164396932559649)\n",
      "Training time took 44.082649 seconds to run 1 epoch\n",
      "('Epoch: ', 276, ' Average loss at step ', 1000, ': ', 127.14308378601075)\n",
      "('Epoch: ', 276, ' Average loss at step ', 2000, ': ', 127.37168353271484)\n",
      "('Epoch: ', 276, ' Average loss at step ', 3000, ': ', 128.40954431915284)\n",
      "('Epoch: ', 276, ' Average loss at step ', 4000, ': ', 127.41966374206542)\n",
      "('Epoch: ', 276, ' Average loss at step ', 4373, ': ', 128.38761024064914)\n",
      "('Epoch: ', 276, ' Average loss at step ', 761, ': ', 6658.0605712890629)\n",
      "('Epoch: ', 276, ' Average loss at step ', 782, ': ', 7731.7753950014003)\n",
      "('Epoch: ', 276, ' Average loss at step ', 787, ': ', 19.86165106023541)\n",
      "('Epoch: ', 276, ' Average loss at step ', 1000, ': ', 5.38357580947876)\n",
      "('Epoch: ', 276, ' Average loss at step ', 2000, ': ', 5.3144540095329287)\n",
      "('Epoch: ', 276, ' Average loss at step ', 2813, ': ', 5.3590623310634067)\n",
      "Training time took 97.782836 seconds to run 1 epoch\n",
      "('Epoch: ', 277, ' Average loss at step ', 1000, ': ', 0.048721869230270387)\n",
      "('Epoch: ', 277, ' Average loss at step ', 2000, ': ', 0.04495368719100952)\n",
      "('Epoch: ', 277, ' Average loss at step ', 2813, ': ', 0.043116835758016614)\n",
      "Training time took 44.030131 seconds to run 1 epoch\n",
      "('Epoch: ', 278, ' Average loss at step ', 1000, ': ', 128.09898880004883)\n",
      "('Epoch: ', 278, ' Average loss at step ', 2000, ': ', 128.20030751037598)\n",
      "('Epoch: ', 278, ' Average loss at step ', 3000, ': ', 129.67792291259767)\n",
      "('Epoch: ', 278, ' Average loss at step ', 4000, ': ', 126.20440983581543)\n",
      "('Epoch: ', 278, ' Average loss at step ', 4373, ': ', 131.06249704668599)\n",
      "('Epoch: ', 278, ' Average loss at step ', 761, ': ', 6698.7364087556534)\n",
      "('Epoch: ', 278, ' Average loss at step ', 782, ': ', 7710.2289676446462)\n",
      "('Epoch: ', 278, ' Average loss at step ', 787, ': ', 19.956193911816936)\n",
      "('Epoch: ', 278, ' Average loss at step ', 1000, ': ', 5.4471746778488157)\n",
      "('Epoch: ', 278, ' Average loss at step ', 2000, ': ', 5.3643908205032345)\n",
      "('Epoch: ', 278, ' Average loss at step ', 2813, ': ', 5.4134887239615903)\n",
      "Training time took 97.804324 seconds to run 1 epoch\n",
      "('Epoch: ', 279, ' Average loss at step ', 1000, ': ', 0.048528577387332919)\n",
      "('Epoch: ', 279, ' Average loss at step ', 2000, ': ', 0.044606510698795315)\n",
      "('Epoch: ', 279, ' Average loss at step ', 2813, ': ', 0.042697444044310473)\n",
      "Training time took 44.024944 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.981921280854\n",
      "Hits @ 1:  0.931887925284\n",
      "Testing time took 73.231981 seconds.\n",
      "\n",
      "('Epoch: ', 280, ' Average loss at step ', 1000, ': ', 127.30142503356933)\n",
      "('Epoch: ', 280, ' Average loss at step ', 2000, ': ', 127.20870945739746)\n",
      "('Epoch: ', 280, ' Average loss at step ', 3000, ': ', 129.35852605438234)\n",
      "('Epoch: ', 280, ' Average loss at step ', 4000, ': ', 127.17721992492676)\n",
      "('Epoch: ', 280, ' Average loss at step ', 4373, ': ', 129.05913978494624)\n",
      "('Epoch: ', 280, ' Average loss at step ', 761, ': ', 6725.0163673802426)\n",
      "('Epoch: ', 280, ' Average loss at step ', 782, ': ', 7746.8640871328826)\n",
      "('Epoch: ', 280, ' Average loss at step ', 787, ': ', 19.404342638020601)\n",
      "('Epoch: ', 280, ' Average loss at step ', 1000, ': ', 5.3656406579017641)\n",
      "('Epoch: ', 280, ' Average loss at step ', 2000, ': ', 5.3878926515579222)\n",
      "('Epoch: ', 280, ' Average loss at step ', 2813, ': ', 5.3854796446015678)\n",
      "Training time took 97.821255 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 281, ' Average loss at step ', 1000, ': ', 0.048422494411468509)\n",
      "('Epoch: ', 281, ' Average loss at step ', 2000, ': ', 0.0445158976316452)\n",
      "('Epoch: ', 281, ' Average loss at step ', 2813, ': ', 0.04263517811086965)\n",
      "Training time took 44.00461 seconds to run 1 epoch\n",
      "('Epoch: ', 282, ' Average loss at step ', 1000, ': ', 126.80810873413085)\n",
      "('Epoch: ', 282, ' Average loss at step ', 2000, ': ', 128.26997100830079)\n",
      "('Epoch: ', 282, ' Average loss at step ', 3000, ': ', 129.4622876815796)\n",
      "('Epoch: ', 282, ' Average loss at step ', 4000, ': ', 129.21411201858521)\n",
      "('Epoch: ', 282, ' Average loss at step ', 4373, ': ', 130.78592177360289)\n",
      "('Epoch: ', 282, ' Average loss at step ', 761, ': ', 6791.5717712402347)\n",
      "('Epoch: ', 282, ' Average loss at step ', 782, ': ', 7710.5356182728474)\n",
      "('Epoch: ', 282, ' Average loss at step ', 787, ': ', 19.772792233765582)\n",
      "('Epoch: ', 282, ' Average loss at step ', 1000, ': ', 5.2008206186294554)\n",
      "('Epoch: ', 282, ' Average loss at step ', 2000, ': ', 5.1051357111930846)\n",
      "('Epoch: ', 282, ' Average loss at step ', 2813, ': ', 5.340980820467907)\n",
      "Training time took 97.794391 seconds to run 1 epoch\n",
      "('Epoch: ', 283, ' Average loss at step ', 1000, ': ', 0.047848741948604584)\n",
      "('Epoch: ', 283, ' Average loss at step ', 2000, ': ', 0.043702209174633029)\n",
      "('Epoch: ', 283, ' Average loss at step ', 2813, ': ', 0.042785354802761175)\n",
      "Training time took 44.033242 seconds to run 1 epoch\n",
      "('Epoch: ', 284, ' Average loss at step ', 1000, ': ', 127.49186961364747)\n",
      "('Epoch: ', 284, ' Average loss at step ', 2000, ': ', 128.34289205932618)\n",
      "('Epoch: ', 284, ' Average loss at step ', 3000, ': ', 129.75013410949708)\n",
      "('Epoch: ', 284, ' Average loss at step ', 4000, ': ', 127.60291382598876)\n",
      "('Epoch: ', 284, ' Average loss at step ', 4373, ': ', 131.92794582407961)\n",
      "('Epoch: ', 284, ' Average loss at step ', 761, ': ', 6776.6351221988079)\n",
      "('Epoch: ', 284, ' Average loss at step ', 782, ': ', 7793.7068493167817)\n",
      "('Epoch: ', 284, ' Average loss at step ', 787, ': ', 19.667655887797892)\n",
      "('Epoch: ', 284, ' Average loss at step ', 1000, ': ', 5.3680896511077885)\n",
      "('Epoch: ', 284, ' Average loss at step ', 2000, ': ', 5.0645781545639039)\n",
      "('Epoch: ', 284, ' Average loss at step ', 2813, ': ', 5.3063372731796044)\n",
      "Training time took 97.800613 seconds to run 1 epoch\n",
      "('Epoch: ', 285, ' Average loss at step ', 1000, ': ', 0.047536935210227969)\n",
      "('Epoch: ', 285, ' Average loss at step ', 2000, ': ', 0.043615406215190888)\n",
      "('Epoch: ', 285, ' Average loss at step ', 2813, ': ', 0.04229617698732855)\n",
      "Training time took 44.028505 seconds to run 1 epoch\n",
      "('Epoch: ', 286, ' Average loss at step ', 1000, ': ', 127.74621696472168)\n",
      "('Epoch: ', 286, ' Average loss at step ', 2000, ': ', 128.34297158813476)\n",
      "('Epoch: ', 286, ' Average loss at step ', 3000, ': ', 129.93186402893068)\n",
      "('Epoch: ', 286, ' Average loss at step ', 4000, ': ', 127.73620559692382)\n",
      "('Epoch: ', 286, ' Average loss at step ', 4373, ': ', 129.35986135339223)\n",
      "('Epoch: ', 286, ' Average loss at step ', 761, ': ', 6739.6250186317848)\n",
      "('Epoch: ', 286, ' Average loss at step ', 782, ': ', 7767.5913235985518)\n",
      "('Epoch: ', 286, ' Average loss at step ', 787, ': ', 19.390351032179428)\n",
      "('Epoch: ', 286, ' Average loss at step ', 1000, ': ', 5.1803695516586306)\n",
      "('Epoch: ', 286, ' Average loss at step ', 2000, ': ', 5.2519323849678043)\n",
      "('Epoch: ', 286, ' Average loss at step ', 2813, ': ', 5.322992353603758)\n",
      "Training time took 97.770301 seconds to run 1 epoch\n",
      "('Epoch: ', 287, ' Average loss at step ', 1000, ': ', 0.047528150022029876)\n",
      "('Epoch: ', 287, ' Average loss at step ', 2000, ': ', 0.043273155152797699)\n",
      "('Epoch: ', 287, ' Average loss at step ', 2813, ': ', 0.042159413028820397)\n",
      "Training time took 43.999502 seconds to run 1 epoch\n",
      "('Epoch: ', 288, ' Average loss at step ', 1000, ': ', 128.57026983642578)\n",
      "('Epoch: ', 288, ' Average loss at step ', 2000, ': ', 128.36891764450073)\n",
      "('Epoch: ', 288, ' Average loss at step ', 3000, ': ', 127.19335888671876)\n",
      "('Epoch: ', 288, ' Average loss at step ', 4000, ': ', 128.74012106323241)\n",
      "('Epoch: ', 288, ' Average loss at step ', 4373, ': ', 129.29981014292727)\n",
      "('Epoch: ', 288, ' Average loss at step ', 761, ': ', 6835.2989775005144)\n",
      "('Epoch: ', 288, ' Average loss at step ', 782, ': ', 7799.5528500370119)\n",
      "('Epoch: ', 288, ' Average loss at step ', 787, ': ', 19.264240841222477)\n",
      "('Epoch: ', 288, ' Average loss at step ', 1000, ': ', 5.3537223467826847)\n",
      "('Epoch: ', 288, ' Average loss at step ', 2000, ': ', 5.1925651292800907)\n",
      "('Epoch: ', 288, ' Average loss at step ', 2813, ': ', 5.3031171025901003)\n",
      "Training time took 97.72954 seconds to run 1 epoch\n",
      "('Epoch: ', 289, ' Average loss at step ', 1000, ': ', 0.046494925498962406)\n",
      "('Epoch: ', 289, ' Average loss at step ', 2000, ': ', 0.043095472693443299)\n",
      "('Epoch: ', 289, ' Average loss at step ', 2813, ': ', 0.041881560104821115)\n",
      "Training time took 44.001654 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.982588392262\n",
      "Hits @ 1:  0.932621747832\n",
      "Testing time took 73.246479 seconds.\n",
      "\n",
      "('Epoch: ', 290, ' Average loss at step ', 1000, ': ', 128.91768287658692)\n",
      "('Epoch: ', 290, ' Average loss at step ', 2000, ': ', 128.06728629302978)\n",
      "('Epoch: ', 290, ' Average loss at step ', 3000, ': ', 128.53547538757323)\n",
      "('Epoch: ', 290, ' Average loss at step ', 4000, ': ', 128.35014872741698)\n",
      "('Epoch: ', 290, ' Average loss at step ', 4373, ': ', 128.34820037759761)\n",
      "('Epoch: ', 290, ' Average loss at step ', 761, ': ', 6896.6654345060651)\n",
      "('Epoch: ', 290, ' Average loss at step ', 782, ': ', 7888.6195651358439)\n",
      "('Epoch: ', 290, ' Average loss at step ', 787, ': ', 19.545632720296922)\n",
      "('Epoch: ', 290, ' Average loss at step ', 1000, ': ', 5.2481911497116087)\n",
      "('Epoch: ', 290, ' Average loss at step ', 2000, ': ', 5.3408014864921567)\n",
      "('Epoch: ', 290, ' Average loss at step ', 2813, ': ', 5.2702500045005909)\n",
      "Training time took 97.886691 seconds to run 1 epoch\n",
      "('Epoch: ', 291, ' Average loss at step ', 1000, ': ', 0.046746104300022122)\n",
      "('Epoch: ', 291, ' Average loss at step ', 2000, ': ', 0.042916904032230377)\n",
      "('Epoch: ', 291, ' Average loss at step ', 2813, ': ', 0.041479732529283157)\n",
      "Training time took 44.003228 seconds to run 1 epoch\n",
      "('Epoch: ', 292, ' Average loss at step ', 1000, ': ', 127.48999234771729)\n",
      "('Epoch: ', 292, ' Average loss at step ', 2000, ': ', 128.84891463470458)\n",
      "('Epoch: ', 292, ' Average loss at step ', 3000, ': ', 127.52175793457032)\n",
      "('Epoch: ', 292, ' Average loss at step ', 4000, ': ', 125.95674977111817)\n",
      "('Epoch: ', 292, ' Average loss at step ', 4373, ': ', 128.73763299757434)\n",
      "('Epoch: ', 292, ' Average loss at step ', 761, ': ', 6935.1044719495276)\n",
      "('Epoch: ', 292, ' Average loss at step ', 782, ': ', 7870.3979842299532)\n",
      "('Epoch: ', 292, ' Average loss at step ', 787, ': ', 19.302624440375176)\n",
      "('Epoch: ', 292, ' Average loss at step ', 1000, ': ', 5.2132523918151854)\n",
      "('Epoch: ', 292, ' Average loss at step ', 2000, ': ', 5.1798089489936832)\n",
      "('Epoch: ', 292, ' Average loss at step ', 2813, ': ', 5.1455026130958146)\n",
      "Training time took 97.938948 seconds to run 1 epoch\n",
      "('Epoch: ', 293, ' Average loss at step ', 1000, ': ', 0.045958624184131623)\n",
      "('Epoch: ', 293, ' Average loss at step ', 2000, ': ', 0.042326127052307129)\n",
      "('Epoch: ', 293, ' Average loss at step ', 2813, ': ', 0.041508342611965877)\n",
      "Training time took 44.017989 seconds to run 1 epoch\n",
      "('Epoch: ', 294, ' Average loss at step ', 1000, ': ', 129.6603067932129)\n",
      "('Epoch: ', 294, ' Average loss at step ', 2000, ': ', 126.84138181304931)\n",
      "('Epoch: ', 294, ' Average loss at step ', 3000, ': ', 127.20303367996216)\n",
      "('Epoch: ', 294, ' Average loss at step ', 4000, ': ', 129.07523626708985)\n",
      "('Epoch: ', 294, ' Average loss at step ', 4373, ': ', 128.82997340540732)\n",
      "('Epoch: ', 294, ' Average loss at step ', 761, ': ', 6893.4865822239926)\n",
      "('Epoch: ', 294, ' Average loss at step ', 782, ': ', 7930.7720114186541)\n",
      "('Epoch: ', 294, ' Average loss at step ', 787, ': ', 19.391122394542354)\n",
      "('Epoch: ', 294, ' Average loss at step ', 1000, ': ', 5.2059552097320561)\n",
      "('Epoch: ', 294, ' Average loss at step ', 2000, ': ', 5.1752372522354122)\n",
      "('Epoch: ', 294, ' Average loss at step ', 2813, ': ', 5.2327318209145455)\n",
      "Training time took 97.658427 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 295, ' Average loss at step ', 1000, ': ', 0.04552407383918762)\n",
      "('Epoch: ', 295, ' Average loss at step ', 2000, ': ', 0.042461571753025056)\n",
      "('Epoch: ', 295, ' Average loss at step ', 2813, ': ', 0.041309811505190842)\n",
      "Training time took 44.030605 seconds to run 1 epoch\n",
      "('Epoch: ', 296, ' Average loss at step ', 1000, ': ', 127.59924752807618)\n",
      "('Epoch: ', 296, ' Average loss at step ', 2000, ': ', 129.63629182434082)\n",
      "('Epoch: ', 296, ' Average loss at step ', 3000, ': ', 128.54995422363282)\n",
      "('Epoch: ', 296, ' Average loss at step ', 4000, ': ', 127.61298139572143)\n",
      "('Epoch: ', 296, ' Average loss at step ', 4373, ': ', 130.27662078283166)\n",
      "('Epoch: ', 296, ' Average loss at step ', 761, ': ', 6864.5223546078332)\n",
      "('Epoch: ', 296, ' Average loss at step ', 782, ': ', 7920.5260327054657)\n",
      "('Epoch: ', 296, ' Average loss at step ', 787, ': ', 19.094851778967083)\n",
      "('Epoch: ', 296, ' Average loss at step ', 1000, ': ', 5.2415378541946414)\n",
      "('Epoch: ', 296, ' Average loss at step ', 2000, ': ', 5.1591565747261043)\n",
      "('Epoch: ', 296, ' Average loss at step ', 2813, ': ', 5.1701022169272886)\n",
      "Training time took 97.837368 seconds to run 1 epoch\n",
      "('Epoch: ', 297, ' Average loss at step ', 1000, ': ', 0.045231559991836548)\n",
      "('Epoch: ', 297, ' Average loss at step ', 2000, ': ', 0.041932253777980807)\n",
      "('Epoch: ', 297, ' Average loss at step ', 2813, ': ', 0.040908186893745008)\n",
      "Training time took 44.035569 seconds to run 1 epoch\n",
      "('Epoch: ', 298, ' Average loss at step ', 1000, ': ', 128.95347996520997)\n",
      "('Epoch: ', 298, ' Average loss at step ', 2000, ': ', 127.96987021636963)\n",
      "('Epoch: ', 298, ' Average loss at step ', 3000, ': ', 128.7515566329956)\n",
      "('Epoch: ', 298, ' Average loss at step ', 4000, ': ', 126.11029414367675)\n",
      "('Epoch: ', 298, ' Average loss at step ', 4373, ': ', 127.06474603632445)\n",
      "('Epoch: ', 298, ' Average loss at step ', 761, ': ', 6972.5183060495474)\n",
      "('Epoch: ', 298, ' Average loss at step ', 782, ': ', 7872.2999584867157)\n",
      "('Epoch: ', 298, ' Average loss at step ', 787, ': ', 18.986985395882876)\n",
      "('Epoch: ', 298, ' Average loss at step ', 1000, ': ', 5.1791023473739628)\n",
      "('Epoch: ', 298, ' Average loss at step ', 2000, ': ', 5.0946263914108281)\n",
      "('Epoch: ', 298, ' Average loss at step ', 2813, ': ', 5.077046879406633)\n",
      "Training time took 97.688595 seconds to run 1 epoch\n",
      "('Epoch: ', 299, ' Average loss at step ', 1000, ': ', 0.044956767559051515)\n",
      "('Epoch: ', 299, ' Average loss at step ', 2000, ': ', 0.042375224888324736)\n",
      "('Epoch: ', 299, ' Average loss at step ', 2813, ': ', 0.040464709691813427)\n",
      "Training time took 44.019742 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.982721814543\n",
      "Hits @ 1:  0.932088058706\n",
      "Testing time took 73.278702 seconds.\n",
      "\n",
      "('Epoch: ', 300, ' Average loss at step ', 1000, ': ', 129.09363055419922)\n",
      "('Epoch: ', 300, ' Average loss at step ', 2000, ': ', 127.10182090759277)\n",
      "('Epoch: ', 300, ' Average loss at step ', 3000, ': ', 128.01909537124635)\n",
      "('Epoch: ', 300, ' Average loss at step ', 4000, ': ', 128.38326077270509)\n",
      "('Epoch: ', 300, ' Average loss at step ', 4373, ': ', 129.14081292511315)\n",
      "('Epoch: ', 300, ' Average loss at step ', 761, ': ', 7034.1702177348889)\n",
      "('Epoch: ', 300, ' Average loss at step ', 782, ': ', 7919.3594650288096)\n",
      "('Epoch: ', 300, ' Average loss at step ', 787, ': ', 19.249201740624038)\n",
      "('Epoch: ', 300, ' Average loss at step ', 1000, ': ', 5.0787330422401427)\n",
      "('Epoch: ', 300, ' Average loss at step ', 2000, ': ', 5.0961220946311947)\n",
      "('Epoch: ', 300, ' Average loss at step ', 2813, ': ', 5.2318395452546369)\n",
      "Training time took 97.892378 seconds to run 1 epoch\n",
      "('Epoch: ', 301, ' Average loss at step ', 1000, ': ', 0.044985707581043241)\n",
      "('Epoch: ', 301, ' Average loss at step ', 2000, ': ', 0.041162443816661835)\n",
      "('Epoch: ', 301, ' Average loss at step ', 2813, ': ', 0.040139543452286368)\n",
      "Training time took 44.028768 seconds to run 1 epoch\n",
      "('Epoch: ', 302, ' Average loss at step ', 1000, ': ', 126.19507269287109)\n",
      "('Epoch: ', 302, ' Average loss at step ', 2000, ': ', 128.291740234375)\n",
      "('Epoch: ', 302, ' Average loss at step ', 3000, ': ', 126.27138233184814)\n",
      "('Epoch: ', 302, ' Average loss at step ', 4000, ': ', 126.72026446533204)\n",
      "('Epoch: ', 302, ' Average loss at step ', 4373, ': ', 127.28458238417103)\n",
      "('Epoch: ', 302, ' Average loss at step ', 761, ': ', 6964.3070723684214)\n",
      "('Epoch: ', 302, ' Average loss at step ', 782, ': ', 7902.8985350312096)\n",
      "('Epoch: ', 302, ' Average loss at step ', 787, ': ', 18.928521781173977)\n",
      "('Epoch: ', 302, ' Average loss at step ', 1000, ': ', 5.1769703407287597)\n",
      "('Epoch: ', 302, ' Average loss at step ', 2000, ': ', 5.0672255868911744)\n",
      "('Epoch: ', 302, ' Average loss at step ', 2813, ': ', 5.1695894772196054)\n",
      "Training time took 97.855482 seconds to run 1 epoch\n",
      "('Epoch: ', 303, ' Average loss at step ', 1000, ': ', 0.044742005407810211)\n",
      "('Epoch: ', 303, ' Average loss at step ', 2000, ': ', 0.0414195573925972)\n",
      "('Epoch: ', 303, ' Average loss at step ', 2813, ': ', 0.039956195527696844)\n",
      "Training time took 44.057998 seconds to run 1 epoch\n",
      "('Epoch: ', 304, ' Average loss at step ', 1000, ': ', 129.91456044006347)\n",
      "('Epoch: ', 304, ' Average loss at step ', 2000, ': ', 128.52151544189454)\n",
      "('Epoch: ', 304, ' Average loss at step ', 3000, ': ', 128.25616307067872)\n",
      "('Epoch: ', 304, ' Average loss at step ', 4000, ': ', 129.84087936401366)\n",
      "('Epoch: ', 304, ' Average loss at step ', 4373, ': ', 129.52711415034469)\n",
      "('Epoch: ', 304, ' Average loss at step ', 761, ': ', 6986.4364479466485)\n",
      "('Epoch: ', 304, ' Average loss at step ', 782, ': ', 8059.259680597791)\n",
      "('Epoch: ', 304, ' Average loss at step ', 787, ': ', 18.781853111645649)\n",
      "('Epoch: ', 304, ' Average loss at step ', 1000, ': ', 5.1283285751342778)\n",
      "('Epoch: ', 304, ' Average loss at step ', 2000, ': ', 5.0421385245323185)\n",
      "('Epoch: ', 304, ' Average loss at step ', 2813, ': ', 5.0642670592650996)\n",
      "Training time took 97.857044 seconds to run 1 epoch\n",
      "('Epoch: ', 305, ' Average loss at step ', 1000, ': ', 0.044137464046478274)\n",
      "('Epoch: ', 305, ' Average loss at step ', 2000, ': ', 0.041324486672878268)\n",
      "('Epoch: ', 305, ' Average loss at step ', 2813, ': ', 0.039676107356113752)\n",
      "Training time took 44.03012 seconds to run 1 epoch\n",
      "('Epoch: ', 306, ' Average loss at step ', 1000, ': ', 128.92640819549561)\n",
      "('Epoch: ', 306, ' Average loss at step ', 2000, ': ', 127.71106333923341)\n",
      "('Epoch: ', 306, ' Average loss at step ', 3000, ': ', 128.04159905242921)\n",
      "('Epoch: ', 306, ' Average loss at step ', 4000, ': ', 130.18037178039552)\n",
      "('Epoch: ', 306, ' Average loss at step ', 4373, ': ', 127.14600661493117)\n",
      "('Epoch: ', 306, ' Average loss at step ', 761, ': ', 6971.61470208419)\n",
      "('Epoch: ', 306, ' Average loss at step ', 782, ': ', 8032.8131695892689)\n",
      "('Epoch: ', 306, ' Average loss at step ', 787, ': ', 18.681691107859137)\n",
      "('Epoch: ', 306, ' Average loss at step ', 1000, ': ', 4.9812038412094113)\n",
      "('Epoch: ', 306, ' Average loss at step ', 2000, ': ', 5.1410745902061459)\n",
      "('Epoch: ', 306, ' Average loss at step ', 2813, ': ', 5.1448508618500428)\n",
      "Training time took 97.740987 seconds to run 1 epoch\n",
      "('Epoch: ', 307, ' Average loss at step ', 1000, ': ', 0.043957489311695096)\n",
      "('Epoch: ', 307, ' Average loss at step ', 2000, ': ', 0.04093703883886337)\n",
      "('Epoch: ', 307, ' Average loss at step ', 2813, ': ', 0.03937058459068167)\n",
      "Training time took 44.016933 seconds to run 1 epoch\n",
      "('Epoch: ', 308, ' Average loss at step ', 1000, ': ', 126.9200511856079)\n",
      "('Epoch: ', 308, ' Average loss at step ', 2000, ': ', 129.4367827987671)\n",
      "('Epoch: ', 308, ' Average loss at step ', 3000, ': ', 128.33676080322266)\n",
      "('Epoch: ', 308, ' Average loss at step ', 4000, ': ', 129.16483392333984)\n",
      "('Epoch: ', 308, ' Average loss at step ', 4373, ': ', 130.05207314029818)\n",
      "('Epoch: ', 308, ' Average loss at step ', 761, ': ', 7027.5867148951484)\n",
      "('Epoch: ', 308, ' Average loss at step ', 782, ': ', 8019.785241277209)\n",
      "('Epoch: ', 308, ' Average loss at step ', 787, ': ', 18.266330501808767)\n",
      "('Epoch: ', 308, ' Average loss at step ', 1000, ': ', 5.0435931267738345)\n",
      "('Epoch: ', 308, ' Average loss at step ', 2000, ': ', 5.0579277005195618)\n",
      "('Epoch: ', 308, ' Average loss at step ', 2813, ': ', 5.2160726938341639)\n",
      "Training time took 97.786903 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 309, ' Average loss at step ', 1000, ': ', 0.04367277628183365)\n",
      "('Epoch: ', 309, ' Average loss at step ', 2000, ': ', 0.04033990466594696)\n",
      "('Epoch: ', 309, ' Average loss at step ', 2813, ': ', 0.039434183554109097)\n",
      "Training time took 44.018943 seconds to run 1 epoch\n",
      "Mean Rank:  3  of  28683\n",
      "Hits @ 10:  0.982521681121\n",
      "Hits @ 1:  0.933288859239\n",
      "Testing time took 73.266468 seconds.\n",
      "\n",
      "('Epoch: ', 310, ' Average loss at step ', 1000, ': ', 126.92184832000733)\n",
      "('Epoch: ', 310, ' Average loss at step ', 2000, ': ', 128.89370965576171)\n",
      "('Epoch: ', 310, ' Average loss at step ', 3000, ': ', 129.23401773071288)\n",
      "('Epoch: ', 310, ' Average loss at step ', 4000, ': ', 127.74871743011475)\n",
      "('Epoch: ', 310, ' Average loss at step ', 4373, ': ', 126.29094790386897)\n",
      "('Epoch: ', 310, ' Average loss at step ', 761, ': ', 7003.6947985197367)\n",
      "('Epoch: ', 310, ' Average loss at step ', 782, ': ', 8067.938499694902)\n",
      "('Epoch: ', 310, ' Average loss at step ', 787, ': ', 18.557705225228656)\n",
      "('Epoch: ', 310, ' Average loss at step ', 1000, ': ', 5.0395156497955318)\n",
      "('Epoch: ', 310, ' Average loss at step ', 2000, ': ', 5.0659979076385495)\n",
      "('Epoch: ', 310, ' Average loss at step ', 2813, ': ', 4.9329720447803362)\n",
      "Training time took 97.862696 seconds to run 1 epoch\n",
      "('Epoch: ', 311, ' Average loss at step ', 1000, ': ', 0.043801318407058719)\n",
      "('Epoch: ', 311, ' Average loss at step ', 2000, ': ', 0.040081341266632077)\n",
      "('Epoch: ', 311, ' Average loss at step ', 2813, ': ', 0.039064855924968063)\n",
      "Training time took 44.016427 seconds to run 1 epoch\n",
      "('Epoch: ', 312, ' Average loss at step ', 1000, ': ', 128.00128002929688)\n",
      "('Epoch: ', 312, ' Average loss at step ', 2000, ': ', 126.66453397369385)\n",
      "('Epoch: ', 312, ' Average loss at step ', 3000, ': ', 128.23532685852049)\n",
      "('Epoch: ', 312, ' Average loss at step ', 4000, ': ', 127.66716381072997)\n",
      "('Epoch: ', 312, ' Average loss at step ', 4373, ': ', 127.34528525157641)\n",
      "('Epoch: ', 312, ' Average loss at step ', 761, ': ', 7086.9716038754113)\n",
      "('Epoch: ', 312, ' Average loss at step ', 782, ': ', 7977.9026557248317)\n",
      "('Epoch: ', 312, ' Average loss at step ', 787, ': ', 18.391120917924489)\n",
      "('Epoch: ', 312, ' Average loss at step ', 1000, ': ', 4.9706880517005922)\n",
      "('Epoch: ', 312, ' Average loss at step ', 2000, ': ', 5.0844242238998412)\n",
      "('Epoch: ', 312, ' Average loss at step ', 2813, ': ', 5.008882890781158)\n",
      "Training time took 97.765474 seconds to run 1 epoch\n",
      "('Epoch: ', 313, ' Average loss at step ', 1000, ': ', 0.043445598244667052)\n",
      "('Epoch: ', 313, ' Average loss at step ', 2000, ': ', 0.040174241244792935)\n",
      "('Epoch: ', 313, ' Average loss at step ', 2813, ': ', 0.038788458470053272)\n",
      "Training time took 44.034339 seconds to run 1 epoch\n",
      "('Epoch: ', 314, ' Average loss at step ', 1000, ': ', 127.7099594192505)\n",
      "('Epoch: ', 314, ' Average loss at step ', 2000, ': ', 127.76412027359009)\n",
      "('Epoch: ', 314, ' Average loss at step ', 3000, ': ', 128.26134880828857)\n",
      "('Epoch: ', 314, ' Average loss at step ', 4000, ': ', 126.88689042663574)\n",
      "('Epoch: ', 314, ' Average loss at step ', 4373, ': ', 128.85047059418054)\n",
      "('Epoch: ', 314, ' Average loss at step ', 761, ': ', 7059.7285358629724)\n",
      "('Epoch: ', 314, ' Average loss at step ', 782, ': ', 8196.1915881832192)\n",
      "('Epoch: ', 314, ' Average loss at step ', 787, ': ', 18.533985205885713)\n",
      "('Epoch: ', 314, ' Average loss at step ', 1000, ': ', 4.9587722887992856)\n",
      "('Epoch: ', 314, ' Average loss at step ', 2000, ': ', 4.9707493238449096)\n",
      "('Epoch: ', 314, ' Average loss at step ', 2813, ': ', 5.045467459509525)\n",
      "Training time took 97.71492 seconds to run 1 epoch\n",
      "('Epoch: ', 315, ' Average loss at step ', 1000, ': ', 0.042768582284450532)\n",
      "('Epoch: ', 315, ' Average loss at step ', 2000, ': ', 0.039990876436233523)\n",
      "('Epoch: ', 315, ' Average loss at step ', 2813, ': ', 0.038493176619407578)\n",
      "Training time took 44.027245 seconds to run 1 epoch\n",
      "('Epoch: ', 316, ' Average loss at step ', 1000, ': ', 128.935811920166)\n",
      "('Epoch: ', 316, ' Average loss at step ', 2000, ': ', 126.37450059509277)\n",
      "('Epoch: ', 316, ' Average loss at step ', 3000, ': ', 128.00104368209838)\n",
      "('Epoch: ', 316, ' Average loss at step ', 4000, ': ', 127.1712597579956)\n",
      "('Epoch: ', 316, ' Average loss at step ', 4373, ': ', 130.51016834218015)\n",
      "('Epoch: ', 316, ' Average loss at step ', 761, ': ', 7095.1547735916938)\n",
      "('Epoch: ', 316, ' Average loss at step ', 782, ': ', 8142.5928078235038)\n",
      "('Epoch: ', 316, ' Average loss at step ', 787, ': ', 17.987652986104251)\n",
      "('Epoch: ', 316, ' Average loss at step ', 1000, ': ', 4.9517122311592106)\n",
      "('Epoch: ', 316, ' Average loss at step ', 2000, ': ', 4.9977617454528804)\n",
      "('Epoch: ', 316, ' Average loss at step ', 2813, ': ', 5.1469252755489254)\n",
      "Training time took 97.859283 seconds to run 1 epoch\n",
      "('Epoch: ', 317, ' Average loss at step ', 1000, ': ', 0.042558704555034639)\n",
      "('Epoch: ', 317, ' Average loss at step ', 2000, ': ', 0.039746368229389192)\n",
      "('Epoch: ', 317, ' Average loss at step ', 2813, ': ', 0.038304788725716729)\n",
      "Training time took 44.027694 seconds to run 1 epoch\n",
      "('Epoch: ', 318, ' Average loss at step ', 1000, ': ', 128.29723200225831)\n",
      "('Epoch: ', 318, ' Average loss at step ', 2000, ': ', 126.91646923828125)\n",
      "('Epoch: ', 318, ' Average loss at step ', 3000, ': ', 128.33532585144042)\n",
      "('Epoch: ', 318, ' Average loss at step ', 4000, ': ', 129.24226196289064)\n",
      "('Epoch: ', 318, ' Average loss at step ', 4373, ': ', 126.94112170639859)\n",
      "('Epoch: ', 318, ' Average loss at step ', 761, ': ', 7129.2871684827305)\n",
      "('Epoch: ', 318, ' Average loss at step ', 782, ': ', 8193.0928484615069)\n",
      "('Epoch: ', 318, ' Average loss at step ', 787, ': ', 18.026788997892812)\n",
      "('Epoch: ', 318, ' Average loss at step ', 1000, ': ', 4.9937602515220645)\n",
      "('Epoch: ', 318, ' Average loss at step ', 2000, ': ', 5.0742685785293578)\n",
      "('Epoch: ', 318, ' Average loss at step ', 2813, ': ', 4.8746862018049644)\n",
      "Training time took 97.695923 seconds to run 1 epoch\n",
      "('Epoch: ', 319, ' Average loss at step ', 1000, ': ', 0.0429206365942955)\n",
      "('Epoch: ', 319, ' Average loss at step ', 2000, ': ', 0.038863810598850253)\n",
      "('Epoch: ', 319, ' Average loss at step ', 2813, ': ', 0.038165018035860483)\n",
      "Training time took 44.020555 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.982988659106\n",
      "Hits @ 1:  0.933022014676\n",
      "Testing time took 73.183264 seconds.\n",
      "\n",
      "('Epoch: ', 320, ' Average loss at step ', 1000, ': ', 129.73906998443604)\n",
      "('Epoch: ', 320, ' Average loss at step ', 2000, ': ', 129.57197583007812)\n",
      "('Epoch: ', 320, ' Average loss at step ', 3000, ': ', 127.77462646484375)\n",
      "('Epoch: ', 320, ' Average loss at step ', 4000, ': ', 129.69368577575685)\n",
      "('Epoch: ', 320, ' Average loss at step ', 4373, ': ', 129.38688614547894)\n",
      "('Epoch: ', 320, ' Average loss at step ', 761, ': ', 7110.1074912623353)\n",
      "('Epoch: ', 320, ' Average loss at step ', 782, ': ', 8188.4307578425096)\n",
      "('Epoch: ', 320, ' Average loss at step ', 787, ': ', 18.037669352902711)\n",
      "('Epoch: ', 320, ' Average loss at step ', 1000, ': ', 5.0187605781555176)\n",
      "('Epoch: ', 320, ' Average loss at step ', 2000, ': ', 4.9452968416213992)\n",
      "('Epoch: ', 320, ' Average loss at step ', 2813, ': ', 4.9882574369167463)\n",
      "Training time took 97.808891 seconds to run 1 epoch\n",
      "('Epoch: ', 321, ' Average loss at step ', 1000, ': ', 0.042419837117195131)\n",
      "('Epoch: ', 321, ' Average loss at step ', 2000, ': ', 0.039044055581092835)\n",
      "('Epoch: ', 321, ' Average loss at step ', 2813, ': ', 0.037838326445941269)\n",
      "Training time took 44.023757 seconds to run 1 epoch\n",
      "('Epoch: ', 322, ' Average loss at step ', 1000, ': ', 128.71136981201172)\n",
      "('Epoch: ', 322, ' Average loss at step ', 2000, ': ', 127.78799266815186)\n",
      "('Epoch: ', 322, ' Average loss at step ', 3000, ': ', 129.11013610839845)\n",
      "('Epoch: ', 322, ' Average loss at step ', 4000, ': ', 127.31343354034423)\n",
      "('Epoch: ', 322, ' Average loss at step ', 4373, ': ', 126.92440098588185)\n",
      "('Epoch: ', 322, ' Average loss at step ', 761, ': ', 7173.4652960526319)\n",
      "('Epoch: ', 322, ' Average loss at step ', 782, ': ', 8139.9237537261924)\n",
      "('Epoch: ', 322, ' Average loss at step ', 787, ': ', 18.016245243810211)\n",
      "('Epoch: ', 322, ' Average loss at step ', 1000, ': ', 4.9115218634605409)\n",
      "('Epoch: ', 322, ' Average loss at step ', 2000, ': ', 5.045087960243225)\n",
      "('Epoch: ', 322, ' Average loss at step ', 2813, ': ', 5.1399372604680176)\n",
      "Training time took 97.787683 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 323, ' Average loss at step ', 1000, ': ', 0.041716456174850466)\n",
      "('Epoch: ', 323, ' Average loss at step ', 2000, ': ', 0.039039551556110379)\n",
      "('Epoch: ', 323, ' Average loss at step ', 2813, ': ', 0.037812056506208599)\n",
      "Training time took 44.054051 seconds to run 1 epoch\n",
      "('Epoch: ', 324, ' Average loss at step ', 1000, ': ', 128.22068241882323)\n",
      "('Epoch: ', 324, ' Average loss at step ', 2000, ': ', 127.79425450134278)\n",
      "('Epoch: ', 324, ' Average loss at step ', 3000, ': ', 128.32228746032715)\n",
      "('Epoch: ', 324, ' Average loss at step ', 4000, ': ', 128.44646713256836)\n",
      "('Epoch: ', 324, ' Average loss at step ', 4373, ': ', 125.8923586773616)\n",
      "('Epoch: ', 324, ' Average loss at step ', 761, ': ', 7132.0808433131169)\n",
      "('Epoch: ', 324, ' Average loss at step ', 782, ': ', 8217.1429644986401)\n",
      "('Epoch: ', 324, ' Average loss at step ', 787, ': ', 18.032815697842274)\n",
      "('Epoch: ', 324, ' Average loss at step ', 1000, ': ', 4.9809398369789122)\n",
      "('Epoch: ', 324, ' Average loss at step ', 2000, ': ', 4.8581956028938293)\n",
      "('Epoch: ', 324, ' Average loss at step ', 2813, ': ', 4.8676853820020929)\n",
      "Training time took 97.785973 seconds to run 1 epoch\n",
      "('Epoch: ', 325, ' Average loss at step ', 1000, ': ', 0.041787773907184599)\n",
      "('Epoch: ', 325, ' Average loss at step ', 2000, ': ', 0.038701377332210539)\n",
      "('Epoch: ', 325, ' Average loss at step ', 2813, ': ', 0.037271411915130802)\n",
      "Training time took 44.00573 seconds to run 1 epoch\n",
      "('Epoch: ', 326, ' Average loss at step ', 1000, ': ', 128.44012230682372)\n",
      "('Epoch: ', 326, ' Average loss at step ', 2000, ': ', 128.33100138092041)\n",
      "('Epoch: ', 326, ' Average loss at step ', 3000, ': ', 127.99437873840333)\n",
      "('Epoch: ', 326, ' Average loss at step ', 4000, ': ', 128.23478002929687)\n",
      "('Epoch: ', 326, ' Average loss at step ', 4373, ': ', 130.67212176579301)\n",
      "('Epoch: ', 326, ' Average loss at step ', 761, ': ', 7156.1864058645151)\n",
      "('Epoch: ', 326, ' Average loss at step ', 782, ': ', 8262.1264735965506)\n",
      "('Epoch: ', 326, ' Average loss at step ', 787, ': ', 17.921469810961465)\n",
      "('Epoch: ', 326, ' Average loss at step ', 1000, ': ', 4.9017584185600285)\n",
      "('Epoch: ', 326, ' Average loss at step ', 2000, ': ', 4.9423552050590516)\n",
      "('Epoch: ', 326, ' Average loss at step ', 2813, ': ', 4.9984093998453298)\n",
      "Training time took 97.725761 seconds to run 1 epoch\n",
      "('Epoch: ', 327, ' Average loss at step ', 1000, ': ', 0.041574491202831271)\n",
      "('Epoch: ', 327, ' Average loss at step ', 2000, ': ', 0.038540898382663724)\n",
      "('Epoch: ', 327, ' Average loss at step ', 2813, ': ', 0.037094692364702087)\n",
      "Training time took 44.014302 seconds to run 1 epoch\n",
      "('Epoch: ', 328, ' Average loss at step ', 1000, ': ', 128.04902178955078)\n",
      "('Epoch: ', 328, ' Average loss at step ', 2000, ': ', 127.44799575805663)\n",
      "('Epoch: ', 328, ' Average loss at step ', 3000, ': ', 130.07998072814942)\n",
      "('Epoch: ', 328, ' Average loss at step ', 4000, ': ', 127.51248480987549)\n",
      "('Epoch: ', 328, ' Average loss at step ', 4373, ': ', 128.69264717512235)\n",
      "('Epoch: ', 328, ' Average loss at step ', 761, ': ', 7317.6228592722036)\n",
      "('Epoch: ', 328, ' Average loss at step ', 782, ': ', 8240.2178653419087)\n",
      "('Epoch: ', 328, ' Average loss at step ', 787, ': ', 17.827796424011542)\n",
      "('Epoch: ', 328, ' Average loss at step ', 1000, ': ', 5.0237368001937863)\n",
      "('Epoch: ', 328, ' Average loss at step ', 2000, ': ', 4.9171465845108031)\n",
      "('Epoch: ', 328, ' Average loss at step ', 2813, ': ', 4.8589045602112568)\n",
      "Training time took 97.888636 seconds to run 1 epoch\n",
      "('Epoch: ', 329, ' Average loss at step ', 1000, ': ', 0.04151824176311493)\n",
      "('Epoch: ', 329, ' Average loss at step ', 2000, ': ', 0.038073559224605563)\n",
      "('Epoch: ', 329, ' Average loss at step ', 2813, ': ', 0.036878233105678275)\n",
      "Training time took 44.0021 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.982721814543\n",
      "Hits @ 1:  0.93335557038\n",
      "Testing time took 73.249491 seconds.\n",
      "\n",
      "('Epoch: ', 330, ' Average loss at step ', 1000, ': ', 127.96957947540284)\n",
      "('Epoch: ', 330, ' Average loss at step ', 2000, ': ', 127.47102763366699)\n",
      "('Epoch: ', 330, ' Average loss at step ', 3000, ': ', 128.24186325073242)\n",
      "('Epoch: ', 330, ' Average loss at step ', 4000, ': ', 126.17328762817382)\n",
      "('Epoch: ', 330, ' Average loss at step ', 4373, ': ', 128.73655913978496)\n",
      "('Epoch: ', 330, ' Average loss at step ', 761, ': ', 7242.708940686678)\n",
      "('Epoch: ', 330, ' Average loss at step ', 782, ': ', 8274.3329627980947)\n",
      "('Epoch: ', 330, ' Average loss at step ', 787, ': ', 17.91102933883667)\n",
      "('Epoch: ', 330, ' Average loss at step ', 1000, ': ', 4.8182697596549984)\n",
      "('Epoch: ', 330, ' Average loss at step ', 2000, ': ', 5.0595194797515868)\n",
      "('Epoch: ', 330, ' Average loss at step ', 2813, ': ', 4.8962946707391977)\n",
      "Training time took 97.784042 seconds to run 1 epoch\n",
      "('Epoch: ', 331, ' Average loss at step ', 1000, ': ', 0.041164710044860837)\n",
      "('Epoch: ', 331, ' Average loss at step ', 2000, ': ', 0.037959386646747591)\n",
      "('Epoch: ', 331, ' Average loss at step ', 2813, ': ', 0.036616798104911016)\n",
      "Training time took 43.996737 seconds to run 1 epoch\n",
      "('Epoch: ', 332, ' Average loss at step ', 1000, ': ', 127.60361317443848)\n",
      "('Epoch: ', 332, ' Average loss at step ', 2000, ': ', 130.33914762878419)\n",
      "('Epoch: ', 332, ' Average loss at step ', 3000, ': ', 128.50505298614502)\n",
      "('Epoch: ', 332, ' Average loss at step ', 4000, ': ', 127.89179364776611)\n",
      "('Epoch: ', 332, ' Average loss at step ', 4373, ': ', 127.20727612895351)\n",
      "('Epoch: ', 332, ' Average loss at step ', 761, ': ', 7320.2621167634661)\n",
      "('Epoch: ', 332, ' Average loss at step ', 782, ': ', 8381.8072470690622)\n",
      "('Epoch: ', 332, ' Average loss at step ', 787, ': ', 17.654710212736639)\n",
      "('Epoch: ', 332, ' Average loss at step ', 1000, ': ', 4.8824691143035892)\n",
      "('Epoch: ', 332, ' Average loss at step ', 2000, ': ', 4.9148551559448244)\n",
      "('Epoch: ', 332, ' Average loss at step ', 2813, ': ', 4.9235511378114447)\n",
      "Training time took 97.645727 seconds to run 1 epoch\n",
      "('Epoch: ', 333, ' Average loss at step ', 1000, ': ', 0.041324989497661592)\n",
      "('Epoch: ', 333, ' Average loss at step ', 2000, ': ', 0.037601352989673612)\n",
      "('Epoch: ', 333, ' Average loss at step ', 2813, ': ', 0.036657529511475211)\n",
      "Training time took 44.028988 seconds to run 1 epoch\n",
      "('Epoch: ', 334, ' Average loss at step ', 1000, ': ', 127.70280043029786)\n",
      "('Epoch: ', 334, ' Average loss at step ', 2000, ': ', 126.16139350128174)\n",
      "('Epoch: ', 334, ' Average loss at step ', 3000, ': ', 128.63956648254396)\n",
      "('Epoch: ', 334, ' Average loss at step ', 4000, ': ', 126.70665072631836)\n",
      "('Epoch: ', 334, ' Average loss at step ', 4373, ': ', 126.8564802190309)\n",
      "('Epoch: ', 334, ' Average loss at step ', 761, ': ', 7265.0217792711755)\n",
      "('Epoch: ', 334, ' Average loss at step ', 782, ': ', 8353.5303297055052)\n",
      "('Epoch: ', 334, ' Average loss at step ', 787, ': ', 17.44592642238122)\n",
      "('Epoch: ', 334, ' Average loss at step ', 1000, ': ', 4.8999425811767576)\n",
      "('Epoch: ', 334, ' Average loss at step ', 2000, ': ', 4.930775833129883)\n",
      "('Epoch: ', 334, ' Average loss at step ', 2813, ': ', 5.0511673683016172)\n",
      "Training time took 97.828089 seconds to run 1 epoch\n",
      "('Epoch: ', 335, ' Average loss at step ', 1000, ': ', 0.040887256026268005)\n",
      "('Epoch: ', 335, ' Average loss at step ', 2000, ': ', 0.03733529478311539)\n",
      "('Epoch: ', 335, ' Average loss at step ', 2813, ': ', 0.036421484107454424)\n",
      "Training time took 44.004474 seconds to run 1 epoch\n",
      "('Epoch: ', 336, ' Average loss at step ', 1000, ': ', 127.89947644805908)\n",
      "('Epoch: ', 336, ' Average loss at step ', 2000, ': ', 128.36720359802246)\n",
      "('Epoch: ', 336, ' Average loss at step ', 3000, ': ', 127.91843789672852)\n",
      "('Epoch: ', 336, ' Average loss at step ', 4000, ': ', 128.99587353515625)\n",
      "('Epoch: ', 336, ' Average loss at step ', 4373, ': ', 129.60219274541384)\n",
      "('Epoch: ', 336, ' Average loss at step ', 761, ': ', 7348.1227436266445)\n",
      "('Epoch: ', 336, ' Average loss at step ', 782, ': ', 8403.0020162702058)\n",
      "('Epoch: ', 336, ' Average loss at step ', 787, ': ', 17.503923161339213)\n",
      "('Epoch: ', 336, ' Average loss at step ', 1000, ': ', 4.8702926669120785)\n",
      "('Epoch: ', 336, ' Average loss at step ', 2000, ': ', 4.8862817335128783)\n",
      "('Epoch: ', 336, ' Average loss at step ', 2813, ': ', 4.9555060487662628)\n",
      "Training time took 97.717459 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 337, ' Average loss at step ', 1000, ': ', 0.040988117516040805)\n",
      "('Epoch: ', 337, ' Average loss at step ', 2000, ': ', 0.037391894698143004)\n",
      "('Epoch: ', 337, ' Average loss at step ', 2813, ': ', 0.035941565271668835)\n",
      "Training time took 44.05233 seconds to run 1 epoch\n",
      "('Epoch: ', 338, ' Average loss at step ', 1000, ': ', 127.33391262817383)\n",
      "('Epoch: ', 338, ' Average loss at step ', 2000, ': ', 130.28617786407472)\n",
      "('Epoch: ', 338, ' Average loss at step ', 3000, ': ', 128.82437857818604)\n",
      "('Epoch: ', 338, ' Average loss at step ', 4000, ': ', 128.6912438583374)\n",
      "('Epoch: ', 338, ' Average loss at step ', 4373, ': ', 127.49554205453524)\n",
      "('Epoch: ', 338, ' Average loss at step ', 761, ': ', 7285.6780601099917)\n",
      "('Epoch: ', 338, ' Average loss at step ', 782, ': ', 8331.8375261333622)\n",
      "('Epoch: ', 338, ' Average loss at step ', 787, ': ', 17.560547547182662)\n",
      "('Epoch: ', 338, ' Average loss at step ', 1000, ': ', 4.9162918939590456)\n",
      "('Epoch: ', 338, ' Average loss at step ', 2000, ': ', 4.8460101156234741)\n",
      "('Epoch: ', 338, ' Average loss at step ', 2813, ': ', 4.9457135576332734)\n",
      "Training time took 97.844719 seconds to run 1 epoch\n",
      "('Epoch: ', 339, ' Average loss at step ', 1000, ': ', 0.040579657196998596)\n",
      "('Epoch: ', 339, ' Average loss at step ', 2000, ': ', 0.036974097788333896)\n",
      "('Epoch: ', 339, ' Average loss at step ', 2813, ': ', 0.035769205742281644)\n",
      "Training time took 44.049473 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.982988659106\n",
      "Hits @ 1:  0.934289526351\n",
      "Testing time took 73.319023 seconds.\n",
      "\n",
      "('Epoch: ', 340, ' Average loss at step ', 1000, ': ', 128.52863872528076)\n",
      "('Epoch: ', 340, ' Average loss at step ', 2000, ': ', 127.084961769104)\n",
      "('Epoch: ', 340, ' Average loss at step ', 3000, ': ', 129.73984855651855)\n",
      "('Epoch: ', 340, ' Average loss at step ', 4000, ': ', 128.05340835189818)\n",
      "('Epoch: ', 340, ' Average loss at step ', 4373, ': ', 129.86317648938908)\n",
      "('Epoch: ', 340, ' Average loss at step ', 761, ': ', 7339.5326396741366)\n",
      "('Epoch: ', 340, ' Average loss at step ', 782, ': ', 8456.0302302986947)\n",
      "('Epoch: ', 340, ' Average loss at step ', 787, ': ', 17.649075667063396)\n",
      "('Epoch: ', 340, ' Average loss at step ', 1000, ': ', 4.7822410740852357)\n",
      "('Epoch: ', 340, ' Average loss at step ', 2000, ': ', 4.7989731421470641)\n",
      "('Epoch: ', 340, ' Average loss at step ', 2813, ': ', 4.8468182133923614)\n",
      "Training time took 97.698626 seconds to run 1 epoch\n",
      "('Epoch: ', 341, ' Average loss at step ', 1000, ': ', 0.039923231959342956)\n",
      "('Epoch: ', 341, ' Average loss at step ', 2000, ': ', 0.036713841736316678)\n",
      "('Epoch: ', 341, ' Average loss at step ', 2813, ': ', 0.035913689750168711)\n",
      "Training time took 44.015741 seconds to run 1 epoch\n",
      "('Epoch: ', 342, ' Average loss at step ', 1000, ': ', 126.19932339477539)\n",
      "('Epoch: ', 342, ' Average loss at step ', 2000, ': ', 127.17695707702637)\n",
      "('Epoch: ', 342, ' Average loss at step ', 3000, ': ', 129.12038961029052)\n",
      "('Epoch: ', 342, ' Average loss at step ', 4000, ': ', 127.86281769561768)\n",
      "('Epoch: ', 342, ' Average loss at step ', 4373, ': ', 127.91558470777287)\n",
      "('Epoch: ', 342, ' Average loss at step ', 761, ': ', 7284.1780132092927)\n",
      "('Epoch: ', 342, ' Average loss at step ', 782, ': ', 8427.2927393015761)\n",
      "('Epoch: ', 342, ' Average loss at step ', 787, ': ', 17.422933150187095)\n",
      "('Epoch: ', 342, ' Average loss at step ', 1000, ': ', 4.9004040451049802)\n",
      "('Epoch: ', 342, ' Average loss at step ', 2000, ': ', 4.7609698567390444)\n",
      "('Epoch: ', 342, ' Average loss at step ', 2813, ': ', 4.8734330684680653)\n",
      "Training time took 97.854893 seconds to run 1 epoch\n",
      "('Epoch: ', 343, ' Average loss at step ', 1000, ': ', 0.039609478712081911)\n",
      "('Epoch: ', 343, ' Average loss at step ', 2000, ': ', 0.036793051481246945)\n",
      "('Epoch: ', 343, ' Average loss at step ', 2813, ': ', 0.035691728659451298)\n",
      "Training time took 44.031579 seconds to run 1 epoch\n",
      "('Epoch: ', 344, ' Average loss at step ', 1000, ': ', 129.76776994323731)\n",
      "('Epoch: ', 344, ' Average loss at step ', 2000, ': ', 127.99713165283202)\n",
      "('Epoch: ', 344, ' Average loss at step ', 3000, ': ', 129.16142227172853)\n",
      "('Epoch: ', 344, ' Average loss at step ', 4000, ': ', 126.46665046691895)\n",
      "('Epoch: ', 344, ' Average loss at step ', 4373, ': ', 128.2924332977623)\n",
      "('Epoch: ', 344, ' Average loss at step ', 761, ': ', 7389.3178768760281)\n",
      "('Epoch: ', 344, ' Average loss at step ', 782, ': ', 8453.561836037532)\n",
      "('Epoch: ', 344, ' Average loss at step ', 787, ': ', 17.48031004937247)\n",
      "('Epoch: ', 344, ' Average loss at step ', 1000, ': ', 4.8523317360877991)\n",
      "('Epoch: ', 344, ' Average loss at step ', 2000, ': ', 4.7575016012191771)\n",
      "('Epoch: ', 344, ' Average loss at step ', 2813, ': ', 5.0159899753890018)\n",
      "Training time took 97.821082 seconds to run 1 epoch\n",
      "('Epoch: ', 345, ' Average loss at step ', 1000, ': ', 0.03964461851119995)\n",
      "('Epoch: ', 345, ' Average loss at step ', 2000, ': ', 0.03654202574491501)\n",
      "('Epoch: ', 345, ' Average loss at step ', 2813, ': ', 0.035628138357782599)\n",
      "Training time took 44.00637 seconds to run 1 epoch\n",
      "('Epoch: ', 346, ' Average loss at step ', 1000, ': ', 128.32505183410643)\n",
      "('Epoch: ', 346, ' Average loss at step ', 2000, ': ', 128.29296172332764)\n",
      "('Epoch: ', 346, ' Average loss at step ', 3000, ': ', 128.19583279037477)\n",
      "('Epoch: ', 346, ' Average loss at step ', 4000, ': ', 127.75957944488525)\n",
      "('Epoch: ', 346, ' Average loss at step ', 4373, ': ', 127.03842776308778)\n",
      "('Epoch: ', 346, ' Average loss at step ', 761, ': ', 7345.7557032534951)\n",
      "('Epoch: ', 346, ' Average loss at step ', 782, ': ', 8474.1166091899413)\n",
      "('Epoch: ', 346, ' Average loss at step ', 787, ': ', 17.828617081387353)\n",
      "('Epoch: ', 346, ' Average loss at step ', 1000, ': ', 4.7762917037010189)\n",
      "('Epoch: ', 346, ' Average loss at step ', 2000, ': ', 4.9260107908248898)\n",
      "('Epoch: ', 346, ' Average loss at step ', 2813, ': ', 4.8062485368380994)\n",
      "Training time took 97.76869 seconds to run 1 epoch\n",
      "('Epoch: ', 347, ' Average loss at step ', 1000, ': ', 0.039345138728618619)\n",
      "('Epoch: ', 347, ' Average loss at step ', 2000, ': ', 0.036166068553924562)\n",
      "('Epoch: ', 347, ' Average loss at step ', 2813, ': ', 0.035164968280369427)\n",
      "Training time took 43.998109 seconds to run 1 epoch\n",
      "('Epoch: ', 348, ' Average loss at step ', 1000, ': ', 128.51522378540039)\n",
      "('Epoch: ', 348, ' Average loss at step ', 2000, ': ', 126.82477418518066)\n",
      "('Epoch: ', 348, ' Average loss at step ', 3000, ': ', 128.56075736236573)\n",
      "('Epoch: ', 348, ' Average loss at step ', 4000, ': ', 129.50148755645753)\n",
      "('Epoch: ', 348, ' Average loss at step ', 4373, ': ', 129.00082182115125)\n",
      "('Epoch: ', 348, ' Average loss at step ', 761, ': ', 7330.0662244294817)\n",
      "('Epoch: ', 348, ' Average loss at step ', 782, ': ', 8474.5842307038256)\n",
      "('Epoch: ', 348, ' Average loss at step ', 787, ': ', 17.744196019403201)\n",
      "('Epoch: ', 348, ' Average loss at step ', 1000, ': ', 4.7193540787696842)\n",
      "('Epoch: ', 348, ' Average loss at step ', 2000, ': ', 4.9295291485786441)\n",
      "('Epoch: ', 348, ' Average loss at step ', 2813, ': ', 4.9069250228957006)\n",
      "Training time took 97.598591 seconds to run 1 epoch\n",
      "('Epoch: ', 349, ' Average loss at step ', 1000, ': ', 0.038957033395767213)\n",
      "('Epoch: ', 349, ' Average loss at step ', 2000, ': ', 0.036019593358039857)\n",
      "('Epoch: ', 349, ' Average loss at step ', 2813, ': ', 0.03513546610994292)\n",
      "Training time took 44.04765 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.982921947965\n",
      "Hits @ 1:  0.935423615744\n",
      "Testing time took 73.348166 seconds.\n",
      "\n",
      "('Epoch: ', 350, ' Average loss at step ', 1000, ': ', 129.23445735931398)\n",
      "('Epoch: ', 350, ' Average loss at step ', 2000, ': ', 128.99279958724975)\n",
      "('Epoch: ', 350, ' Average loss at step ', 3000, ': ', 129.48000389862059)\n",
      "('Epoch: ', 350, ' Average loss at step ', 4000, ': ', 126.53741711425781)\n",
      "('Epoch: ', 350, ' Average loss at step ', 4373, ': ', 126.96833827931394)\n",
      "('Epoch: ', 350, ' Average loss at step ', 761, ': ', 7399.4370075426605)\n",
      "('Epoch: ', 350, ' Average loss at step ', 782, ': ', 8482.3773801366442)\n",
      "('Epoch: ', 350, ' Average loss at step ', 787, ': ', 17.283127885435071)\n",
      "('Epoch: ', 350, ' Average loss at step ', 1000, ': ', 4.9550404496192932)\n",
      "('Epoch: ', 350, ' Average loss at step ', 2000, ': ', 4.8188083992004396)\n",
      "('Epoch: ', 350, ' Average loss at step ', 2813, ': ', 4.7588177390873723)\n",
      "Training time took 97.737499 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 351, ' Average loss at step ', 1000, ': ', 0.038898516535758973)\n",
      "('Epoch: ', 351, ' Average loss at step ', 2000, ': ', 0.036064169406890868)\n",
      "('Epoch: ', 351, ' Average loss at step ', 2813, ': ', 0.035069606427488659)\n",
      "Training time took 44.016055 seconds to run 1 epoch\n",
      "('Epoch: ', 352, ' Average loss at step ', 1000, ': ', 128.0636166229248)\n",
      "('Epoch: ', 352, ' Average loss at step ', 2000, ': ', 128.96073860931398)\n",
      "('Epoch: ', 352, ' Average loss at step ', 3000, ': ', 128.1254492263794)\n",
      "('Epoch: ', 352, ' Average loss at step ', 4000, ': ', 129.29688584899901)\n",
      "('Epoch: ', 352, ' Average loss at step ', 4373, ': ', 130.70211714057513)\n",
      "('Epoch: ', 352, ' Average loss at step ', 761, ': ', 7393.2249424984584)\n",
      "('Epoch: ', 352, ' Average loss at step ', 782, ': ', 8475.9817685409325)\n",
      "('Epoch: ', 352, ' Average loss at step ', 787, ': ', 17.117292450281198)\n",
      "('Epoch: ', 352, ' Average loss at step ', 1000, ': ', 4.8136109004020691)\n",
      "('Epoch: ', 352, ' Average loss at step ', 2000, ': ', 4.8059584684371952)\n",
      "('Epoch: ', 352, ' Average loss at step ', 2813, ': ', 4.7822729877650447)\n",
      "Training time took 97.836054 seconds to run 1 epoch\n",
      "('Epoch: ', 353, ' Average loss at step ', 1000, ': ', 0.038778726518154144)\n",
      "('Epoch: ', 353, ' Average loss at step ', 2000, ': ', 0.035682325899600985)\n",
      "('Epoch: ', 353, ' Average loss at step ', 2813, ': ', 0.034539162305188296)\n",
      "Training time took 44.046606 seconds to run 1 epoch\n",
      "('Epoch: ', 354, ' Average loss at step ', 1000, ': ', 126.62687032318115)\n",
      "('Epoch: ', 354, ' Average loss at step ', 2000, ': ', 129.43838508605958)\n",
      "('Epoch: ', 354, ' Average loss at step ', 3000, ': ', 127.04950575637817)\n",
      "('Epoch: ', 354, ' Average loss at step ', 4000, ': ', 128.67788250732423)\n",
      "('Epoch: ', 354, ' Average loss at step ', 4373, ': ', 129.1875442381828)\n",
      "('Epoch: ', 354, ' Average loss at step ', 761, ': ', 7439.627726665296)\n",
      "('Epoch: ', 354, ' Average loss at step ', 782, ': ', 8489.2521894506244)\n",
      "('Epoch: ', 354, ' Average loss at step ', 787, ': ', 17.407525084400906)\n",
      "('Epoch: ', 354, ' Average loss at step ', 1000, ': ', 4.8817693614959721)\n",
      "('Epoch: ', 354, ' Average loss at step ', 2000, ': ', 4.7969801588058472)\n",
      "('Epoch: ', 354, ' Average loss at step ', 2813, ': ', 4.835363093268108)\n",
      "Training time took 97.711565 seconds to run 1 epoch\n",
      "('Epoch: ', 355, ' Average loss at step ', 1000, ': ', 0.03802997750043869)\n",
      "('Epoch: ', 355, ' Average loss at step ', 2000, ': ', 0.0358752475976944)\n",
      "('Epoch: ', 355, ' Average loss at step ', 2813, ': ', 0.034880576976414383)\n",
      "Training time took 44.050161 seconds to run 1 epoch\n",
      "('Epoch: ', 356, ' Average loss at step ', 1000, ': ', 129.60589139556885)\n",
      "('Epoch: ', 356, ' Average loss at step ', 2000, ': ', 126.58252487945556)\n",
      "('Epoch: ', 356, ' Average loss at step ', 3000, ': ', 127.6511411705017)\n",
      "('Epoch: ', 356, ' Average loss at step ', 4000, ': ', 128.72887783050538)\n",
      "('Epoch: ', 356, ' Average loss at step ', 4373, ': ', 128.20122183522869)\n",
      "('Epoch: ', 356, ' Average loss at step ', 761, ': ', 7470.8465987356085)\n",
      "('Epoch: ', 356, ' Average loss at step ', 782, ': ', 8526.4722742527611)\n",
      "('Epoch: ', 356, ' Average loss at step ', 787, ': ', 16.995430016942304)\n",
      "('Epoch: ', 356, ' Average loss at step ', 1000, ': ', 4.6474858479499819)\n",
      "('Epoch: ', 356, ' Average loss at step ', 2000, ': ', 4.8481872472763063)\n",
      "('Epoch: ', 356, ' Average loss at step ', 2813, ': ', 4.8749140906216475)\n",
      "Training time took 97.913589 seconds to run 1 epoch\n",
      "('Epoch: ', 357, ' Average loss at step ', 1000, ': ', 0.038087345778942107)\n",
      "('Epoch: ', 357, ' Average loss at step ', 2000, ': ', 0.035372785627841949)\n",
      "('Epoch: ', 357, ' Average loss at step ', 2813, ': ', 0.034122711111759317)\n",
      "Training time took 44.032377 seconds to run 1 epoch\n",
      "('Epoch: ', 358, ' Average loss at step ', 1000, ': ', 129.37333485412597)\n",
      "('Epoch: ', 358, ' Average loss at step ', 2000, ': ', 129.56484639739989)\n",
      "('Epoch: ', 358, ' Average loss at step ', 3000, ': ', 128.41522686767578)\n",
      "('Epoch: ', 358, ' Average loss at step ', 4000, ': ', 129.00348148345947)\n",
      "('Epoch: ', 358, ' Average loss at step ', 4373, ': ', 127.5714160344934)\n",
      "('Epoch: ', 358, ' Average loss at step ', 761, ': ', 7397.1537067614099)\n",
      "('Epoch: ', 358, ' Average loss at step ', 782, ': ', 8530.7972138584355)\n",
      "('Epoch: ', 358, ' Average loss at step ', 787, ': ', 16.910622612513961)\n",
      "('Epoch: ', 358, ' Average loss at step ', 1000, ': ', 4.7866492509841922)\n",
      "('Epoch: ', 358, ' Average loss at step ', 2000, ': ', 4.7824935631752012)\n",
      "('Epoch: ', 358, ' Average loss at step ', 2813, ': ', 4.8205016616530019)\n",
      "Training time took 97.721084 seconds to run 1 epoch\n",
      "('Epoch: ', 359, ' Average loss at step ', 1000, ': ', 0.038276646316051481)\n",
      "('Epoch: ', 359, ' Average loss at step ', 2000, ': ', 0.035094464242458344)\n",
      "('Epoch: ', 359, ' Average loss at step ', 2813, ': ', 0.034117882254675692)\n",
      "Training time took 44.024718 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.982655103402\n",
      "Hits @ 1:  0.934156104069\n",
      "Testing time took 73.215132 seconds.\n",
      "\n",
      "('Epoch: ', 360, ' Average loss at step ', 1000, ': ', 128.50225229644775)\n",
      "('Epoch: ', 360, ' Average loss at step ', 2000, ': ', 128.48235330200194)\n",
      "('Epoch: ', 360, ' Average loss at step ', 3000, ': ', 128.24315824127197)\n",
      "('Epoch: ', 360, ' Average loss at step ', 4000, ': ', 128.50860182189942)\n",
      "('Epoch: ', 360, ' Average loss at step ', 4373, ': ', 128.37524090018323)\n",
      "('Epoch: ', 360, ' Average loss at step ', 761, ': ', 7507.162885485197)\n",
      "('Epoch: ', 360, ' Average loss at step ', 782, ': ', 8602.6992362556011)\n",
      "('Epoch: ', 360, ' Average loss at step ', 787, ': ', 16.731078260727511)\n",
      "('Epoch: ', 360, ' Average loss at step ', 1000, ': ', 4.7883093562126158)\n",
      "('Epoch: ', 360, ' Average loss at step ', 2000, ': ', 4.6366006183624267)\n",
      "('Epoch: ', 360, ' Average loss at step ', 2813, ': ', 4.8295682187150852)\n",
      "Training time took 97.746619 seconds to run 1 epoch\n",
      "('Epoch: ', 361, ' Average loss at step ', 1000, ': ', 0.037874700784683225)\n",
      "('Epoch: ', 361, ' Average loss at step ', 2000, ': ', 0.035123846113681793)\n",
      "('Epoch: ', 361, ' Average loss at step ', 2813, ': ', 0.033980307981298474)\n",
      "Training time took 44.01805 seconds to run 1 epoch\n",
      "('Epoch: ', 362, ' Average loss at step ', 1000, ': ', 127.37699425506592)\n",
      "('Epoch: ', 362, ' Average loss at step ', 2000, ': ', 128.3663503189087)\n",
      "('Epoch: ', 362, ' Average loss at step ', 3000, ': ', 126.92978043365478)\n",
      "('Epoch: ', 362, ' Average loss at step ', 4000, ': ', 128.3064573097229)\n",
      "('Epoch: ', 362, ' Average loss at step ', 4373, ': ', 127.05101281853132)\n",
      "('Epoch: ', 362, ' Average loss at step ', 761, ': ', 7522.8742781789679)\n",
      "('Epoch: ', 362, ' Average loss at step ', 782, ': ', 8607.4927014144523)\n",
      "('Epoch: ', 362, ' Average loss at step ', 787, ': ', 16.790944786168843)\n",
      "('Epoch: ', 362, ' Average loss at step ', 1000, ': ', 4.9731913900375364)\n",
      "('Epoch: ', 362, ' Average loss at step ', 2000, ': ', 4.7913445611000061)\n",
      "('Epoch: ', 362, ' Average loss at step ', 2813, ': ', 4.7020970976411416)\n",
      "Training time took 97.744918 seconds to run 1 epoch\n",
      "('Epoch: ', 363, ' Average loss at step ', 1000, ': ', 0.037635688781738279)\n",
      "('Epoch: ', 363, ' Average loss at step ', 2000, ': ', 0.03463564473390579)\n",
      "('Epoch: ', 363, ' Average loss at step ', 2813, ': ', 0.034096473910538432)\n",
      "Training time took 44.034449 seconds to run 1 epoch\n",
      "('Epoch: ', 364, ' Average loss at step ', 1000, ': ', 127.78062660217284)\n",
      "('Epoch: ', 364, ' Average loss at step ', 2000, ': ', 129.16044094848633)\n",
      "('Epoch: ', 364, ' Average loss at step ', 3000, ': ', 127.33408951568603)\n",
      "('Epoch: ', 364, ' Average loss at step ', 4000, ': ', 128.467780708313)\n",
      "('Epoch: ', 364, ' Average loss at step ', 4373, ': ', 128.4163343368038)\n",
      "('Epoch: ', 364, ' Average loss at step ', 761, ': ', 7579.6231024491162)\n",
      "('Epoch: ', 364, ' Average loss at step ', 782, ': ', 8645.7955289442616)\n",
      "('Epoch: ', 364, ' Average loss at step ', 787, ': ', 17.02009158583391)\n",
      "('Epoch: ', 364, ' Average loss at step ', 1000, ': ', 4.7648474235534666)\n",
      "('Epoch: ', 364, ' Average loss at step ', 2000, ': ', 4.628547788143158)\n",
      "('Epoch: ', 364, ' Average loss at step ', 2813, ': ', 4.7595920592106031)\n",
      "Training time took 97.807294 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 365, ' Average loss at step ', 1000, ': ', 0.037329498171806336)\n",
      "('Epoch: ', 365, ' Average loss at step ', 2000, ': ', 0.034886232852935788)\n",
      "('Epoch: ', 365, ' Average loss at step ', 2813, ': ', 0.033546058635406308)\n",
      "Training time took 44.034633 seconds to run 1 epoch\n",
      "('Epoch: ', 366, ' Average loss at step ', 1000, ': ', 128.28508190155029)\n",
      "('Epoch: ', 366, ' Average loss at step ', 2000, ': ', 130.02178623962402)\n",
      "('Epoch: ', 366, ' Average loss at step ', 3000, ': ', 128.4309979019165)\n",
      "('Epoch: ', 366, ' Average loss at step ', 4000, ': ', 128.12439244842528)\n",
      "('Epoch: ', 366, ' Average loss at step ', 4373, ': ', 128.49804933609502)\n",
      "('Epoch: ', 366, ' Average loss at step ', 761, ': ', 7533.3378572162828)\n",
      "('Epoch: ', 366, ' Average loss at step ', 782, ': ', 8623.1525688220227)\n",
      "('Epoch: ', 366, ' Average loss at step ', 787, ': ', 16.744732842190576)\n",
      "('Epoch: ', 366, ' Average loss at step ', 1000, ': ', 4.7958467535972593)\n",
      "('Epoch: ', 366, ' Average loss at step ', 2000, ': ', 4.754207722663879)\n",
      "('Epoch: ', 366, ' Average loss at step ', 2813, ': ', 4.6440084808565709)\n",
      "Training time took 97.718274 seconds to run 1 epoch\n",
      "('Epoch: ', 367, ' Average loss at step ', 1000, ': ', 0.037407702386379242)\n",
      "('Epoch: ', 367, ' Average loss at step ', 2000, ': ', 0.03434509187936783)\n",
      "('Epoch: ', 367, ' Average loss at step ', 2813, ': ', 0.033578000485603443)\n",
      "Training time took 44.019411 seconds to run 1 epoch\n",
      "('Epoch: ', 368, ' Average loss at step ', 1000, ': ', 127.40027729797363)\n",
      "('Epoch: ', 368, ' Average loss at step ', 2000, ': ', 128.93184342956542)\n",
      "('Epoch: ', 368, ' Average loss at step ', 3000, ': ', 127.26990985870361)\n",
      "('Epoch: ', 368, ' Average loss at step ', 4000, ': ', 128.91183435058593)\n",
      "('Epoch: ', 368, ' Average loss at step ', 4373, ': ', 130.3763440860215)\n",
      "('Epoch: ', 368, ' Average loss at step ', 761, ': ', 7555.3855407714846)\n",
      "('Epoch: ', 368, ' Average loss at step ', 782, ': ', 8646.3480201164366)\n",
      "('Epoch: ', 368, ' Average loss at step ', 787, ': ', 16.599743698692809)\n",
      "('Epoch: ', 368, ' Average loss at step ', 1000, ': ', 4.7913980693817138)\n",
      "('Epoch: ', 368, ' Average loss at step ', 2000, ': ', 4.8274199748039246)\n",
      "('Epoch: ', 368, ' Average loss at step ', 2813, ': ', 4.5910887160324698)\n",
      "Training time took 97.764793 seconds to run 1 epoch\n",
      "('Epoch: ', 369, ' Average loss at step ', 1000, ': ', 0.03751446199417114)\n",
      "('Epoch: ', 369, ' Average loss at step ', 2000, ': ', 0.034420083820819854)\n",
      "('Epoch: ', 369, ' Average loss at step ', 2813, ': ', 0.033022706805191607)\n",
      "Training time took 44.00122 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.983455637091\n",
      "Hits @ 1:  0.935623749166\n",
      "Testing time took 73.224267 seconds.\n",
      "\n",
      "('Epoch: ', 370, ' Average loss at step ', 1000, ': ', 129.40116654968261)\n",
      "('Epoch: ', 370, ' Average loss at step ', 2000, ': ', 127.00487689208984)\n",
      "('Epoch: ', 370, ' Average loss at step ', 3000, ': ', 127.9646439743042)\n",
      "('Epoch: ', 370, ' Average loss at step ', 4000, ': ', 128.02898208618163)\n",
      "('Epoch: ', 370, ' Average loss at step ', 4373, ': ', 127.62206854871525)\n",
      "('Epoch: ', 370, ' Average loss at step ', 761, ': ', 7667.5282856188323)\n",
      "('Epoch: ', 370, ' Average loss at step ', 782, ': ', 8679.7382012243925)\n",
      "('Epoch: ', 370, ' Average loss at step ', 787, ': ', 16.847099472851546)\n",
      "('Epoch: ', 370, ' Average loss at step ', 1000, ': ', 4.7060532617568969)\n",
      "('Epoch: ', 370, ' Average loss at step ', 2000, ': ', 4.7463915185928345)\n",
      "('Epoch: ', 370, ' Average loss at step ', 2813, ': ', 4.8241704602546882)\n",
      "Training time took 97.749507 seconds to run 1 epoch\n",
      "('Epoch: ', 371, ' Average loss at step ', 1000, ': ', 0.036889538288116454)\n",
      "('Epoch: ', 371, ' Average loss at step ', 2000, ': ', 0.034238065659999845)\n",
      "('Epoch: ', 371, ' Average loss at step ', 2813, ': ', 0.033252654184261564)\n",
      "Training time took 44.024971 seconds to run 1 epoch\n",
      "('Epoch: ', 372, ' Average loss at step ', 1000, ': ', 128.1895173034668)\n",
      "('Epoch: ', 372, ' Average loss at step ', 2000, ': ', 128.32067004394531)\n",
      "('Epoch: ', 372, ' Average loss at step ', 3000, ': ', 127.15299221801757)\n",
      "('Epoch: ', 372, ' Average loss at step ', 4000, ': ', 129.28108172607421)\n",
      "('Epoch: ', 372, ' Average loss at step ', 4373, ': ', 128.11924997965494)\n",
      "('Epoch: ', 372, ' Average loss at step ', 761, ': ', 7622.1406211451476)\n",
      "('Epoch: ', 372, ' Average loss at step ', 782, ': ', 8678.9733170864674)\n",
      "('Epoch: ', 372, ' Average loss at step ', 787, ': ', 16.555408446236726)\n",
      "('Epoch: ', 372, ' Average loss at step ', 1000, ': ', 4.7642153720855713)\n",
      "('Epoch: ', 372, ' Average loss at step ', 2000, ': ', 4.6161818408966067)\n",
      "('Epoch: ', 372, ' Average loss at step ', 2813, ': ', 4.7669477815111279)\n",
      "Training time took 97.761387 seconds to run 1 epoch\n",
      "('Epoch: ', 373, ' Average loss at step ', 1000, ': ', 0.037029052853584286)\n",
      "('Epoch: ', 373, ' Average loss at step ', 2000, ': ', 0.033841167986392973)\n",
      "('Epoch: ', 373, ' Average loss at step ', 2813, ': ', 0.032827549893867797)\n",
      "Training time took 44.05275 seconds to run 1 epoch\n",
      "('Epoch: ', 374, ' Average loss at step ', 1000, ': ', 128.35238663482667)\n",
      "('Epoch: ', 374, ' Average loss at step ', 2000, ': ', 127.6576863861084)\n",
      "('Epoch: ', 374, ' Average loss at step ', 3000, ': ', 126.52010091400146)\n",
      "('Epoch: ', 374, ' Average loss at step ', 4000, ': ', 128.49721997833251)\n",
      "('Epoch: ', 374, ' Average loss at step ', 4373, ': ', 128.06604545347153)\n",
      "('Epoch: ', 374, ' Average loss at step ', 761, ': ', 7620.5166722347858)\n",
      "('Epoch: ', 374, ' Average loss at step ', 782, ': ', 8748.6971337077866)\n",
      "('Epoch: ', 374, ' Average loss at step ', 787, ': ', 16.195215447258402)\n",
      "('Epoch: ', 374, ' Average loss at step ', 1000, ': ', 4.7113154854774475)\n",
      "('Epoch: ', 374, ' Average loss at step ', 2000, ': ', 4.7082434225082395)\n",
      "('Epoch: ', 374, ' Average loss at step ', 2813, ': ', 4.6915130585872484)\n",
      "Training time took 97.866645 seconds to run 1 epoch\n",
      "('Epoch: ', 375, ' Average loss at step ', 1000, ': ', 0.036608247637748718)\n",
      "('Epoch: ', 375, ' Average loss at step ', 2000, ': ', 0.03371911644935608)\n",
      "('Epoch: ', 375, ' Average loss at step ', 2813, ': ', 0.032617579246389458)\n",
      "Training time took 44.04492 seconds to run 1 epoch\n",
      "('Epoch: ', 376, ' Average loss at step ', 1000, ': ', 127.07861770534515)\n",
      "('Epoch: ', 376, ' Average loss at step ', 2000, ': ', 126.46330981445313)\n",
      "('Epoch: ', 376, ' Average loss at step ', 3000, ': ', 128.18902818298341)\n",
      "('Epoch: ', 376, ' Average loss at step ', 4000, ': ', 128.28617967224122)\n",
      "('Epoch: ', 376, ' Average loss at step ', 4373, ': ', 125.02783207226825)\n",
      "('Epoch: ', 376, ' Average loss at step ', 761, ': ', 7633.8788847270762)\n",
      "('Epoch: ', 376, ' Average loss at step ', 782, ': ', 8704.3023186169576)\n",
      "('Epoch: ', 376, ' Average loss at step ', 787, ': ', 16.492038742579879)\n",
      "('Epoch: ', 376, ' Average loss at step ', 1000, ': ', 4.6610081629753113)\n",
      "('Epoch: ', 376, ' Average loss at step ', 2000, ': ', 4.632465067863464)\n",
      "('Epoch: ', 376, ' Average loss at step ', 2813, ': ', 4.6194282359090346)\n",
      "Training time took 97.806281 seconds to run 1 epoch\n",
      "('Epoch: ', 377, ' Average loss at step ', 1000, ': ', 0.036035414516925809)\n",
      "('Epoch: ', 377, ' Average loss at step ', 2000, ': ', 0.033659156084060671)\n",
      "('Epoch: ', 377, ' Average loss at step ', 2813, ': ', 0.032986390987053291)\n",
      "Training time took 44.031916 seconds to run 1 epoch\n",
      "('Epoch: ', 378, ' Average loss at step ', 1000, ': ', 130.33623588180541)\n",
      "('Epoch: ', 378, ' Average loss at step ', 2000, ': ', 128.21871353149413)\n",
      "('Epoch: ', 378, ' Average loss at step ', 3000, ': ', 128.86637184906004)\n",
      "('Epoch: ', 378, ' Average loss at step ', 4000, ': ', 128.43805402374267)\n",
      "('Epoch: ', 378, ' Average loss at step ', 4373, ': ', 128.32905277129143)\n",
      "('Epoch: ', 378, ' Average loss at step ', 761, ': ', 7661.0337151778376)\n",
      "('Epoch: ', 378, ' Average loss at step ', 782, ': ', 8801.0905708576738)\n",
      "('Epoch: ', 378, ' Average loss at step ', 787, ': ', 16.37521438744232)\n",
      "('Epoch: ', 378, ' Average loss at step ', 1000, ': ', 4.7282839055061343)\n",
      "('Epoch: ', 378, ' Average loss at step ', 2000, ': ', 4.6102014703750607)\n",
      "('Epoch: ', 378, ' Average loss at step ', 2813, ': ', 4.6169723090279868)\n",
      "Training time took 97.864385 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 379, ' Average loss at step ', 1000, ': ', 0.036124832987785342)\n",
      "('Epoch: ', 379, ' Average loss at step ', 2000, ': ', 0.033303612947463992)\n",
      "('Epoch: ', 379, ' Average loss at step ', 2813, ': ', 0.03268824422300743)\n",
      "Training time took 44.079812 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.983455637091\n",
      "Hits @ 1:  0.935223482322\n",
      "Testing time took 73.222489 seconds.\n",
      "\n",
      "('Epoch: ', 380, ' Average loss at step ', 1000, ': ', 127.42840719604492)\n",
      "('Epoch: ', 380, ' Average loss at step ', 2000, ': ', 127.84610313415527)\n",
      "('Epoch: ', 380, ' Average loss at step ', 3000, ': ', 128.33392122650147)\n",
      "('Epoch: ', 380, ' Average loss at step ', 4000, ': ', 129.0760608291626)\n",
      "('Epoch: ', 380, ' Average loss at step ', 4373, ': ', 130.3109018879552)\n",
      "('Epoch: ', 380, ' Average loss at step ', 761, ': ', 7694.964541786595)\n",
      "('Epoch: ', 380, ' Average loss at step ', 782, ': ', 8722.0478834477035)\n",
      "('Epoch: ', 380, ' Average loss at step ', 787, ': ', 16.40441891133937)\n",
      "('Epoch: ', 380, ' Average loss at step ', 1000, ': ', 4.6287563285827638)\n",
      "('Epoch: ', 380, ' Average loss at step ', 2000, ': ', 4.6532429556846617)\n",
      "('Epoch: ', 380, ' Average loss at step ', 2813, ': ', 4.7335379599350427)\n",
      "Training time took 97.74457 seconds to run 1 epoch\n",
      "('Epoch: ', 381, ' Average loss at step ', 1000, ': ', 0.035792965769767759)\n",
      "('Epoch: ', 381, ' Average loss at step ', 2000, ': ', 0.03310166817903519)\n",
      "('Epoch: ', 381, ' Average loss at step ', 2813, ': ', 0.032257827998969354)\n",
      "Training time took 44.021103 seconds to run 1 epoch\n",
      "('Epoch: ', 382, ' Average loss at step ', 1000, ': ', 129.78131233978272)\n",
      "('Epoch: ', 382, ' Average loss at step ', 2000, ': ', 127.5269393081665)\n",
      "('Epoch: ', 382, ' Average loss at step ', 3000, ': ', 129.32401934051515)\n",
      "('Epoch: ', 382, ' Average loss at step ', 4000, ': ', 127.89969232559204)\n",
      "('Epoch: ', 382, ' Average loss at step ', 4373, ': ', 128.51014904309343)\n",
      "('Epoch: ', 382, ' Average loss at step ', 761, ': ', 7659.1120033665711)\n",
      "('Epoch: ', 382, ' Average loss at step ', 782, ': ', 8783.6651453465111)\n",
      "('Epoch: ', 382, ' Average loss at step ', 787, ': ', 16.44389610921457)\n",
      "('Epoch: ', 382, ' Average loss at step ', 1000, ': ', 4.46350847196579)\n",
      "('Epoch: ', 382, ' Average loss at step ', 2000, ': ', 4.6640483589172366)\n",
      "('Epoch: ', 382, ' Average loss at step ', 2813, ': ', 4.6505208937405369)\n",
      "Training time took 97.833548 seconds to run 1 epoch\n",
      "('Epoch: ', 383, ' Average loss at step ', 1000, ': ', 0.03588691431283951)\n",
      "('Epoch: ', 383, ' Average loss at step ', 2000, ': ', 0.033047223389148714)\n",
      "('Epoch: ', 383, ' Average loss at step ', 2813, ': ', 0.032050581401204828)\n",
      "Training time took 44.057321 seconds to run 1 epoch\n",
      "('Epoch: ', 384, ' Average loss at step ', 1000, ': ', 128.28868241882324)\n",
      "('Epoch: ', 384, ' Average loss at step ', 2000, ': ', 128.54890684509277)\n",
      "('Epoch: ', 384, ' Average loss at step ', 3000, ': ', 128.26369235992431)\n",
      "('Epoch: ', 384, ' Average loss at step ', 4000, ': ', 128.9380079421997)\n",
      "('Epoch: ', 384, ' Average loss at step ', 4373, ': ', 127.95698924731182)\n",
      "('Epoch: ', 384, ' Average loss at step ', 761, ': ', 7712.6382860685653)\n",
      "('Epoch: ', 384, ' Average loss at step ', 782, ': ', 8823.3327170944704)\n",
      "('Epoch: ', 384, ' Average loss at step ', 787, ': ', 16.435826979823997)\n",
      "('Epoch: ', 384, ' Average loss at step ', 1000, ': ', 4.6493968157768251)\n",
      "('Epoch: ', 384, ' Average loss at step ', 2000, ': ', 4.6362183327674868)\n",
      "('Epoch: ', 384, ' Average loss at step ', 2813, ': ', 4.6239277294703891)\n",
      "Training time took 97.876183 seconds to run 1 epoch\n",
      "('Epoch: ', 385, ' Average loss at step ', 1000, ': ', 0.035746491968631743)\n",
      "('Epoch: ', 385, ' Average loss at step ', 2000, ': ', 0.033099226832389833)\n",
      "('Epoch: ', 385, ' Average loss at step ', 2813, ': ', 0.031941208492946155)\n",
      "Training time took 44.026089 seconds to run 1 epoch\n",
      "('Epoch: ', 386, ' Average loss at step ', 1000, ': ', 127.66764236450196)\n",
      "('Epoch: ', 386, ' Average loss at step ', 2000, ': ', 125.97885734558105)\n",
      "('Epoch: ', 386, ' Average loss at step ', 3000, ': ', 126.60380278015137)\n",
      "('Epoch: ', 386, ' Average loss at step ', 4000, ': ', 127.984362449646)\n",
      "('Epoch: ', 386, ' Average loss at step ', 4373, ': ', 127.51384107528195)\n",
      "('Epoch: ', 386, ' Average loss at step ', 761, ': ', 7712.1950635408102)\n",
      "('Epoch: ', 386, ' Average loss at step ', 782, ': ', 8805.7640219870354)\n",
      "('Epoch: ', 386, ' Average loss at step ', 787, ': ', 16.300523055418758)\n",
      "('Epoch: ', 386, ' Average loss at step ', 1000, ': ', 4.6878796720504763)\n",
      "('Epoch: ', 386, ' Average loss at step ', 2000, ': ', 4.5945212411880494)\n",
      "('Epoch: ', 386, ' Average loss at step ', 2813, ': ', 4.706233233066615)\n",
      "Training time took 97.789455 seconds to run 1 epoch\n",
      "('Epoch: ', 387, ' Average loss at step ', 1000, ': ', 0.035300100505352018)\n",
      "('Epoch: ', 387, ' Average loss at step ', 2000, ': ', 0.032346379876136783)\n",
      "('Epoch: ', 387, ' Average loss at step ', 2813, ': ', 0.03201740407591383)\n",
      "Training time took 44.029723 seconds to run 1 epoch\n",
      "('Epoch: ', 388, ' Average loss at step ', 1000, ': ', 129.44086462402345)\n",
      "('Epoch: ', 388, ' Average loss at step ', 2000, ': ', 126.84821862792968)\n",
      "('Epoch: ', 388, ' Average loss at step ', 3000, ': ', 128.64177175903319)\n",
      "('Epoch: ', 388, ' Average loss at step ', 4000, ': ', 127.93343169403076)\n",
      "('Epoch: ', 388, ' Average loss at step ', 4373, ': ', 128.47606101087345)\n",
      "('Epoch: ', 388, ' Average loss at step ', 761, ': ', 7673.9727134303039)\n",
      "('Epoch: ', 388, ' Average loss at step ', 782, ': ', 8879.6112205905883)\n",
      "('Epoch: ', 388, ' Average loss at step ', 787, ': ', 16.38633919975533)\n",
      "('Epoch: ', 388, ' Average loss at step ', 1000, ': ', 4.6614619936943056)\n",
      "('Epoch: ', 388, ' Average loss at step ', 2000, ': ', 4.4862215652465824)\n",
      "('Epoch: ', 388, ' Average loss at step ', 2813, ': ', 4.5173041092351154)\n",
      "Training time took 97.784675 seconds to run 1 epoch\n",
      "('Epoch: ', 389, ' Average loss at step ', 1000, ': ', 0.035169611513614654)\n",
      "('Epoch: ', 389, ' Average loss at step ', 2000, ': ', 0.03277257591485977)\n",
      "('Epoch: ', 389, ' Average loss at step ', 2813, ': ', 0.031760668813301425)\n",
      "Training time took 44.058709 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.983455637091\n",
      "Hits @ 1:  0.936224149433\n",
      "Testing time took 73.19808 seconds.\n",
      "\n",
      "('Epoch: ', 390, ' Average loss at step ', 1000, ': ', 126.17834359741211)\n",
      "('Epoch: ', 390, ' Average loss at step ', 2000, ': ', 127.06284253692627)\n",
      "('Epoch: ', 390, ' Average loss at step ', 3000, ': ', 128.23454366302491)\n",
      "('Epoch: ', 390, ' Average loss at step ', 4000, ': ', 129.08550982666014)\n",
      "('Epoch: ', 390, ' Average loss at step ', 4373, ': ', 128.91876979540754)\n",
      "('Epoch: ', 390, ' Average loss at step ', 761, ': ', 7715.2952354029603)\n",
      "('Epoch: ', 390, ' Average loss at step ', 782, ': ', 8896.4941593810017)\n",
      "('Epoch: ', 390, ' Average loss at step ', 787, ': ', 16.043554292683687)\n",
      "('Epoch: ', 390, ' Average loss at step ', 1000, ': ', 4.5338618049621582)\n",
      "('Epoch: ', 390, ' Average loss at step ', 2000, ': ', 4.5798852210044858)\n",
      "('Epoch: ', 390, ' Average loss at step ', 2813, ': ', 4.6516556874871844)\n",
      "Training time took 97.804262 seconds to run 1 epoch\n",
      "('Epoch: ', 391, ' Average loss at step ', 1000, ': ', 0.035604148447513577)\n",
      "('Epoch: ', 391, ' Average loss at step ', 2000, ': ', 0.03238477909564972)\n",
      "('Epoch: ', 391, ' Average loss at step ', 2813, ': ', 0.031225573473376008)\n",
      "Training time took 43.998101 seconds to run 1 epoch\n",
      "('Epoch: ', 392, ' Average loss at step ', 1000, ': ', 125.87994300842286)\n",
      "('Epoch: ', 392, ' Average loss at step ', 2000, ': ', 128.02579507446288)\n",
      "('Epoch: ', 392, ' Average loss at step ', 3000, ': ', 127.39259555053711)\n",
      "('Epoch: ', 392, ' Average loss at step ', 4000, ': ', 127.45053253936767)\n",
      "('Epoch: ', 392, ' Average loss at step ', 4373, ': ', 133.39869525868406)\n",
      "('Epoch: ', 392, ' Average loss at step ', 761, ': ', 7743.3049309981498)\n",
      "('Epoch: ', 392, ' Average loss at step ', 782, ': ', 8896.9933303657162)\n",
      "('Epoch: ', 392, ' Average loss at step ', 787, ': ', 16.519138182089225)\n",
      "('Epoch: ', 392, ' Average loss at step ', 1000, ': ', 4.5531818623542781)\n",
      "('Epoch: ', 392, ' Average loss at step ', 2000, ': ', 4.5317929730415347)\n",
      "('Epoch: ', 392, ' Average loss at step ', 2813, ': ', 4.6787866107348739)\n",
      "Training time took 97.828301 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 393, ' Average loss at step ', 1000, ': ', 0.035138585031032565)\n",
      "('Epoch: ', 393, ' Average loss at step ', 2000, ': ', 0.032232894599437713)\n",
      "('Epoch: ', 393, ' Average loss at step ', 2813, ': ', 0.031543212204143918)\n",
      "Training time took 44.030532 seconds to run 1 epoch\n",
      "('Epoch: ', 394, ' Average loss at step ', 1000, ': ', 129.03704064941405)\n",
      "('Epoch: ', 394, ' Average loss at step ', 2000, ': ', 128.24367039489746)\n",
      "('Epoch: ', 394, ' Average loss at step ', 3000, ': ', 129.74595472717286)\n",
      "('Epoch: ', 394, ' Average loss at step ', 4000, ': ', 129.23017533874511)\n",
      "('Epoch: ', 394, ' Average loss at step ', 4373, ': ', 126.8890679267145)\n",
      "('Epoch: ', 394, ' Average loss at step ', 761, ': ', 7771.465436112253)\n",
      "('Epoch: ', 394, ' Average loss at step ', 782, ': ', 8908.7710848721599)\n",
      "('Epoch: ', 394, ' Average loss at step ', 787, ': ', 15.996396262530455)\n",
      "('Epoch: ', 394, ' Average loss at step ', 1000, ': ', 4.5888972244262698)\n",
      "('Epoch: ', 394, ' Average loss at step ', 2000, ': ', 4.5547543101310728)\n",
      "('Epoch: ', 394, ' Average loss at step ', 2813, ': ', 4.7615640004867403)\n",
      "Training time took 97.857395 seconds to run 1 epoch\n",
      "('Epoch: ', 395, ' Average loss at step ', 1000, ': ', 0.03504261988401413)\n",
      "('Epoch: ', 395, ' Average loss at step ', 2000, ': ', 0.032247463941574094)\n",
      "('Epoch: ', 395, ' Average loss at step ', 2813, ': ', 0.031083515051550464)\n",
      "Training time took 44.013099 seconds to run 1 epoch\n",
      "('Epoch: ', 396, ' Average loss at step ', 1000, ': ', 128.97357484436034)\n",
      "('Epoch: ', 396, ' Average loss at step ', 2000, ': ', 128.76417993927001)\n",
      "('Epoch: ', 396, ' Average loss at step ', 3000, ': ', 128.01743128967286)\n",
      "('Epoch: ', 396, ' Average loss at step ', 4000, ': ', 129.98153858947754)\n",
      "('Epoch: ', 396, ' Average loss at step ', 4373, ': ', 127.20628451275569)\n",
      "('Epoch: ', 396, ' Average loss at step ', 761, ': ', 7810.8962807103208)\n",
      "('Epoch: ', 396, ' Average loss at step ', 782, ': ', 8836.0270111435657)\n",
      "('Epoch: ', 396, ' Average loss at step ', 787, ': ', 16.214583280432315)\n",
      "('Epoch: ', 396, ' Average loss at step ', 1000, ': ', 4.5592009258270263)\n",
      "('Epoch: ', 396, ' Average loss at step ', 2000, ': ', 4.5551316819190983)\n",
      "('Epoch: ', 396, ' Average loss at step ', 2813, ': ', 4.5042091496472292)\n",
      "Training time took 97.83558 seconds to run 1 epoch\n",
      "('Epoch: ', 397, ' Average loss at step ', 1000, ': ', 0.034047906041145326)\n",
      "('Epoch: ', 397, ' Average loss at step ', 2000, ': ', 0.032132204711437226)\n",
      "('Epoch: ', 397, ' Average loss at step ', 2813, ': ', 0.031289060200963704)\n",
      "Training time took 44.068261 seconds to run 1 epoch\n",
      "('Epoch: ', 398, ' Average loss at step ', 1000, ': ', 129.07598882293701)\n",
      "('Epoch: ', 398, ' Average loss at step ', 2000, ': ', 129.60616255950927)\n",
      "('Epoch: ', 398, ' Average loss at step ', 3000, ': ', 129.0861293106079)\n",
      "('Epoch: ', 398, ' Average loss at step ', 4000, ': ', 127.63745629882813)\n",
      "('Epoch: ', 398, ' Average loss at step ', 4373, ': ', 131.79933131638393)\n",
      "('Epoch: ', 398, ' Average loss at step ', 761, ': ', 7819.6243421052632)\n",
      "('Epoch: ', 398, ' Average loss at step ', 782, ': ', 8905.594174510843)\n",
      "('Epoch: ', 398, ' Average loss at step ', 787, ': ', 16.083587921909402)\n",
      "('Epoch: ', 398, ' Average loss at step ', 1000, ': ', 4.4959764585494995)\n",
      "('Epoch: ', 398, ' Average loss at step ', 2000, ': ', 4.4641598320007327)\n",
      "('Epoch: ', 398, ' Average loss at step ', 2813, ': ', 4.5556654824411931)\n",
      "Training time took 97.843008 seconds to run 1 epoch\n",
      "('Epoch: ', 399, ' Average loss at step ', 1000, ': ', 0.034601981461048127)\n",
      "('Epoch: ', 399, ' Average loss at step ', 2000, ': ', 0.031662169277667997)\n",
      "('Epoch: ', 399, ' Average loss at step ', 2813, ': ', 0.030938841659447242)\n",
      "Training time took 44.027538 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.983589059373\n",
      "Hits @ 1:  0.935557038025\n",
      "Testing time took 73.238203 seconds.\n",
      "\n",
      "('Epoch: ', 400, ' Average loss at step ', 1000, ': ', 127.25660890960694)\n",
      "('Epoch: ', 400, ' Average loss at step ', 2000, ': ', 128.68257514953612)\n",
      "('Epoch: ', 400, ' Average loss at step ', 3000, ': ', 126.06955931091309)\n",
      "('Epoch: ', 400, ' Average loss at step ', 4000, ': ', 128.84269200897216)\n",
      "('Epoch: ', 400, ' Average loss at step ', 4373, ': ', 131.16634229434433)\n",
      "('Epoch: ', 400, ' Average loss at step ', 761, ': ', 7849.4395360043172)\n",
      "('Epoch: ', 400, ' Average loss at step ', 782, ': ', 9013.915175981314)\n",
      "('Epoch: ', 400, ' Average loss at step ', 787, ': ', 15.867489202028619)\n",
      "('Epoch: ', 400, ' Average loss at step ', 1000, ': ', 4.6854409580230714)\n",
      "('Epoch: ', 400, ' Average loss at step ', 2000, ': ', 4.6081940312385559)\n",
      "('Epoch: ', 400, ' Average loss at step ', 2813, ': ', 4.520980561308086)\n",
      "Training time took 97.825364 seconds to run 1 epoch\n",
      "('Epoch: ', 401, ' Average loss at step ', 1000, ': ', 0.034671227872371674)\n",
      "('Epoch: ', 401, ' Average loss at step ', 2000, ': ', 0.03157204729318619)\n",
      "('Epoch: ', 401, ' Average loss at step ', 2813, ': ', 0.030755954569783705)\n",
      "Training time took 44.043843 seconds to run 1 epoch\n",
      "('Epoch: ', 402, ' Average loss at step ', 1000, ': ', 130.77257984924316)\n",
      "('Epoch: ', 402, ' Average loss at step ', 2000, ': ', 128.26126751708983)\n",
      "('Epoch: ', 402, ' Average loss at step ', 3000, ': ', 127.99212097167968)\n",
      "('Epoch: ', 402, ' Average loss at step ', 4000, ': ', 126.70251766967773)\n",
      "('Epoch: ', 402, ' Average loss at step ', 4373, ': ', 129.38867774060978)\n",
      "('Epoch: ', 402, ' Average loss at step ', 761, ': ', 7827.4982563219573)\n",
      "('Epoch: ', 402, ' Average loss at step ', 782, ': ', 8955.3816890154849)\n",
      "('Epoch: ', 402, ' Average loss at step ', 787, ': ', 15.782175593097096)\n",
      "('Epoch: ', 402, ' Average loss at step ', 1000, ': ', 4.5670658330917355)\n",
      "('Epoch: ', 402, ' Average loss at step ', 2000, ': ', 4.5318505988121034)\n",
      "('Epoch: ', 402, ' Average loss at step ', 2813, ': ', 4.489328188261962)\n",
      "Training time took 97.897152 seconds to run 1 epoch\n",
      "('Epoch: ', 403, ' Average loss at step ', 1000, ': ', 0.034102556645870211)\n",
      "('Epoch: ', 403, ' Average loss at step ', 2000, ': ', 0.031612977445125583)\n",
      "('Epoch: ', 403, ' Average loss at step ', 2813, ': ', 0.030740652912355997)\n",
      "Training time took 44.041184 seconds to run 1 epoch\n",
      "('Epoch: ', 404, ' Average loss at step ', 1000, ': ', 129.43954574584961)\n",
      "('Epoch: ', 404, ' Average loss at step ', 2000, ': ', 128.50272801971437)\n",
      "('Epoch: ', 404, ' Average loss at step ', 3000, ': ', 126.32784034729004)\n",
      "('Epoch: ', 404, ' Average loss at step ', 4000, ': ', 130.07396801757812)\n",
      "('Epoch: ', 404, ' Average loss at step ', 4373, ': ', 126.95312986066264)\n",
      "('Epoch: ', 404, ' Average loss at step ', 761, ': ', 7828.8316534745063)\n",
      "('Epoch: ', 404, ' Average loss at step ', 782, ': ', 9046.4127552066657)\n",
      "('Epoch: ', 404, ' Average loss at step ', 787, ': ', 15.571438765101155)\n",
      "('Epoch: ', 404, ' Average loss at step ', 1000, ': ', 4.4879539608955383)\n",
      "('Epoch: ', 404, ' Average loss at step ', 2000, ': ', 4.5437882795333859)\n",
      "('Epoch: ', 404, ' Average loss at step ', 2813, ': ', 4.5317941064317822)\n",
      "Training time took 97.77071 seconds to run 1 epoch\n",
      "('Epoch: ', 405, ' Average loss at step ', 1000, ': ', 0.034014097869396208)\n",
      "('Epoch: ', 405, ' Average loss at step ', 2000, ': ', 0.03154022842645645)\n",
      "('Epoch: ', 405, ' Average loss at step ', 2813, ': ', 0.030496665483037828)\n",
      "Training time took 44.053532 seconds to run 1 epoch\n",
      "('Epoch: ', 406, ' Average loss at step ', 1000, ': ', 129.59274182128905)\n",
      "('Epoch: ', 406, ' Average loss at step ', 2000, ': ', 129.20265879821778)\n",
      "('Epoch: ', 406, ' Average loss at step ', 3000, ': ', 128.52978920745849)\n",
      "('Epoch: ', 406, ' Average loss at step ', 4000, ': ', 128.35968289184569)\n",
      "('Epoch: ', 406, ' Average loss at step ', 4373, ': ', 127.68719599323887)\n",
      "('Epoch: ', 406, ' Average loss at step ', 761, ': ', 7932.190651983964)\n",
      "('Epoch: ', 406, ' Average loss at step ', 782, ': ', 8994.4272692261529)\n",
      "('Epoch: ', 406, ' Average loss at step ', 787, ': ', 15.754931005812784)\n",
      "('Epoch: ', 406, ' Average loss at step ', 1000, ': ', 4.6344942240715028)\n",
      "('Epoch: ', 406, ' Average loss at step ', 2000, ': ', 4.4731557874679568)\n",
      "('Epoch: ', 406, ' Average loss at step ', 2813, ': ', 4.4778542524488101)\n",
      "Training time took 97.734312 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 407, ' Average loss at step ', 1000, ': ', 0.03373332130908966)\n",
      "('Epoch: ', 407, ' Average loss at step ', 2000, ': ', 0.031135941088199615)\n",
      "('Epoch: ', 407, ' Average loss at step ', 2813, ': ', 0.030475009324515395)\n",
      "Training time took 44.023337 seconds to run 1 epoch\n",
      "('Epoch: ', 408, ' Average loss at step ', 1000, ': ', 128.95454878234864)\n",
      "('Epoch: ', 408, ' Average loss at step ', 2000, ': ', 128.62195474243165)\n",
      "('Epoch: ', 408, ' Average loss at step ', 3000, ': ', 128.71107312774657)\n",
      "('Epoch: ', 408, ' Average loss at step ', 4000, ': ', 128.33501934051515)\n",
      "('Epoch: ', 408, ' Average loss at step ', 4373, ': ', 130.70448754423407)\n",
      "('Epoch: ', 408, ' Average loss at step ', 761, ': ', 7933.6168360659949)\n",
      "('Epoch: ', 408, ' Average loss at step ', 782, ': ', 9069.2990313150203)\n",
      "('Epoch: ', 408, ' Average loss at step ', 787, ': ', 15.735198261173627)\n",
      "('Epoch: ', 408, ' Average loss at step ', 1000, ': ', 4.412153521537781)\n",
      "('Epoch: ', 408, ' Average loss at step ', 2000, ': ', 4.514627369403839)\n",
      "('Epoch: ', 408, ' Average loss at step ', 2813, ': ', 4.4766079962547192)\n",
      "Training time took 97.71014 seconds to run 1 epoch\n",
      "('Epoch: ', 409, ' Average loss at step ', 1000, ': ', 0.033708891391754148)\n",
      "('Epoch: ', 409, ' Average loss at step ', 2000, ': ', 0.03093728280067444)\n",
      "('Epoch: ', 409, ' Average loss at step ', 2813, ': ', 0.030525185571515501)\n",
      "Training time took 44.024188 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.984056037358\n",
      "Hits @ 1:  0.935557038025\n",
      "Testing time took 73.250219 seconds.\n",
      "\n",
      "('Epoch: ', 410, ' Average loss at step ', 1000, ': ', 127.22070448303222)\n",
      "('Epoch: ', 410, ' Average loss at step ', 2000, ': ', 129.78422688293458)\n",
      "('Epoch: ', 410, ' Average loss at step ', 3000, ': ', 128.81548931121827)\n",
      "('Epoch: ', 410, ' Average loss at step ', 4000, ': ', 127.22794556427002)\n",
      "('Epoch: ', 410, ' Average loss at step ', 4373, ': ', 128.06496929866012)\n",
      "('Epoch: ', 410, ' Average loss at step ', 761, ': ', 7836.511716180099)\n",
      "('Epoch: ', 410, ' Average loss at step ', 782, ': ', 9128.5565193361872)\n",
      "('Epoch: ', 410, ' Average loss at step ', 787, ': ', 15.741749275731676)\n",
      "('Epoch: ', 410, ' Average loss at step ', 1000, ': ', 4.5377874207496642)\n",
      "('Epoch: ', 410, ' Average loss at step ', 2000, ': ', 4.4315293507575992)\n",
      "('Epoch: ', 410, ' Average loss at step ', 2813, ': ', 4.4564909799932844)\n",
      "Training time took 97.861841 seconds to run 1 epoch\n",
      "('Epoch: ', 411, ' Average loss at step ', 1000, ': ', 0.033339095056056978)\n",
      "('Epoch: ', 411, ' Average loss at step ', 2000, ': ', 0.031001305282115935)\n",
      "('Epoch: ', 411, ' Average loss at step ', 2813, ': ', 0.03026213551976998)\n",
      "Training time took 44.026606 seconds to run 1 epoch\n",
      "('Epoch: ', 412, ' Average loss at step ', 1000, ': ', 128.72426069641114)\n",
      "('Epoch: ', 412, ' Average loss at step ', 2000, ': ', 130.184106590271)\n",
      "('Epoch: ', 412, ' Average loss at step ', 3000, ': ', 128.59271634674073)\n",
      "('Epoch: ', 412, ' Average loss at step ', 4000, ': ', 128.20345092010498)\n",
      "('Epoch: ', 412, ' Average loss at step ', 4373, ': ', 127.50062868672032)\n",
      "('Epoch: ', 412, ' Average loss at step ', 761, ': ', 7839.1925215871706)\n",
      "('Epoch: ', 412, ' Average loss at step ', 782, ': ', 9042.9217480843872)\n",
      "('Epoch: ', 412, ' Average loss at step ', 787, ': ', 15.65115652011551)\n",
      "('Epoch: ', 412, ' Average loss at step ', 1000, ': ', 4.4548344726562501)\n",
      "('Epoch: ', 412, ' Average loss at step ', 2000, ': ', 4.46422621679306)\n",
      "('Epoch: ', 412, ' Average loss at step ', 2813, ': ', 4.5545505884245703)\n",
      "Training time took 97.656194 seconds to run 1 epoch\n",
      "('Epoch: ', 413, ' Average loss at step ', 1000, ': ', 0.033129460930824278)\n",
      "('Epoch: ', 413, ' Average loss at step ', 2000, ': ', 0.030676528096199036)\n",
      "('Epoch: ', 413, ' Average loss at step ', 2813, ': ', 0.030264409892077515)\n",
      "Training time took 44.008584 seconds to run 1 epoch\n",
      "('Epoch: ', 414, ' Average loss at step ', 1000, ': ', 127.39964450073242)\n",
      "('Epoch: ', 414, ' Average loss at step ', 2000, ': ', 128.70233366394044)\n",
      "('Epoch: ', 414, ' Average loss at step ', 3000, ': ', 129.94703234100342)\n",
      "('Epoch: ', 414, ' Average loss at step ', 4000, ': ', 128.47103907012939)\n",
      "('Epoch: ', 414, ' Average loss at step ', 4373, ': ', 125.93020716021138)\n",
      "('Epoch: ', 414, ' Average loss at step ', 761, ': ', 7903.5892012746708)\n",
      "('Epoch: ', 414, ' Average loss at step ', 782, ': ', 9142.2671861245599)\n",
      "('Epoch: ', 414, ' Average loss at step ', 787, ': ', 15.483171444812804)\n",
      "('Epoch: ', 414, ' Average loss at step ', 1000, ': ', 4.4087257189750675)\n",
      "('Epoch: ', 414, ' Average loss at step ', 2000, ': ', 4.5010330862998966)\n",
      "('Epoch: ', 414, ' Average loss at step ', 2813, ': ', 4.4100775454431922)\n",
      "Training time took 97.897817 seconds to run 1 epoch\n",
      "('Epoch: ', 415, ' Average loss at step ', 1000, ': ', 0.032973839521408081)\n",
      "('Epoch: ', 415, ' Average loss at step ', 2000, ': ', 0.030716438353061676)\n",
      "('Epoch: ', 415, ' Average loss at step ', 2813, ': ', 0.029977058028352672)\n",
      "Training time took 44.003226 seconds to run 1 epoch\n",
      "('Epoch: ', 416, ' Average loss at step ', 1000, ': ', 128.0614681777954)\n",
      "('Epoch: ', 416, ' Average loss at step ', 2000, ': ', 128.41709310150148)\n",
      "('Epoch: ', 416, ' Average loss at step ', 3000, ': ', 130.11133959960938)\n",
      "('Epoch: ', 416, ' Average loss at step ', 4000, ': ', 127.61674333953857)\n",
      "('Epoch: ', 416, ' Average loss at step ', 4373, ': ', 127.00172889873545)\n",
      "('Epoch: ', 416, ' Average loss at step ', 761, ': ', 7898.0356567382814)\n",
      "('Epoch: ', 416, ' Average loss at step ', 782, ': ', 9035.428649042693)\n",
      "('Epoch: ', 416, ' Average loss at step ', 787, ': ', 15.675555803090258)\n",
      "('Epoch: ', 416, ' Average loss at step ', 1000, ': ', 4.5393168296813968)\n",
      "('Epoch: ', 416, ' Average loss at step ', 2000, ': ', 4.4008727030754091)\n",
      "('Epoch: ', 416, ' Average loss at step ', 2813, ': ', 4.4469586411133184)\n",
      "Training time took 97.783067 seconds to run 1 epoch\n",
      "('Epoch: ', 417, ' Average loss at step ', 1000, ': ', 0.033053071022033691)\n",
      "('Epoch: ', 417, ' Average loss at step ', 2000, ': ', 0.030866652309894563)\n",
      "('Epoch: ', 417, ' Average loss at step ', 2813, ': ', 0.029691755991851167)\n",
      "Training time took 44.018763 seconds to run 1 epoch\n",
      "('Epoch: ', 418, ' Average loss at step ', 1000, ': ', 128.38215700531006)\n",
      "('Epoch: ', 418, ' Average loss at step ', 2000, ': ', 127.14302154541015)\n",
      "('Epoch: ', 418, ' Average loss at step ', 3000, ': ', 128.02569915771485)\n",
      "('Epoch: ', 418, ' Average loss at step ', 4000, ': ', 127.08061008453369)\n",
      "('Epoch: ', 418, ' Average loss at step ', 4373, ': ', 129.08032669559603)\n",
      "('Epoch: ', 418, ' Average loss at step ', 761, ': ', 7980.34375)\n",
      "('Epoch: ', 418, ' Average loss at step ', 782, ': ', 9161.9316706346035)\n",
      "('Epoch: ', 418, ' Average loss at step ', 787, ': ', 15.384333716094039)\n",
      "('Epoch: ', 418, ' Average loss at step ', 1000, ': ', 4.5205898580551152)\n",
      "('Epoch: ', 418, ' Average loss at step ', 2000, ': ', 4.3515865416526793)\n",
      "('Epoch: ', 418, ' Average loss at step ', 2813, ': ', 4.5169739535289448)\n",
      "Training time took 97.788987 seconds to run 1 epoch\n",
      "('Epoch: ', 419, ' Average loss at step ', 1000, ': ', 0.032741469919681548)\n",
      "('Epoch: ', 419, ' Average loss at step ', 2000, ': ', 0.030473065197467803)\n",
      "('Epoch: ', 419, ' Average loss at step ', 2813, ': ', 0.029513598956498018)\n",
      "Training time took 44.046862 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.984256170781\n",
      "Hits @ 1:  0.935156771181\n",
      "Testing time took 73.318843 seconds.\n",
      "\n",
      "('Epoch: ', 420, ' Average loss at step ', 1000, ': ', 126.57274588012696)\n",
      "('Epoch: ', 420, ' Average loss at step ', 2000, ': ', 128.66999999999999)\n",
      "('Epoch: ', 420, ' Average loss at step ', 3000, ': ', 127.52059132385254)\n",
      "('Epoch: ', 420, ' Average loss at step ', 4000, ': ', 128.11857733917236)\n",
      "('Epoch: ', 420, ' Average loss at step ', 4373, ': ', 127.71823909718503)\n",
      "('Epoch: ', 420, ' Average loss at step ', 761, ': ', 8001.7433009097449)\n",
      "('Epoch: ', 420, ' Average loss at step ', 782, ': ', 9142.2466951924616)\n",
      "('Epoch: ', 420, ' Average loss at step ', 787, ': ', 15.268069937028958)\n",
      "('Epoch: ', 420, ' Average loss at step ', 1000, ': ', 4.4788280735015871)\n",
      "('Epoch: ', 420, ' Average loss at step ', 2000, ': ', 4.4529131627082821)\n",
      "('Epoch: ', 420, ' Average loss at step ', 2813, ': ', 4.3263750041059676)\n",
      "Training time took 97.900379 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 421, ' Average loss at step ', 1000, ': ', 0.032736805319786073)\n",
      "('Epoch: ', 421, ' Average loss at step ', 2000, ': ', 0.030477289736270903)\n",
      "('Epoch: ', 421, ' Average loss at step ', 2813, ': ', 0.02934887293230724)\n",
      "Training time took 44.047065 seconds to run 1 epoch\n",
      "('Epoch: ', 422, ' Average loss at step ', 1000, ': ', 127.28616355133056)\n",
      "('Epoch: ', 422, ' Average loss at step ', 2000, ': ', 128.53811923217773)\n",
      "('Epoch: ', 422, ' Average loss at step ', 3000, ': ', 127.23374472808838)\n",
      "('Epoch: ', 422, ' Average loss at step ', 4000, ': ', 130.48639750671387)\n",
      "('Epoch: ', 422, ' Average loss at step ', 4373, ': ', 127.20530909876669)\n",
      "('Epoch: ', 422, ' Average loss at step ', 761, ': ', 7988.3369281969572)\n",
      "('Epoch: ', 422, ' Average loss at step ', 782, ': ', 9178.6574603873232)\n",
      "('Epoch: ', 422, ' Average loss at step ', 787, ': ', 15.04505270795361)\n",
      "('Epoch: ', 422, ' Average loss at step ', 1000, ': ', 4.2792660589218139)\n",
      "('Epoch: ', 422, ' Average loss at step ', 2000, ': ', 4.5064737663269039)\n",
      "('Epoch: ', 422, ' Average loss at step ', 2813, ': ', 4.4695739910520356)\n",
      "Training time took 97.788711 seconds to run 1 epoch\n",
      "('Epoch: ', 423, ' Average loss at step ', 1000, ': ', 0.032747068464756009)\n",
      "('Epoch: ', 423, ' Average loss at step ', 2000, ': ', 0.03002233010530472)\n",
      "('Epoch: ', 423, ' Average loss at step ', 2813, ': ', 0.02939570544682113)\n",
      "Training time took 44.028686 seconds to run 1 epoch\n",
      "('Epoch: ', 424, ' Average loss at step ', 1000, ': ', 126.25011184692383)\n",
      "('Epoch: ', 424, ' Average loss at step ', 2000, ': ', 128.84074283599853)\n",
      "('Epoch: ', 424, ' Average loss at step ', 3000, ': ', 127.58987338256836)\n",
      "('Epoch: ', 424, ' Average loss at step ', 4000, ': ', 127.29902468872071)\n",
      "('Epoch: ', 424, ' Average loss at step ', 4373, ': ', 129.62632548424506)\n",
      "('Epoch: ', 424, ' Average loss at step ', 761, ': ', 8103.70603541324)\n",
      "('Epoch: ', 424, ' Average loss at step ', 782, ': ', 9219.1438278999285)\n",
      "('Epoch: ', 424, ' Average loss at step ', 787, ': ', 14.959484892643742)\n",
      "('Epoch: ', 424, ' Average loss at step ', 1000, ': ', 4.4083450584411619)\n",
      "('Epoch: ', 424, ' Average loss at step ', 2000, ': ', 4.4355347290039067)\n",
      "('Epoch: ', 424, ' Average loss at step ', 2813, ': ', 4.4699434605725292)\n",
      "Training time took 97.748039 seconds to run 1 epoch\n",
      "('Epoch: ', 425, ' Average loss at step ', 1000, ': ', 0.032256613373756411)\n",
      "('Epoch: ', 425, ' Average loss at step ', 2000, ': ', 0.030030142664909363)\n",
      "('Epoch: ', 425, ' Average loss at step ', 2813, ': ', 0.029242372644945905)\n",
      "Training time took 44.020467 seconds to run 1 epoch\n",
      "('Epoch: ', 426, ' Average loss at step ', 1000, ': ', 127.64218579864502)\n",
      "('Epoch: ', 426, ' Average loss at step ', 2000, ': ', 127.89996710968018)\n",
      "('Epoch: ', 426, ' Average loss at step ', 3000, ': ', 127.60029843139648)\n",
      "('Epoch: ', 426, ' Average loss at step ', 4000, ': ', 127.15526446533202)\n",
      "('Epoch: ', 426, ' Average loss at step ', 4373, ': ', 129.37517375330771)\n",
      "('Epoch: ', 426, ' Average loss at step ', 761, ': ', 7994.7869734914675)\n",
      "('Epoch: ', 426, ' Average loss at step ', 782, ': ', 9218.0858993627953)\n",
      "('Epoch: ', 426, ' Average loss at step ', 787, ': ', 15.306738870441155)\n",
      "('Epoch: ', 426, ' Average loss at step ', 1000, ': ', 4.500078138828278)\n",
      "('Epoch: ', 426, ' Average loss at step ', 2000, ': ', 4.3964558458328247)\n",
      "('Epoch: ', 426, ' Average loss at step ', 2813, ': ', 4.4772038941312893)\n",
      "Training time took 97.723857 seconds to run 1 epoch\n",
      "('Epoch: ', 427, ' Average loss at step ', 1000, ': ', 0.03235674333572388)\n",
      "('Epoch: ', 427, ' Average loss at step ', 2000, ': ', 0.029898455858230592)\n",
      "('Epoch: ', 427, ' Average loss at step ', 2813, ': ', 0.02904919626677565)\n",
      "Training time took 44.028187 seconds to run 1 epoch\n",
      "('Epoch: ', 428, ' Average loss at step ', 1000, ': ', 127.44957772827148)\n",
      "('Epoch: ', 428, ' Average loss at step ', 2000, ': ', 127.31856470489502)\n",
      "('Epoch: ', 428, ' Average loss at step ', 3000, ': ', 128.41763864135743)\n",
      "('Epoch: ', 428, ' Average loss at step ', 4000, ': ', 128.90181433105468)\n",
      "('Epoch: ', 428, ' Average loss at step ', 4373, ': ', 128.79299532982611)\n",
      "('Epoch: ', 428, ' Average loss at step ', 761, ': ', 8037.0190448961757)\n",
      "('Epoch: ', 428, ' Average loss at step ', 782, ': ', 9245.8629098811616)\n",
      "('Epoch: ', 428, ' Average loss at step ', 787, ': ', 15.135955944012746)\n",
      "('Epoch: ', 428, ' Average loss at step ', 1000, ': ', 4.5658071022033688)\n",
      "('Epoch: ', 428, ' Average loss at step ', 2000, ': ', 4.3051831474304203)\n",
      "('Epoch: ', 428, ' Average loss at step ', 2813, ': ', 4.5008995350945762)\n",
      "Training time took 97.673925 seconds to run 1 epoch\n",
      "('Epoch: ', 429, ' Average loss at step ', 1000, ': ', 0.032186703562736514)\n",
      "('Epoch: ', 429, ' Average loss at step ', 2000, ': ', 0.029692734122276306)\n",
      "('Epoch: ', 429, ' Average loss at step ', 2813, ': ', 0.029263140532770768)\n",
      "Training time took 44.019882 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.984056037358\n",
      "Hits @ 1:  0.935690460307\n",
      "Testing time took 73.348934 seconds.\n",
      "\n",
      "('Epoch: ', 430, ' Average loss at step ', 1000, ': ', 129.34437232971192)\n",
      "('Epoch: ', 430, ' Average loss at step ', 2000, ': ', 129.33257656860351)\n",
      "('Epoch: ', 430, ' Average loss at step ', 3000, ': ', 128.69136262512208)\n",
      "('Epoch: ', 430, ' Average loss at step ', 4000, ': ', 126.98091402435303)\n",
      "('Epoch: ', 430, ' Average loss at step ', 4373, ': ', 128.80986490557271)\n",
      "('Epoch: ', 430, ' Average loss at step ', 761, ': ', 8024.0304578279192)\n",
      "('Epoch: ', 430, ' Average loss at step ', 782, ': ', 9195.0857393115803)\n",
      "('Epoch: ', 430, ' Average loss at step ', 787, ': ', 15.387339624739786)\n",
      "('Epoch: ', 430, ' Average loss at step ', 1000, ': ', 4.5135674242973325)\n",
      "('Epoch: ', 430, ' Average loss at step ', 2000, ': ', 4.4317676773071293)\n",
      "('Epoch: ', 430, ' Average loss at step ', 2813, ': ', 4.2471888634958876)\n",
      "Training time took 97.782162 seconds to run 1 epoch\n",
      "('Epoch: ', 431, ' Average loss at step ', 1000, ': ', 0.031920283317565919)\n",
      "('Epoch: ', 431, ' Average loss at step ', 2000, ': ', 0.029578588664531707)\n",
      "('Epoch: ', 431, ' Average loss at step ', 2813, ': ', 0.028968738144254449)\n",
      "Training time took 44.026811 seconds to run 1 epoch\n",
      "('Epoch: ', 432, ' Average loss at step ', 1000, ': ', 128.73770790100099)\n",
      "('Epoch: ', 432, ' Average loss at step ', 2000, ': ', 127.26467023468018)\n",
      "('Epoch: ', 432, ' Average loss at step ', 3000, ': ', 128.09882849884033)\n",
      "('Epoch: ', 432, ' Average loss at step ', 4000, ': ', 128.24973504638672)\n",
      "('Epoch: ', 432, ' Average loss at step ', 4373, ': ', 127.42906039248231)\n",
      "('Epoch: ', 432, ' Average loss at step ', 761, ': ', 8151.9025364925983)\n",
      "('Epoch: ', 432, ' Average loss at step ', 782, ': ', 9263.1934631582099)\n",
      "('Epoch: ', 432, ' Average loss at step ', 787, ': ', 15.173570882879748)\n",
      "('Epoch: ', 432, ' Average loss at step ', 1000, ': ', 4.4111695299148561)\n",
      "('Epoch: ', 432, ' Average loss at step ', 2000, ': ', 4.3290069103240967)\n",
      "('Epoch: ', 432, ' Average loss at step ', 2813, ': ', 4.460483344317657)\n",
      "Training time took 97.794395 seconds to run 1 epoch\n",
      "('Epoch: ', 433, ' Average loss at step ', 1000, ': ', 0.031662678241729733)\n",
      "('Epoch: ', 433, ' Average loss at step ', 2000, ': ', 0.029517418682575226)\n",
      "('Epoch: ', 433, ' Average loss at step ', 2813, ': ', 0.028791423354830061)\n",
      "Training time took 44.05552 seconds to run 1 epoch\n",
      "('Epoch: ', 434, ' Average loss at step ', 1000, ': ', 127.99161836242676)\n",
      "('Epoch: ', 434, ' Average loss at step ', 2000, ': ', 126.94581491851807)\n",
      "('Epoch: ', 434, ' Average loss at step ', 3000, ': ', 127.99531552124023)\n",
      "('Epoch: ', 434, ' Average loss at step ', 4000, ': ', 128.21491706848144)\n",
      "('Epoch: ', 434, ' Average loss at step ', 4373, ': ', 127.01616619479272)\n",
      "('Epoch: ', 434, ' Average loss at step ', 761, ': ', 8041.7055837530843)\n",
      "('Epoch: ', 434, ' Average loss at step ', 782, ': ', 9210.8399500340111)\n",
      "('Epoch: ', 434, ' Average loss at step ', 787, ': ', 15.134891875220923)\n",
      "('Epoch: ', 434, ' Average loss at step ', 1000, ': ', 4.3861754078865047)\n",
      "('Epoch: ', 434, ' Average loss at step ', 2000, ': ', 4.3856609549522396)\n",
      "('Epoch: ', 434, ' Average loss at step ', 2813, ': ', 4.2896488687674985)\n",
      "Training time took 97.881478 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 435, ' Average loss at step ', 1000, ': ', 0.032022484421730044)\n",
      "('Epoch: ', 435, ' Average loss at step ', 2000, ': ', 0.029146746754646301)\n",
      "('Epoch: ', 435, ' Average loss at step ', 2813, ': ', 0.028395841274355432)\n",
      "Training time took 44.067986 seconds to run 1 epoch\n",
      "('Epoch: ', 436, ' Average loss at step ', 1000, ': ', 127.91527584838867)\n",
      "('Epoch: ', 436, ' Average loss at step ', 2000, ': ', 129.47604039764406)\n",
      "('Epoch: ', 436, ' Average loss at step ', 3000, ': ', 129.14013189697266)\n",
      "('Epoch: ', 436, ' Average loss at step ', 4000, ': ', 126.7435456237793)\n",
      "('Epoch: ', 436, ' Average loss at step ', 4373, ': ', 125.46069772781864)\n",
      "('Epoch: ', 436, ' Average loss at step ', 761, ': ', 8078.2717754163241)\n",
      "('Epoch: ', 436, ' Average loss at step ', 782, ': ', 9247.8543752750884)\n",
      "('Epoch: ', 436, ' Average loss at step ', 787, ': ', 14.837385167905696)\n",
      "('Epoch: ', 436, ' Average loss at step ', 1000, ': ', 4.3923429055213932)\n",
      "('Epoch: ', 436, ' Average loss at step ', 2000, ': ', 4.299647298336029)\n",
      "('Epoch: ', 436, ' Average loss at step ', 2813, ': ', 4.4634663447957905)\n",
      "Training time took 97.787705 seconds to run 1 epoch\n",
      "('Epoch: ', 437, ' Average loss at step ', 1000, ': ', 0.031513959705829618)\n",
      "('Epoch: ', 437, ' Average loss at step ', 2000, ': ', 0.029100362598896028)\n",
      "('Epoch: ', 437, ' Average loss at step ', 2813, ': ', 0.028544953303971315)\n",
      "Training time took 44.033782 seconds to run 1 epoch\n",
      "('Epoch: ', 438, ' Average loss at step ', 1000, ': ', 128.2855767211914)\n",
      "('Epoch: ', 438, ' Average loss at step ', 2000, ': ', 128.46353045654297)\n",
      "('Epoch: ', 438, ' Average loss at step ', 3000, ': ', 127.55396380615234)\n",
      "('Epoch: ', 438, ' Average loss at step ', 4000, ': ', 129.21244612884522)\n",
      "('Epoch: ', 438, ' Average loss at step ', 4373, ': ', 128.74111280133647)\n",
      "('Epoch: ', 438, ' Average loss at step ', 761, ': ', 8106.1277632863894)\n",
      "('Epoch: ', 438, ' Average loss at step ', 782, ': ', 9312.89306077945)\n",
      "('Epoch: ', 438, ' Average loss at step ', 787, ': ', 14.751822829549852)\n",
      "('Epoch: ', 438, ' Average loss at step ', 1000, ': ', 4.3586568021774292)\n",
      "('Epoch: ', 438, ' Average loss at step ', 2000, ': ', 4.2718856253623958)\n",
      "('Epoch: ', 438, ' Average loss at step ', 2813, ': ', 4.3690352457497506)\n",
      "Training time took 97.764537 seconds to run 1 epoch\n",
      "('Epoch: ', 439, ' Average loss at step ', 1000, ': ', 0.031468198478221895)\n",
      "('Epoch: ', 439, ' Average loss at step ', 2000, ': ', 0.029290880680084227)\n",
      "('Epoch: ', 439, ' Average loss at step ', 2813, ': ', 0.028335892508182619)\n",
      "Training time took 44.024947 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.984723148766\n",
      "Hits @ 1:  0.935223482322\n",
      "Testing time took 73.285816 seconds.\n",
      "\n",
      "('Epoch: ', 440, ' Average loss at step ', 1000, ': ', 129.94111756896973)\n",
      "('Epoch: ', 440, ' Average loss at step ', 2000, ': ', 126.86624590301514)\n",
      "('Epoch: ', 440, ' Average loss at step ', 3000, ': ', 127.81400401306152)\n",
      "('Epoch: ', 440, ' Average loss at step ', 4000, ': ', 127.42151303863525)\n",
      "('Epoch: ', 440, ' Average loss at step ', 4373, ': ', 128.69031918433404)\n",
      "('Epoch: ', 440, ' Average loss at step ', 761, ': ', 8132.878319027549)\n",
      "('Epoch: ', 440, ' Average loss at step ', 782, ': ', 9327.3504215098837)\n",
      "('Epoch: ', 440, ' Average loss at step ', 787, ': ', 14.883912605790389)\n",
      "('Epoch: ', 440, ' Average loss at step ', 1000, ': ', 4.3985940790176388)\n",
      "('Epoch: ', 440, ' Average loss at step ', 2000, ': ', 4.4099413471221922)\n",
      "('Epoch: ', 440, ' Average loss at step ', 2813, ': ', 4.4457477671759467)\n",
      "Training time took 97.790435 seconds to run 1 epoch\n",
      "('Epoch: ', 441, ' Average loss at step ', 1000, ': ', 0.031393287241458893)\n",
      "('Epoch: ', 441, ' Average loss at step ', 2000, ': ', 0.028980282902717591)\n",
      "('Epoch: ', 441, ' Average loss at step ', 2813, ': ', 0.028153361064459891)\n",
      "Training time took 44.040371 seconds to run 1 epoch\n",
      "('Epoch: ', 442, ' Average loss at step ', 1000, ': ', 129.42697200775146)\n",
      "('Epoch: ', 442, ' Average loss at step ', 2000, ': ', 127.9722746963501)\n",
      "('Epoch: ', 442, ' Average loss at step ', 3000, ': ', 128.05223404693604)\n",
      "('Epoch: ', 442, ' Average loss at step ', 4000, ': ', 128.29310643768309)\n",
      "('Epoch: ', 442, ' Average loss at step ', 4373, ': ', 128.87233459308584)\n",
      "('Epoch: ', 442, ' Average loss at step ', 761, ': ', 8192.0464429353415)\n",
      "('Epoch: ', 442, ' Average loss at step ', 782, ': ', 9393.3383901598518)\n",
      "('Epoch: ', 442, ' Average loss at step ', 787, ': ', 14.985675866367252)\n",
      "('Epoch: ', 442, ' Average loss at step ', 1000, ': ', 4.3861861500740051)\n",
      "('Epoch: ', 442, ' Average loss at step ', 2000, ': ', 4.4048160572052)\n",
      "('Epoch: ', 442, ' Average loss at step ', 2813, ': ', 4.3164141154641591)\n",
      "Training time took 97.994536 seconds to run 1 epoch\n",
      "('Epoch: ', 443, ' Average loss at step ', 1000, ': ', 0.031173146188259126)\n",
      "('Epoch: ', 443, ' Average loss at step ', 2000, ': ', 0.029060136795043944)\n",
      "('Epoch: ', 443, ' Average loss at step ', 2813, ': ', 0.028043089902459694)\n",
      "Training time took 44.045425 seconds to run 1 epoch\n",
      "('Epoch: ', 444, ' Average loss at step ', 1000, ': ', 127.26204277038575)\n",
      "('Epoch: ', 444, ' Average loss at step ', 2000, ': ', 129.31461901855468)\n",
      "('Epoch: ', 444, ' Average loss at step ', 3000, ': ', 126.78150230407715)\n",
      "('Epoch: ', 444, ' Average loss at step ', 4000, ': ', 128.67471656036378)\n",
      "('Epoch: ', 444, ' Average loss at step ', 4373, ': ', 130.51269141576623)\n",
      "('Epoch: ', 444, ' Average loss at step ', 761, ': ', 8099.9210089432563)\n",
      "('Epoch: ', 444, ' Average loss at step ', 782, ': ', 9356.6571327824895)\n",
      "('Epoch: ', 444, ' Average loss at step ', 787, ': ', 14.791691747330526)\n",
      "('Epoch: ', 444, ' Average loss at step ', 1000, ': ', 4.2965293455123899)\n",
      "('Epoch: ', 444, ' Average loss at step ', 2000, ': ', 4.316836643218994)\n",
      "('Epoch: ', 444, ' Average loss at step ', 2813, ': ', 4.3934076531180022)\n",
      "Training time took 97.870245 seconds to run 1 epoch\n",
      "('Epoch: ', 445, ' Average loss at step ', 1000, ': ', 0.031207013905048372)\n",
      "('Epoch: ', 445, ' Average loss at step ', 2000, ': ', 0.028624800443649293)\n",
      "('Epoch: ', 445, ' Average loss at step ', 2813, ': ', 0.028001785278320312)\n",
      "Training time took 44.035484 seconds to run 1 epoch\n",
      "('Epoch: ', 446, ' Average loss at step ', 1000, ': ', 127.69345288848876)\n",
      "('Epoch: ', 446, ' Average loss at step ', 2000, ': ', 128.96175732421875)\n",
      "('Epoch: ', 446, ' Average loss at step ', 3000, ': ', 127.48864540100098)\n",
      "('Epoch: ', 446, ' Average loss at step ', 4000, ': ', 127.62795204925537)\n",
      "('Epoch: ', 446, ' Average loss at step ', 4373, ': ', 129.7821765202348)\n",
      "('Epoch: ', 446, ' Average loss at step ', 761, ': ', 8136.9207480982732)\n",
      "('Epoch: ', 446, ' Average loss at step ', 782, ': ', 9350.3128094740314)\n",
      "('Epoch: ', 446, ' Average loss at step ', 787, ': ', 14.968728026664287)\n",
      "('Epoch: ', 446, ' Average loss at step ', 1000, ': ', 4.3619043416976933)\n",
      "('Epoch: ', 446, ' Average loss at step ', 2000, ': ', 4.4831518874168399)\n",
      "('Epoch: ', 446, ' Average loss at step ', 2813, ': ', 4.3461241774958346)\n",
      "Training time took 97.713094 seconds to run 1 epoch\n",
      "('Epoch: ', 447, ' Average loss at step ', 1000, ': ', 0.031068378806114197)\n",
      "('Epoch: ', 447, ' Average loss at step ', 2000, ': ', 0.028422633409500121)\n",
      "('Epoch: ', 447, ' Average loss at step ', 2813, ': ', 0.027871416780748979)\n",
      "Training time took 44.018639 seconds to run 1 epoch\n",
      "('Epoch: ', 448, ' Average loss at step ', 1000, ': ', 126.59556965637206)\n",
      "('Epoch: ', 448, ' Average loss at step ', 2000, ': ', 127.72875360107422)\n",
      "('Epoch: ', 448, ' Average loss at step ', 3000, ': ', 129.40303268432618)\n",
      "('Epoch: ', 448, ' Average loss at step ', 4000, ': ', 128.44488895416259)\n",
      "('Epoch: ', 448, ' Average loss at step ', 4373, ': ', 129.73164919371246)\n",
      "('Epoch: ', 448, ' Average loss at step ', 761, ': ', 8161.1711978310032)\n",
      "('Epoch: ', 448, ' Average loss at step ', 782, ': ', 9404.3716758112605)\n",
      "('Epoch: ', 448, ' Average loss at step ', 787, ': ', 14.715041645913937)\n",
      "('Epoch: ', 448, ' Average loss at step ', 1000, ': ', 4.4584579138755798)\n",
      "('Epoch: ', 448, ' Average loss at step ', 2000, ': ', 4.3086619777679447)\n",
      "('Epoch: ', 448, ' Average loss at step ', 2813, ': ', 4.502669763682511)\n",
      "Training time took 97.821833 seconds to run 1 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 449, ' Average loss at step ', 1000, ': ', 0.030933822572231293)\n",
      "('Epoch: ', 449, ' Average loss at step ', 2000, ': ', 0.028418780267238618)\n",
      "('Epoch: ', 449, ' Average loss at step ', 2813, ': ', 0.027745434436304815)\n",
      "Training time took 44.019442 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.984122748499\n",
      "Hits @ 1:  0.936357571714\n",
      "Testing time took 73.32238 seconds.\n",
      "\n",
      "('Epoch: ', 450, ' Average loss at step ', 1000, ': ', 128.55168016052247)\n",
      "('Epoch: ', 450, ' Average loss at step ', 2000, ': ', 128.47743089294434)\n",
      "('Epoch: ', 450, ' Average loss at step ', 3000, ': ', 128.78423646545411)\n",
      "('Epoch: ', 450, ' Average loss at step ', 4000, ': ', 127.91275736999512)\n",
      "('Epoch: ', 450, ' Average loss at step ', 4373, ': ', 128.39544759770877)\n",
      "('Epoch: ', 450, ' Average loss at step ', 761, ': ', 8218.8879150390621)\n",
      "('Epoch: ', 450, ' Average loss at step ', 782, ': ', 9344.4377819652291)\n",
      "('Epoch: ', 450, ' Average loss at step ', 787, ': ', 14.858896516358277)\n",
      "('Epoch: ', 450, ' Average loss at step ', 1000, ': ', 4.4339100365638737)\n",
      "('Epoch: ', 450, ' Average loss at step ', 2000, ': ', 4.3046481609344482)\n",
      "('Epoch: ', 450, ' Average loss at step ', 2813, ': ', 4.3231587850401558)\n",
      "Training time took 97.67768 seconds to run 1 epoch\n",
      "('Epoch: ', 451, ' Average loss at step ', 1000, ': ', 0.030435466766357423)\n",
      "('Epoch: ', 451, ' Average loss at step ', 2000, ': ', 0.028125107705593108)\n",
      "('Epoch: ', 451, ' Average loss at step ', 2813, ': ', 0.027792159192667806)\n",
      "Training time took 44.026246 seconds to run 1 epoch\n",
      "('Epoch: ', 452, ' Average loss at step ', 1000, ': ', 125.17865207672119)\n",
      "('Epoch: ', 452, ' Average loss at step ', 2000, ': ', 127.50798052978516)\n",
      "('Epoch: ', 452, ' Average loss at step ', 3000, ': ', 128.00258416748048)\n",
      "('Epoch: ', 452, ' Average loss at step ', 4000, ': ', 129.18499964904785)\n",
      "('Epoch: ', 452, ' Average loss at step ', 4373, ': ', 128.41116088949224)\n",
      "('Epoch: ', 452, ' Average loss at step ', 761, ': ', 8142.6837068256582)\n",
      "('Epoch: ', 452, ' Average loss at step ', 782, ': ', 9409.5732553167018)\n",
      "('Epoch: ', 452, ' Average loss at step ', 787, ': ', 14.79031704400332)\n",
      "('Epoch: ', 452, ' Average loss at step ', 1000, ': ', 4.3597267632484433)\n",
      "('Epoch: ', 452, ' Average loss at step ', 2000, ': ', 4.3788447227478029)\n",
      "('Epoch: ', 452, ' Average loss at step ', 2813, ': ', 4.3146570034215017)\n",
      "Training time took 97.829507 seconds to run 1 epoch\n",
      "('Epoch: ', 453, ' Average loss at step ', 1000, ': ', 0.030539639472961427)\n",
      "('Epoch: ', 453, ' Average loss at step ', 2000, ': ', 0.028170521199703216)\n",
      "('Epoch: ', 453, ' Average loss at step ', 2813, ': ', 0.027710027956023005)\n",
      "Training time took 43.99302 seconds to run 1 epoch\n",
      "('Epoch: ', 454, ' Average loss at step ', 1000, ': ', 128.06086590576172)\n",
      "('Epoch: ', 454, ' Average loss at step ', 2000, ': ', 128.35455294799806)\n",
      "('Epoch: ', 454, ' Average loss at step ', 3000, ': ', 128.94288467407227)\n",
      "('Epoch: ', 454, ' Average loss at step ', 4000, ': ', 127.10740425109863)\n",
      "('Epoch: ', 454, ' Average loss at step ', 4373, ': ', 133.12199563877556)\n",
      "('Epoch: ', 454, ' Average loss at step ', 761, ': ', 8188.0697317023023)\n",
      "('Epoch: ', 454, ' Average loss at step ', 782, ': ', 9510.9228934509047)\n",
      "('Epoch: ', 454, ' Average loss at step ', 787, ': ', 14.758503580214716)\n",
      "('Epoch: ', 454, ' Average loss at step ', 1000, ': ', 4.4014027042388912)\n",
      "('Epoch: ', 454, ' Average loss at step ', 2000, ': ', 4.2174482178688049)\n",
      "('Epoch: ', 454, ' Average loss at step ', 2813, ': ', 4.3597028214355991)\n",
      "Training time took 97.875647 seconds to run 1 epoch\n",
      "('Epoch: ', 455, ' Average loss at step ', 1000, ': ', 0.030340609908103944)\n",
      "('Epoch: ', 455, ' Average loss at step ', 2000, ': ', 0.02824610358476639)\n",
      "('Epoch: ', 455, ' Average loss at step ', 2813, ': ', 0.027324402787415266)\n",
      "Training time took 44.053449 seconds to run 1 epoch\n",
      "('Epoch: ', 456, ' Average loss at step ', 1000, ': ', 127.12003740692138)\n",
      "('Epoch: ', 456, ' Average loss at step ', 2000, ': ', 129.46167221069337)\n",
      "('Epoch: ', 456, ' Average loss at step ', 3000, ': ', 129.5572237701416)\n",
      "('Epoch: ', 456, ' Average loss at step ', 4000, ': ', 127.26656389617919)\n",
      "('Epoch: ', 456, ' Average loss at step ', 4373, ': ', 131.57023050451792)\n",
      "('Epoch: ', 456, ' Average loss at step ', 761, ': ', 8299.2940622430106)\n",
      "('Epoch: ', 456, ' Average loss at step ', 782, ': ', 9488.8032701714546)\n",
      "('Epoch: ', 456, ' Average loss at step ', 787, ': ', 14.433327816824876)\n",
      "('Epoch: ', 456, ' Average loss at step ', 1000, ': ', 4.2810609354972842)\n",
      "('Epoch: ', 456, ' Average loss at step ', 2000, ': ', 4.2511729059219361)\n",
      "('Epoch: ', 456, ' Average loss at step ', 2813, ': ', 4.2389232483990673)\n",
      "Training time took 97.814368 seconds to run 1 epoch\n",
      "('Epoch: ', 457, ' Average loss at step ', 1000, ': ', 0.030101567745208741)\n",
      "('Epoch: ', 457, ' Average loss at step ', 2000, ': ', 0.027815961837768556)\n",
      "('Epoch: ', 457, ' Average loss at step ', 2813, ': ', 0.027498426989381538)\n",
      "Training time took 44.031002 seconds to run 1 epoch\n",
      "('Epoch: ', 458, ' Average loss at step ', 1000, ': ', 126.77359614562988)\n",
      "('Epoch: ', 458, ' Average loss at step ', 2000, ': ', 128.78731597900389)\n",
      "('Epoch: ', 458, ' Average loss at step ', 3000, ': ', 130.1862798614502)\n",
      "('Epoch: ', 458, ' Average loss at step ', 4000, ': ', 126.91102429199219)\n",
      "('Epoch: ', 458, ' Average loss at step ', 4373, ': ', 131.37206731816775)\n",
      "('Epoch: ', 458, ' Average loss at step ', 761, ': ', 8278.1510093287416)\n",
      "('Epoch: ', 458, ' Average loss at step ', 782, ': ', 9463.1297102572826)\n",
      "('Epoch: ', 458, ' Average loss at step ', 787, ': ', 14.270795018921675)\n",
      "('Epoch: ', 458, ' Average loss at step ', 1000, ': ', 4.3693084917068479)\n",
      "('Epoch: ', 458, ' Average loss at step ', 2000, ': ', 4.2585574917793272)\n",
      "('Epoch: ', 458, ' Average loss at step ', 2813, ': ', 4.4389125349486402)\n",
      "Training time took 97.854906 seconds to run 1 epoch\n",
      "('Epoch: ', 459, ' Average loss at step ', 1000, ': ', 0.030249804556369782)\n",
      "('Epoch: ', 459, ' Average loss at step ', 2000, ': ', 0.027968667626380922)\n",
      "('Epoch: ', 459, ' Average loss at step ', 2813, ': ', 0.027438475580638267)\n",
      "Training time took 44.026092 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.983789192795\n",
      "Hits @ 1:  0.93509006004\n",
      "Testing time took 73.331659 seconds.\n",
      "\n",
      "('Epoch: ', 460, ' Average loss at step ', 1000, ': ', 127.84214845275879)\n",
      "('Epoch: ', 460, ' Average loss at step ', 2000, ': ', 129.52818362426757)\n",
      "('Epoch: ', 460, ' Average loss at step ', 3000, ': ', 128.92598268890382)\n",
      "('Epoch: ', 460, ' Average loss at step ', 4000, ': ', 128.82646444702149)\n",
      "('Epoch: ', 460, ' Average loss at step ', 4373, ': ', 131.15696720410418)\n",
      "('Epoch: ', 460, ' Average loss at step ', 761, ': ', 8236.2483905993013)\n",
      "('Epoch: ', 460, ' Average loss at step ', 782, ': ', 9569.629039417614)\n",
      "('Epoch: ', 460, ' Average loss at step ', 787, ': ', 14.290475426739409)\n",
      "('Epoch: ', 460, ' Average loss at step ', 1000, ': ', 4.3688270931243895)\n",
      "('Epoch: ', 460, ' Average loss at step ', 2000, ': ', 4.4005284337997432)\n",
      "('Epoch: ', 460, ' Average loss at step ', 2813, ': ', 4.2941901777765432)\n",
      "Training time took 97.799656 seconds to run 1 epoch\n",
      "('Epoch: ', 461, ' Average loss at step ', 1000, ': ', 0.030023697972297668)\n",
      "('Epoch: ', 461, ' Average loss at step ', 2000, ': ', 0.02758721286058426)\n",
      "('Epoch: ', 461, ' Average loss at step ', 2813, ': ', 0.027091736350153467)\n",
      "Training time took 44.043129 seconds to run 1 epoch\n",
      "('Epoch: ', 462, ' Average loss at step ', 1000, ': ', 127.92359416961671)\n",
      "('Epoch: ', 462, ' Average loss at step ', 2000, ': ', 129.10186314392089)\n",
      "('Epoch: ', 462, ' Average loss at step ', 3000, ': ', 127.44813537597656)\n",
      "('Epoch: ', 462, ' Average loss at step ', 4000, ': ', 127.26042922973633)\n",
      "('Epoch: ', 462, ' Average loss at step ', 4373, ': ', 128.80022295059698)\n",
      "('Epoch: ', 462, ' Average loss at step ', 761, ': ', 8230.6913606342514)\n",
      "('Epoch: ', 462, ' Average loss at step ', 782, ': ', 9519.3432861015517)\n",
      "('Epoch: ', 462, ' Average loss at step ', 787, ': ', 14.37837181018509)\n",
      "('Epoch: ', 462, ' Average loss at step ', 1000, ': ', 4.3450008368492128)\n",
      "('Epoch: ', 462, ' Average loss at step ', 2000, ': ', 4.4282811307907108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 462, ' Average loss at step ', 2813, ': ', 4.3012790092693765)\n",
      "Training time took 97.740449 seconds to run 1 epoch\n",
      "('Epoch: ', 463, ' Average loss at step ', 1000, ': ', 0.029885623276233671)\n",
      "('Epoch: ', 463, ' Average loss at step ', 2000, ': ', 0.027919007241725923)\n",
      "('Epoch: ', 463, ' Average loss at step ', 2813, ': ', 0.02694536011500899)\n",
      "Training time took 44.013418 seconds to run 1 epoch\n",
      "('Epoch: ', 464, ' Average loss at step ', 1000, ': ', 126.87776944732666)\n",
      "('Epoch: ', 464, ' Average loss at step ', 2000, ': ', 127.26872082519532)\n",
      "('Epoch: ', 464, ' Average loss at step ', 3000, ': ', 128.24191672515869)\n",
      "('Epoch: ', 464, ' Average loss at step ', 4000, ': ', 128.64158479309083)\n",
      "('Epoch: ', 464, ' Average loss at step ', 4373, ': ', 126.82795698924731)\n",
      "('Epoch: ', 464, ' Average loss at step ', 761, ': ', 8271.9084488718127)\n",
      "('Epoch: ', 464, ' Average loss at step ', 782, ': ', 9595.322819552257)\n",
      "('Epoch: ', 464, ' Average loss at step ', 787, ': ', 14.305617107993168)\n",
      "('Epoch: ', 464, ' Average loss at step ', 1000, ': ', 4.296156538486481)\n",
      "('Epoch: ', 464, ' Average loss at step ', 2000, ': ', 4.2468031201362608)\n",
      "('Epoch: ', 464, ' Average loss at step ', 2813, ': ', 4.2602312975916368)\n",
      "Training time took 97.824449 seconds to run 1 epoch\n",
      "('Epoch: ', 465, ' Average loss at step ', 1000, ': ', 0.030091181039810181)\n",
      "('Epoch: ', 465, ' Average loss at step ', 2000, ': ', 0.027208062887191773)\n",
      "('Epoch: ', 465, ' Average loss at step ', 2813, ': ', 0.026921263249049632)\n",
      "Training time took 44.045991 seconds to run 1 epoch\n",
      "('Epoch: ', 466, ' Average loss at step ', 1000, ': ', 127.84141386413575)\n",
      "('Epoch: ', 466, ' Average loss at step ', 2000, ': ', 128.52804158782959)\n",
      "('Epoch: ', 466, ' Average loss at step ', 3000, ': ', 126.79421186065674)\n",
      "('Epoch: ', 466, ' Average loss at step ', 4000, ': ', 127.90269175720215)\n",
      "('Epoch: ', 466, ' Average loss at step ', 4373, ': ', 127.47377748386835)\n",
      "('Epoch: ', 466, ' Average loss at step ', 761, ': ', 8403.5433201840042)\n",
      "('Epoch: ', 466, ' Average loss at step ', 782, ': ', 9543.1320466299221)\n",
      "('Epoch: ', 466, ' Average loss at step ', 787, ': ', 14.509358222854653)\n",
      "('Epoch: ', 466, ' Average loss at step ', 1000, ': ', 4.2545605807304385)\n",
      "('Epoch: ', 466, ' Average loss at step ', 2000, ': ', 4.1697938766479492)\n",
      "('Epoch: ', 466, ' Average loss at step ', 2813, ': ', 4.2829782815989601)\n",
      "Training time took 97.779653 seconds to run 1 epoch\n",
      "('Epoch: ', 467, ' Average loss at step ', 1000, ': ', 0.029702050507068634)\n",
      "('Epoch: ', 467, ' Average loss at step ', 2000, ': ', 0.027535801827907561)\n",
      "('Epoch: ', 467, ' Average loss at step ', 2813, ': ', 0.026526214894402791)\n",
      "Training time took 44.0238 seconds to run 1 epoch\n",
      "('Epoch: ', 468, ' Average loss at step ', 1000, ': ', 128.10600736999513)\n",
      "('Epoch: ', 468, ' Average loss at step ', 2000, ': ', 127.66455511474609)\n",
      "('Epoch: ', 468, ' Average loss at step ', 3000, ': ', 129.27276016998292)\n",
      "('Epoch: ', 468, ' Average loss at step ', 4000, ': ', 127.99510169982911)\n",
      "('Epoch: ', 468, ' Average loss at step ', 4373, ': ', 129.84075236576859)\n",
      "('Epoch: ', 468, ' Average loss at step ', 761, ': ', 8255.7446481805091)\n",
      "('Epoch: ', 468, ' Average loss at step ', 782, ': ', 9689.0148603803209)\n",
      "('Epoch: ', 468, ' Average loss at step ', 787, ': ', 14.422155945658988)\n",
      "('Epoch: ', 468, ' Average loss at step ', 1000, ': ', 4.2488270545005795)\n",
      "('Epoch: ', 468, ' Average loss at step ', 2000, ': ', 4.3591020779609684)\n",
      "('Epoch: ', 468, ' Average loss at step ', 2813, ': ', 4.416686286479969)\n",
      "Training time took 97.874094 seconds to run 1 epoch\n",
      "('Epoch: ', 469, ' Average loss at step ', 1000, ': ', 0.029509055912494659)\n",
      "('Epoch: ', 469, ' Average loss at step ', 2000, ': ', 0.027344941139221191)\n",
      "('Epoch: ', 469, ' Average loss at step ', 2813, ': ', 0.026687979037538539)\n",
      "Training time took 44.038388 seconds to run 1 epoch\n",
      "Mean Rank:  2  of  28683\n",
      "Hits @ 10:  0.984322881921\n",
      "Hits @ 1:  0.936691127418\n",
      "Testing time took 73.398108 seconds.\n",
      "\n",
      "('Epoch: ', 470, ' Average loss at step ', 1000, ': ', 129.09431501770018)\n",
      "('Epoch: ', 470, ' Average loss at step ', 2000, ': ', 130.5363179168701)\n",
      "('Epoch: ', 470, ' Average loss at step ', 3000, ': ', 128.31289225769044)\n",
      "('Epoch: ', 470, ' Average loss at step ', 4000, ': ', 128.17362963867188)\n",
      "('Epoch: ', 470, ' Average loss at step ', 4373, ': ', 132.31208801269531)\n",
      "('Epoch: ', 470, ' Average loss at step ', 761, ': ', 8292.2833110608553)\n",
      "('Epoch: ', 470, ' Average loss at step ', 782, ': ', 9592.1490970860668)\n",
      "('Epoch: ', 470, ' Average loss at step ', 787, ': ', 14.408696780071308)\n",
      "('Epoch: ', 470, ' Average loss at step ', 1000, ': ', 4.2767769021987911)\n",
      "('Epoch: ', 470, ' Average loss at step ', 2000, ': ', 4.2230453033447262)\n",
      "('Epoch: ', 470, ' Average loss at step ', 2813, ': ', 4.2864178618774043)\n",
      "Training time took 97.713664 seconds to run 1 epoch\n",
      "('Epoch: ', 471, ' Average loss at step ', 1000, ': ', 0.029566166698932649)\n",
      "('Epoch: ', 471, ' Average loss at step ', 2000, ': ', 0.027231547832489014)\n",
      "('Epoch: ', 471, ' Average loss at step ', 2813, ': ', 0.026525639768304497)\n",
      "Training time took 44.014642 seconds to run 1 epoch\n",
      "('Epoch: ', 472, ' Average loss at step ', 1000, ': ', 126.9572194366455)\n",
      "('Epoch: ', 472, ' Average loss at step ', 2000, ': ', 126.24446808624268)\n",
      "('Epoch: ', 472, ' Average loss at step ', 3000, ': ', 128.75633831405639)\n",
      "('Epoch: ', 472, ' Average loss at step ', 4000, ': ', 128.76370249176026)\n",
      "('Epoch: ', 472, ' Average loss at step ', 4373, ': ', 127.85330630886939)\n",
      "('Epoch: ', 472, ' Average loss at step ', 761, ': ', 8353.2053723787012)\n",
      "('Epoch: ', 472, ' Average loss at step ', 782, ': ', 9633.7958665522965)\n",
      "('Epoch: ', 472, ' Average loss at step ', 787, ': ', 14.467129598137076)\n",
      "('Epoch: ', 472, ' Average loss at step ', 1000, ': ', 4.2513375415802006)\n",
      "('Epoch: ', 472, ' Average loss at step ', 2000, ': ', 4.3194977159500123)\n",
      "('Epoch: ', 472, ' Average loss at step ', 2813, ': ', 4.2392875919201103)\n",
      "Training time took 97.779424 seconds to run 1 epoch\n",
      "('Epoch: ', 473, ' Average loss at step ', 1000, ': ', 0.029296647071838378)\n",
      "('Epoch: ', 473, ' Average loss at step ', 2000, ': ', 0.027343322932720186)\n",
      "('Epoch: ', 473, ' Average loss at step ', 2813, ': ', 0.026203948288715532)\n",
      "Training time took 44.031952 seconds to run 1 epoch\n",
      "('Epoch: ', 474, ' Average loss at step ', 1000, ': ', 128.1048715133667)\n",
      "('Epoch: ', 474, ' Average loss at step ', 2000, ': ', 126.91397647094726)\n",
      "('Epoch: ', 474, ' Average loss at step ', 3000, ': ', 129.30690411376952)\n",
      "('Epoch: ', 474, ' Average loss at step ', 4000, ': ', 128.19955062866211)\n",
      "('Epoch: ', 474, ' Average loss at step ', 4373, ': ', 129.73495948955576)\n",
      "('Epoch: ', 474, ' Average loss at step ', 761, ': ', 8291.0091996042356)\n",
      "('Epoch: ', 474, ' Average loss at step ', 782, ': ', 9679.2345481804186)\n",
      "('Epoch: ', 474, ' Average loss at step ', 787, ': ', 14.227912029237238)\n",
      "('Epoch: ', 474, ' Average loss at step ', 1000, ': ', 4.4220848636627199)\n",
      "('Epoch: ', 474, ' Average loss at step ', 2000, ': ', 4.3694053697586064)\n",
      "('Epoch: ', 474, ' Average loss at step ', 2813, ': ', 4.3123405619795099)\n",
      "Training time took 97.921639 seconds to run 1 epoch\n",
      "('Epoch: ', 475, ' Average loss at step ', 1000, ': ', 0.02911644196510315)\n",
      "('Epoch: ', 475, ' Average loss at step ', 2000, ': ', 0.027054143905639649)\n",
      "('Epoch: ', 475, ' Average loss at step ', 2813, ': ', 0.02615036393327666)\n",
      "Training time took 44.050451 seconds to run 1 epoch\n",
      "('Epoch: ', 476, ' Average loss at step ', 1000, ': ', 125.56512159729004)\n",
      "('Epoch: ', 476, ' Average loss at step ', 2000, ': ', 128.66723762512208)\n",
      "('Epoch: ', 476, ' Average loss at step ', 3000, ': ', 129.75597411346436)\n",
      "('Epoch: ', 476, ' Average loss at step ', 4000, ': ', 125.95370574951171)\n",
      "('Epoch: ', 476, ' Average loss at step ', 4373, ': ', 128.33333333333334)\n",
      "('Epoch: ', 476, ' Average loss at step ', 761, ': ', 8460.7773684853)\n",
      "('Epoch: ', 476, ' Average loss at step ', 782, ': ', 9620.9961806528081)\n",
      "('Epoch: ', 476, ' Average loss at step ', 787, ': ', 14.00495030376444)\n",
      "('Epoch: ', 476, ' Average loss at step ', 1000, ': ', 4.3127106008529665)\n",
      "('Epoch: ', 476, ' Average loss at step ', 2000, ': ', 4.1934043664932252)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 476, ' Average loss at step ', 2813, ': ', 4.2867938503255987)\n",
      "Training time took 97.714539 seconds to run 1 epoch\n",
      "('Epoch: ', 477, ' Average loss at step ', 1000, ': ', 0.029067320823669432)\n",
      "('Epoch: ', 477, ' Average loss at step ', 2000, ': ', 0.027122558176517486)\n",
      "('Epoch: ', 477, ' Average loss at step ', 2813, ': ', 0.026072775935891815)\n",
      "Training time took 44.030729 seconds to run 1 epoch\n",
      "('Epoch: ', 478, ' Average loss at step ', 1000, ': ', 127.97163877868653)\n",
      "('Epoch: ', 478, ' Average loss at step ', 2000, ': ', 125.95316611480713)\n",
      "('Epoch: ', 478, ' Average loss at step ', 3000, ': ', 127.96492921447754)\n",
      "('Epoch: ', 478, ' Average loss at step ', 4000, ': ', 127.96111993408203)\n",
      "('Epoch: ', 478, ' Average loss at step ', 4373, ': ', 129.67981018558626)\n",
      "('Epoch: ', 478, ' Average loss at step ', 761, ': ', 8471.8609297902967)\n",
      "('Epoch: ', 478, ' Average loss at step ', 782, ': ', 9654.7345388024169)\n",
      "('Epoch: ', 478, ' Average loss at step ', 787, ': ', 14.193240530921607)\n",
      "('Epoch: ', 478, ' Average loss at step ', 1000, ': ', 4.3257726540565491)\n",
      "('Epoch: ', 478, ' Average loss at step ', 2000, ': ', 4.2133431830406192)\n",
      "('Epoch: ', 478, ' Average loss at step ', 2813, ': ', 4.329620482299128)\n",
      "Training time took 97.641507 seconds to run 1 epoch\n",
      "('Epoch: ', 479, ' Average loss at step ', 1000, ': ', 0.029150147080421449)\n",
      "('Epoch: ', 479, ' Average loss at step ', 2000, ': ', 0.026717111289501189)\n",
      "('Epoch: ', 479, ' Average loss at step ', 2813, ': ', 0.026203978311252124)\n",
      "Training time took 44.019962 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984256170781\n",
      "Hits @ 1:  0.935690460307\n",
      "Testing time took 73.297838 seconds.\n",
      "\n",
      "('Epoch: ', 480, ' Average loss at step ', 1000, ': ', 127.13701002120972)\n",
      "('Epoch: ', 480, ' Average loss at step ', 2000, ': ', 127.97780102539062)\n",
      "('Epoch: ', 480, ' Average loss at step ', 3000, ': ', 127.24534428405762)\n",
      "('Epoch: ', 480, ' Average loss at step ', 4000, ': ', 127.85172317504883)\n",
      "('Epoch: ', 480, ' Average loss at step ', 4373, ': ', 126.59091771033502)\n",
      "('Epoch: ', 480, ' Average loss at step ', 761, ': ', 8416.6131823087999)\n",
      "('Epoch: ', 480, ' Average loss at step ', 782, ': ', 9746.7199347541209)\n",
      "('Epoch: ', 480, ' Average loss at step ', 787, ': ', 14.114302936097744)\n",
      "('Epoch: ', 480, ' Average loss at step ', 1000, ': ', 4.247163372039795)\n",
      "('Epoch: ', 480, ' Average loss at step ', 2000, ': ', 4.2028506708145139)\n",
      "('Epoch: ', 480, ' Average loss at step ', 2813, ': ', 4.251205104325205)\n",
      "Training time took 97.657064 seconds to run 1 epoch\n",
      "('Epoch: ', 481, ' Average loss at step ', 1000, ': ', 0.028825597524642945)\n",
      "('Epoch: ', 481, ' Average loss at step ', 2000, ': ', 0.026435392677783966)\n",
      "('Epoch: ', 481, ' Average loss at step ', 2813, ': ', 0.026149496215904875)\n",
      "Training time took 44.043909 seconds to run 1 epoch\n",
      "('Epoch: ', 482, ' Average loss at step ', 1000, ': ', 128.2931272277832)\n",
      "('Epoch: ', 482, ' Average loss at step ', 2000, ': ', 129.43869834899903)\n",
      "('Epoch: ', 482, ' Average loss at step ', 3000, ': ', 128.2199164276123)\n",
      "('Epoch: ', 482, ' Average loss at step ', 4000, ': ', 126.74085745239258)\n",
      "('Epoch: ', 482, ' Average loss at step ', 4373, ': ', 126.62515283400013)\n",
      "('Epoch: ', 482, ' Average loss at step ', 761, ': ', 8359.3101954409958)\n",
      "('Epoch: ', 482, ' Average loss at step ', 782, ': ', 9727.2072588228239)\n",
      "('Epoch: ', 482, ' Average loss at step ', 787, ': ', 14.250278110115886)\n",
      "('Epoch: ', 482, ' Average loss at step ', 1000, ': ', 4.1783054823875423)\n",
      "('Epoch: ', 482, ' Average loss at step ', 2000, ': ', 4.195111396312714)\n",
      "('Epoch: ', 482, ' Average loss at step ', 2813, ': ', 4.1436963010891317)\n",
      "Training time took 97.742025 seconds to run 1 epoch\n",
      "('Epoch: ', 483, ' Average loss at step ', 1000, ': ', 0.028670458316802979)\n",
      "('Epoch: ', 483, ' Average loss at step ', 2000, ': ', 0.026659355580806732)\n",
      "('Epoch: ', 483, ' Average loss at step ', 2813, ': ', 0.026036748451552367)\n",
      "Training time took 44.014852 seconds to run 1 epoch\n",
      "('Epoch: ', 484, ' Average loss at step ', 1000, ': ', 128.6328653526306)\n",
      "('Epoch: ', 484, ' Average loss at step ', 2000, ': ', 128.02176428222657)\n",
      "('Epoch: ', 484, ' Average loss at step ', 3000, ': ', 130.26590600585936)\n",
      "('Epoch: ', 484, ' Average loss at step ', 4000, ': ', 127.5786545791626)\n",
      "('Epoch: ', 484, ' Average loss at step ', 4373, ': ', 129.0551647781044)\n",
      "('Epoch: ', 484, ' Average loss at step ', 761, ': ', 8485.1241724917763)\n",
      "('Epoch: ', 484, ' Average loss at step ', 782, ': ', 9694.4777491297209)\n",
      "('Epoch: ', 484, ' Average loss at step ', 787, ': ', 14.230078139074584)\n",
      "('Epoch: ', 484, ' Average loss at step ', 1000, ': ', 4.3165220441818235)\n",
      "('Epoch: ', 484, ' Average loss at step ', 2000, ': ', 4.2430563330650326)\n",
      "('Epoch: ', 484, ' Average loss at step ', 2813, ': ', 4.3664760736409081)\n",
      "Training time took 97.735988 seconds to run 1 epoch\n",
      "('Epoch: ', 485, ' Average loss at step ', 1000, ': ', 0.02852777796983719)\n",
      "('Epoch: ', 485, ' Average loss at step ', 2000, ': ', 0.026615386366844178)\n",
      "('Epoch: ', 485, ' Average loss at step ', 2813, ': ', 0.025830597713075835)\n",
      "Training time took 44.061473 seconds to run 1 epoch\n",
      "('Epoch: ', 486, ' Average loss at step ', 1000, ': ', 127.53316859436035)\n",
      "('Epoch: ', 486, ' Average loss at step ', 2000, ': ', 125.67828327178955)\n",
      "('Epoch: ', 486, ' Average loss at step ', 3000, ': ', 129.81264714813233)\n",
      "('Epoch: ', 486, ' Average loss at step ', 4000, ': ', 128.75610305404663)\n",
      "('Epoch: ', 486, ' Average loss at step ', 4373, ': ', 130.9409201837355)\n",
      "('Epoch: ', 486, ' Average loss at step ', 761, ': ', 8476.0776765522205)\n",
      "('Epoch: ', 486, ' Average loss at step ', 782, ': ', 9690.0591570552569)\n",
      "('Epoch: ', 486, ' Average loss at step ', 787, ': ', 14.006631465358588)\n",
      "('Epoch: ', 486, ' Average loss at step ', 1000, ': ', 4.2375938243865967)\n",
      "('Epoch: ', 486, ' Average loss at step ', 2000, ': ', 4.3457355947494509)\n",
      "('Epoch: ', 486, ' Average loss at step ', 2813, ': ', 4.2221991698730168)\n",
      "Training time took 97.777432 seconds to run 1 epoch\n",
      "('Epoch: ', 487, ' Average loss at step ', 1000, ': ', 0.028627545893192292)\n",
      "('Epoch: ', 487, ' Average loss at step ', 2000, ': ', 0.026427393078804016)\n",
      "('Epoch: ', 487, ' Average loss at step ', 2813, ': ', 0.025457239723557908)\n",
      "Training time took 44.031968 seconds to run 1 epoch\n",
      "('Epoch: ', 488, ' Average loss at step ', 1000, ': ', 128.50414836883544)\n",
      "('Epoch: ', 488, ' Average loss at step ', 2000, ': ', 127.66532303619385)\n",
      "('Epoch: ', 488, ' Average loss at step ', 3000, ': ', 128.65096508789063)\n",
      "('Epoch: ', 488, ' Average loss at step ', 4000, ': ', 129.34135479736329)\n",
      "('Epoch: ', 488, ' Average loss at step ', 4373, ': ', 127.36962275351247)\n",
      "('Epoch: ', 488, ' Average loss at step ', 761, ': ', 8451.0064170435853)\n",
      "('Epoch: ', 488, ' Average loss at step ', 782, ': ', 9755.5040744288181)\n",
      "('Epoch: ', 488, ' Average loss at step ', 787, ': ', 13.795731346722475)\n",
      "('Epoch: ', 488, ' Average loss at step ', 1000, ': ', 4.2467559294700621)\n",
      "('Epoch: ', 488, ' Average loss at step ', 2000, ': ', 4.1692920603752137)\n",
      "('Epoch: ', 488, ' Average loss at step ', 2813, ': ', 4.2827949424095344)\n",
      "Training time took 97.718694 seconds to run 1 epoch\n",
      "('Epoch: ', 489, ' Average loss at step ', 1000, ': ', 0.028466898083686829)\n",
      "('Epoch: ', 489, ' Average loss at step ', 2000, ': ', 0.026127142965793611)\n",
      "('Epoch: ', 489, ' Average loss at step ', 2813, ': ', 0.025668427348136902)\n",
      "Training time took 44.05278 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984056037358\n",
      "Hits @ 1:  0.935890593729\n",
      "Testing time took 73.350441 seconds.\n",
      "\n",
      "('Epoch: ', 490, ' Average loss at step ', 1000, ': ', 129.4177328414917)\n",
      "('Epoch: ', 490, ' Average loss at step ', 2000, ': ', 129.3888305130005)\n",
      "('Epoch: ', 490, ' Average loss at step ', 3000, ': ', 128.37650935363769)\n",
      "('Epoch: ', 490, ' Average loss at step ', 4000, ': ', 128.25602864074708)\n",
      "('Epoch: ', 490, ' Average loss at step ', 4373, ': ', 129.79528745015463)\n",
      "('Epoch: ', 490, ' Average loss at step ', 761, ': ', 8502.5902093184613)\n",
      "('Epoch: ', 490, ' Average loss at step ', 782, ': ', 9790.341841264204)\n",
      "('Epoch: ', 490, ' Average loss at step ', 787, ': ', 14.087719154115245)\n",
      "('Epoch: ', 490, ' Average loss at step ', 1000, ': ', 4.2223440146446229)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 490, ' Average loss at step ', 2000, ': ', 4.2203623614311221)\n",
      "('Epoch: ', 490, ' Average loss at step ', 2813, ': ', 4.287520049240789)\n",
      "Training time took 97.84264 seconds to run 1 epoch\n",
      "('Epoch: ', 491, ' Average loss at step ', 1000, ': ', 0.028159611225128174)\n",
      "('Epoch: ', 491, ' Average loss at step ', 2000, ': ', 0.026314247012138366)\n",
      "('Epoch: ', 491, ' Average loss at step ', 2813, ': ', 0.025676355866963051)\n",
      "Training time took 44.043409 seconds to run 1 epoch\n",
      "('Epoch: ', 492, ' Average loss at step ', 1000, ': ', 128.03968173217774)\n",
      "('Epoch: ', 492, ' Average loss at step ', 2000, ': ', 126.49758201599121)\n",
      "('Epoch: ', 492, ' Average loss at step ', 3000, ': ', 127.49931839752198)\n",
      "('Epoch: ', 492, ' Average loss at step ', 4000, ': ', 128.0224281463623)\n",
      "('Epoch: ', 492, ' Average loss at step ', 4373, ': ', 125.96774193548387)\n",
      "('Epoch: ', 492, ' Average loss at step ', 761, ': ', 8552.6246405350539)\n",
      "('Epoch: ', 492, ' Average loss at step ', 782, ': ', 9810.0292718669971)\n",
      "('Epoch: ', 492, ' Average loss at step ', 787, ': ', 14.066894619822806)\n",
      "('Epoch: ', 492, ' Average loss at step ', 1000, ': ', 4.3192259306907657)\n",
      "('Epoch: ', 492, ' Average loss at step ', 2000, ': ', 4.0793008365631103)\n",
      "('Epoch: ', 492, ' Average loss at step ', 2813, ': ', 4.2186719795753218)\n",
      "Training time took 97.946834 seconds to run 1 epoch\n",
      "('Epoch: ', 493, ' Average loss at step ', 1000, ': ', 0.028495623350143433)\n",
      "('Epoch: ', 493, ' Average loss at step ', 2000, ': ', 0.02615710473060608)\n",
      "('Epoch: ', 493, ' Average loss at step ', 2813, ': ', 0.025022076268501468)\n",
      "Training time took 44.026762 seconds to run 1 epoch\n",
      "('Epoch: ', 494, ' Average loss at step ', 1000, ': ', 126.61198718261718)\n",
      "('Epoch: ', 494, ' Average loss at step ', 2000, ': ', 126.56037287902832)\n",
      "('Epoch: ', 494, ' Average loss at step ', 3000, ': ', 127.97993937683106)\n",
      "('Epoch: ', 494, ' Average loss at step ', 4000, ': ', 128.36066569519042)\n",
      "('Epoch: ', 494, ' Average loss at step ', 4373, ': ', 126.49607886037519)\n",
      "('Epoch: ', 494, ' Average loss at step ', 761, ': ', 8493.3359901829772)\n",
      "('Epoch: ', 494, ' Average loss at step ', 782, ': ', 9886.2355259933174)\n",
      "('Epoch: ', 494, ' Average loss at step ', 787, ': ', 14.22307825695164)\n",
      "('Epoch: ', 494, ' Average loss at step ', 1000, ': ', 4.136619572162628)\n",
      "('Epoch: ', 494, ' Average loss at step ', 2000, ': ', 4.2064801225662229)\n",
      "('Epoch: ', 494, ' Average loss at step ', 2813, ': ', 4.252253653380671)\n",
      "Training time took 97.814019 seconds to run 1 epoch\n",
      "('Epoch: ', 495, ' Average loss at step ', 1000, ': ', 0.028032122731208801)\n",
      "('Epoch: ', 495, ' Average loss at step ', 2000, ': ', 0.025851736128330232)\n",
      "('Epoch: ', 495, ' Average loss at step ', 2813, ': ', 0.025220998549109024)\n",
      "Training time took 44.007548 seconds to run 1 epoch\n",
      "('Epoch: ', 496, ' Average loss at step ', 1000, ': ', 128.84468311309814)\n",
      "('Epoch: ', 496, ' Average loss at step ', 2000, ': ', 129.0893822364807)\n",
      "('Epoch: ', 496, ' Average loss at step ', 3000, ': ', 129.87257662963867)\n",
      "('Epoch: ', 496, ' Average loss at step ', 4000, ': ', 128.51522012329102)\n",
      "('Epoch: ', 496, ' Average loss at step ', 4373, ': ', 127.31186077158938)\n",
      "('Epoch: ', 496, ' Average loss at step ', 761, ': ', 8478.8950593647205)\n",
      "('Epoch: ', 496, ' Average loss at step ', 782, ': ', 9811.4295724631884)\n",
      "('Epoch: ', 496, ' Average loss at step ', 787, ': ', 13.980405262711697)\n",
      "('Epoch: ', 496, ' Average loss at step ', 1000, ': ', 4.2456884698867796)\n",
      "('Epoch: ', 496, ' Average loss at step ', 2000, ': ', 4.1073326277732853)\n",
      "('Epoch: ', 496, ' Average loss at step ', 2813, ': ', 4.3081107609377707)\n",
      "Training time took 97.727551 seconds to run 1 epoch\n",
      "('Epoch: ', 497, ' Average loss at step ', 1000, ': ', 0.028181373238563536)\n",
      "('Epoch: ', 497, ' Average loss at step ', 2000, ': ', 0.0259351726770401)\n",
      "('Epoch: ', 497, ' Average loss at step ', 2813, ': ', 0.025400616779115988)\n",
      "Training time took 44.024949 seconds to run 1 epoch\n",
      "('Epoch: ', 498, ' Average loss at step ', 1000, ': ', 127.57090774917603)\n",
      "('Epoch: ', 498, ' Average loss at step ', 2000, ': ', 128.15801062011718)\n",
      "('Epoch: ', 498, ' Average loss at step ', 3000, ': ', 128.75651973724365)\n",
      "('Epoch: ', 498, ' Average loss at step ', 4000, ': ', 127.97756295776367)\n",
      "('Epoch: ', 498, ' Average loss at step ', 4373, ': ', 130.01056053817913)\n",
      "('Epoch: ', 498, ' Average loss at step ', 761, ': ', 8508.3925684878704)\n",
      "('Epoch: ', 498, ' Average loss at step ', 782, ': ', 9876.3598764104518)\n",
      "('Epoch: ', 498, ' Average loss at step ', 787, ': ', 13.910040781394823)\n",
      "('Epoch: ', 498, ' Average loss at step ', 1000, ': ', 4.2595222616195683)\n",
      "('Epoch: ', 498, ' Average loss at step ', 2000, ': ', 4.1459619445800779)\n",
      "('Epoch: ', 498, ' Average loss at step ', 2813, ': ', 4.2908924160332518)\n",
      "Training time took 97.80541 seconds to run 1 epoch\n",
      "('Epoch: ', 499, ' Average loss at step ', 1000, ': ', 0.028051717519760131)\n",
      "('Epoch: ', 499, ' Average loss at step ', 2000, ': ', 0.025424727201461793)\n",
      "('Epoch: ', 499, ' Average loss at step ', 2813, ': ', 0.025166211383683339)\n",
      "Training time took 44.049486 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984322881921\n",
      "Hits @ 1:  0.93595730487\n",
      "Testing time took 73.306554 seconds.\n",
      "\n",
      "('Epoch: ', 500, ' Average loss at step ', 1000, ': ', 128.14404848480225)\n",
      "('Epoch: ', 500, ' Average loss at step ', 2000, ': ', 127.84568327331543)\n",
      "('Epoch: ', 500, ' Average loss at step ', 3000, ': ', 127.48048345184326)\n",
      "('Epoch: ', 500, ' Average loss at step ', 4000, ': ', 128.5538098526001)\n",
      "('Epoch: ', 500, ' Average loss at step ', 4373, ': ', 132.95907281034735)\n",
      "('Epoch: ', 500, ' Average loss at step ', 761, ': ', 8524.4791542454768)\n",
      "('Epoch: ', 500, ' Average loss at step ', 782, ': ', 9876.501663657371)\n",
      "('Epoch: ', 500, ' Average loss at step ', 787, ': ', 13.734164262242595)\n",
      "('Epoch: ', 500, ' Average loss at step ', 1000, ': ', 4.1738069667816164)\n",
      "('Epoch: ', 500, ' Average loss at step ', 2000, ': ', 4.2959533753395078)\n",
      "('Epoch: ', 500, ' Average loss at step ', 2813, ': ', 4.198748074141629)\n",
      "Training time took 97.743365 seconds to run 1 epoch\n",
      "('Epoch: ', 501, ' Average loss at step ', 1000, ': ', 0.027950276076793672)\n",
      "('Epoch: ', 501, ' Average loss at step ', 2000, ': ', 0.025686268091201784)\n",
      "('Epoch: ', 501, ' Average loss at step ', 2813, ': ', 0.025095647558790124)\n",
      "Training time took 44.006932 seconds to run 1 epoch\n",
      "('Epoch: ', 502, ' Average loss at step ', 1000, ': ', 128.56005454254151)\n",
      "('Epoch: ', 502, ' Average loss at step ', 2000, ': ', 128.27448006439209)\n",
      "('Epoch: ', 502, ' Average loss at step ', 3000, ': ', 128.18696569061279)\n",
      "('Epoch: ', 502, ' Average loss at step ', 4000, ': ', 126.80234896087646)\n",
      "('Epoch: ', 502, ' Average loss at step ', 4373, ': ', 123.79258436797768)\n",
      "('Epoch: ', 502, ' Average loss at step ', 761, ': ', 8583.2609805458469)\n",
      "('Epoch: ', 502, ' Average loss at step ', 782, ': ', 9885.9300882532407)\n",
      "('Epoch: ', 502, ' Average loss at step ', 787, ': ', 13.734693425302288)\n",
      "('Epoch: ', 502, ' Average loss at step ', 1000, ': ', 4.1687212529182434)\n",
      "('Epoch: ', 502, ' Average loss at step ', 2000, ': ', 4.1713048481941222)\n",
      "('Epoch: ', 502, ' Average loss at step ', 2813, ': ', 4.1259075749683847)\n",
      "Training time took 97.763492 seconds to run 1 epoch\n",
      "('Epoch: ', 503, ' Average loss at step ', 1000, ': ', 0.028160214841365813)\n",
      "('Epoch: ', 503, ' Average loss at step ', 2000, ': ', 0.025219590008258821)\n",
      "('Epoch: ', 503, ' Average loss at step ', 2813, ': ', 0.024885162417524555)\n",
      "Training time took 44.026246 seconds to run 1 epoch\n",
      "('Epoch: ', 504, ' Average loss at step ', 1000, ': ', 128.31510737609864)\n",
      "('Epoch: ', 504, ' Average loss at step ', 2000, ': ', 128.13171576690675)\n",
      "('Epoch: ', 504, ' Average loss at step ', 3000, ': ', 128.47872422027586)\n",
      "('Epoch: ', 504, ' Average loss at step ', 4000, ': ', 129.58665632629393)\n",
      "('Epoch: ', 504, ' Average loss at step ', 4373, ': ', 130.86865701983052)\n",
      "('Epoch: ', 504, ' Average loss at step ', 761, ': ', 8533.1146169562089)\n",
      "('Epoch: ', 504, ' Average loss at step ', 782, ': ', 9847.7847248619564)\n",
      "('Epoch: ', 504, ' Average loss at step ', 787, ': ', 13.899460858061113)\n",
      "('Epoch: ', 504, ' Average loss at step ', 1000, ': ', 4.1555303964614865)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 504, ' Average loss at step ', 2000, ': ', 4.1051417741775511)\n",
      "('Epoch: ', 504, ' Average loss at step ', 2813, ': ', 4.11322899933519)\n",
      "Training time took 97.759377 seconds to run 1 epoch\n",
      "('Epoch: ', 505, ' Average loss at step ', 1000, ': ', 0.027587134659290313)\n",
      "('Epoch: ', 505, ' Average loss at step ', 2000, ': ', 0.025336025357246397)\n",
      "('Epoch: ', 505, ' Average loss at step ', 2813, ': ', 0.024995338226774057)\n",
      "Training time took 44.026591 seconds to run 1 epoch\n",
      "('Epoch: ', 506, ' Average loss at step ', 1000, ': ', 128.06018535614012)\n",
      "('Epoch: ', 506, ' Average loss at step ', 2000, ': ', 128.71701846313476)\n",
      "('Epoch: ', 506, ' Average loss at step ', 3000, ': ', 127.27060720825196)\n",
      "('Epoch: ', 506, ' Average loss at step ', 4000, ': ', 128.82523457336427)\n",
      "('Epoch: ', 506, ' Average loss at step ', 4373, ': ', 129.48504573042675)\n",
      "('Epoch: ', 506, ' Average loss at step ', 761, ': ', 8476.4665903191817)\n",
      "('Epoch: ', 506, ' Average loss at step ', 782, ': ', 9908.6346124509837)\n",
      "('Epoch: ', 506, ' Average loss at step ', 787, ': ', 13.645246009486929)\n",
      "('Epoch: ', 506, ' Average loss at step ', 1000, ': ', 4.1324290261268617)\n",
      "('Epoch: ', 506, ' Average loss at step ', 2000, ': ', 4.2589005646705624)\n",
      "('Epoch: ', 506, ' Average loss at step ', 2813, ': ', 4.1674608215322637)\n",
      "Training time took 97.837393 seconds to run 1 epoch\n",
      "('Epoch: ', 507, ' Average loss at step ', 1000, ': ', 0.027371623575687409)\n",
      "('Epoch: ', 507, ' Average loss at step ', 2000, ': ', 0.02540363711118698)\n",
      "('Epoch: ', 507, ' Average loss at step ', 2813, ': ', 0.024687706469902263)\n",
      "Training time took 44.008672 seconds to run 1 epoch\n",
      "('Epoch: ', 508, ' Average loss at step ', 1000, ': ', 129.64138403320314)\n",
      "('Epoch: ', 508, ' Average loss at step ', 2000, ': ', 126.74533023834229)\n",
      "('Epoch: ', 508, ' Average loss at step ', 3000, ': ', 126.57970354461671)\n",
      "('Epoch: ', 508, ' Average loss at step ', 4000, ': ', 128.22180212402344)\n",
      "('Epoch: ', 508, ' Average loss at step ', 4373, ': ', 127.80992846335134)\n",
      "('Epoch: ', 508, ' Average loss at step ', 761, ': ', 8582.564831542968)\n",
      "('Epoch: ', 508, ' Average loss at step ', 782, ': ', 9876.9802661851791)\n",
      "('Epoch: ', 508, ' Average loss at step ', 787, ': ', 13.692103447804925)\n",
      "('Epoch: ', 508, ' Average loss at step ', 1000, ': ', 4.1095613837242126)\n",
      "('Epoch: ', 508, ' Average loss at step ', 2000, ': ', 4.1959039845466615)\n",
      "('Epoch: ', 508, ' Average loss at step ', 2813, ': ', 4.143938406934879)\n",
      "Training time took 97.779485 seconds to run 1 epoch\n",
      "('Epoch: ', 509, ' Average loss at step ', 1000, ': ', 0.027467775583267212)\n",
      "('Epoch: ', 509, ' Average loss at step ', 2000, ': ', 0.025203243553638458)\n",
      "('Epoch: ', 509, ' Average loss at step ', 2813, ': ', 0.024802001899686354)\n",
      "Training time took 44.04025 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984523015344\n",
      "Hits @ 1:  0.93595730487\n",
      "Testing time took 73.370034 seconds.\n",
      "\n",
      "('Epoch: ', 510, ' Average loss at step ', 1000, ': ', 124.70876801300049)\n",
      "('Epoch: ', 510, ' Average loss at step ', 2000, ': ', 127.23132263946533)\n",
      "('Epoch: ', 510, ' Average loss at step ', 3000, ': ', 129.74382789611818)\n",
      "('Epoch: ', 510, ' Average loss at step ', 4000, ': ', 128.94049890899657)\n",
      "('Epoch: ', 510, ' Average loss at step ', 4373, ': ', 129.89616974451209)\n",
      "('Epoch: ', 510, ' Average loss at step ', 761, ': ', 8534.4522955643497)\n",
      "('Epoch: ', 510, ' Average loss at step ', 782, ': ', 9851.7935464348593)\n",
      "('Epoch: ', 510, ' Average loss at step ', 787, ': ', 13.346715472126736)\n",
      "('Epoch: ', 510, ' Average loss at step ', 1000, ': ', 4.2493665833473209)\n",
      "('Epoch: ', 510, ' Average loss at step ', 2000, ': ', 4.1012541027069096)\n",
      "('Epoch: ', 510, ' Average loss at step ', 2813, ': ', 4.2217913126123365)\n",
      "Training time took 97.80342 seconds to run 1 epoch\n",
      "('Epoch: ', 511, ' Average loss at step ', 1000, ': ', 0.027277581870555876)\n",
      "('Epoch: ', 511, ' Average loss at step ', 2000, ': ', 0.025232765495777128)\n",
      "('Epoch: ', 511, ' Average loss at step ', 2813, ': ', 0.024654161827317601)\n",
      "Training time took 44.033208 seconds to run 1 epoch\n",
      "('Epoch: ', 512, ' Average loss at step ', 1000, ': ', 127.3241388092041)\n",
      "('Epoch: ', 512, ' Average loss at step ', 2000, ': ', 129.11968856811524)\n",
      "('Epoch: ', 512, ' Average loss at step ', 3000, ': ', 127.83292512512207)\n",
      "('Epoch: ', 512, ' Average loss at step ', 4000, ': ', 127.75652073669434)\n",
      "('Epoch: ', 512, ' Average loss at step ', 4373, ': ', 126.63933274053758)\n",
      "('Epoch: ', 512, ' Average loss at step ', 761, ': ', 8661.6727230674351)\n",
      "('Epoch: ', 512, ' Average loss at step ', 782, ': ', 9926.8504746518884)\n",
      "('Epoch: ', 512, ' Average loss at step ', 787, ': ', 13.831555019504847)\n",
      "('Epoch: ', 512, ' Average loss at step ', 1000, ': ', 4.2191340746879575)\n",
      "('Epoch: ', 512, ' Average loss at step ', 2000, ': ', 4.123786334991455)\n",
      "('Epoch: ', 512, ' Average loss at step ', 2813, ': ', 4.2097620130172508)\n",
      "Training time took 97.810249 seconds to run 1 epoch\n",
      "('Epoch: ', 513, ' Average loss at step ', 1000, ': ', 0.027368421554565429)\n",
      "('Epoch: ', 513, ' Average loss at step ', 2000, ': ', 0.024981880962848663)\n",
      "('Epoch: ', 513, ' Average loss at step ', 2813, ': ', 0.024469950002402506)\n",
      "Training time took 44.044489 seconds to run 1 epoch\n",
      "('Epoch: ', 514, ' Average loss at step ', 1000, ': ', 127.91803527069092)\n",
      "('Epoch: ', 514, ' Average loss at step ', 2000, ': ', 129.34588108825685)\n",
      "('Epoch: ', 514, ' Average loss at step ', 3000, ': ', 127.77069885253906)\n",
      "('Epoch: ', 514, ' Average loss at step ', 4000, ': ', 128.02250467681884)\n",
      "('Epoch: ', 514, ' Average loss at step ', 4373, ': ', 128.73713411310666)\n",
      "('Epoch: ', 514, ' Average loss at step ', 761, ': ', 8660.7949501439143)\n",
      "('Epoch: ', 514, ' Average loss at step ', 782, ': ', 9959.9247740526971)\n",
      "('Epoch: ', 514, ' Average loss at step ', 787, ': ', 13.757813858925235)\n",
      "('Epoch: ', 514, ' Average loss at step ', 1000, ': ', 4.1142799334526066)\n",
      "('Epoch: ', 514, ' Average loss at step ', 2000, ': ', 4.1842623491287227)\n",
      "('Epoch: ', 514, ' Average loss at step ', 2813, ': ', 4.1800116934799796)\n",
      "Training time took 97.685048 seconds to run 1 epoch\n",
      "('Epoch: ', 515, ' Average loss at step ', 1000, ': ', 0.027435727179050445)\n",
      "('Epoch: ', 515, ' Average loss at step ', 2000, ': ', 0.025056282162666321)\n",
      "('Epoch: ', 515, ' Average loss at step ', 2813, ': ', 0.024212118440073701)\n",
      "Training time took 44.045454 seconds to run 1 epoch\n",
      "('Epoch: ', 516, ' Average loss at step ', 1000, ': ', 127.79210410308838)\n",
      "('Epoch: ', 516, ' Average loss at step ', 2000, ': ', 128.07509420013429)\n",
      "('Epoch: ', 516, ' Average loss at step ', 3000, ': ', 127.68291722869873)\n",
      "('Epoch: ', 516, ' Average loss at step ', 4000, ': ', 128.08731150817871)\n",
      "('Epoch: ', 516, ' Average loss at step ', 4373, ': ', 128.62430035170689)\n",
      "('Epoch: ', 516, ' Average loss at step ', 761, ': ', 8688.6858314915698)\n",
      "('Epoch: ', 516, ' Average loss at step ', 782, ': ', 9929.5274887964151)\n",
      "('Epoch: ', 516, ' Average loss at step ', 787, ': ', 13.758449372444444)\n",
      "('Epoch: ', 516, ' Average loss at step ', 1000, ': ', 4.1539007143974302)\n",
      "('Epoch: ', 516, ' Average loss at step ', 2000, ': ', 4.1434669041633603)\n",
      "('Epoch: ', 516, ' Average loss at step ', 2813, ': ', 4.1483761395139647)\n",
      "Training time took 97.692874 seconds to run 1 epoch\n",
      "('Epoch: ', 517, ' Average loss at step ', 1000, ': ', 0.026945587515830993)\n",
      "('Epoch: ', 517, ' Average loss at step ', 2000, ': ', 0.024788896918296815)\n",
      "('Epoch: ', 517, ' Average loss at step ', 2813, ': ', 0.024487168037245426)\n",
      "Training time took 44.030665 seconds to run 1 epoch\n",
      "('Epoch: ', 518, ' Average loss at step ', 1000, ': ', 128.02088291168212)\n",
      "('Epoch: ', 518, ' Average loss at step ', 2000, ': ', 130.18242731475831)\n",
      "('Epoch: ', 518, ' Average loss at step ', 3000, ': ', 128.89394253540038)\n",
      "('Epoch: ', 518, ' Average loss at step ', 4000, ': ', 127.29431638336182)\n",
      "('Epoch: ', 518, ' Average loss at step ', 4373, ': ', 128.11835932987992)\n",
      "('Epoch: ', 518, ' Average loss at step ', 761, ': ', 8652.1482563219579)\n",
      "('Epoch: ', 518, ' Average loss at step ', 782, ': ', 9937.6902921434867)\n",
      "('Epoch: ', 518, ' Average loss at step ', 787, ': ', 13.522925844022639)\n",
      "('Epoch: ', 518, ' Average loss at step ', 1000, ': ', 4.0807127680778503)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 518, ' Average loss at step ', 2000, ': ', 4.1525206556320189)\n",
      "('Epoch: ', 518, ' Average loss at step ', 2813, ': ', 4.0875216628530344)\n",
      "Training time took 97.724918 seconds to run 1 epoch\n",
      "('Epoch: ', 519, ' Average loss at step ', 1000, ': ', 0.026894941985607147)\n",
      "('Epoch: ', 519, ' Average loss at step ', 2000, ': ', 0.024826761901378631)\n",
      "('Epoch: ', 519, ' Average loss at step ', 2813, ': ', 0.024270975531028409)\n",
      "Training time took 44.012502 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984389593062\n",
      "Hits @ 1:  0.935623749166\n",
      "Testing time took 73.294478 seconds.\n",
      "\n",
      "('Epoch: ', 520, ' Average loss at step ', 1000, ': ', 128.74316871643066)\n",
      "('Epoch: ', 520, ' Average loss at step ', 2000, ': ', 128.1198253173828)\n",
      "('Epoch: ', 520, ' Average loss at step ', 3000, ': ', 130.50999999999999)\n",
      "('Epoch: ', 520, ' Average loss at step ', 4000, ': ', 127.20563535308838)\n",
      "('Epoch: ', 520, ' Average loss at step ', 4373, ': ', 129.76324419821464)\n",
      "('Epoch: ', 520, ' Average loss at step ', 761, ': ', 8729.4365157277953)\n",
      "('Epoch: ', 520, ' Average loss at step ', 782, ': ', 9956.8805655309698)\n",
      "('Epoch: ', 520, ' Average loss at step ', 787, ': ', 13.449718733780257)\n",
      "('Epoch: ', 520, ' Average loss at step ', 1000, ': ', 4.0428854236602785)\n",
      "('Epoch: ', 520, ' Average loss at step ', 2000, ': ', 4.1128986759185793)\n",
      "('Epoch: ', 520, ' Average loss at step ', 2813, ': ', 4.1275970700926381)\n",
      "Training time took 97.77743 seconds to run 1 epoch\n",
      "('Epoch: ', 521, ' Average loss at step ', 1000, ': ', 0.02689878273010254)\n",
      "('Epoch: ', 521, ' Average loss at step ', 2000, ': ', 0.024612687349319456)\n",
      "('Epoch: ', 521, ' Average loss at step ', 2813, ': ', 0.024240810148821675)\n",
      "Training time took 44.008384 seconds to run 1 epoch\n",
      "('Epoch: ', 522, ' Average loss at step ', 1000, ': ', 130.05315254211425)\n",
      "('Epoch: ', 522, ' Average loss at step ', 2000, ': ', 129.63583849334717)\n",
      "('Epoch: ', 522, ' Average loss at step ', 3000, ': ', 127.32443519592285)\n",
      "('Epoch: ', 522, ' Average loss at step ', 4000, ': ', 127.747447555542)\n",
      "('Epoch: ', 522, ' Average loss at step ', 4373, ': ', 127.61905091808688)\n",
      "('Epoch: ', 522, ' Average loss at step ', 761, ': ', 8786.0243928608143)\n",
      "('Epoch: ', 522, ' Average loss at step ', 782, ': ', 9971.6682144536244)\n",
      "('Epoch: ', 522, ' Average loss at step ', 787, ': ', 13.712368762523466)\n",
      "('Epoch: ', 522, ' Average loss at step ', 1000, ': ', 4.1544431972503659)\n",
      "('Epoch: ', 522, ' Average loss at step ', 2000, ': ', 4.1789103088378905)\n",
      "('Epoch: ', 522, ' Average loss at step ', 2813, ': ', 4.1953872283691256)\n",
      "Training time took 97.650171 seconds to run 1 epoch\n",
      "('Epoch: ', 523, ' Average loss at step ', 1000, ': ', 0.026655574440956117)\n",
      "('Epoch: ', 523, ' Average loss at step ', 2000, ': ', 0.02459895408153534)\n",
      "('Epoch: ', 523, ' Average loss at step ', 2813, ': ', 0.024192271414648723)\n",
      "Training time took 44.030235 seconds to run 1 epoch\n",
      "('Epoch: ', 524, ' Average loss at step ', 1000, ': ', 127.99573965454101)\n",
      "('Epoch: ', 524, ' Average loss at step ', 2000, ': ', 128.64161281585694)\n",
      "('Epoch: ', 524, ' Average loss at step ', 3000, ': ', 129.3095072784424)\n",
      "('Epoch: ', 524, ' Average loss at step ', 4000, ': ', 126.82897389221192)\n",
      "('Epoch: ', 524, ' Average loss at step ', 4373, ': ', 131.08791568715085)\n",
      "('Epoch: ', 524, ' Average loss at step ', 761, ': ', 8704.4564125462584)\n",
      "('Epoch: ', 524, ' Average loss at step ', 782, ': ', 10109.278981148967)\n",
      "('Epoch: ', 524, ' Average loss at step ', 787, ': ', 13.268010163731853)\n",
      "('Epoch: ', 524, ' Average loss at step ', 1000, ': ', 4.0832315559387204)\n",
      "('Epoch: ', 524, ' Average loss at step ', 2000, ': ', 4.0834966464042664)\n",
      "('Epoch: ', 524, ' Average loss at step ', 2813, ': ', 4.3824259917724309)\n",
      "Training time took 97.724588 seconds to run 1 epoch\n",
      "('Epoch: ', 525, ' Average loss at step ', 1000, ': ', 0.026622675299644471)\n",
      "('Epoch: ', 525, ' Average loss at step ', 2000, ': ', 0.024449631869792939)\n",
      "('Epoch: ', 525, ' Average loss at step ', 2813, ': ', 0.024054054996650209)\n",
      "Training time took 44.023057 seconds to run 1 epoch\n",
      "('Epoch: ', 526, ' Average loss at step ', 1000, ': ', 127.93426110076905)\n",
      "('Epoch: ', 526, ' Average loss at step ', 2000, ': ', 129.35604517364501)\n",
      "('Epoch: ', 526, ' Average loss at step ', 3000, ': ', 128.00347409057616)\n",
      "('Epoch: ', 526, ' Average loss at step ', 4000, ': ', 128.22643004608153)\n",
      "('Epoch: ', 526, ' Average loss at step ', 4373, ': ', 128.03849806836857)\n",
      "('Epoch: ', 526, ' Average loss at step ', 761, ': ', 8590.0980751439147)\n",
      "('Epoch: ', 526, ' Average loss at step ', 782, ': ', 10056.166838388284)\n",
      "('Epoch: ', 526, ' Average loss at step ', 787, ': ', 13.068428122056956)\n",
      "('Epoch: ', 526, ' Average loss at step ', 1000, ': ', 4.0620066642761232)\n",
      "('Epoch: ', 526, ' Average loss at step ', 2000, ': ', 4.1745926799774171)\n",
      "('Epoch: ', 526, ' Average loss at step ', 2813, ': ', 4.1993499178017304)\n",
      "Training time took 97.817819 seconds to run 1 epoch\n",
      "('Epoch: ', 527, ' Average loss at step ', 1000, ': ', 0.026695608139038086)\n",
      "('Epoch: ', 527, ' Average loss at step ', 2000, ': ', 0.02431570076942444)\n",
      "('Epoch: ', 527, ' Average loss at step ', 2813, ': ', 0.023921976021945183)\n",
      "Training time took 44.025081 seconds to run 1 epoch\n",
      "('Epoch: ', 528, ' Average loss at step ', 1000, ': ', 127.20152523803711)\n",
      "('Epoch: ', 528, ' Average loss at step ', 2000, ': ', 127.75687962341308)\n",
      "('Epoch: ', 528, ' Average loss at step ', 3000, ': ', 130.04532557678223)\n",
      "('Epoch: ', 528, ' Average loss at step ', 4000, ': ', 128.32029565429687)\n",
      "('Epoch: ', 528, ' Average loss at step ', 4373, ': ', 128.72226423858314)\n",
      "('Epoch: ', 528, ' Average loss at step ', 761, ': ', 8710.3044099506587)\n",
      "('Epoch: ', 528, ' Average loss at step ', 782, ': ', 10156.995226597512)\n",
      "('Epoch: ', 528, ' Average loss at step ', 787, ': ', 13.092824251597165)\n",
      "('Epoch: ', 528, ' Average loss at step ', 1000, ': ', 4.1904129199981686)\n",
      "('Epoch: ', 528, ' Average loss at step ', 2000, ': ', 4.0922883973121644)\n",
      "('Epoch: ', 528, ' Average loss at step ', 2813, ': ', 4.1044439200697278)\n",
      "Training time took 97.745457 seconds to run 1 epoch\n",
      "('Epoch: ', 529, ' Average loss at step ', 1000, ': ', 0.026609219551086426)\n",
      "('Epoch: ', 529, ' Average loss at step ', 2000, ': ', 0.024154978156089784)\n",
      "('Epoch: ', 529, ' Average loss at step ', 2813, ': ', 0.023750607016051344)\n",
      "Training time took 44.020857 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984456304203\n",
      "Hits @ 1:  0.935423615744\n",
      "Testing time took 73.398543 seconds.\n",
      "\n",
      "('Epoch: ', 530, ' Average loss at step ', 1000, ': ', 128.20218161010743)\n",
      "('Epoch: ', 530, ' Average loss at step ', 2000, ': ', 129.96716361999512)\n",
      "('Epoch: ', 530, ' Average loss at step ', 3000, ': ', 129.47027815246582)\n",
      "('Epoch: ', 530, ' Average loss at step ', 4000, ': ', 127.31458642578124)\n",
      "('Epoch: ', 530, ' Average loss at step ', 4373, ': ', 129.91941685830392)\n",
      "('Epoch: ', 530, ' Average loss at step ', 761, ': ', 8733.2339214124186)\n",
      "('Epoch: ', 530, ' Average loss at step ', 782, ': ', 10082.14120581086)\n",
      "('Epoch: ', 530, ' Average loss at step ', 787, ': ', 13.67486254738184)\n",
      "('Epoch: ', 530, ' Average loss at step ', 1000, ': ', 4.2006638431549073)\n",
      "('Epoch: ', 530, ' Average loss at step ', 2000, ': ', 4.0400509829521178)\n",
      "('Epoch: ', 530, ' Average loss at step ', 2813, ': ', 4.1706224679946899)\n",
      "Training time took 97.732093 seconds to run 1 epoch\n",
      "('Epoch: ', 531, ' Average loss at step ', 1000, ': ', 0.026365505576133728)\n",
      "('Epoch: ', 531, ' Average loss at step ', 2000, ': ', 0.024144904911518095)\n",
      "('Epoch: ', 531, ' Average loss at step ', 2813, ': ', 0.023769075060125641)\n",
      "Training time took 44.040339 seconds to run 1 epoch\n",
      "('Epoch: ', 532, ' Average loss at step ', 1000, ': ', 127.2278531036377)\n",
      "('Epoch: ', 532, ' Average loss at step ', 2000, ': ', 128.47718295288087)\n",
      "('Epoch: ', 532, ' Average loss at step ', 3000, ': ', 127.51863864135743)\n",
      "('Epoch: ', 532, ' Average loss at step ', 4000, ': ', 128.51437316131592)\n",
      "('Epoch: ', 532, ' Average loss at step ', 4373, ': ', 128.84408602150538)\n",
      "('Epoch: ', 532, ' Average loss at step ', 761, ': ', 8706.8510228207233)\n",
      "('Epoch: ', 532, ' Average loss at step ', 782, ': ', 10019.231134588068)\n",
      "('Epoch: ', 532, ' Average loss at step ', 787, ': ', 13.387913312014126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 532, ' Average loss at step ', 1000, ': ', 4.1594071478843686)\n",
      "('Epoch: ', 532, ' Average loss at step ', 2000, ': ', 4.0718459959030149)\n",
      "('Epoch: ', 532, ' Average loss at step ', 2813, ': ', 4.1527059219153646)\n",
      "Training time took 97.72059 seconds to run 1 epoch\n",
      "('Epoch: ', 533, ' Average loss at step ', 1000, ': ', 0.026215057253837586)\n",
      "('Epoch: ', 533, ' Average loss at step ', 2000, ': ', 0.024068102419376375)\n",
      "('Epoch: ', 533, ' Average loss at step ', 2813, ': ', 0.02378455942193863)\n",
      "Training time took 44.035403 seconds to run 1 epoch\n",
      "('Epoch: ', 534, ' Average loss at step ', 1000, ': ', 127.26331275939941)\n",
      "('Epoch: ', 534, ' Average loss at step ', 2000, ': ', 127.6464250869751)\n",
      "('Epoch: ', 534, ' Average loss at step ', 3000, ': ', 127.9519513168335)\n",
      "('Epoch: ', 534, ' Average loss at step ', 4000, ': ', 127.56526818847657)\n",
      "('Epoch: ', 534, ' Average loss at step ', 4373, ': ', 133.39596219216622)\n",
      "('Epoch: ', 534, ' Average loss at step ', 761, ': ', 8764.7737278988479)\n",
      "('Epoch: ', 534, ' Average loss at step ', 782, ': ', 10172.748074383802)\n",
      "('Epoch: ', 534, ' Average loss at step ', 787, ': ', 13.344209713486922)\n",
      "('Epoch: ', 534, ' Average loss at step ', 1000, ': ', 4.1329551839828493)\n",
      "('Epoch: ', 534, ' Average loss at step ', 2000, ': ', 3.9989686331748961)\n",
      "('Epoch: ', 534, ' Average loss at step ', 2813, ': ', 4.0343801986995)\n",
      "Training time took 97.769001 seconds to run 1 epoch\n",
      "('Epoch: ', 535, ' Average loss at step ', 1000, ': ', 0.026227927625179292)\n",
      "('Epoch: ', 535, ' Average loss at step ', 2000, ': ', 0.023974504649639131)\n",
      "('Epoch: ', 535, ' Average loss at step ', 2813, ': ', 0.023654043087231114)\n",
      "Training time took 44.059879 seconds to run 1 epoch\n",
      "('Epoch: ', 536, ' Average loss at step ', 1000, ': ', 126.12775399780273)\n",
      "('Epoch: ', 536, ' Average loss at step ', 2000, ': ', 127.79721876907348)\n",
      "('Epoch: ', 536, ' Average loss at step ', 3000, ': ', 128.87956677246095)\n",
      "('Epoch: ', 536, ' Average loss at step ', 4000, ': ', 126.00874964141846)\n",
      "('Epoch: ', 536, ' Average loss at step ', 4373, ': ', 129.69750392052435)\n",
      "('Epoch: ', 536, ' Average loss at step ', 761, ': ', 8813.5713256835934)\n",
      "('Epoch: ', 536, ' Average loss at step ', 782, ': ', 10073.105394976392)\n",
      "('Epoch: ', 536, ' Average loss at step ', 787, ': ', 12.977768007428894)\n",
      "('Epoch: ', 536, ' Average loss at step ', 1000, ': ', 3.9628241801261903)\n",
      "('Epoch: ', 536, ' Average loss at step ', 2000, ': ', 3.9832590627670288)\n",
      "('Epoch: ', 536, ' Average loss at step ', 2813, ': ', 4.0606208094235123)\n",
      "Training time took 97.891218 seconds to run 1 epoch\n",
      "('Epoch: ', 537, ' Average loss at step ', 1000, ': ', 0.025899331390857698)\n",
      "('Epoch: ', 537, ' Average loss at step ', 2000, ': ', 0.024119079291820528)\n",
      "('Epoch: ', 537, ' Average loss at step ', 2813, ': ', 0.023458379536426714)\n",
      "Training time took 44.01172 seconds to run 1 epoch\n",
      "('Epoch: ', 538, ' Average loss at step ', 1000, ': ', 129.19807533264159)\n",
      "('Epoch: ', 538, ' Average loss at step ', 2000, ': ', 125.74014895629882)\n",
      "('Epoch: ', 538, ' Average loss at step ', 3000, ': ', 129.12298160552979)\n",
      "('Epoch: ', 538, ' Average loss at step ', 4000, ': ', 129.23777893066406)\n",
      "('Epoch: ', 538, ' Average loss at step ', 4373, ': ', 127.87763095158402)\n",
      "('Epoch: ', 538, ' Average loss at step ', 761, ': ', 8804.2883936831822)\n",
      "('Epoch: ', 538, ' Average loss at step ', 782, ': ', 10157.51924303277)\n",
      "('Epoch: ', 538, ' Average loss at step ', 787, ': ', 12.898678934907792)\n",
      "('Epoch: ', 538, ' Average loss at step ', 1000, ': ', 4.0470766248703001)\n",
      "('Epoch: ', 538, ' Average loss at step ', 2000, ': ', 4.0428815894126888)\n",
      "('Epoch: ', 538, ' Average loss at step ', 2813, ': ', 4.1055707168109308)\n",
      "Training time took 97.827179 seconds to run 1 epoch\n",
      "('Epoch: ', 539, ' Average loss at step ', 1000, ': ', 0.026167094469070434)\n",
      "('Epoch: ', 539, ' Average loss at step ', 2000, ': ', 0.023900459706783294)\n",
      "('Epoch: ', 539, ' Average loss at step ', 2813, ': ', 0.023108303987333927)\n",
      "Training time took 44.03249 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984456304203\n",
      "Hits @ 1:  0.934956637759\n",
      "Testing time took 73.349878 seconds.\n",
      "\n",
      "('Epoch: ', 540, ' Average loss at step ', 1000, ': ', 128.07268145751954)\n",
      "('Epoch: ', 540, ' Average loss at step ', 2000, ': ', 126.9893106765747)\n",
      "('Epoch: ', 540, ' Average loss at step ', 3000, ': ', 127.39893045043945)\n",
      "('Epoch: ', 540, ' Average loss at step ', 4000, ': ', 128.81837194061279)\n",
      "('Epoch: ', 540, ' Average loss at step ', 4373, ': ', 128.01075268817203)\n",
      "('Epoch: ', 540, ' Average loss at step ', 761, ': ', 8783.001193076685)\n",
      "('Epoch: ', 540, ' Average loss at step ', 782, ': ', 10229.96113693882)\n",
      "('Epoch: ', 540, ' Average loss at step ', 787, ': ', 13.262734248134622)\n",
      "('Epoch: ', 540, ' Average loss at step ', 1000, ': ', 4.0459667387008666)\n",
      "('Epoch: ', 540, ' Average loss at step ', 2000, ': ', 4.2053000788688664)\n",
      "('Epoch: ', 540, ' Average loss at step ', 2813, ': ', 4.0788582522293613)\n",
      "Training time took 97.79071 seconds to run 1 epoch\n",
      "('Epoch: ', 541, ' Average loss at step ', 1000, ': ', 0.026270986914634704)\n",
      "('Epoch: ', 541, ' Average loss at step ', 2000, ': ', 0.023795370042324068)\n",
      "('Epoch: ', 541, ' Average loss at step ', 2813, ': ', 0.023164213878180594)\n",
      "Training time took 44.084155 seconds to run 1 epoch\n",
      "('Epoch: ', 542, ' Average loss at step ', 1000, ': ', 127.87138899230958)\n",
      "('Epoch: ', 542, ' Average loss at step ', 2000, ': ', 127.66994277191162)\n",
      "('Epoch: ', 542, ' Average loss at step ', 3000, ': ', 127.39527573394776)\n",
      "('Epoch: ', 542, ' Average loss at step ', 4000, ': ', 128.04717589569091)\n",
      "('Epoch: ', 542, ' Average loss at step ', 4373, ': ', 127.01685497324954)\n",
      "('Epoch: ', 542, ' Average loss at step ', 761, ': ', 8770.6073948910362)\n",
      "('Epoch: ', 542, ' Average loss at step ', 782, ': ', 10227.46424855954)\n",
      "('Epoch: ', 542, ' Average loss at step ', 787, ': ', 13.275366299024975)\n",
      "('Epoch: ', 542, ' Average loss at step ', 1000, ': ', 4.083988932132721)\n",
      "('Epoch: ', 542, ' Average loss at step ', 2000, ': ', 4.0980618500709536)\n",
      "('Epoch: ', 542, ' Average loss at step ', 2813, ': ', 4.0752761546026894)\n",
      "Training time took 97.891319 seconds to run 1 epoch\n",
      "('Epoch: ', 543, ' Average loss at step ', 1000, ': ', 0.025900805473327636)\n",
      "('Epoch: ', 543, ' Average loss at step ', 2000, ': ', 0.023737256884574891)\n",
      "('Epoch: ', 543, ' Average loss at step ', 2813, ': ', 0.023242665555676802)\n",
      "Training time took 44.055899 seconds to run 1 epoch\n",
      "('Epoch: ', 544, ' Average loss at step ', 1000, ': ', 129.16174055480957)\n",
      "('Epoch: ', 544, ' Average loss at step ', 2000, ': ', 128.61447539520265)\n",
      "('Epoch: ', 544, ' Average loss at step ', 3000, ': ', 127.42126664733887)\n",
      "('Epoch: ', 544, ' Average loss at step ', 4000, ': ', 127.2774277191162)\n",
      "('Epoch: ', 544, ' Average loss at step ', 4373, ': ', 126.11400462735084)\n",
      "('Epoch: ', 544, ' Average loss at step ', 761, ': ', 8890.1417178505344)\n",
      "('Epoch: ', 544, ' Average loss at step ', 782, ': ', 10233.802791268206)\n",
      "('Epoch: ', 544, ' Average loss at step ', 787, ': ', 13.069777403775669)\n",
      "('Epoch: ', 544, ' Average loss at step ', 1000, ': ', 4.109354813098907)\n",
      "('Epoch: ', 544, ' Average loss at step ', 2000, ': ', 4.0571900696754453)\n",
      "('Epoch: ', 544, ' Average loss at step ', 2813, ': ', 4.1169165108591468)\n",
      "Training time took 97.731345 seconds to run 1 epoch\n",
      "('Epoch: ', 545, ' Average loss at step ', 1000, ': ', 0.025675861656665803)\n",
      "('Epoch: ', 545, ' Average loss at step ', 2000, ': ', 0.023727514922618865)\n",
      "('Epoch: ', 545, ' Average loss at step ', 2813, ': ', 0.023121657776715134)\n",
      "Training time took 44.033117 seconds to run 1 epoch\n",
      "('Epoch: ', 546, ' Average loss at step ', 1000, ': ', 129.08176089477539)\n",
      "('Epoch: ', 546, ' Average loss at step ', 2000, ': ', 128.6095393600464)\n",
      "('Epoch: ', 546, ' Average loss at step ', 3000, ': ', 128.66201168060303)\n",
      "('Epoch: ', 546, ' Average loss at step ', 4000, ': ', 129.06408879089355)\n",
      "('Epoch: ', 546, ' Average loss at step ', 4373, ': ', 126.31763368011802)\n",
      "('Epoch: ', 546, ' Average loss at step ', 761, ': ', 8730.5884675678462)\n",
      "('Epoch: ', 546, ' Average loss at step ', 782, ': ', 10233.996056863196)\n",
      "('Epoch: ', 546, ' Average loss at step ', 787, ': ', 13.033519855285721)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 546, ' Average loss at step ', 1000, ': ', 4.0066948027610776)\n",
      "('Epoch: ', 546, ' Average loss at step ', 2000, ': ', 3.9173568058013917)\n",
      "('Epoch: ', 546, ' Average loss at step ', 2813, ': ', 4.0858403767270994)\n",
      "Training time took 97.774298 seconds to run 1 epoch\n",
      "('Epoch: ', 547, ' Average loss at step ', 1000, ': ', 0.025307311236858369)\n",
      "('Epoch: ', 547, ' Average loss at step ', 2000, ': ', 0.023656468510627745)\n",
      "('Epoch: ', 547, ' Average loss at step ', 2813, ': ', 0.023026310751590822)\n",
      "Training time took 44.038531 seconds to run 1 epoch\n",
      "('Epoch: ', 548, ' Average loss at step ', 1000, ': ', 127.50597910690307)\n",
      "('Epoch: ', 548, ' Average loss at step ', 2000, ': ', 130.62644015502929)\n",
      "('Epoch: ', 548, ' Average loss at step ', 3000, ': ', 128.16019474029542)\n",
      "('Epoch: ', 548, ' Average loss at step ', 4000, ': ', 126.84)\n",
      "('Epoch: ', 548, ' Average loss at step ', 4373, ': ', 128.6839383033014)\n",
      "('Epoch: ', 548, ' Average loss at step ', 761, ': ', 8898.7663233706826)\n",
      "('Epoch: ', 548, ' Average loss at step ', 782, ': ', 10307.813287126881)\n",
      "('Epoch: ', 548, ' Average loss at step ', 787, ': ', 12.955508483275203)\n",
      "('Epoch: ', 548, ' Average loss at step ', 1000, ': ', 4.1177178177833555)\n",
      "('Epoch: ', 548, ' Average loss at step ', 2000, ': ', 4.00517423915863)\n",
      "('Epoch: ', 548, ' Average loss at step ', 2813, ': ', 4.0522586747343317)\n",
      "Training time took 97.708129 seconds to run 1 epoch\n",
      "('Epoch: ', 549, ' Average loss at step ', 1000, ': ', 0.025710226058959961)\n",
      "('Epoch: ', 549, ' Average loss at step ', 2000, ': ', 0.023507489144802093)\n",
      "('Epoch: ', 549, ' Average loss at step ', 2813, ': ', 0.023090787268624516)\n",
      "Training time took 44.045093 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984322881921\n",
      "Hits @ 1:  0.935290193462\n",
      "Testing time took 73.351937 seconds.\n",
      "\n",
      "('Epoch: ', 550, ' Average loss at step ', 1000, ': ', 129.5541066055298)\n",
      "('Epoch: ', 550, ' Average loss at step ', 2000, ': ', 130.2670210494995)\n",
      "('Epoch: ', 550, ' Average loss at step ', 3000, ': ', 124.98116750335693)\n",
      "('Epoch: ', 550, ' Average loss at step ', 4000, ': ', 128.75071801757812)\n",
      "('Epoch: ', 550, ' Average loss at step ', 4373, ': ', 127.15053763440861)\n",
      "('Epoch: ', 550, ' Average loss at step ', 761, ': ', 8951.4032451428866)\n",
      "('Epoch: ', 550, ' Average loss at step ', 782, ': ', 10330.873705835867)\n",
      "('Epoch: ', 550, ' Average loss at step ', 787, ': ', 12.913689642462112)\n",
      "('Epoch: ', 550, ' Average loss at step ', 1000, ': ', 4.0146704130172726)\n",
      "('Epoch: ', 550, ' Average loss at step ', 2000, ': ', 3.9725633063316343)\n",
      "('Epoch: ', 550, ' Average loss at step ', 2813, ': ', 3.9868665134965493)\n",
      "Training time took 97.928221 seconds to run 1 epoch\n",
      "('Epoch: ', 551, ' Average loss at step ', 1000, ': ', 0.025271017611026764)\n",
      "('Epoch: ', 551, ' Average loss at step ', 2000, ': ', 0.023241737008094787)\n",
      "('Epoch: ', 551, ' Average loss at step ', 2813, ': ', 0.023088720631716873)\n",
      "Training time took 44.03089 seconds to run 1 epoch\n",
      "('Epoch: ', 552, ' Average loss at step ', 1000, ': ', 128.31081073760987)\n",
      "('Epoch: ', 552, ' Average loss at step ', 2000, ': ', 127.50711646270751)\n",
      "('Epoch: ', 552, ' Average loss at step ', 3000, ': ', 127.06299179077149)\n",
      "('Epoch: ', 552, ' Average loss at step ', 4000, ': ', 129.70665683746338)\n",
      "('Epoch: ', 552, ' Average loss at step ', 4373, ': ', 128.78143753543978)\n",
      "('Epoch: ', 552, ' Average loss at step ', 761, ': ', 8888.7604087428044)\n",
      "('Epoch: ', 552, ' Average loss at step ', 782, ': ', 10332.336745258483)\n",
      "('Epoch: ', 552, ' Average loss at step ', 787, ': ', 13.094249132025332)\n",
      "('Epoch: ', 552, ' Average loss at step ', 1000, ': ', 3.9991927547454833)\n",
      "('Epoch: ', 552, ' Average loss at step ', 2000, ': ', 4.0189791584014891)\n",
      "('Epoch: ', 552, ' Average loss at step ', 2813, ': ', 4.0794181218875449)\n",
      "Training time took 97.786421 seconds to run 1 epoch\n",
      "('Epoch: ', 553, ' Average loss at step ', 1000, ': ', 0.025292915284633635)\n",
      "('Epoch: ', 553, ' Average loss at step ', 2000, ': ', 0.023619215726852417)\n",
      "('Epoch: ', 553, ' Average loss at step ', 2813, ': ', 0.022773094732185889)\n",
      "Training time took 44.01183 seconds to run 1 epoch\n",
      "('Epoch: ', 554, ' Average loss at step ', 1000, ': ', 129.24368261718749)\n",
      "('Epoch: ', 554, ' Average loss at step ', 2000, ': ', 128.31991415405273)\n",
      "('Epoch: ', 554, ' Average loss at step ', 3000, ': ', 129.45197917175292)\n",
      "('Epoch: ', 554, ' Average loss at step ', 4000, ': ', 128.7120637664795)\n",
      "('Epoch: ', 554, ' Average loss at step ', 4373, ': ', 128.54204793130197)\n",
      "('Epoch: ', 554, ' Average loss at step ', 761, ': ', 8889.9175151624186)\n",
      "('Epoch: ', 554, ' Average loss at step ', 782, ': ', 10223.896425606194)\n",
      "('Epoch: ', 554, ' Average loss at step ', 787, ': ', 13.061755094212733)\n",
      "('Epoch: ', 554, ' Average loss at step ', 1000, ': ', 4.0456377758979798)\n",
      "('Epoch: ', 554, ' Average loss at step ', 2000, ': ', 4.1213118152618406)\n",
      "('Epoch: ', 554, ' Average loss at step ', 2813, ': ', 4.0310709382512888)\n",
      "Training time took 97.696114 seconds to run 1 epoch\n",
      "('Epoch: ', 555, ' Average loss at step ', 1000, ': ', 0.025153040885925293)\n",
      "('Epoch: ', 555, ' Average loss at step ', 2000, ': ', 0.023364517688751221)\n",
      "('Epoch: ', 555, ' Average loss at step ', 2813, ': ', 0.02260454549578023)\n",
      "Training time took 44.046888 seconds to run 1 epoch\n",
      "('Epoch: ', 556, ' Average loss at step ', 1000, ': ', 128.3692176361084)\n",
      "('Epoch: ', 556, ' Average loss at step ', 2000, ': ', 127.39394099426269)\n",
      "('Epoch: ', 556, ' Average loss at step ', 3000, ': ', 127.22850836944581)\n",
      "('Epoch: ', 556, ' Average loss at step ', 4000, ': ', 128.26669983673096)\n",
      "('Epoch: ', 556, ' Average loss at step ', 4373, ': ', 126.23655913978494)\n",
      "('Epoch: ', 556, ' Average loss at step ', 761, ': ', 8878.7293848941208)\n",
      "('Epoch: ', 556, ' Average loss at step ', 782, ': ', 10371.763684379001)\n",
      "('Epoch: ', 556, ' Average loss at step ', 787, ': ', 12.843823762947062)\n",
      "('Epoch: ', 556, ' Average loss at step ', 1000, ': ', 3.9066547794342039)\n",
      "('Epoch: ', 556, ' Average loss at step ', 2000, ': ', 4.0572190909385677)\n",
      "('Epoch: ', 556, ' Average loss at step ', 2813, ': ', 3.9737929516825181)\n",
      "Training time took 97.712203 seconds to run 1 epoch\n",
      "('Epoch: ', 557, ' Average loss at step ', 1000, ': ', 0.025121633291244509)\n",
      "('Epoch: ', 557, ' Average loss at step ', 2000, ': ', 0.0231517590880394)\n",
      "('Epoch: ', 557, ' Average loss at step ', 2813, ': ', 0.022837483677370794)\n",
      "Training time took 44.02547 seconds to run 1 epoch\n",
      "('Epoch: ', 558, ' Average loss at step ', 1000, ': ', 129.23399174499511)\n",
      "('Epoch: ', 558, ' Average loss at step ', 2000, ': ', 126.23442846679687)\n",
      "('Epoch: ', 558, ' Average loss at step ', 3000, ': ', 127.70178314208984)\n",
      "('Epoch: ', 558, ' Average loss at step ', 4000, ': ', 127.11027433776856)\n",
      "('Epoch: ', 558, ' Average loss at step ', 4373, ': ', 125.75296775243615)\n",
      "('Epoch: ', 558, ' Average loss at step ', 761, ': ', 8886.0101067794003)\n",
      "('Epoch: ', 558, ' Average loss at step ', 782, ': ', 10400.162531385044)\n",
      "('Epoch: ', 558, ' Average loss at step ', 787, ': ', 12.801374986274855)\n",
      "('Epoch: ', 558, ' Average loss at step ', 1000, ': ', 4.0050772581100462)\n",
      "('Epoch: ', 558, ' Average loss at step ', 2000, ': ', 4.0643548593521119)\n",
      "('Epoch: ', 558, ' Average loss at step ', 2813, ': ', 4.0947670290622806)\n",
      "Training time took 97.583399 seconds to run 1 epoch\n",
      "('Epoch: ', 559, ' Average loss at step ', 1000, ': ', 0.025049411892890928)\n",
      "('Epoch: ', 559, ' Average loss at step ', 2000, ': ', 0.023087557673454284)\n",
      "('Epoch: ', 559, ' Average loss at step ', 2813, ': ', 0.022619204347944025)\n",
      "Training time took 44.014553 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984656437625\n",
      "Hits @ 1:  0.933755837225\n",
      "Testing time took 73.39329 seconds.\n",
      "\n",
      "('Epoch: ', 560, ' Average loss at step ', 1000, ': ', 126.59201547241211)\n",
      "('Epoch: ', 560, ' Average loss at step ', 2000, ': ', 128.62081984710693)\n",
      "('Epoch: ', 560, ' Average loss at step ', 3000, ': ', 126.91083544921875)\n",
      "('Epoch: ', 560, ' Average loss at step ', 4000, ': ', 129.97388289642333)\n",
      "('Epoch: ', 560, ' Average loss at step ', 4373, ': ', 130.27948463604014)\n",
      "('Epoch: ', 560, ' Average loss at step ', 761, ': ', 8853.1683092619242)\n",
      "('Epoch: ', 560, ' Average loss at step ', 782, ': ', 10289.209349491837)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 560, ' Average loss at step ', 787, ': ', 12.853927094214441)\n",
      "('Epoch: ', 560, ' Average loss at step ', 1000, ': ', 4.0952576174736022)\n",
      "('Epoch: ', 560, ' Average loss at step ', 2000, ': ', 3.9213390851020815)\n",
      "('Epoch: ', 560, ' Average loss at step ', 2813, ': ', 3.9970205335194255)\n",
      "Training time took 97.86933 seconds to run 1 epoch\n",
      "('Epoch: ', 561, ' Average loss at step ', 1000, ': ', 0.025060112655162812)\n",
      "('Epoch: ', 561, ' Average loss at step ', 2000, ': ', 0.023165961980819702)\n",
      "('Epoch: ', 561, ' Average loss at step ', 2813, ': ', 0.022501526501378401)\n",
      "Training time took 44.034712 seconds to run 1 epoch\n",
      "('Epoch: ', 562, ' Average loss at step ', 1000, ': ', 128.21094986724853)\n",
      "('Epoch: ', 562, ' Average loss at step ', 2000, ': ', 127.72204061889649)\n",
      "('Epoch: ', 562, ' Average loss at step ', 3000, ': ', 127.94149885559082)\n",
      "('Epoch: ', 562, ' Average loss at step ', 4000, ': ', 128.41853339004516)\n",
      "('Epoch: ', 562, ' Average loss at step ', 4373, ': ', 128.84541979143697)\n",
      "('Epoch: ', 562, ' Average loss at step ', 761, ': ', 8976.3008236533715)\n",
      "('Epoch: ', 562, ' Average loss at step ', 782, ': ', 10313.770833541734)\n",
      "('Epoch: ', 562, ' Average loss at step ', 787, ': ', 12.753404489910329)\n",
      "('Epoch: ', 562, ' Average loss at step ', 1000, ': ', 4.0483278403282164)\n",
      "('Epoch: ', 562, ' Average loss at step ', 2000, ': ', 4.0699955329895019)\n",
      "('Epoch: ', 562, ' Average loss at step ', 2813, ': ', 4.0208271965017461)\n",
      "Training time took 97.775827 seconds to run 1 epoch\n",
      "('Epoch: ', 563, ' Average loss at step ', 1000, ': ', 0.024713236689567566)\n",
      "('Epoch: ', 563, ' Average loss at step ', 2000, ': ', 0.023044445753097532)\n",
      "('Epoch: ', 563, ' Average loss at step ', 2813, ': ', 0.022353026520442493)\n",
      "Training time took 44.060267 seconds to run 1 epoch\n",
      "('Epoch: ', 564, ' Average loss at step ', 1000, ': ', 129.02399242401123)\n",
      "('Epoch: ', 564, ' Average loss at step ', 2000, ': ', 129.25762439727782)\n",
      "('Epoch: ', 564, ' Average loss at step ', 3000, ': ', 126.70085686492919)\n",
      "('Epoch: ', 564, ' Average loss at step ', 4000, ': ', 129.89428728485106)\n",
      "('Epoch: ', 564, ' Average loss at step ', 4373, ': ', 127.38631984751711)\n",
      "('Epoch: ', 564, ' Average loss at step ', 761, ': ', 8912.1299894634049)\n",
      "('Epoch: ', 564, ' Average loss at step ', 782, ': ', 10335.625900288092)\n",
      "('Epoch: ', 564, ' Average loss at step ', 787, ': ', 13.025872175930111)\n",
      "('Epoch: ', 564, ' Average loss at step ', 1000, ': ', 3.9841201887130739)\n",
      "('Epoch: ', 564, ' Average loss at step ', 2000, ': ', 3.8910075044631958)\n",
      "('Epoch: ', 564, ' Average loss at step ', 2813, ': ', 4.0073320372351287)\n",
      "Training time took 97.695078 seconds to run 1 epoch\n",
      "('Epoch: ', 565, ' Average loss at step ', 1000, ': ', 0.024478396594524384)\n",
      "('Epoch: ', 565, ' Average loss at step ', 2000, ': ', 0.022856403112411498)\n",
      "('Epoch: ', 565, ' Average loss at step ', 2813, ': ', 0.022750509416528522)\n",
      "Training time took 44.03736 seconds to run 1 epoch\n",
      "('Epoch: ', 566, ' Average loss at step ', 1000, ': ', 128.76681144714357)\n",
      "('Epoch: ', 566, ' Average loss at step ', 2000, ': ', 130.50580405426027)\n",
      "('Epoch: ', 566, ' Average loss at step ', 3000, ': ', 128.16687898254395)\n",
      "('Epoch: ', 566, ' Average loss at step ', 4000, ': ', 126.62388501739503)\n",
      "('Epoch: ', 566, ' Average loss at step ', 4373, ': ', 125.72683592765561)\n",
      "('Epoch: ', 566, ' Average loss at step ', 761, ': ', 8962.5244294819076)\n",
      "('Epoch: ', 566, ' Average loss at step ', 782, ': ', 10340.462836857794)\n",
      "('Epoch: ', 566, ' Average loss at step ', 787, ': ', 12.695012183589789)\n",
      "('Epoch: ', 566, ' Average loss at step ', 1000, ': ', 4.0319255056381227)\n",
      "('Epoch: ', 566, ' Average loss at step ', 2000, ': ', 4.0043092269897462)\n",
      "('Epoch: ', 566, ' Average loss at step ', 2813, ': ', 4.0984725282697259)\n",
      "Training time took 97.780465 seconds to run 1 epoch\n",
      "('Epoch: ', 567, ' Average loss at step ', 1000, ': ', 0.024764978110790252)\n",
      "('Epoch: ', 567, ' Average loss at step ', 2000, ': ', 0.022879307866096498)\n",
      "('Epoch: ', 567, ' Average loss at step ', 2813, ': ', 0.02217593554205495)\n",
      "Training time took 44.05137 seconds to run 1 epoch\n",
      "('Epoch: ', 568, ' Average loss at step ', 1000, ': ', 127.61574117279052)\n",
      "('Epoch: ', 568, ' Average loss at step ', 2000, ': ', 128.32817340850829)\n",
      "('Epoch: ', 568, ' Average loss at step ', 3000, ': ', 128.87126499938964)\n",
      "('Epoch: ', 568, ' Average loss at step ', 4000, ': ', 127.68962956237793)\n",
      "('Epoch: ', 568, ' Average loss at step ', 4373, ': ', 127.54265276590984)\n",
      "('Epoch: ', 568, ' Average loss at step ', 761, ': ', 8992.9512881630344)\n",
      "('Epoch: ', 568, ' Average loss at step ', 782, ': ', 10412.446479123319)\n",
      "('Epoch: ', 568, ' Average loss at step ', 787, ': ', 13.06188875178951)\n",
      "('Epoch: ', 568, ' Average loss at step ', 1000, ': ', 4.0546634426116945)\n",
      "('Epoch: ', 568, ' Average loss at step ', 2000, ': ', 4.0333256611824035)\n",
      "('Epoch: ', 568, ' Average loss at step ', 2813, ': ', 3.9758265235741148)\n",
      "Training time took 97.68698 seconds to run 1 epoch\n",
      "('Epoch: ', 569, ' Average loss at step ', 1000, ': ', 0.024605234265327455)\n",
      "('Epoch: ', 569, ' Average loss at step ', 2000, ': ', 0.022771929502487184)\n",
      "('Epoch: ', 569, ' Average loss at step ', 2813, ': ', 0.022124885778708997)\n",
      "Training time took 44.041499 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984389593062\n",
      "Hits @ 1:  0.934623082055\n",
      "Testing time took 73.342467 seconds.\n",
      "\n",
      "('Epoch: ', 570, ' Average loss at step ', 1000, ': ', 127.89371751403809)\n",
      "('Epoch: ', 570, ' Average loss at step ', 2000, ': ', 128.08569271850587)\n",
      "('Epoch: ', 570, ' Average loss at step ', 3000, ': ', 127.75131835937501)\n",
      "('Epoch: ', 570, ' Average loss at step ', 4000, ': ', 128.51369198608398)\n",
      "('Epoch: ', 570, ' Average loss at step ', 4373, ': ', 128.40811805314914)\n",
      "('Epoch: ', 570, ' Average loss at step ', 761, ': ', 9073.649427554481)\n",
      "('Epoch: ', 570, ' Average loss at step ', 782, ': ', 10410.34189878261)\n",
      "('Epoch: ', 570, ' Average loss at step ', 787, ': ', 12.545719498593085)\n",
      "('Epoch: ', 570, ' Average loss at step ', 1000, ': ', 3.9009947810173036)\n",
      "('Epoch: ', 570, ' Average loss at step ', 2000, ': ', 3.9422566409111024)\n",
      "('Epoch: ', 570, ' Average loss at step ', 2813, ': ', 4.0227242990080363)\n",
      "Training time took 97.626418 seconds to run 1 epoch\n",
      "('Epoch: ', 571, ' Average loss at step ', 1000, ': ', 0.024771396517753601)\n",
      "('Epoch: ', 571, ' Average loss at step ', 2000, ': ', 0.022657534956932068)\n",
      "('Epoch: ', 571, ' Average loss at step ', 2813, ': ', 0.022124093741618941)\n",
      "Training time took 44.035153 seconds to run 1 epoch\n",
      "('Epoch: ', 572, ' Average loss at step ', 1000, ': ', 128.40622743988038)\n",
      "('Epoch: ', 572, ' Average loss at step ', 2000, ': ', 127.72850650024414)\n",
      "('Epoch: ', 572, ' Average loss at step ', 3000, ': ', 128.58579804992675)\n",
      "('Epoch: ', 572, ' Average loss at step ', 4000, ': ', 127.52003121948242)\n",
      "('Epoch: ', 572, ' Average loss at step ', 4373, ': ', 129.49106372300014)\n",
      "('Epoch: ', 572, ' Average loss at step ', 761, ': ', 8916.0644524825238)\n",
      "('Epoch: ', 572, ' Average loss at step ', 782, ': ', 10444.829884938181)\n",
      "('Epoch: ', 572, ' Average loss at step ', 787, ': ', 12.393627329333745)\n",
      "('Epoch: ', 572, ' Average loss at step ', 1000, ': ', 3.9990156970024109)\n",
      "('Epoch: ', 572, ' Average loss at step ', 2000, ': ', 3.9282442402839659)\n",
      "('Epoch: ', 572, ' Average loss at step ', 2813, ': ', 4.1008504676114166)\n",
      "Training time took 97.827636 seconds to run 1 epoch\n",
      "('Epoch: ', 573, ' Average loss at step ', 1000, ': ', 0.024544231593608856)\n",
      "('Epoch: ', 573, ' Average loss at step ', 2000, ': ', 0.022492722630500794)\n",
      "('Epoch: ', 573, ' Average loss at step ', 2813, ': ', 0.021989939101223877)\n",
      "Training time took 44.049631 seconds to run 1 epoch\n",
      "('Epoch: ', 574, ' Average loss at step ', 1000, ': ', 128.18163830566405)\n",
      "('Epoch: ', 574, ' Average loss at step ', 2000, ': ', 128.32275924682617)\n",
      "('Epoch: ', 574, ' Average loss at step ', 3000, ': ', 128.58523152160643)\n",
      "('Epoch: ', 574, ' Average loss at step ', 4000, ': ', 127.45309177398681)\n",
      "('Epoch: ', 574, ' Average loss at step ', 4373, ': ', 127.36992727300172)\n",
      "('Epoch: ', 574, ' Average loss at step ', 761, ': ', 9074.167277446546)\n",
      "('Epoch: ', 574, ' Average loss at step ', 782, ': ', 10408.671366087148)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 574, ' Average loss at step ', 787, ': ', 12.689208830282585)\n",
      "('Epoch: ', 574, ' Average loss at step ', 1000, ': ', 3.9624787178039549)\n",
      "('Epoch: ', 574, ' Average loss at step ', 2000, ': ', 4.0766903243064885)\n",
      "('Epoch: ', 574, ' Average loss at step ', 2813, ': ', 3.9900963006935681)\n",
      "Training time took 97.805695 seconds to run 1 epoch\n",
      "('Epoch: ', 575, ' Average loss at step ', 1000, ': ', 0.024541272103786468)\n",
      "('Epoch: ', 575, ' Average loss at step ', 2000, ': ', 0.022461936831474304)\n",
      "('Epoch: ', 575, ' Average loss at step ', 2813, ': ', 0.022102906932971747)\n",
      "Training time took 44.023119 seconds to run 1 epoch\n",
      "('Epoch: ', 576, ' Average loss at step ', 1000, ': ', 126.34507957458496)\n",
      "('Epoch: ', 576, ' Average loss at step ', 2000, ': ', 128.8161234512329)\n",
      "('Epoch: ', 576, ' Average loss at step ', 3000, ': ', 127.96490552520751)\n",
      "('Epoch: ', 576, ' Average loss at step ', 4000, ': ', 126.85176654052735)\n",
      "('Epoch: ', 576, ' Average loss at step ', 4373, ': ', 128.38710017870832)\n",
      "('Epoch: ', 576, ' Average loss at step ', 761, ': ', 8988.1934981496706)\n",
      "('Epoch: ', 576, ' Average loss at step ', 782, ': ', 10546.573764854753)\n",
      "('Epoch: ', 576, ' Average loss at step ', 787, ': ', 12.837741618848028)\n",
      "('Epoch: ', 576, ' Average loss at step ', 1000, ': ', 4.0174582433700561)\n",
      "('Epoch: ', 576, ' Average loss at step ', 2000, ': ', 3.9223737983703613)\n",
      "('Epoch: ', 576, ' Average loss at step ', 2813, ': ', 4.1134474171793523)\n",
      "Training time took 97.733908 seconds to run 1 epoch\n",
      "('Epoch: ', 577, ' Average loss at step ', 1000, ': ', 0.024334955036640168)\n",
      "('Epoch: ', 577, ' Average loss at step ', 2000, ': ', 0.02262428492307663)\n",
      "('Epoch: ', 577, ' Average loss at step ', 2813, ': ', 0.021822979517758186)\n",
      "Training time took 44.020863 seconds to run 1 epoch\n",
      "('Epoch: ', 578, ' Average loss at step ', 1000, ': ', 128.49063331604003)\n",
      "('Epoch: ', 578, ' Average loss at step ', 2000, ': ', 125.65000000000001)\n",
      "('Epoch: ', 578, ' Average loss at step ', 3000, ': ', 129.12703258514404)\n",
      "('Epoch: ', 578, ' Average loss at step ', 4000, ': ', 127.75955871582032)\n",
      "('Epoch: ', 578, ' Average loss at step ', 4373, ': ', 127.15288535497521)\n",
      "('Epoch: ', 578, ' Average loss at step ', 761, ': ', 8993.7495316354853)\n",
      "('Epoch: ', 578, ' Average loss at step ', 782, ': ', 10511.793415768047)\n",
      "('Epoch: ', 578, ' Average loss at step ', 787, ': ', 12.539953993780315)\n",
      "('Epoch: ', 578, ' Average loss at step ', 1000, ': ', 3.9953417730331422)\n",
      "('Epoch: ', 578, ' Average loss at step ', 2000, ': ', 4.0525036821365354)\n",
      "('Epoch: ', 578, ' Average loss at step ', 2813, ': ', 4.1082155587050719)\n",
      "Training time took 97.961595 seconds to run 1 epoch\n",
      "('Epoch: ', 579, ' Average loss at step ', 1000, ': ', 0.024292992234230041)\n",
      "('Epoch: ', 579, ' Average loss at step ', 2000, ': ', 0.022245927929878236)\n",
      "('Epoch: ', 579, ' Average loss at step ', 2813, ': ', 0.021838997531994222)\n",
      "Training time took 43.997856 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984456304203\n",
      "Hits @ 1:  0.934489659773\n",
      "Testing time took 73.337319 seconds.\n",
      "\n",
      "('Epoch: ', 580, ' Average loss at step ', 1000, ': ', 128.4710115814209)\n",
      "('Epoch: ', 580, ' Average loss at step ', 2000, ': ', 128.71180351257325)\n",
      "('Epoch: ', 580, ' Average loss at step ', 3000, ': ', 128.19923754119873)\n",
      "('Epoch: ', 580, ' Average loss at step ', 4000, ': ', 126.53591860961915)\n",
      "('Epoch: ', 580, ' Average loss at step ', 4373, ': ', 127.81214178762129)\n",
      "('Epoch: ', 580, ' Average loss at step ', 761, ': ', 9062.7398617393101)\n",
      "('Epoch: ', 580, ' Average loss at step ', 782, ': ', 10530.70292556118)\n",
      "('Epoch: ', 580, ' Average loss at step ', 787, ': ', 12.215788739328167)\n",
      "('Epoch: ', 580, ' Average loss at step ', 1000, ': ', 4.0172828927040101)\n",
      "('Epoch: ', 580, ' Average loss at step ', 2000, ': ', 4.0550056238174434)\n",
      "('Epoch: ', 580, ' Average loss at step ', 2813, ': ', 4.0194405170497047)\n",
      "Training time took 97.785472 seconds to run 1 epoch\n",
      "('Epoch: ', 581, ' Average loss at step ', 1000, ': ', 0.024374481916427611)\n",
      "('Epoch: ', 581, ' Average loss at step ', 2000, ': ', 0.022186937391757967)\n",
      "('Epoch: ', 581, ' Average loss at step ', 2813, ': ', 0.021835764640657774)\n",
      "Training time took 44.044369 seconds to run 1 epoch\n",
      "('Epoch: ', 582, ' Average loss at step ', 1000, ': ', 127.70029278564454)\n",
      "('Epoch: ', 582, ' Average loss at step ', 2000, ': ', 126.86708079528809)\n",
      "('Epoch: ', 582, ' Average loss at step ', 3000, ': ', 128.61258586883545)\n",
      "('Epoch: ', 582, ' Average loss at step ', 4000, ': ', 129.17977750396727)\n",
      "('Epoch: ', 582, ' Average loss at step ', 4373, ': ', 128.92473118279571)\n",
      "('Epoch: ', 582, ' Average loss at step ', 761, ': ', 9095.6843107524674)\n",
      "('Epoch: ', 582, ' Average loss at step ', 782, ': ', 10502.105017980753)\n",
      "('Epoch: ', 582, ' Average loss at step ', 787, ': ', 12.639865966243597)\n",
      "('Epoch: ', 582, ' Average loss at step ', 1000, ': ', 4.0264333820343019)\n",
      "('Epoch: ', 582, ' Average loss at step ', 2000, ': ', 3.9593696026802063)\n",
      "('Epoch: ', 582, ' Average loss at step ', 2813, ': ', 3.887537653810285)\n",
      "Training time took 97.856304 seconds to run 1 epoch\n",
      "('Epoch: ', 583, ' Average loss at step ', 1000, ': ', 0.023933755457401274)\n",
      "('Epoch: ', 583, ' Average loss at step ', 2000, ': ', 0.022266327261924745)\n",
      "('Epoch: ', 583, ' Average loss at step ', 2813, ': ', 0.021645815648468843)\n",
      "Training time took 44.016456 seconds to run 1 epoch\n",
      "('Epoch: ', 584, ' Average loss at step ', 1000, ': ', 129.23710066986084)\n",
      "('Epoch: ', 584, ' Average loss at step ', 2000, ': ', 128.54386585235596)\n",
      "('Epoch: ', 584, ' Average loss at step ', 3000, ': ', 127.03560489654541)\n",
      "('Epoch: ', 584, ' Average loss at step ', 4000, ': ', 128.66256975555419)\n",
      "('Epoch: ', 584, ' Average loss at step ', 4373, ': ', 129.21915392721854)\n",
      "('Epoch: ', 584, ' Average loss at step ', 761, ': ', 9152.5190577456833)\n",
      "('Epoch: ', 584, ' Average loss at step ', 782, ': ', 10581.494682673456)\n",
      "('Epoch: ', 584, ' Average loss at step ', 787, ': ', 12.33628722183577)\n",
      "('Epoch: ', 584, ' Average loss at step ', 1000, ': ', 4.040247274398804)\n",
      "('Epoch: ', 584, ' Average loss at step ', 2000, ': ', 3.89315562915802)\n",
      "('Epoch: ', 584, ' Average loss at step ', 2813, ': ', 3.9983045138748996)\n",
      "Training time took 97.749561 seconds to run 1 epoch\n",
      "('Epoch: ', 585, ' Average loss at step ', 1000, ': ', 0.02399843418598175)\n",
      "('Epoch: ', 585, ' Average loss at step ', 2000, ': ', 0.022342882335186005)\n",
      "('Epoch: ', 585, ' Average loss at step ', 2813, ': ', 0.021711166489300469)\n",
      "Training time took 44.023896 seconds to run 1 epoch\n",
      "('Epoch: ', 586, ' Average loss at step ', 1000, ': ', 129.02969925689698)\n",
      "('Epoch: ', 586, ' Average loss at step ', 2000, ': ', 127.55883971405029)\n",
      "('Epoch: ', 586, ' Average loss at step ', 3000, ': ', 128.2875220336914)\n",
      "('Epoch: ', 586, ' Average loss at step ', 4000, ': ', 127.97290990447998)\n",
      "('Epoch: ', 586, ' Average loss at step ', 4373, ': ', 130.18886627689486)\n",
      "('Epoch: ', 586, ' Average loss at step ', 761, ': ', 9106.5522216796871)\n",
      "('Epoch: ', 586, ' Average loss at step ', 782, ': ', 10509.226303667174)\n",
      "('Epoch: ', 586, ' Average loss at step ', 787, ': ', 12.354546914573843)\n",
      "('Epoch: ', 586, ' Average loss at step ', 1000, ': ', 3.9002359957695005)\n",
      "('Epoch: ', 586, ' Average loss at step ', 2000, ': ', 3.9237052979469298)\n",
      "('Epoch: ', 586, ' Average loss at step ', 2813, ': ', 3.9617322618738182)\n",
      "Training time took 97.863454 seconds to run 1 epoch\n",
      "('Epoch: ', 587, ' Average loss at step ', 1000, ': ', 0.02399311399459839)\n",
      "('Epoch: ', 587, ' Average loss at step ', 2000, ': ', 0.022154233872890474)\n",
      "('Epoch: ', 587, ' Average loss at step ', 2813, ': ', 0.021208137420597923)\n",
      "Training time took 44.04683 seconds to run 1 epoch\n",
      "('Epoch: ', 588, ' Average loss at step ', 1000, ': ', 128.28884700775146)\n",
      "('Epoch: ', 588, ' Average loss at step ', 2000, ': ', 129.80079897308349)\n",
      "('Epoch: ', 588, ' Average loss at step ', 3000, ': ', 126.43051748657227)\n",
      "('Epoch: ', 588, ' Average loss at step ', 4000, ': ', 127.85496288299561)\n",
      "('Epoch: ', 588, ' Average loss at step ', 4373, ': ', 128.57080320132675)\n",
      "('Epoch: ', 588, ' Average loss at step ', 761, ': ', 9100.1139577765207)\n",
      "('Epoch: ', 588, ' Average loss at step ', 782, ': ', 10538.745624849951)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 588, ' Average loss at step ', 787, ': ', 12.64852655449593)\n",
      "('Epoch: ', 588, ' Average loss at step ', 1000, ': ', 3.8831228165626528)\n",
      "('Epoch: ', 588, ' Average loss at step ', 2000, ': ', 3.9539082937240599)\n",
      "('Epoch: ', 588, ' Average loss at step ', 2813, ': ', 3.8455746320668114)\n",
      "Training time took 97.796593 seconds to run 1 epoch\n",
      "('Epoch: ', 589, ' Average loss at step ', 1000, ': ', 0.024088794350624085)\n",
      "('Epoch: ', 589, ' Average loss at step ', 2000, ': ', 0.021802035570144655)\n",
      "('Epoch: ', 589, ' Average loss at step ', 2813, ': ', 0.021667968169808975)\n",
      "Training time took 44.035259 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984589726484\n",
      "Hits @ 1:  0.935623749166\n",
      "Testing time took 73.317199 seconds.\n",
      "\n",
      "('Epoch: ', 590, ' Average loss at step ', 1000, ': ', 127.9954295501709)\n",
      "('Epoch: ', 590, ' Average loss at step ', 2000, ': ', 128.41293481445314)\n",
      "('Epoch: ', 590, ' Average loss at step ', 3000, ': ', 128.19550109100342)\n",
      "('Epoch: ', 590, ' Average loss at step ', 4000, ': ', 127.04104720306397)\n",
      "('Epoch: ', 590, ' Average loss at step ', 4373, ': ', 128.03763440860214)\n",
      "('Epoch: ', 590, ' Average loss at step ', 761, ': ', 9052.8675562808385)\n",
      "('Epoch: ', 590, ' Average loss at step ', 782, ': ', 10578.852819777328)\n",
      "('Epoch: ', 590, ' Average loss at step ', 787, ': ', 12.399060158935818)\n",
      "('Epoch: ', 590, ' Average loss at step ', 1000, ': ', 4.0268874268531798)\n",
      "('Epoch: ', 590, ' Average loss at step ', 2000, ': ', 3.9544770941734315)\n",
      "('Epoch: ', 590, ' Average loss at step ', 2813, ': ', 3.8840750144620246)\n",
      "Training time took 97.832472 seconds to run 1 epoch\n",
      "('Epoch: ', 591, ' Average loss at step ', 1000, ': ', 0.023880802512168883)\n",
      "('Epoch: ', 591, ' Average loss at step ', 2000, ': ', 0.021859252333641051)\n",
      "('Epoch: ', 591, ' Average loss at step ', 2813, ': ', 0.021422093504755369)\n",
      "Training time took 44.051607 seconds to run 1 epoch\n",
      "('Epoch: ', 592, ' Average loss at step ', 1000, ': ', 125.17003591918946)\n",
      "('Epoch: ', 592, ' Average loss at step ', 2000, ': ', 127.0975223312378)\n",
      "('Epoch: ', 592, ' Average loss at step ', 3000, ': ', 128.72337224578857)\n",
      "('Epoch: ', 592, ' Average loss at step ', 4000, ': ', 126.08279649353027)\n",
      "('Epoch: ', 592, ' Average loss at step ', 4373, ': ', 133.79269060524561)\n",
      "('Epoch: ', 592, ' Average loss at step ', 761, ': ', 9119.5109773334698)\n",
      "('Epoch: ', 592, ' Average loss at step ', 782, ': ', 10606.472055432738)\n",
      "('Epoch: ', 592, ' Average loss at step ', 787, ': ', 12.354085868854863)\n",
      "('Epoch: ', 592, ' Average loss at step ', 1000, ': ', 3.9677081298828125)\n",
      "('Epoch: ', 592, ' Average loss at step ', 2000, ': ', 4.0329470300674437)\n",
      "('Epoch: ', 592, ' Average loss at step ', 2813, ': ', 3.995191308665158)\n",
      "Training time took 97.748203 seconds to run 1 epoch\n",
      "('Epoch: ', 593, ' Average loss at step ', 1000, ': ', 0.024032112717628479)\n",
      "('Epoch: ', 593, ' Average loss at step ', 2000, ': ', 0.021678267121315001)\n",
      "('Epoch: ', 593, ' Average loss at step ', 2813, ': ', 0.021438325420389034)\n",
      "Training time took 44.031033 seconds to run 1 epoch\n",
      "('Epoch: ', 594, ' Average loss at step ', 1000, ': ', 128.63383286285401)\n",
      "('Epoch: ', 594, ' Average loss at step ', 2000, ': ', 127.25)\n",
      "('Epoch: ', 594, ' Average loss at step ', 3000, ': ', 128.83137738800048)\n",
      "('Epoch: ', 594, ' Average loss at step ', 4000, ': ', 127.09676474761963)\n",
      "('Epoch: ', 594, ' Average loss at step ', 4373, ': ', 126.99218996109501)\n",
      "('Epoch: ', 594, ' Average loss at step ', 761, ': ', 9194.4604125976566)\n",
      "('Epoch: ', 594, ' Average loss at step ', 782, ': ', 10561.124437945142)\n",
      "('Epoch: ', 594, ' Average loss at step ', 787, ': ', 12.327954872873903)\n",
      "('Epoch: ', 594, ' Average loss at step ', 1000, ': ', 3.9093570914268492)\n",
      "('Epoch: ', 594, ' Average loss at step ', 2000, ': ', 3.9645036458969116)\n",
      "('Epoch: ', 594, ' Average loss at step ', 2813, ': ', 3.9938212873900465)\n",
      "Training time took 97.729527 seconds to run 1 epoch\n",
      "('Epoch: ', 595, ' Average loss at step ', 1000, ': ', 0.02368878048658371)\n",
      "('Epoch: ', 595, ' Average loss at step ', 2000, ': ', 0.021744313180446624)\n",
      "('Epoch: ', 595, ' Average loss at step ', 2813, ': ', 0.021457561131181389)\n",
      "Training time took 44.028316 seconds to run 1 epoch\n",
      "('Epoch: ', 596, ' Average loss at step ', 1000, ': ', 128.54419409179687)\n",
      "('Epoch: ', 596, ' Average loss at step ', 2000, ': ', 129.00917849731445)\n",
      "('Epoch: ', 596, ' Average loss at step ', 3000, ': ', 126.40638848114014)\n",
      "('Epoch: ', 596, ' Average loss at step ', 4000, ': ', 126.65671594238282)\n",
      "('Epoch: ', 596, ' Average loss at step ', 4373, ': ', 131.47849462365591)\n",
      "('Epoch: ', 596, ' Average loss at step ', 761, ': ', 9172.1909031918167)\n",
      "('Epoch: ', 596, ' Average loss at step ', 782, ': ', 10594.698812369958)\n",
      "('Epoch: ', 596, ' Average loss at step ', 787, ': ', 12.49073410276845)\n",
      "('Epoch: ', 596, ' Average loss at step ', 1000, ': ', 4.0254550681114196)\n",
      "('Epoch: ', 596, ' Average loss at step ', 2000, ': ', 3.8505087246894836)\n",
      "('Epoch: ', 596, ' Average loss at step ', 2813, ': ', 3.861953668993682)\n",
      "Training time took 97.68534 seconds to run 1 epoch\n",
      "('Epoch: ', 597, ' Average loss at step ', 1000, ': ', 0.023641828417778014)\n",
      "('Epoch: ', 597, ' Average loss at step ', 2000, ': ', 0.021633664608001708)\n",
      "('Epoch: ', 597, ' Average loss at step ', 2813, ': ', 0.02120559387312734)\n",
      "Training time took 44.028258 seconds to run 1 epoch\n",
      "('Epoch: ', 598, ' Average loss at step ', 1000, ': ', 128.15163817977904)\n",
      "('Epoch: ', 598, ' Average loss at step ', 2000, ': ', 129.42068976593018)\n",
      "('Epoch: ', 598, ' Average loss at step ', 3000, ': ', 127.44331977081299)\n",
      "('Epoch: ', 598, ' Average loss at step ', 4000, ': ', 127.64832593154907)\n",
      "('Epoch: ', 598, ' Average loss at step ', 4373, ': ', 129.43564162715788)\n",
      "('Epoch: ', 598, ' Average loss at step ', 761, ': ', 9188.4466135125404)\n",
      "('Epoch: ', 598, ' Average loss at step ', 782, ': ', 10608.515157975553)\n",
      "('Epoch: ', 598, ' Average loss at step ', 787, ': ', 12.429282267281724)\n",
      "('Epoch: ', 598, ' Average loss at step ', 1000, ': ', 4.053041431427002)\n",
      "('Epoch: ', 598, ' Average loss at step ', 2000, ': ', 3.8706132006645202)\n",
      "('Epoch: ', 598, ' Average loss at step ', 2813, ': ', 3.9927580679578734)\n",
      "Training time took 97.801889 seconds to run 1 epoch\n",
      "('Epoch: ', 599, ' Average loss at step ', 1000, ': ', 0.023489848077297211)\n",
      "('Epoch: ', 599, ' Average loss at step ', 2000, ': ', 0.021572666347026825)\n",
      "('Epoch: ', 599, ' Average loss at step ', 2813, ': ', 0.021277649355639378)\n",
      "Training time took 44.017182 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.985323549033\n",
      "Hits @ 1:  0.93509006004\n",
      "Testing time took 73.418786 seconds.\n",
      "\n",
      "('Epoch: ', 600, ' Average loss at step ', 1000, ': ', 127.7536124420166)\n",
      "('Epoch: ', 600, ' Average loss at step ', 2000, ': ', 127.57442727661133)\n",
      "('Epoch: ', 600, ' Average loss at step ', 3000, ': ', 128.51651222991944)\n",
      "('Epoch: ', 600, ' Average loss at step ', 4000, ': ', 128.62092907714845)\n",
      "('Epoch: ', 600, ' Average loss at step ', 4373, ': ', 128.06691988052862)\n",
      "('Epoch: ', 600, ' Average loss at step ', 761, ': ', 9145.5077206260285)\n",
      "('Epoch: ', 600, ' Average loss at step ', 782, ': ', 10656.188943586947)\n",
      "('Epoch: ', 600, ' Average loss at step ', 787, ': ', 12.184272712726933)\n",
      "('Epoch: ', 600, ' Average loss at step ', 1000, ': ', 3.8474510111808775)\n",
      "('Epoch: ', 600, ' Average loss at step ', 2000, ': ', 3.9661011724472046)\n",
      "('Epoch: ', 600, ' Average loss at step ', 2813, ': ', 4.0511551531664844)\n",
      "Training time took 97.741213 seconds to run 1 epoch\n",
      "('Epoch: ', 601, ' Average loss at step ', 1000, ': ', 0.023225268065929412)\n",
      "('Epoch: ', 601, ' Average loss at step ', 2000, ': ', 0.021507466316223144)\n",
      "('Epoch: ', 601, ' Average loss at step ', 2813, ': ', 0.021445473573477983)\n",
      "Training time took 44.022034 seconds to run 1 epoch\n",
      "('Epoch: ', 602, ' Average loss at step ', 1000, ': ', 128.07623928833007)\n",
      "('Epoch: ', 602, ' Average loss at step ', 2000, ': ', 127.05428507232666)\n",
      "('Epoch: ', 602, ' Average loss at step ', 3000, ': ', 128.39005288696288)\n",
      "('Epoch: ', 602, ' Average loss at step ', 4000, ': ', 127.02306308746338)\n",
      "('Epoch: ', 602, ' Average loss at step ', 4373, ': ', 129.46256403769218)\n",
      "('Epoch: ', 602, ' Average loss at step ', 761, ': ', 9093.0754156815383)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 602, ' Average loss at step ', 782, ': ', 10601.197194977392)\n",
      "('Epoch: ', 602, ' Average loss at step ', 787, ': ', 12.372660924460142)\n",
      "('Epoch: ', 602, ' Average loss at step ', 1000, ': ', 3.9723349542617798)\n",
      "('Epoch: ', 602, ' Average loss at step ', 2000, ': ', 3.9125055584907531)\n",
      "('Epoch: ', 602, ' Average loss at step ', 2813, ': ', 3.8828856980272115)\n",
      "Training time took 97.711426 seconds to run 1 epoch\n",
      "('Epoch: ', 603, ' Average loss at step ', 1000, ': ', 0.023422509729862213)\n",
      "('Epoch: ', 603, ' Average loss at step ', 2000, ': ', 0.021453769981861114)\n",
      "('Epoch: ', 603, ' Average loss at step ', 2813, ': ', 0.020854274554205646)\n",
      "Training time took 44.007267 seconds to run 1 epoch\n",
      "('Epoch: ', 604, ' Average loss at step ', 1000, ': ', 129.30240153884887)\n",
      "('Epoch: ', 604, ' Average loss at step ', 2000, ': ', 127.69938700866699)\n",
      "('Epoch: ', 604, ' Average loss at step ', 3000, ': ', 128.29219112014769)\n",
      "('Epoch: ', 604, ' Average loss at step ', 4000, ': ', 128.23763209533692)\n",
      "('Epoch: ', 604, ' Average loss at step ', 4373, ': ', 128.44952017261136)\n",
      "('Epoch: ', 604, ' Average loss at step ', 761, ': ', 9102.4143137078536)\n",
      "('Epoch: ', 604, ' Average loss at step ', 782, ': ', 10644.575158425696)\n",
      "('Epoch: ', 604, ' Average loss at step ', 787, ': ', 12.248096054746904)\n",
      "('Epoch: ', 604, ' Average loss at step ', 1000, ': ', 3.8850522732734678)\n",
      "('Epoch: ', 604, ' Average loss at step ', 2000, ': ', 3.8891631889343263)\n",
      "('Epoch: ', 604, ' Average loss at step ', 2813, ': ', 3.8535607401373353)\n",
      "Training time took 97.888283 seconds to run 1 epoch\n",
      "('Epoch: ', 605, ' Average loss at step ', 1000, ': ', 0.023352921009063721)\n",
      "('Epoch: ', 605, ' Average loss at step ', 2000, ': ', 0.021316608011722565)\n",
      "('Epoch: ', 605, ' Average loss at step ', 2813, ': ', 0.020958700276947961)\n",
      "Training time took 44.020707 seconds to run 1 epoch\n",
      "('Epoch: ', 606, ' Average loss at step ', 1000, ': ', 128.36196533966066)\n",
      "('Epoch: ', 606, ' Average loss at step ', 2000, ': ', 128.56029464721681)\n",
      "('Epoch: ', 606, ' Average loss at step ', 3000, ': ', 128.52674493408202)\n",
      "('Epoch: ', 606, ' Average loss at step ', 4000, ': ', 127.93569682312011)\n",
      "('Epoch: ', 606, ' Average loss at step ', 4373, ': ', 128.68351327219318)\n",
      "('Epoch: ', 606, ' Average loss at step ', 761, ': ', 9233.1703523334709)\n",
      "('Epoch: ', 606, ' Average loss at step ', 782, ': ', 10694.718719990396)\n",
      "('Epoch: ', 606, ' Average loss at step ', 787, ': ', 12.320083032127554)\n",
      "('Epoch: ', 606, ' Average loss at step ', 1000, ': ', 3.9127568192481994)\n",
      "('Epoch: ', 606, ' Average loss at step ', 2000, ': ', 3.9145824012756347)\n",
      "('Epoch: ', 606, ' Average loss at step ', 2813, ': ', 3.9559534371192822)\n",
      "Training time took 97.808169 seconds to run 1 epoch\n",
      "('Epoch: ', 607, ' Average loss at step ', 1000, ': ', 0.023051189601421357)\n",
      "('Epoch: ', 607, ' Average loss at step ', 2000, ': ', 0.021406989455223083)\n",
      "('Epoch: ', 607, ' Average loss at step ', 2813, ': ', 0.021024349801646077)\n",
      "Training time took 44.055547 seconds to run 1 epoch\n",
      "('Epoch: ', 608, ' Average loss at step ', 1000, ': ', 128.76565974426271)\n",
      "('Epoch: ', 608, ' Average loss at step ', 2000, ': ', 128.19921072387694)\n",
      "('Epoch: ', 608, ' Average loss at step ', 3000, ': ', 127.33480225372314)\n",
      "('Epoch: ', 608, ' Average loss at step ', 4000, ': ', 128.25769219970704)\n",
      "('Epoch: ', 608, ' Average loss at step ', 4373, ': ', 126.98928351043374)\n",
      "('Epoch: ', 608, ' Average loss at step ', 761, ': ', 9234.3980153937082)\n",
      "('Epoch: ', 608, ' Average loss at step ', 782, ': ', 10582.463461432659)\n",
      "('Epoch: ', 608, ' Average loss at step ', 787, ': ', 12.241842978479905)\n",
      "('Epoch: ', 608, ' Average loss at step ', 1000, ': ', 3.8752654733657836)\n",
      "('Epoch: ', 608, ' Average loss at step ', 2000, ': ', 3.8360962705612183)\n",
      "('Epoch: ', 608, ' Average loss at step ', 2813, ': ', 4.0098383385559604)\n",
      "Training time took 97.793251 seconds to run 1 epoch\n",
      "('Epoch: ', 609, ' Average loss at step ', 1000, ': ', 0.023459697663784026)\n",
      "('Epoch: ', 609, ' Average loss at step ', 2000, ': ', 0.021183702528476716)\n",
      "('Epoch: ', 609, ' Average loss at step ', 2813, ': ', 0.02090570881155324)\n",
      "Training time took 44.020572 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984989993329\n",
      "Hits @ 1:  0.93509006004\n",
      "Testing time took 73.358285 seconds.\n",
      "\n",
      "('Epoch: ', 610, ' Average loss at step ', 1000, ': ', 129.79120762634278)\n",
      "('Epoch: ', 610, ' Average loss at step ', 2000, ': ', 124.43848324584961)\n",
      "('Epoch: ', 610, ' Average loss at step ', 3000, ': ', 129.3545772705078)\n",
      "('Epoch: ', 610, ' Average loss at step ', 4000, ': ', 128.53002667236328)\n",
      "('Epoch: ', 610, ' Average loss at step ', 4373, ': ', 128.36021505376345)\n",
      "('Epoch: ', 610, ' Average loss at step ', 761, ': ', 9245.1951390316608)\n",
      "('Epoch: ', 610, ' Average loss at step ', 782, ': ', 10781.314215548975)\n",
      "('Epoch: ', 610, ' Average loss at step ', 787, ': ', 12.065639637808763)\n",
      "('Epoch: ', 610, ' Average loss at step ', 1000, ': ', 3.8980596742630005)\n",
      "('Epoch: ', 610, ' Average loss at step ', 2000, ': ', 3.9449103174209594)\n",
      "('Epoch: ', 610, ' Average loss at step ', 2813, ': ', 3.8711923695550174)\n",
      "Training time took 97.817126 seconds to run 1 epoch\n",
      "('Epoch: ', 611, ' Average loss at step ', 1000, ': ', 0.023343886971473694)\n",
      "('Epoch: ', 611, ' Average loss at step ', 2000, ': ', 0.021088866114616394)\n",
      "('Epoch: ', 611, ' Average loss at step ', 2813, ': ', 0.020518814548483037)\n",
      "Training time took 44.045906 seconds to run 1 epoch\n",
      "('Epoch: ', 612, ' Average loss at step ', 1000, ': ', 129.44368685150147)\n",
      "('Epoch: ', 612, ' Average loss at step ', 2000, ': ', 126.88029953002929)\n",
      "('Epoch: ', 612, ' Average loss at step ', 3000, ': ', 126.82876620483398)\n",
      "('Epoch: ', 612, ' Average loss at step ', 4000, ': ', 127.95045041275024)\n",
      "('Epoch: ', 612, ' Average loss at step ', 4373, ': ', 129.40668696741903)\n",
      "('Epoch: ', 612, ' Average loss at step ', 761, ': ', 9284.5380197625418)\n",
      "('Epoch: ', 612, ' Average loss at step ', 782, ': ', 10673.213845305498)\n",
      "('Epoch: ', 612, ' Average loss at step ', 787, ': ', 11.983806642867227)\n",
      "('Epoch: ', 612, ' Average loss at step ', 1000, ': ', 3.85870307970047)\n",
      "('Epoch: ', 612, ' Average loss at step ', 2000, ': ', 3.8487307105064392)\n",
      "('Epoch: ', 612, ' Average loss at step ', 2813, ': ', 3.9216112791023816)\n",
      "Training time took 97.738975 seconds to run 1 epoch\n",
      "('Epoch: ', 613, ' Average loss at step ', 1000, ': ', 0.023163145482540129)\n",
      "('Epoch: ', 613, ' Average loss at step ', 2000, ': ', 0.021213170289993286)\n",
      "('Epoch: ', 613, ' Average loss at step ', 2813, ': ', 0.020726450044533301)\n",
      "Training time took 44.071028 seconds to run 1 epoch\n",
      "('Epoch: ', 614, ' Average loss at step ', 1000, ': ', 127.90237086486816)\n",
      "('Epoch: ', 614, ' Average loss at step ', 2000, ': ', 128.23656777191161)\n",
      "('Epoch: ', 614, ' Average loss at step ', 3000, ': ', 129.52490716552734)\n",
      "('Epoch: ', 614, ' Average loss at step ', 4000, ': ', 126.39075286865234)\n",
      "('Epoch: ', 614, ' Average loss at step ', 4373, ': ', 127.48923607282741)\n",
      "('Epoch: ', 614, ' Average loss at step ', 761, ': ', 9233.3254156815383)\n",
      "('Epoch: ', 614, ' Average loss at step ', 782, ': ', 10722.281921464868)\n",
      "('Epoch: ', 614, ' Average loss at step ', 787, ': ', 12.047880560993844)\n",
      "('Epoch: ', 614, ' Average loss at step ', 1000, ': ', 4.0024816880226135)\n",
      "('Epoch: ', 614, ' Average loss at step ', 2000, ': ', 3.907139407157898)\n",
      "('Epoch: ', 614, ' Average loss at step ', 2813, ': ', 3.8292609864267808)\n",
      "Training time took 97.699653 seconds to run 1 epoch\n",
      "('Epoch: ', 615, ' Average loss at step ', 1000, ': ', 0.022714234292507171)\n",
      "('Epoch: ', 615, ' Average loss at step ', 2000, ': ', 0.020941232204437256)\n",
      "('Epoch: ', 615, ' Average loss at step ', 2813, ': ', 0.020955586081067918)\n",
      "Training time took 44.048052 seconds to run 1 epoch\n",
      "('Epoch: ', 616, ' Average loss at step ', 1000, ': ', 127.23566371154786)\n",
      "('Epoch: ', 616, ' Average loss at step ', 2000, ': ', 127.60189886474609)\n",
      "('Epoch: ', 616, ' Average loss at step ', 3000, ': ', 127.29308660125733)\n",
      "('Epoch: ', 616, ' Average loss at step ', 4000, ': ', 129.75524520111085)\n",
      "('Epoch: ', 616, ' Average loss at step ', 4373, ': ', 127.28572074315881)\n",
      "('Epoch: ', 616, ' Average loss at step ', 761, ': ', 9223.9010530170635)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 616, ' Average loss at step ', 782, ': ', 10680.289836497679)\n",
      "('Epoch: ', 616, ' Average loss at step ', 787, ': ', 12.013771904030525)\n",
      "('Epoch: ', 616, ' Average loss at step ', 1000, ': ', 4.0506985797882082)\n",
      "('Epoch: ', 616, ' Average loss at step ', 2000, ': ', 3.8775058698654177)\n",
      "('Epoch: ', 616, ' Average loss at step ', 2813, ': ', 3.9251988503733291)\n",
      "Training time took 97.873475 seconds to run 1 epoch\n",
      "('Epoch: ', 617, ' Average loss at step ', 1000, ': ', 0.022997026562690735)\n",
      "('Epoch: ', 617, ' Average loss at step ', 2000, ': ', 0.020924839854240419)\n",
      "('Epoch: ', 617, ' Average loss at step ', 2813, ': ', 0.020483461947276675)\n",
      "Training time took 44.01526 seconds to run 1 epoch\n",
      "('Epoch: ', 618, ' Average loss at step ', 1000, ': ', 129.2581171646118)\n",
      "('Epoch: ', 618, ' Average loss at step ', 2000, ': ', 127.27870542907715)\n",
      "('Epoch: ', 618, ' Average loss at step ', 3000, ': ', 129.14793476486207)\n",
      "('Epoch: ', 618, ' Average loss at step ', 4000, ': ', 127.69602054595947)\n",
      "('Epoch: ', 618, ' Average loss at step ', 4373, ': ', 123.65591397849462)\n",
      "('Epoch: ', 618, ' Average loss at step ', 761, ': ', 9189.8413657740548)\n",
      "('Epoch: ', 618, ' Average loss at step ', 782, ': ', 10715.202103423095)\n",
      "('Epoch: ', 618, ' Average loss at step ', 787, ': ', 11.941655162636561)\n",
      "('Epoch: ', 618, ' Average loss at step ', 1000, ': ', 3.9434704117774961)\n",
      "('Epoch: ', 618, ' Average loss at step ', 2000, ': ', 3.942087558746338)\n",
      "('Epoch: ', 618, ' Average loss at step ', 2813, ': ', 3.8912788335912922)\n",
      "Training time took 97.78081 seconds to run 1 epoch\n",
      "('Epoch: ', 619, ' Average loss at step ', 1000, ': ', 0.022993730902671813)\n",
      "('Epoch: ', 619, ' Average loss at step ', 2000, ': ', 0.020909513652324678)\n",
      "('Epoch: ', 619, ' Average loss at step ', 2813, ': ', 0.020238182668028206)\n",
      "Training time took 44.012597 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.98512341561\n",
      "Hits @ 1:  0.935890593729\n",
      "Testing time took 73.439787 seconds.\n",
      "\n",
      "('Epoch: ', 620, ' Average loss at step ', 1000, ': ', 128.6964891052246)\n",
      "('Epoch: ', 620, ' Average loss at step ', 2000, ': ', 128.95870413208007)\n",
      "('Epoch: ', 620, ' Average loss at step ', 3000, ': ', 128.0620474395752)\n",
      "('Epoch: ', 620, ' Average loss at step ', 4000, ': ', 128.71919563293457)\n",
      "('Epoch: ', 620, ' Average loss at step ', 4373, ': ', 127.54001707671792)\n",
      "('Epoch: ', 620, ' Average loss at step ', 761, ': ', 9325.0872359426394)\n",
      "('Epoch: ', 620, ' Average loss at step ', 782, ': ', 10747.442954870559)\n",
      "('Epoch: ', 620, ' Average loss at step ', 787, ': ', 12.115938003433266)\n",
      "('Epoch: ', 620, ' Average loss at step ', 1000, ': ', 3.930375220298767)\n",
      "('Epoch: ', 620, ' Average loss at step ', 2000, ': ', 3.9385869750976563)\n",
      "('Epoch: ', 620, ' Average loss at step ', 2813, ': ', 3.8099362914785377)\n",
      "Training time took 97.89389 seconds to run 1 epoch\n",
      "('Epoch: ', 621, ' Average loss at step ', 1000, ': ', 0.022653496325016023)\n",
      "('Epoch: ', 621, ' Average loss at step ', 2000, ': ', 0.020839757084846498)\n",
      "('Epoch: ', 621, ' Average loss at step ', 2813, ': ', 0.020647757379292267)\n",
      "Training time took 44.053364 seconds to run 1 epoch\n",
      "('Epoch: ', 622, ' Average loss at step ', 1000, ': ', 127.48214151000977)\n",
      "('Epoch: ', 622, ' Average loss at step ', 2000, ': ', 130.61003282165527)\n",
      "('Epoch: ', 622, ' Average loss at step ', 3000, ': ', 128.5510708770752)\n",
      "('Epoch: ', 622, ' Average loss at step ', 4000, ': ', 129.36110801696776)\n",
      "('Epoch: ', 622, ' Average loss at step ', 4373, ': ', 128.2324967743248)\n",
      "('Epoch: ', 622, ' Average loss at step ', 761, ': ', 9291.4043148643086)\n",
      "('Epoch: ', 622, ' Average loss at step ', 782, ': ', 10720.503074733915)\n",
      "('Epoch: ', 622, ' Average loss at step ', 787, ': ', 12.102023926703378)\n",
      "('Epoch: ', 622, ' Average loss at step ', 1000, ': ', 3.7857756972312928)\n",
      "('Epoch: ', 622, ' Average loss at step ', 2000, ': ', 3.827522659778595)\n",
      "('Epoch: ', 622, ' Average loss at step ', 2813, ': ', 3.8235392570495605)\n",
      "Training time took 97.705648 seconds to run 1 epoch\n",
      "('Epoch: ', 623, ' Average loss at step ', 1000, ': ', 0.022939357638359071)\n",
      "('Epoch: ', 623, ' Average loss at step ', 2000, ': ', 0.020660939753055572)\n",
      "('Epoch: ', 623, ' Average loss at step ', 2813, ': ', 0.020392284678120917)\n",
      "Training time took 44.017582 seconds to run 1 epoch\n",
      "('Epoch: ', 624, ' Average loss at step ', 1000, ': ', 128.2187869720459)\n",
      "('Epoch: ', 624, ' Average loss at step ', 2000, ': ', 128.07038513946534)\n",
      "('Epoch: ', 624, ' Average loss at step ', 3000, ': ', 128.63047107696534)\n",
      "('Epoch: ', 624, ' Average loss at step ', 4000, ': ', 129.13494413757323)\n",
      "('Epoch: ', 624, ' Average loss at step ', 4373, ': ', 129.61829417238954)\n",
      "('Epoch: ', 624, ' Average loss at step ', 761, ': ', 9360.3829345703125)\n",
      "('Epoch: ', 624, ' Average loss at step ', 782, ': ', 10799.172589603673)\n",
      "('Epoch: ', 624, ' Average loss at step ', 787, ': ', 11.932495528505049)\n",
      "('Epoch: ', 624, ' Average loss at step ', 1000, ': ', 4.0138321962356569)\n",
      "('Epoch: ', 624, ' Average loss at step ', 2000, ': ', 3.8957234511375427)\n",
      "('Epoch: ', 624, ' Average loss at step ', 2813, ': ', 3.8282531006582854)\n",
      "Training time took 97.841228 seconds to run 1 epoch\n",
      "('Epoch: ', 625, ' Average loss at step ', 1000, ': ', 0.022733019709587098)\n",
      "('Epoch: ', 625, ' Average loss at step ', 2000, ': ', 0.020612794339656831)\n",
      "('Epoch: ', 625, ' Average loss at step ', 2813, ': ', 0.020321464010060127)\n",
      "Training time took 44.004799 seconds to run 1 epoch\n",
      "('Epoch: ', 626, ' Average loss at step ', 1000, ': ', 128.8279713821411)\n",
      "('Epoch: ', 626, ' Average loss at step ', 2000, ': ', 127.68246424102783)\n",
      "('Epoch: ', 626, ' Average loss at step ', 3000, ': ', 128.89861285400391)\n",
      "('Epoch: ', 626, ' Average loss at step ', 4000, ': ', 128.48175929260253)\n",
      "('Epoch: ', 626, ' Average loss at step ', 4373, ': ', 128.68520187049785)\n",
      "('Epoch: ', 626, ' Average loss at step ', 761, ': ', 9325.82414165296)\n",
      "('Epoch: ', 626, ' Average loss at step ', 782, ': ', 10809.229131447062)\n",
      "('Epoch: ', 626, ' Average loss at step ', 787, ': ', 12.045405182826308)\n",
      "('Epoch: ', 626, ' Average loss at step ', 1000, ': ', 3.8084915976524352)\n",
      "('Epoch: ', 626, ' Average loss at step ', 2000, ': ', 3.9380122585296631)\n",
      "('Epoch: ', 626, ' Average loss at step ', 2813, ': ', 3.8656731896799772)\n",
      "Training time took 97.682496 seconds to run 1 epoch\n",
      "('Epoch: ', 627, ' Average loss at step ', 1000, ': ', 0.022633179008960724)\n",
      "('Epoch: ', 627, ' Average loss at step ', 2000, ': ', 0.02068141496181488)\n",
      "('Epoch: ', 627, ' Average loss at step ', 2813, ': ', 0.020445128967022073)\n",
      "Training time took 44.024899 seconds to run 1 epoch\n",
      "('Epoch: ', 628, ' Average loss at step ', 1000, ': ', 129.54322751617431)\n",
      "('Epoch: ', 628, ' Average loss at step ', 2000, ': ', 127.48170445251465)\n",
      "('Epoch: ', 628, ' Average loss at step ', 3000, ': ', 128.22)\n",
      "('Epoch: ', 628, ' Average loss at step ', 4000, ': ', 128.45559497833253)\n",
      "('Epoch: ', 628, ' Average loss at step ', 4373, ': ', 126.37096774193549)\n",
      "('Epoch: ', 628, ' Average loss at step ', 761, ': ', 9307.7522917094975)\n",
      "('Epoch: ', 628, ' Average loss at step ', 782, ': ', 10854.357913282251)\n",
      "('Epoch: ', 628, ' Average loss at step ', 787, ': ', 11.951281293354569)\n",
      "('Epoch: ', 628, ' Average loss at step ', 1000, ': ', 3.8348778748512267)\n",
      "('Epoch: ', 628, ' Average loss at step ', 2000, ': ', 3.7574608478546141)\n",
      "('Epoch: ', 628, ' Average loss at step ', 2813, ': ', 3.9169964990005117)\n",
      "Training time took 97.817614 seconds to run 1 epoch\n",
      "('Epoch: ', 629, ' Average loss at step ', 1000, ': ', 0.02227442741394043)\n",
      "('Epoch: ', 629, ' Average loss at step ', 2000, ': ', 0.020742109298706055)\n",
      "('Epoch: ', 629, ' Average loss at step ', 2813, ': ', 0.020298970670535647)\n",
      "Training time took 44.017414 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984989993329\n",
      "Hits @ 1:  0.936224149433\n",
      "Testing time took 73.42773 seconds.\n",
      "\n",
      "('Epoch: ', 630, ' Average loss at step ', 1000, ': ', 128.60077388000488)\n",
      "('Epoch: ', 630, ' Average loss at step ', 2000, ': ', 128.77265159606932)\n",
      "('Epoch: ', 630, ' Average loss at step ', 3000, ': ', 127.59933905029297)\n",
      "('Epoch: ', 630, ' Average loss at step ', 4000, ': ', 128.69698616027833)\n",
      "('Epoch: ', 630, ' Average loss at step ', 4373, ': ', 129.34169469853884)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 630, ' Average loss at step ', 761, ': ', 9376.2534468801405)\n",
      "('Epoch: ', 630, ' Average loss at step ', 782, ': ', 10804.245041538292)\n",
      "('Epoch: ', 630, ' Average loss at step ', 787, ': ', 11.901019806170282)\n",
      "('Epoch: ', 630, ' Average loss at step ', 1000, ': ', 3.8089764204025269)\n",
      "('Epoch: ', 630, ' Average loss at step ', 2000, ': ', 3.8950797839164735)\n",
      "('Epoch: ', 630, ' Average loss at step ', 2813, ': ', 3.9520859213298176)\n",
      "Training time took 97.849855 seconds to run 1 epoch\n",
      "('Epoch: ', 631, ' Average loss at step ', 1000, ': ', 0.022428227722644807)\n",
      "('Epoch: ', 631, ' Average loss at step ', 2000, ': ', 0.020456314265727998)\n",
      "('Epoch: ', 631, ' Average loss at step ', 2813, ': ', 0.020189836768093956)\n",
      "Training time took 44.036513 seconds to run 1 epoch\n",
      "('Epoch: ', 632, ' Average loss at step ', 1000, ': ', 129.45928942871095)\n",
      "('Epoch: ', 632, ' Average loss at step ', 2000, ': ', 127.95164634704589)\n",
      "('Epoch: ', 632, ' Average loss at step ', 3000, ': ', 128.41309549713134)\n",
      "('Epoch: ', 632, ' Average loss at step ', 4000, ': ', 128.96719952392579)\n",
      "('Epoch: ', 632, ' Average loss at step ', 4373, ': ', 129.29232878326087)\n",
      "('Epoch: ', 632, ' Average loss at step ', 761, ': ', 9276.227308413856)\n",
      "('Epoch: ', 632, ' Average loss at step ', 782, ': ', 10868.941457516405)\n",
      "('Epoch: ', 632, ' Average loss at step ', 787, ': ', 12.00402079041071)\n",
      "('Epoch: ', 632, ' Average loss at step ', 1000, ': ', 3.9081616430282593)\n",
      "('Epoch: ', 632, ' Average loss at step ', 2000, ': ', 3.8956170544624329)\n",
      "('Epoch: ', 632, ' Average loss at step ', 2813, ': ', 3.9383413979572617)\n",
      "Training time took 97.795427 seconds to run 1 epoch\n",
      "('Epoch: ', 633, ' Average loss at step ', 1000, ': ', 0.022288048028945923)\n",
      "('Epoch: ', 633, ' Average loss at step ', 2000, ': ', 0.02056737059354782)\n",
      "('Epoch: ', 633, ' Average loss at step ', 2813, ': ', 0.020178431654211335)\n",
      "Training time took 44.040643 seconds to run 1 epoch\n",
      "('Epoch: ', 634, ' Average loss at step ', 1000, ': ', 128.26729470825197)\n",
      "('Epoch: ', 634, ' Average loss at step ', 2000, ': ', 128.45370285034178)\n",
      "('Epoch: ', 634, ' Average loss at step ', 3000, ': ', 128.9283698272705)\n",
      "('Epoch: ', 634, ' Average loss at step ', 4000, ': ', 128.22)\n",
      "('Epoch: ', 634, ' Average loss at step ', 4373, ': ', 128.09139784946237)\n",
      "('Epoch: ', 634, ' Average loss at step ', 761, ': ', 9463.4048506887339)\n",
      "('Epoch: ', 634, ' Average loss at step ', 782, ': ', 10845.269441846391)\n",
      "('Epoch: ', 634, ' Average loss at step ', 787, ': ', 11.712347825368246)\n",
      "('Epoch: ', 634, ' Average loss at step ', 1000, ': ', 3.8893401303291322)\n",
      "('Epoch: ', 634, ' Average loss at step ', 2000, ': ', 3.9914251966476439)\n",
      "('Epoch: ', 634, ' Average loss at step ', 2813, ': ', 3.8420122744414607)\n",
      "Training time took 97.6469 seconds to run 1 epoch\n",
      "('Epoch: ', 635, ' Average loss at step ', 1000, ': ', 0.022283675491809846)\n",
      "('Epoch: ', 635, ' Average loss at step ', 2000, ': ', 0.020303303718566895)\n",
      "('Epoch: ', 635, ' Average loss at step ', 2813, ': ', 0.02020698778441387)\n",
      "Training time took 44.01372 seconds to run 1 epoch\n",
      "('Epoch: ', 636, ' Average loss at step ', 1000, ': ', 127.12486433410645)\n",
      "('Epoch: ', 636, ' Average loss at step ', 2000, ': ', 127.77799392700196)\n",
      "('Epoch: ', 636, ' Average loss at step ', 3000, ': ', 128.11782543182372)\n",
      "('Epoch: ', 636, ' Average loss at step ', 4000, ': ', 127.04090946960449)\n",
      "('Epoch: ', 636, ' Average loss at step ', 4373, ': ', 125.80691155054237)\n",
      "('Epoch: ', 636, ' Average loss at step ', 761, ': ', 9364.7647313168181)\n",
      "('Epoch: ', 636, ' Average loss at step ', 782, ': ', 10925.30537522007)\n",
      "('Epoch: ', 636, ' Average loss at step ', 787, ': ', 12.023661041987761)\n",
      "('Epoch: ', 636, ' Average loss at step ', 1000, ': ', 3.7652932567596435)\n",
      "('Epoch: ', 636, ' Average loss at step ', 2000, ': ', 3.8398953046798705)\n",
      "('Epoch: ', 636, ' Average loss at step ', 2813, ': ', 3.8449172304181629)\n",
      "Training time took 97.727868 seconds to run 1 epoch\n",
      "('Epoch: ', 637, ' Average loss at step ', 1000, ': ', 0.022065656721591949)\n",
      "('Epoch: ', 637, ' Average loss at step ', 2000, ': ', 0.020322133898735047)\n",
      "('Epoch: ', 637, ' Average loss at step ', 2813, ': ', 0.02009746872732792)\n",
      "Training time took 44.020383 seconds to run 1 epoch\n",
      "('Epoch: ', 638, ' Average loss at step ', 1000, ': ', 127.25871374511719)\n",
      "('Epoch: ', 638, ' Average loss at step ', 2000, ': ', 129.29219168090819)\n",
      "('Epoch: ', 638, ' Average loss at step ', 3000, ': ', 128.47047628784179)\n",
      "('Epoch: ', 638, ' Average loss at step ', 4000, ': ', 129.50107453155516)\n",
      "('Epoch: ', 638, ' Average loss at step ', 4373, ': ', 130.22832505420973)\n",
      "('Epoch: ', 638, ' Average loss at step ', 761, ': ', 9434.3706260279614)\n",
      "('Epoch: ', 638, ' Average loss at step ', 782, ': ', 10904.384315480955)\n",
      "('Epoch: ', 638, ' Average loss at step ', 787, ': ', 11.979130451309166)\n",
      "('Epoch: ', 638, ' Average loss at step ', 1000, ': ', 3.8024009737968445)\n",
      "('Epoch: ', 638, ' Average loss at step ', 2000, ': ', 3.8196287908554076)\n",
      "('Epoch: ', 638, ' Average loss at step ', 2813, ': ', 3.9091957966095121)\n",
      "Training time took 97.812889 seconds to run 1 epoch\n",
      "('Epoch: ', 639, ' Average loss at step ', 1000, ': ', 0.022187713503837584)\n",
      "('Epoch: ', 639, ' Average loss at step ', 2000, ': ', 0.020359562277793883)\n",
      "('Epoch: ', 639, ' Average loss at step ', 2813, ': ', 0.019821766488657796)\n",
      "Training time took 44.013466 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.98505670447\n",
      "Hits @ 1:  0.937091394263\n",
      "Testing time took 73.363652 seconds.\n",
      "\n",
      "('Epoch: ', 640, ' Average loss at step ', 1000, ': ', 128.86044355773925)\n",
      "('Epoch: ', 640, ' Average loss at step ', 2000, ': ', 127.22104388427735)\n",
      "('Epoch: ', 640, ' Average loss at step ', 3000, ': ', 128.70117910766601)\n",
      "('Epoch: ', 640, ' Average loss at step ', 4000, ': ', 127.11822785186767)\n",
      "('Epoch: ', 640, ' Average loss at step ', 4373, ': ', 129.52376581007434)\n",
      "('Epoch: ', 640, ' Average loss at step ', 761, ': ', 9421.8502473530025)\n",
      "('Epoch: ', 640, ' Average loss at step ', 782, ': ', 10880.748367602633)\n",
      "('Epoch: ', 640, ' Average loss at step ', 787, ': ', 11.948176506518104)\n",
      "('Epoch: ', 640, ' Average loss at step ', 1000, ': ', 3.8474168438911436)\n",
      "('Epoch: ', 640, ' Average loss at step ', 2000, ': ', 3.9098067374229433)\n",
      "('Epoch: ', 640, ' Average loss at step ', 2813, ': ', 3.8714787472645051)\n",
      "Training time took 97.688538 seconds to run 1 epoch\n",
      "('Epoch: ', 641, ' Average loss at step ', 1000, ': ', 0.022056275784969329)\n",
      "('Epoch: ', 641, ' Average loss at step ', 2000, ': ', 0.020187774121761322)\n",
      "('Epoch: ', 641, ' Average loss at step ', 2813, ': ', 0.019823822335069404)\n",
      "Training time took 44.043095 seconds to run 1 epoch\n",
      "('Epoch: ', 642, ' Average loss at step ', 1000, ': ', 128.28757653808594)\n",
      "('Epoch: ', 642, ' Average loss at step ', 2000, ': ', 129.01029776000976)\n",
      "('Epoch: ', 642, ' Average loss at step ', 3000, ': ', 128.26815585327148)\n",
      "('Epoch: ', 642, ' Average loss at step ', 4000, ': ', 127.83737547302246)\n",
      "('Epoch: ', 642, ' Average loss at step ', 4373, ': ', 130.66936981037099)\n",
      "('Epoch: ', 642, ' Average loss at step ', 761, ': ', 9421.4743164062493)\n",
      "('Epoch: ', 642, ' Average loss at step ', 782, ': ', 10989.091190430938)\n",
      "('Epoch: ', 642, ' Average loss at step ', 787, ': ', 11.930671742247565)\n",
      "('Epoch: ', 642, ' Average loss at step ', 1000, ': ', 3.8628143124580383)\n",
      "('Epoch: ', 642, ' Average loss at step ', 2000, ': ', 3.8234016156196593)\n",
      "('Epoch: ', 642, ' Average loss at step ', 2813, ': ', 3.8080248909043561)\n",
      "Training time took 97.747955 seconds to run 1 epoch\n",
      "('Epoch: ', 643, ' Average loss at step ', 1000, ': ', 0.022086946666240691)\n",
      "('Epoch: ', 643, ' Average loss at step ', 2000, ': ', 0.020226394772529601)\n",
      "('Epoch: ', 643, ' Average loss at step ', 2813, ': ', 0.019767524059770142)\n",
      "Training time took 43.998642 seconds to run 1 epoch\n",
      "('Epoch: ', 644, ' Average loss at step ', 1000, ': ', 128.25675801849366)\n",
      "('Epoch: ', 644, ' Average loss at step ', 2000, ': ', 129.12670413970946)\n",
      "('Epoch: ', 644, ' Average loss at step ', 3000, ': ', 129.56519272613525)\n",
      "('Epoch: ', 644, ' Average loss at step ', 4000, ': ', 129.38662687683106)\n",
      "('Epoch: ', 644, ' Average loss at step ', 4373, ': ', 127.09677419354838)\n",
      "('Epoch: ', 644, ' Average loss at step ', 761, ': ', 9365.4242071854442)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 644, ' Average loss at step ', 782, ': ', 10874.632933788813)\n",
      "('Epoch: ', 644, ' Average loss at step ', 787, ': ', 11.886020475974822)\n",
      "('Epoch: ', 644, ' Average loss at step ', 1000, ': ', 3.7780662689208984)\n",
      "('Epoch: ', 644, ' Average loss at step ', 2000, ': ', 3.696700047492981)\n",
      "('Epoch: ', 644, ' Average loss at step ', 2813, ': ', 3.8319191815230647)\n",
      "Training time took 97.829552 seconds to run 1 epoch\n",
      "('Epoch: ', 645, ' Average loss at step ', 1000, ': ', 0.021769206583499907)\n",
      "('Epoch: ', 645, ' Average loss at step ', 2000, ': ', 0.020323131561279299)\n",
      "('Epoch: ', 645, ' Average loss at step ', 2813, ': ', 0.019745818646670563)\n",
      "Training time took 44.017499 seconds to run 1 epoch\n",
      "('Epoch: ', 646, ' Average loss at step ', 1000, ': ', 129.29125575256347)\n",
      "('Epoch: ', 646, ' Average loss at step ', 2000, ': ', 127.81251155853272)\n",
      "('Epoch: ', 646, ' Average loss at step ', 3000, ': ', 128.91553235626222)\n",
      "('Epoch: ', 646, ' Average loss at step ', 4000, ': ', 127.41934759521484)\n",
      "('Epoch: ', 646, ' Average loss at step ', 4373, ': ', 130.8210713376281)\n",
      "('Epoch: ', 646, ' Average loss at step ', 761, ': ', 9383.9385530170639)\n",
      "('Epoch: ', 646, ' Average loss at step ', 782, ': ', 10945.552126055338)\n",
      "('Epoch: ', 646, ' Average loss at step ', 787, ': ', 11.900226286046074)\n",
      "('Epoch: ', 646, ' Average loss at step ', 1000, ': ', 3.8163775734901426)\n",
      "('Epoch: ', 646, ' Average loss at step ', 2000, ': ', 3.8195195670127871)\n",
      "('Epoch: ', 646, ' Average loss at step ', 2813, ': ', 3.9175150106693137)\n",
      "Training time took 97.684123 seconds to run 1 epoch\n",
      "('Epoch: ', 647, ' Average loss at step ', 1000, ': ', 0.021842455089092255)\n",
      "('Epoch: ', 647, ' Average loss at step ', 2000, ': ', 0.02005140459537506)\n",
      "('Epoch: ', 647, ' Average loss at step ', 2813, ': ', 0.019806443543856956)\n",
      "Training time took 44.015946 seconds to run 1 epoch\n",
      "('Epoch: ', 648, ' Average loss at step ', 1000, ': ', 127.73243091583252)\n",
      "('Epoch: ', 648, ' Average loss at step ', 2000, ': ', 128.40562090301515)\n",
      "('Epoch: ', 648, ' Average loss at step ', 3000, ': ', 127.6422444152832)\n",
      "('Epoch: ', 648, ' Average loss at step ', 4000, ': ', 128.54094998931885)\n",
      "('Epoch: ', 648, ' Average loss at step ', 4373, ': ', 128.41397849462365)\n",
      "('Epoch: ', 648, ' Average loss at step ', 761, ': ', 9381.2316496196545)\n",
      "('Epoch: ', 648, ' Average loss at step ', 782, ': ', 11022.932802871919)\n",
      "('Epoch: ', 648, ' Average loss at step ', 787, ': ', 11.59175908110524)\n",
      "('Epoch: ', 648, ' Average loss at step ', 1000, ': ', 3.8429337110519408)\n",
      "('Epoch: ', 648, ' Average loss at step ', 2000, ': ', 3.897420840740204)\n",
      "('Epoch: ', 648, ' Average loss at step ', 2813, ': ', 3.8713305436918888)\n",
      "Training time took 97.802115 seconds to run 1 epoch\n",
      "('Epoch: ', 649, ' Average loss at step ', 1000, ': ', 0.021792893171310425)\n",
      "('Epoch: ', 649, ' Average loss at step ', 2000, ': ', 0.019922950625419617)\n",
      "('Epoch: ', 649, ' Average loss at step ', 2813, ': ', 0.019561537454280947)\n",
      "Training time took 44.028614 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.98505670447\n",
      "Hits @ 1:  0.937091394263\n",
      "Testing time took 73.417861 seconds.\n",
      "\n",
      "('Epoch: ', 650, ' Average loss at step ', 1000, ': ', 129.23420264816284)\n",
      "('Epoch: ', 650, ' Average loss at step ', 2000, ': ', 127.15247987365723)\n",
      "('Epoch: ', 650, ' Average loss at step ', 3000, ': ', 129.17718055725098)\n",
      "('Epoch: ', 650, ' Average loss at step ', 4000, ': ', 127.52906452941895)\n",
      "('Epoch: ', 650, ' Average loss at step ', 4373, ': ', 129.33059011479861)\n",
      "('Epoch: ', 650, ' Average loss at step ', 761, ': ', 9443.4556929738901)\n",
      "('Epoch: ', 650, ' Average loss at step ', 782, ': ', 11051.98555100132)\n",
      "('Epoch: ', 650, ' Average loss at step ', 787, ': ', 11.751323474272517)\n",
      "('Epoch: ', 650, ' Average loss at step ', 1000, ': ', 3.894803244113922)\n",
      "('Epoch: ', 650, ' Average loss at step ', 2000, ': ', 3.8009277367591858)\n",
      "('Epoch: ', 650, ' Average loss at step ', 2813, ': ', 3.7937629340317449)\n",
      "Training time took 97.784987 seconds to run 1 epoch\n",
      "('Epoch: ', 651, ' Average loss at step ', 1000, ': ', 0.021787242829799651)\n",
      "('Epoch: ', 651, ' Average loss at step ', 2000, ': ', 0.019946459650993346)\n",
      "('Epoch: ', 651, ' Average loss at step ', 2813, ': ', 0.0195160170494042)\n",
      "Training time took 44.07147 seconds to run 1 epoch\n",
      "('Epoch: ', 652, ' Average loss at step ', 1000, ': ', 130.02136872100829)\n",
      "('Epoch: ', 652, ' Average loss at step ', 2000, ': ', 129.04073829650878)\n",
      "('Epoch: ', 652, ' Average loss at step ', 3000, ': ', 126.740412399292)\n",
      "('Epoch: ', 652, ' Average loss at step ', 4000, ': ', 128.66265587615968)\n",
      "('Epoch: ', 652, ' Average loss at step ', 4373, ': ', 128.7382720208937)\n",
      "('Epoch: ', 652, ' Average loss at step ', 761, ': ', 9475.8925035978627)\n",
      "('Epoch: ', 652, ' Average loss at step ', 782, ': ', 10976.782911781771)\n",
      "('Epoch: ', 652, ' Average loss at step ', 787, ': ', 11.670374370409938)\n",
      "('Epoch: ', 652, ' Average loss at step ', 1000, ': ', 3.7933483228683471)\n",
      "('Epoch: ', 652, ' Average loss at step ', 2000, ': ', 3.8409267063140868)\n",
      "('Epoch: ', 652, ' Average loss at step ', 2813, ': ', 3.8345376288362325)\n",
      "Training time took 97.727219 seconds to run 1 epoch\n",
      "('Epoch: ', 653, ' Average loss at step ', 1000, ': ', 0.021700260579586027)\n",
      "('Epoch: ', 653, ' Average loss at step ', 2000, ': ', 0.020026686310768128)\n",
      "('Epoch: ', 653, ' Average loss at step ', 2813, ': ', 0.019565998186618822)\n",
      "Training time took 44.015109 seconds to run 1 epoch\n",
      "('Epoch: ', 654, ' Average loss at step ', 1000, ': ', 128.39040361785888)\n",
      "('Epoch: ', 654, ' Average loss at step ', 2000, ': ', 131.42359004211426)\n",
      "('Epoch: ', 654, ' Average loss at step ', 3000, ': ', 128.40180450439453)\n",
      "('Epoch: ', 654, ' Average loss at step ', 4000, ': ', 129.31317877197264)\n",
      "('Epoch: ', 654, ' Average loss at step ', 4373, ': ', 127.48823149486255)\n",
      "('Epoch: ', 654, ' Average loss at step ', 761, ': ', 9543.735675370066)\n",
      "('Epoch: ', 654, ' Average loss at step ', 782, ': ', 11033.536042783691)\n",
      "('Epoch: ', 654, ' Average loss at step ', 787, ': ', 11.987839502839339)\n",
      "('Epoch: ', 654, ' Average loss at step ', 1000, ': ', 3.7660940403938294)\n",
      "('Epoch: ', 654, ' Average loss at step ', 2000, ': ', 3.7063510856628419)\n",
      "('Epoch: ', 654, ' Average loss at step ', 2813, ': ', 3.7646646311717666)\n",
      "Training time took 97.966195 seconds to run 1 epoch\n",
      "('Epoch: ', 655, ' Average loss at step ', 1000, ': ', 0.021577926158905029)\n",
      "('Epoch: ', 655, ' Average loss at step ', 2000, ': ', 0.019815911054611206)\n",
      "('Epoch: ', 655, ' Average loss at step ', 2813, ': ', 0.019414976239204407)\n",
      "Training time took 44.043733 seconds to run 1 epoch\n",
      "('Epoch: ', 656, ' Average loss at step ', 1000, ': ', 128.00029807281493)\n",
      "('Epoch: ', 656, ' Average loss at step ', 2000, ': ', 130.27270350646972)\n",
      "('Epoch: ', 656, ' Average loss at step ', 3000, ': ', 129.20034976196288)\n",
      "('Epoch: ', 656, ' Average loss at step ', 4000, ': ', 128.93882098388673)\n",
      "('Epoch: ', 656, ' Average loss at step ', 4373, ': ', 131.28606865995673)\n",
      "('Epoch: ', 656, ' Average loss at step ', 761, ': ', 9553.9520604183799)\n",
      "('Epoch: ', 656, ' Average loss at step ', 782, ': ', 10990.895322128081)\n",
      "('Epoch: ', 656, ' Average loss at step ', 787, ': ', 11.638617129726263)\n",
      "('Epoch: ', 656, ' Average loss at step ', 1000, ': ', 3.7764051613807679)\n",
      "('Epoch: ', 656, ' Average loss at step ', 2000, ': ', 3.8880781059265135)\n",
      "('Epoch: ', 656, ' Average loss at step ', 2813, ': ', 3.7964305102531544)\n",
      "Training time took 97.878469 seconds to run 1 epoch\n",
      "('Epoch: ', 657, ' Average loss at step ', 1000, ': ', 0.021677717745304109)\n",
      "('Epoch: ', 657, ' Average loss at step ', 2000, ': ', 0.019756218671798706)\n",
      "('Epoch: ', 657, ' Average loss at step ', 2813, ': ', 0.019324251803858526)\n",
      "Training time took 44.041073 seconds to run 1 epoch\n",
      "('Epoch: ', 658, ' Average loss at step ', 1000, ': ', 128.08994104766845)\n",
      "('Epoch: ', 658, ' Average loss at step ', 2000, ': ', 127.28369096374512)\n",
      "('Epoch: ', 658, ' Average loss at step ', 3000, ': ', 128.16768170166014)\n",
      "('Epoch: ', 658, ' Average loss at step ', 4000, ': ', 128.7599986038208)\n",
      "('Epoch: ', 658, ' Average loss at step ', 4373, ': ', 126.12608394827895)\n",
      "('Epoch: ', 658, ' Average loss at step ', 761, ': ', 9411.9412173622532)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 658, ' Average loss at step ', 782, ': ', 11045.053207026249)\n",
      "('Epoch: ', 658, ' Average loss at step ', 787, ': ', 11.530479858243131)\n",
      "('Epoch: ', 658, ' Average loss at step ', 1000, ': ', 3.719526285648346)\n",
      "('Epoch: ', 658, ' Average loss at step ', 2000, ': ', 3.7571838407516478)\n",
      "('Epoch: ', 658, ' Average loss at step ', 2813, ': ', 3.9485239412984239)\n",
      "Training time took 97.851466 seconds to run 1 epoch\n",
      "('Epoch: ', 659, ' Average loss at step ', 1000, ': ', 0.02151175171136856)\n",
      "('Epoch: ', 659, ' Average loss at step ', 2000, ': ', 0.019756590604782104)\n",
      "('Epoch: ', 659, ' Average loss at step ', 2813, ': ', 0.019247842172683754)\n",
      "Training time took 44.04819 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.98512341561\n",
      "Hits @ 1:  0.937224816544\n",
      "Testing time took 73.441613 seconds.\n",
      "\n",
      "('Epoch: ', 660, ' Average loss at step ', 1000, ': ', 129.66537082672119)\n",
      "('Epoch: ', 660, ' Average loss at step ', 2000, ': ', 129.2613482208252)\n",
      "('Epoch: ', 660, ' Average loss at step ', 3000, ': ', 128.33852322387696)\n",
      "('Epoch: ', 660, ' Average loss at step ', 4000, ': ', 128.44406172180175)\n",
      "('Epoch: ', 660, ' Average loss at step ', 4373, ': ', 126.78693049441102)\n",
      "('Epoch: ', 660, ' Average loss at step ', 761, ': ', 9609.6272255345393)\n",
      "('Epoch: ', 660, ' Average loss at step ', 782, ': ', 11047.588171339828)\n",
      "('Epoch: ', 660, ' Average loss at step ', 787, ': ', 11.449522315697513)\n",
      "('Epoch: ', 660, ' Average loss at step ', 1000, ': ', 3.7317170987129211)\n",
      "('Epoch: ', 660, ' Average loss at step ', 2000, ': ', 3.7612768301963806)\n",
      "('Epoch: ', 660, ' Average loss at step ', 2813, ': ', 3.8664440985383659)\n",
      "Training time took 97.790604 seconds to run 1 epoch\n",
      "('Epoch: ', 661, ' Average loss at step ', 1000, ': ', 0.021285133957862853)\n",
      "('Epoch: ', 661, ' Average loss at step ', 2000, ': ', 0.019640511631965639)\n",
      "('Epoch: ', 661, ' Average loss at step ', 2813, ': ', 0.019610561393751887)\n",
      "Training time took 44.029406 seconds to run 1 epoch\n",
      "('Epoch: ', 662, ' Average loss at step ', 1000, ': ', 128.16036407470702)\n",
      "('Epoch: ', 662, ' Average loss at step ', 2000, ': ', 128.15022415924074)\n",
      "('Epoch: ', 662, ' Average loss at step ', 3000, ': ', 126.37001904296875)\n",
      "('Epoch: ', 662, ' Average loss at step ', 4000, ': ', 129.97090718841554)\n",
      "('Epoch: ', 662, ' Average loss at step ', 4373, ': ', 127.52738296344717)\n",
      "('Epoch: ', 662, ' Average loss at step ', 761, ': ', 9465.8469643040698)\n",
      "('Epoch: ', 662, ' Average loss at step ', 782, ': ', 11108.040808058578)\n",
      "('Epoch: ', 662, ' Average loss at step ', 787, ': ', 11.554173479250066)\n",
      "('Epoch: ', 662, ' Average loss at step ', 1000, ': ', 3.8397302227020265)\n",
      "('Epoch: ', 662, ' Average loss at step ', 2000, ': ', 3.7741894183158875)\n",
      "('Epoch: ', 662, ' Average loss at step ', 2813, ': ', 3.7776923285329285)\n",
      "Training time took 97.745556 seconds to run 1 epoch\n",
      "('Epoch: ', 663, ' Average loss at step ', 1000, ': ', 0.021366992592811586)\n",
      "('Epoch: ', 663, ' Average loss at step ', 2000, ': ', 0.019689191281795502)\n",
      "('Epoch: ', 663, ' Average loss at step ', 2813, ': ', 0.019196699258729154)\n",
      "Training time took 43.990348 seconds to run 1 epoch\n",
      "('Epoch: ', 664, ' Average loss at step ', 1000, ': ', 129.58281404113771)\n",
      "('Epoch: ', 664, ' Average loss at step ', 2000, ': ', 128.18926491546631)\n",
      "('Epoch: ', 664, ' Average loss at step ', 3000, ': ', 130.2772459564209)\n",
      "('Epoch: ', 664, ' Average loss at step ', 4000, ': ', 127.02573699951172)\n",
      "('Epoch: ', 664, ' Average loss at step ', 4373, ': ', 126.53288814585696)\n",
      "('Epoch: ', 664, ' Average loss at step ', 761, ': ', 9537.8841379266032)\n",
      "('Epoch: ', 664, ' Average loss at step ', 782, ': ', 11023.826548870638)\n",
      "('Epoch: ', 664, ' Average loss at step ', 787, ': ', 11.563208046153605)\n",
      "('Epoch: ', 664, ' Average loss at step ', 1000, ': ', 3.7873144879341125)\n",
      "('Epoch: ', 664, ' Average loss at step ', 2000, ': ', 3.8982845835685729)\n",
      "('Epoch: ', 664, ' Average loss at step ', 2813, ': ', 3.8397482492653605)\n",
      "Training time took 97.772917 seconds to run 1 epoch\n",
      "('Epoch: ', 665, ' Average loss at step ', 1000, ': ', 0.021207698941230774)\n",
      "('Epoch: ', 665, ' Average loss at step ', 2000, ': ', 0.019518397331237794)\n",
      "('Epoch: ', 665, ' Average loss at step ', 2813, ': ', 0.019130102005498164)\n",
      "Training time took 43.99758 seconds to run 1 epoch\n",
      "('Epoch: ', 666, ' Average loss at step ', 1000, ': ', 127.22574046325684)\n",
      "('Epoch: ', 666, ' Average loss at step ', 2000, ': ', 127.83959217071533)\n",
      "('Epoch: ', 666, ' Average loss at step ', 3000, ': ', 129.31651580047608)\n",
      "('Epoch: ', 666, ' Average loss at step ', 4000, ': ', 128.39236657714844)\n",
      "('Epoch: ', 666, ' Average loss at step ', 4373, ': ', 128.70033026254305)\n",
      "('Epoch: ', 666, ' Average loss at step ', 761, ': ', 9520.7177149722447)\n",
      "('Epoch: ', 666, ' Average loss at step ', 782, ': ', 11113.416482649447)\n",
      "('Epoch: ', 666, ' Average loss at step ', 787, ': ', 11.663392782817967)\n",
      "('Epoch: ', 666, ' Average loss at step ', 1000, ': ', 3.742488284111023)\n",
      "('Epoch: ', 666, ' Average loss at step ', 2000, ': ', 3.8768720445632936)\n",
      "('Epoch: ', 666, ' Average loss at step ', 2813, ': ', 3.8537265537994836)\n",
      "Training time took 97.787972 seconds to run 1 epoch\n",
      "('Epoch: ', 667, ' Average loss at step ', 1000, ': ', 0.021063415110111238)\n",
      "('Epoch: ', 667, ' Average loss at step ', 2000, ': ', 0.019693377792835236)\n",
      "('Epoch: ', 667, ' Average loss at step ', 2813, ': ', 0.019281615691231976)\n",
      "Training time took 44.029447 seconds to run 1 epoch\n",
      "('Epoch: ', 668, ' Average loss at step ', 1000, ': ', 128.25922621154785)\n",
      "('Epoch: ', 668, ' Average loss at step ', 2000, ': ', 128.45157695007325)\n",
      "('Epoch: ', 668, ' Average loss at step ', 3000, ': ', 128.01804453277589)\n",
      "('Epoch: ', 668, ' Average loss at step ', 4000, ': ', 128.93947806549073)\n",
      "('Epoch: ', 668, ' Average loss at step ', 4373, ': ', 128.89745375930622)\n",
      "('Epoch: ', 668, ' Average loss at step ', 761, ': ', 9591.1173853824021)\n",
      "('Epoch: ', 668, ' Average loss at step ', 782, ': ', 11129.254338263245)\n",
      "('Epoch: ', 668, ' Average loss at step ', 787, ': ', 11.668321389885046)\n",
      "('Epoch: ', 668, ' Average loss at step ', 1000, ': ', 3.8340382714271546)\n",
      "('Epoch: ', 668, ' Average loss at step ', 2000, ': ', 3.9301614689826967)\n",
      "('Epoch: ', 668, ' Average loss at step ', 2813, ': ', 3.8009734042172361)\n",
      "Training time took 97.834474 seconds to run 1 epoch\n",
      "('Epoch: ', 669, ' Average loss at step ', 1000, ': ', 0.021401223480701448)\n",
      "('Epoch: ', 669, ' Average loss at step ', 2000, ': ', 0.019335991621017456)\n",
      "('Epoch: ', 669, ' Average loss at step ', 2813, ': ', 0.01902523857032137)\n",
      "Training time took 44.026139 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.98512341561\n",
      "Hits @ 1:  0.937625083389\n",
      "Testing time took 74.04942 seconds.\n",
      "\n",
      "('Epoch: ', 670, ' Average loss at step ', 1000, ': ', 128.75618184661866)\n",
      "('Epoch: ', 670, ' Average loss at step ', 2000, ': ', 127.92748405456543)\n",
      "('Epoch: ', 670, ' Average loss at step ', 3000, ': ', 127.05931206512452)\n",
      "('Epoch: ', 670, ' Average loss at step ', 4000, ': ', 127.39876132202149)\n",
      "('Epoch: ', 670, ' Average loss at step ', 4373, ': ', 129.13978494623655)\n",
      "('Epoch: ', 670, ' Average loss at step ', 761, ': ', 9611.9709504780021)\n",
      "('Epoch: ', 670, ' Average loss at step ', 782, ': ', 11031.826461342629)\n",
      "('Epoch: ', 670, ' Average loss at step ', 787, ': ', 11.680101165334687)\n",
      "('Epoch: ', 670, ' Average loss at step ', 1000, ': ', 3.683856915473938)\n",
      "('Epoch: ', 670, ' Average loss at step ', 2000, ': ', 3.8141921138763428)\n",
      "('Epoch: ', 670, ' Average loss at step ', 2813, ': ', 3.9328388310418338)\n",
      "Training time took 97.669224 seconds to run 1 epoch\n",
      "('Epoch: ', 671, ' Average loss at step ', 1000, ': ', 0.021358476400375366)\n",
      "('Epoch: ', 671, ' Average loss at step ', 2000, ': ', 0.019349020361900331)\n",
      "('Epoch: ', 671, ' Average loss at step ', 2813, ': ', 0.01891423020456812)\n",
      "Training time took 44.026655 seconds to run 1 epoch\n",
      "('Epoch: ', 672, ' Average loss at step ', 1000, ': ', 127.32609491348266)\n",
      "('Epoch: ', 672, ' Average loss at step ', 2000, ': ', 129.26858737945557)\n",
      "('Epoch: ', 672, ' Average loss at step ', 3000, ': ', 128.3503258743286)\n",
      "('Epoch: ', 672, ' Average loss at step ', 4000, ': ', 128.0735132598877)\n",
      "('Epoch: ', 672, ' Average loss at step ', 4373, ': ', 130.51264728012904)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 672, ' Average loss at step ', 761, ': ', 9590.0620599043996)\n",
      "('Epoch: ', 672, ' Average loss at step ', 782, ': ', 11119.811685364317)\n",
      "('Epoch: ', 672, ' Average loss at step ', 787, ': ', 11.358898961210372)\n",
      "('Epoch: ', 672, ' Average loss at step ', 1000, ': ', 3.8375205564498902)\n",
      "('Epoch: ', 672, ' Average loss at step ', 2000, ': ', 3.8214371385574339)\n",
      "('Epoch: ', 672, ' Average loss at step ', 2813, ': ', 3.6797867291079367)\n",
      "Training time took 97.748227 seconds to run 1 epoch\n",
      "('Epoch: ', 673, ' Average loss at step ', 1000, ': ', 0.021186152040958403)\n",
      "('Epoch: ', 673, ' Average loss at step ', 2000, ': ', 0.01925669413805008)\n",
      "('Epoch: ', 673, ' Average loss at step ', 2813, ': ', 0.01879559611452037)\n",
      "Training time took 44.005685 seconds to run 1 epoch\n",
      "('Epoch: ', 674, ' Average loss at step ', 1000, ': ', 128.51403157424926)\n",
      "('Epoch: ', 674, ' Average loss at step ', 2000, ': ', 128.14460200500488)\n",
      "('Epoch: ', 674, ' Average loss at step ', 3000, ': ', 127.9041298751831)\n",
      "('Epoch: ', 674, ' Average loss at step ', 4000, ': ', 127.869844039917)\n",
      "('Epoch: ', 674, ' Average loss at step ', 4373, ': ', 126.82795698924731)\n",
      "('Epoch: ', 674, ' Average loss at step ', 761, ': ', 9599.1061285721626)\n",
      "('Epoch: ', 674, ' Average loss at step ', 782, ': ', 11200.099260513365)\n",
      "('Epoch: ', 674, ' Average loss at step ', 787, ': ', 11.328765199384616)\n",
      "('Epoch: ', 674, ' Average loss at step ', 1000, ': ', 3.8047796497344972)\n",
      "('Epoch: ', 674, ' Average loss at step ', 2000, ': ', 3.7841328477859495)\n",
      "('Epoch: ', 674, ' Average loss at step ', 2813, ': ', 3.8245771107415258)\n",
      "Training time took 97.825157 seconds to run 1 epoch\n",
      "('Epoch: ', 675, ' Average loss at step ', 1000, ': ', 0.021445803403854369)\n",
      "('Epoch: ', 675, ' Average loss at step ', 2000, ': ', 0.019367118477821351)\n",
      "('Epoch: ', 675, ' Average loss at step ', 2813, ': ', 0.018804728177380679)\n",
      "Training time took 44.009925 seconds to run 1 epoch\n",
      "('Epoch: ', 676, ' Average loss at step ', 1000, ': ', 128.11196538162233)\n",
      "('Epoch: ', 676, ' Average loss at step ', 2000, ': ', 129.2810322265625)\n",
      "('Epoch: ', 676, ' Average loss at step ', 3000, ': ', 129.16600608825684)\n",
      "('Epoch: ', 676, ' Average loss at step ', 4000, ': ', 128.60673604583741)\n",
      "('Epoch: ', 676, ' Average loss at step ', 4373, ': ', 130.19300263927829)\n",
      "('Epoch: ', 676, ' Average loss at step ', 761, ': ', 9594.7626008686275)\n",
      "('Epoch: ', 676, ' Average loss at step ', 782, ': ', 11155.496405724833)\n",
      "('Epoch: ', 676, ' Average loss at step ', 787, ': ', 11.378924531184383)\n",
      "('Epoch: ', 676, ' Average loss at step ', 1000, ': ', 3.8235931801795959)\n",
      "('Epoch: ', 676, ' Average loss at step ', 2000, ': ', 3.7208147625923158)\n",
      "('Epoch: ', 676, ' Average loss at step ', 2813, ': ', 3.8384549799811079)\n",
      "Training time took 97.668969 seconds to run 1 epoch\n",
      "('Epoch: ', 677, ' Average loss at step ', 1000, ': ', 0.021329197645187377)\n",
      "('Epoch: ', 677, ' Average loss at step ', 2000, ': ', 0.019109690785408018)\n",
      "('Epoch: ', 677, ' Average loss at step ', 2813, ': ', 0.018688552632120443)\n",
      "Training time took 44.019979 seconds to run 1 epoch\n",
      "('Epoch: ', 678, ' Average loss at step ', 1000, ': ', 126.56619905090332)\n",
      "('Epoch: ', 678, ' Average loss at step ', 2000, ': ', 127.66726234817504)\n",
      "('Epoch: ', 678, ' Average loss at step ', 3000, ': ', 128.26774414825439)\n",
      "('Epoch: ', 678, ' Average loss at step ', 4000, ': ', 128.29519511413574)\n",
      "('Epoch: ', 678, ' Average loss at step ', 4373, ': ', 126.26575301795877)\n",
      "('Epoch: ', 678, ' Average loss at step ', 761, ': ', 9696.6387200606496)\n",
      "('Epoch: ', 678, ' Average loss at step ', 782, ': ', 11127.06200796755)\n",
      "('Epoch: ', 678, ' Average loss at step ', 787, ': ', 11.550543751122085)\n",
      "('Epoch: ', 678, ' Average loss at step ', 1000, ': ', 3.8274102172851561)\n",
      "('Epoch: ', 678, ' Average loss at step ', 2000, ': ', 3.7781883010864257)\n",
      "('Epoch: ', 678, ' Average loss at step ', 2813, ': ', 3.8307448954417787)\n",
      "Training time took 97.751565 seconds to run 1 epoch\n",
      "('Epoch: ', 679, ' Average loss at step ', 1000, ': ', 0.020816289067268373)\n",
      "('Epoch: ', 679, ' Average loss at step ', 2000, ': ', 0.019095589876174927)\n",
      "('Epoch: ', 679, ' Average loss at step ', 2813, ': ', 0.018694052628695671)\n",
      "Training time took 44.007984 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984723148766\n",
      "Hits @ 1:  0.937224816544\n",
      "Testing time took 73.462467 seconds.\n",
      "\n",
      "('Epoch: ', 680, ' Average loss at step ', 1000, ': ', 129.56595043945313)\n",
      "('Epoch: ', 680, ' Average loss at step ', 2000, ': ', 127.80727294158936)\n",
      "('Epoch: ', 680, ' Average loss at step ', 3000, ': ', 127.22457207107544)\n",
      "('Epoch: ', 680, ' Average loss at step ', 4000, ': ', 128.27327290344238)\n",
      "('Epoch: ', 680, ' Average loss at step ', 4373, ': ', 129.73548632796093)\n",
      "('Epoch: ', 680, ' Average loss at step ', 761, ': ', 9606.4798359118013)\n",
      "('Epoch: ', 680, ' Average loss at step ', 782, ': ', 11256.042463588348)\n",
      "('Epoch: ', 680, ' Average loss at step ', 787, ': ', 11.440410951318329)\n",
      "('Epoch: ', 680, ' Average loss at step ', 1000, ': ', 3.7634638547897339)\n",
      "('Epoch: ', 680, ' Average loss at step ', 2000, ': ', 3.9467702546119692)\n",
      "('Epoch: ', 680, ' Average loss at step ', 2813, ': ', 3.7675671965030615)\n",
      "Training time took 97.867737 seconds to run 1 epoch\n",
      "('Epoch: ', 681, ' Average loss at step ', 1000, ': ', 0.02091440749168396)\n",
      "('Epoch: ', 681, ' Average loss at step ', 2000, ': ', 0.019063758671283723)\n",
      "('Epoch: ', 681, ' Average loss at step ', 2813, ': ', 0.018745029574544558)\n",
      "Training time took 44.039961 seconds to run 1 epoch\n",
      "('Epoch: ', 682, ' Average loss at step ', 1000, ': ', 128.54419020843505)\n",
      "('Epoch: ', 682, ' Average loss at step ', 2000, ': ', 127.8040985031128)\n",
      "('Epoch: ', 682, ' Average loss at step ', 3000, ': ', 127.44447016143799)\n",
      "('Epoch: ', 682, ' Average loss at step ', 4000, ': ', 127.90603913116455)\n",
      "('Epoch: ', 682, ' Average loss at step ', 4373, ': ', 126.6968263195407)\n",
      "('Epoch: ', 682, ' Average loss at step ', 761, ': ', 9637.0459003649266)\n",
      "('Epoch: ', 682, ' Average loss at step ', 782, ': ', 11203.697028674176)\n",
      "('Epoch: ', 682, ' Average loss at step ', 787, ': ', 11.11169447304335)\n",
      "('Epoch: ', 682, ' Average loss at step ', 1000, ': ', 3.7001231174468994)\n",
      "('Epoch: ', 682, ' Average loss at step ', 2000, ': ', 3.8362889533042908)\n",
      "('Epoch: ', 682, ' Average loss at step ', 2813, ': ', 3.7540057104796611)\n",
      "Training time took 97.831911 seconds to run 1 epoch\n",
      "('Epoch: ', 683, ' Average loss at step ', 1000, ': ', 0.021011988043785096)\n",
      "('Epoch: ', 683, ' Average loss at step ', 2000, ': ', 0.019021001100540162)\n",
      "('Epoch: ', 683, ' Average loss at step ', 2813, ': ', 0.018638578835379314)\n",
      "Training time took 44.014885 seconds to run 1 epoch\n",
      "('Epoch: ', 684, ' Average loss at step ', 1000, ': ', 127.87520861816407)\n",
      "('Epoch: ', 684, ' Average loss at step ', 2000, ': ', 128.00378833007812)\n",
      "('Epoch: ', 684, ' Average loss at step ', 3000, ': ', 128.77599404144286)\n",
      "('Epoch: ', 684, ' Average loss at step ', 4000, ': ', 128.30099702453614)\n",
      "('Epoch: ', 684, ' Average loss at step ', 4373, ': ', 128.1720430107527)\n",
      "('Epoch: ', 684, ' Average loss at step ', 761, ': ', 9627.2833200555106)\n",
      "('Epoch: ', 684, ' Average loss at step ', 782, ': ', 11168.140478703184)\n",
      "('Epoch: ', 684, ' Average loss at step ', 787, ': ', 11.564998989493489)\n",
      "('Epoch: ', 684, ' Average loss at step ', 1000, ': ', 3.8957657461166382)\n",
      "('Epoch: ', 684, ' Average loss at step ', 2000, ': ', 3.805704532146454)\n",
      "('Epoch: ', 684, ' Average loss at step ', 2813, ': ', 3.7558401218188808)\n",
      "Training time took 97.849769 seconds to run 1 epoch\n",
      "('Epoch: ', 685, ' Average loss at step ', 1000, ': ', 0.020975469291210174)\n",
      "('Epoch: ', 685, ' Average loss at step ', 2000, ': ', 0.018825941801071167)\n",
      "('Epoch: ', 685, ' Average loss at step ', 2813, ': ', 0.018435061565173671)\n",
      "Training time took 43.985759 seconds to run 1 epoch\n",
      "('Epoch: ', 686, ' Average loss at step ', 1000, ': ', 128.73172578430174)\n",
      "('Epoch: ', 686, ' Average loss at step ', 2000, ': ', 127.27448868560791)\n",
      "('Epoch: ', 686, ' Average loss at step ', 3000, ': ', 127.96223857879639)\n",
      "('Epoch: ', 686, ' Average loss at step ', 4000, ': ', 126.88072261047363)\n",
      "('Epoch: ', 686, ' Average loss at step ', 4373, ': ', 128.88729273888373)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 686, ' Average loss at step ', 761, ': ', 9736.4563393040698)\n",
      "('Epoch: ', 686, ' Average loss at step ', 782, ': ', 11173.881602112677)\n",
      "('Epoch: ', 686, ' Average loss at step ', 787, ': ', 11.217951221320465)\n",
      "('Epoch: ', 686, ' Average loss at step ', 1000, ': ', 3.6762593293190005)\n",
      "('Epoch: ', 686, ' Average loss at step ', 2000, ': ', 3.7858627820014954)\n",
      "('Epoch: ', 686, ' Average loss at step ', 2813, ': ', 3.685564794563895)\n",
      "Training time took 97.801926 seconds to run 1 epoch\n",
      "('Epoch: ', 687, ' Average loss at step ', 1000, ': ', 0.020734959959983826)\n",
      "('Epoch: ', 687, ' Average loss at step ', 2000, ': ', 0.019101185977458954)\n",
      "('Epoch: ', 687, ' Average loss at step ', 2813, ': ', 0.018654804658419979)\n",
      "Training time took 44.030108 seconds to run 1 epoch\n",
      "('Epoch: ', 688, ' Average loss at step ', 1000, ': ', 127.62329125213623)\n",
      "('Epoch: ', 688, ' Average loss at step ', 2000, ': ', 128.96993950653075)\n",
      "('Epoch: ', 688, ' Average loss at step ', 3000, ': ', 128.48578442382814)\n",
      "('Epoch: ', 688, ' Average loss at step ', 4000, ': ', 128.83433839416503)\n",
      "('Epoch: ', 688, ' Average loss at step ', 4373, ': ', 129.35483870967741)\n",
      "('Epoch: ', 688, ' Average loss at step ', 761, ': ', 9791.3175312243002)\n",
      "('Epoch: ', 688, ' Average loss at step ', 782, ': ', 11305.975556553098)\n",
      "('Epoch: ', 688, ' Average loss at step ', 787, ': ', 11.231092212764361)\n",
      "('Epoch: ', 688, ' Average loss at step ', 1000, ': ', 3.7742855520248413)\n",
      "('Epoch: ', 688, ' Average loss at step ', 2000, ': ', 3.7561036090850832)\n",
      "('Epoch: ', 688, ' Average loss at step ', 2813, ': ', 3.831881567762403)\n",
      "Training time took 97.793407 seconds to run 1 epoch\n",
      "('Epoch: ', 689, ' Average loss at step ', 1000, ': ', 0.02066933137178421)\n",
      "('Epoch: ', 689, ' Average loss at step ', 2000, ': ', 0.018879701673984527)\n",
      "('Epoch: ', 689, ' Average loss at step ', 2813, ': ', 0.018510588210791788)\n",
      "Training time took 44.038823 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984723148766\n",
      "Hits @ 1:  0.936691127418\n",
      "Testing time took 73.459092 seconds.\n",
      "\n",
      "('Epoch: ', 690, ' Average loss at step ', 1000, ': ', 126.85535873413086)\n",
      "('Epoch: ', 690, ' Average loss at step ', 2000, ': ', 128.87488094329834)\n",
      "('Epoch: ', 690, ' Average loss at step ', 3000, ': ', 128.93244105529786)\n",
      "('Epoch: ', 690, ' Average loss at step ', 4000, ': ', 127.55586810302735)\n",
      "('Epoch: ', 690, ' Average loss at step ', 4373, ': ', 125.5397173358548)\n",
      "('Epoch: ', 690, ' Average loss at step ', 761, ': ', 9622.9461419356503)\n",
      "('Epoch: ', 690, ' Average loss at step ', 782, ': ', 11200.066238071182)\n",
      "('Epoch: ', 690, ' Average loss at step ', 787, ': ', 11.135553673023486)\n",
      "('Epoch: ', 690, ' Average loss at step ', 1000, ': ', 3.8399382643699647)\n",
      "('Epoch: ', 690, ' Average loss at step ', 2000, ': ', 3.8496327185630799)\n",
      "('Epoch: ', 690, ' Average loss at step ', 2813, ': ', 3.8353715465573841)\n",
      "Training time took 97.838594 seconds to run 1 epoch\n",
      "('Epoch: ', 691, ' Average loss at step ', 1000, ': ', 0.020575900733470917)\n",
      "('Epoch: ', 691, ' Average loss at step ', 2000, ': ', 0.018892429292201997)\n",
      "('Epoch: ', 691, ' Average loss at step ', 2813, ': ', 0.018447259303384228)\n",
      "Training time took 44.023999 seconds to run 1 epoch\n",
      "('Epoch: ', 692, ' Average loss at step ', 1000, ': ', 127.64745644378662)\n",
      "('Epoch: ', 692, ' Average loss at step ', 2000, ': ', 128.20833145141603)\n",
      "('Epoch: ', 692, ' Average loss at step ', 3000, ': ', 129.85122579956055)\n",
      "('Epoch: ', 692, ' Average loss at step ', 4000, ': ', 126.91770590209961)\n",
      "('Epoch: ', 692, ' Average loss at step ', 4373, ': ', 129.41472441150296)\n",
      "('Epoch: ', 692, ' Average loss at step ', 761, ': ', 9704.2338064093346)\n",
      "('Epoch: ', 692, ' Average loss at step ', 782, ': ', 11259.666347606233)\n",
      "('Epoch: ', 692, ' Average loss at step ', 787, ': ', 11.110076189647801)\n",
      "('Epoch: ', 692, ' Average loss at step ', 1000, ': ', 3.6859399542808533)\n",
      "('Epoch: ', 692, ' Average loss at step ', 2000, ': ', 3.7045588359832764)\n",
      "('Epoch: ', 692, ' Average loss at step ', 2813, ': ', 3.6924939079237689)\n",
      "Training time took 97.823818 seconds to run 1 epoch\n",
      "('Epoch: ', 693, ' Average loss at step ', 1000, ': ', 0.020430029451847076)\n",
      "('Epoch: ', 693, ' Average loss at step ', 2000, ': ', 0.018747843742370606)\n",
      "('Epoch: ', 693, ' Average loss at step ', 2813, ': ', 0.018504145036777251)\n",
      "Training time took 44.01735 seconds to run 1 epoch\n",
      "('Epoch: ', 694, ' Average loss at step ', 1000, ': ', 127.11189833068848)\n",
      "('Epoch: ', 694, ' Average loss at step ', 2000, ': ', 128.42557989501952)\n",
      "('Epoch: ', 694, ' Average loss at step ', 3000, ': ', 127.28862209320069)\n",
      "('Epoch: ', 694, ' Average loss at step ', 4000, ': ', 127.43309367370605)\n",
      "('Epoch: ', 694, ' Average loss at step ', 4373, ': ', 128.09165169090352)\n",
      "('Epoch: ', 694, ' Average loss at step ', 761, ': ', 9636.7222643400492)\n",
      "('Epoch: ', 694, ' Average loss at step ', 782, ': ', 11277.502608959867)\n",
      "('Epoch: ', 694, ' Average loss at step ', 787, ': ', 11.373600707406002)\n",
      "('Epoch: ', 694, ' Average loss at step ', 1000, ': ', 3.8480386958122255)\n",
      "('Epoch: ', 694, ' Average loss at step ', 2000, ': ', 3.7603003063201905)\n",
      "('Epoch: ', 694, ' Average loss at step ', 2813, ': ', 3.8136089535182331)\n",
      "Training time took 97.757683 seconds to run 1 epoch\n",
      "('Epoch: ', 695, ' Average loss at step ', 1000, ': ', 0.02074704146385193)\n",
      "('Epoch: ', 695, ' Average loss at step ', 2000, ': ', 0.018721393525600434)\n",
      "('Epoch: ', 695, ' Average loss at step ', 2813, ': ', 0.01824272618505168)\n",
      "Training time took 44.033144 seconds to run 1 epoch\n",
      "('Epoch: ', 696, ' Average loss at step ', 1000, ': ', 128.68414323425293)\n",
      "('Epoch: ', 696, ' Average loss at step ', 2000, ': ', 128.75853428649901)\n",
      "('Epoch: ', 696, ' Average loss at step ', 3000, ': ', 128.38139044189452)\n",
      "('Epoch: ', 696, ' Average loss at step ', 4000, ': ', 126.4055864944458)\n",
      "('Epoch: ', 696, ' Average loss at step ', 4373, ': ', 134.682463225498)\n",
      "('Epoch: ', 696, ' Average loss at step ', 761, ': ', 9766.4237311112247)\n",
      "('Epoch: ', 696, ' Average loss at step ', 782, ': ', 11278.783842079465)\n",
      "('Epoch: ', 696, ' Average loss at step ', 787, ': ', 11.118253517393544)\n",
      "('Epoch: ', 696, ' Average loss at step ', 1000, ': ', 3.7922618880271912)\n",
      "('Epoch: ', 696, ' Average loss at step ', 2000, ': ', 3.7643827724456789)\n",
      "('Epoch: ', 696, ' Average loss at step ', 2813, ': ', 3.8803737627461627)\n",
      "Training time took 97.757157 seconds to run 1 epoch\n",
      "('Epoch: ', 697, ' Average loss at step ', 1000, ': ', 0.020358051776885985)\n",
      "('Epoch: ', 697, ' Average loss at step ', 2000, ': ', 0.018698307156562805)\n",
      "('Epoch: ', 697, ' Average loss at step ', 2813, ': ', 0.018240032598302869)\n",
      "Training time took 44.023461 seconds to run 1 epoch\n",
      "('Epoch: ', 698, ' Average loss at step ', 1000, ': ', 128.8018112487793)\n",
      "('Epoch: ', 698, ' Average loss at step ', 2000, ': ', 128.88248826599121)\n",
      "('Epoch: ', 698, ' Average loss at step ', 3000, ': ', 128.86068431091309)\n",
      "('Epoch: ', 698, ' Average loss at step ', 4000, ': ', 126.75980657958985)\n",
      "('Epoch: ', 698, ' Average loss at step ', 4373, ': ', 127.3140148860152)\n",
      "('Epoch: ', 698, ' Average loss at step ', 761, ': ', 9687.5125616776313)\n",
      "('Epoch: ', 698, ' Average loss at step ', 782, ': ', 11162.560101107354)\n",
      "('Epoch: ', 698, ' Average loss at step ', 787, ': ', 11.420497671035106)\n",
      "('Epoch: ', 698, ' Average loss at step ', 1000, ': ', 3.5976991624832153)\n",
      "('Epoch: ', 698, ' Average loss at step ', 2000, ': ', 3.8457670707702638)\n",
      "('Epoch: ', 698, ' Average loss at step ', 2813, ': ', 3.7014372466232976)\n",
      "Training time took 97.807225 seconds to run 1 epoch\n",
      "('Epoch: ', 699, ' Average loss at step ', 1000, ': ', 0.020393612086772917)\n",
      "('Epoch: ', 699, ' Average loss at step ', 2000, ': ', 0.018626804769039156)\n",
      "('Epoch: ', 699, ' Average loss at step ', 2813, ': ', 0.018375492521694729)\n",
      "Training time took 44.029565 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984789859907\n",
      "Hits @ 1:  0.936624416278\n",
      "Testing time took 73.46314 seconds.\n",
      "\n",
      "('Epoch: ', 700, ' Average loss at step ', 1000, ': ', 129.7047766571045)\n",
      "('Epoch: ', 700, ' Average loss at step ', 2000, ': ', 127.71045635604858)\n",
      "('Epoch: ', 700, ' Average loss at step ', 3000, ': ', 128.51189083862306)\n",
      "('Epoch: ', 700, ' Average loss at step ', 4000, ': ', 129.09494563293458)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 700, ' Average loss at step ', 4373, ': ', 125.97240829467773)\n",
      "('Epoch: ', 700, ' Average loss at step ', 761, ': ', 9814.8740761204772)\n",
      "('Epoch: ', 700, ' Average loss at step ', 782, ': ', 11296.910984640084)\n",
      "('Epoch: ', 700, ' Average loss at step ', 787, ': ', 11.090478489417157)\n",
      "('Epoch: ', 700, ' Average loss at step ', 1000, ': ', 3.7437865195274354)\n",
      "('Epoch: ', 700, ' Average loss at step ', 2000, ': ', 3.7447843732833861)\n",
      "('Epoch: ', 700, ' Average loss at step ', 2813, ': ', 3.7407909655218643)\n",
      "Training time took 97.806503 seconds to run 1 epoch\n",
      "('Epoch: ', 701, ' Average loss at step ', 1000, ': ', 0.020385035514831541)\n",
      "('Epoch: ', 701, ' Average loss at step ', 2000, ': ', 0.018451020896434783)\n",
      "('Epoch: ', 701, ' Average loss at step ', 2813, ': ', 0.018154739379295574)\n",
      "Training time took 44.043651 seconds to run 1 epoch\n",
      "('Epoch: ', 702, ' Average loss at step ', 1000, ': ', 128.75262993621826)\n",
      "('Epoch: ', 702, ' Average loss at step ', 2000, ': ', 127.37036707305909)\n",
      "('Epoch: ', 702, ' Average loss at step ', 3000, ': ', 129.78410987854005)\n",
      "('Epoch: ', 702, ' Average loss at step ', 4000, ': ', 128.3056856918335)\n",
      "('Epoch: ', 702, ' Average loss at step ', 4373, ': ', 130.59327371658819)\n",
      "('Epoch: ', 702, ' Average loss at step ', 761, ': ', 9695.963529887953)\n",
      "('Epoch: ', 702, ' Average loss at step ', 782, ': ', 11273.541638324265)\n",
      "('Epoch: ', 702, ' Average loss at step ', 787, ': ', 11.073087756567025)\n",
      "('Epoch: ', 702, ' Average loss at step ', 1000, ': ', 3.7140889620780944)\n",
      "('Epoch: ', 702, ' Average loss at step ', 2000, ': ', 3.8340196928977965)\n",
      "('Epoch: ', 702, ' Average loss at step ', 2813, ': ', 3.7896497860330665)\n",
      "Training time took 97.830024 seconds to run 1 epoch\n",
      "('Epoch: ', 703, ' Average loss at step ', 1000, ': ', 0.020417286336421966)\n",
      "('Epoch: ', 703, ' Average loss at step ', 2000, ': ', 0.018639473080635072)\n",
      "('Epoch: ', 703, ' Average loss at step ', 2813, ': ', 0.01804167964481955)\n",
      "Training time took 44.012 seconds to run 1 epoch\n",
      "('Epoch: ', 704, ' Average loss at step ', 1000, ': ', 128.05568108367919)\n",
      "('Epoch: ', 704, ' Average loss at step ', 2000, ': ', 127.34006105041504)\n",
      "('Epoch: ', 704, ' Average loss at step ', 3000, ': ', 129.04631430053712)\n",
      "('Epoch: ', 704, ' Average loss at step ', 4000, ': ', 129.70245511627198)\n",
      "('Epoch: ', 704, ' Average loss at step ', 4373, ': ', 127.80184198194935)\n",
      "('Epoch: ', 704, ' Average loss at step ', 761, ': ', 9727.5306094520965)\n",
      "('Epoch: ', 704, ' Average loss at step ', 782, ': ', 11292.243010263284)\n",
      "('Epoch: ', 704, ' Average loss at step ', 787, ': ', 11.030418603474857)\n",
      "('Epoch: ', 704, ' Average loss at step ', 1000, ': ', 3.810086851119995)\n",
      "('Epoch: ', 704, ' Average loss at step ', 2000, ': ', 3.7228670034408569)\n",
      "('Epoch: ', 704, ' Average loss at step ', 2813, ': ', 3.7303194142327518)\n",
      "Training time took 97.817215 seconds to run 1 epoch\n",
      "('Epoch: ', 705, ' Average loss at step ', 1000, ': ', 0.020265853822231294)\n",
      "('Epoch: ', 705, ' Average loss at step ', 2000, ': ', 0.018450135469436645)\n",
      "('Epoch: ', 705, ' Average loss at step ', 2813, ': ', 0.018031347047519214)\n",
      "Training time took 44.025958 seconds to run 1 epoch\n",
      "('Epoch: ', 706, ' Average loss at step ', 1000, ': ', 127.85031259155274)\n",
      "('Epoch: ', 706, ' Average loss at step ', 2000, ': ', 130.2290997695923)\n",
      "('Epoch: ', 706, ' Average loss at step ', 3000, ': ', 128.63222365570067)\n",
      "('Epoch: ', 706, ' Average loss at step ', 4000, ': ', 129.70955166625976)\n",
      "('Epoch: ', 706, ' Average loss at step ', 4373, ': ', 129.96438036682784)\n",
      "('Epoch: ', 706, ' Average loss at step ', 761, ': ', 9799.7840826737247)\n",
      "('Epoch: ', 706, ' Average loss at step ', 782, ': ', 11354.137551516485)\n",
      "('Epoch: ', 706, ' Average loss at step ', 787, ': ', 11.154144586800923)\n",
      "('Epoch: ', 706, ' Average loss at step ', 1000, ': ', 3.6481962971687318)\n",
      "('Epoch: ', 706, ' Average loss at step ', 2000, ': ', 3.8604975652694704)\n",
      "('Epoch: ', 706, ' Average loss at step ', 2813, ': ', 3.7535830002112931)\n",
      "Training time took 97.658186 seconds to run 1 epoch\n",
      "('Epoch: ', 707, ' Average loss at step ', 1000, ': ', 0.020157435655593872)\n",
      "('Epoch: ', 707, ' Average loss at step ', 2000, ': ', 0.018493430197238921)\n",
      "('Epoch: ', 707, ' Average loss at step ', 2813, ': ', 0.018093509994116911)\n",
      "Training time took 44.034155 seconds to run 1 epoch\n",
      "('Epoch: ', 708, ' Average loss at step ', 1000, ': ', 129.99507830810546)\n",
      "('Epoch: ', 708, ' Average loss at step ', 2000, ': ', 128.19162232971192)\n",
      "('Epoch: ', 708, ' Average loss at step ', 3000, ': ', 127.53195133972169)\n",
      "('Epoch: ', 708, ' Average loss at step ', 4000, ': ', 128.11756184387207)\n",
      "('Epoch: ', 708, ' Average loss at step ', 4373, ': ', 131.13270404774656)\n",
      "('Epoch: ', 708, ' Average loss at step ', 761, ': ', 9813.335045744243)\n",
      "('Epoch: ', 708, ' Average loss at step ', 782, ': ', 11365.965697773287)\n",
      "('Epoch: ', 708, ' Average loss at step ', 787, ': ', 11.162065652793904)\n",
      "('Epoch: ', 708, ' Average loss at step ', 1000, ': ', 3.5348443374633791)\n",
      "('Epoch: ', 708, ' Average loss at step ', 2000, ': ', 3.6841651973724363)\n",
      "('Epoch: ', 708, ' Average loss at step ', 2813, ': ', 3.8026749388924959)\n",
      "Training time took 97.757529 seconds to run 1 epoch\n",
      "('Epoch: ', 709, ' Average loss at step ', 1000, ': ', 0.020129088401794434)\n",
      "('Epoch: ', 709, ' Average loss at step ', 2000, ': ', 0.018310038089752196)\n",
      "('Epoch: ', 709, ' Average loss at step ', 2813, ': ', 0.018128830223835161)\n",
      "Training time took 44.012502 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.98418945964\n",
      "Hits @ 1:  0.936557705137\n",
      "Testing time took 73.437426 seconds.\n",
      "\n",
      "('Epoch: ', 710, ' Average loss at step ', 1000, ': ', 129.88814360809326)\n",
      "('Epoch: ', 710, ' Average loss at step ', 2000, ': ', 128.5149843902588)\n",
      "('Epoch: ', 710, ' Average loss at step ', 3000, ': ', 130.03024462890625)\n",
      "('Epoch: ', 710, ' Average loss at step ', 4000, ': ', 129.07650978088378)\n",
      "('Epoch: ', 710, ' Average loss at step ', 4373, ': ', 128.53428854993595)\n",
      "('Epoch: ', 710, ' Average loss at step ', 761, ': ', 9806.0474288137339)\n",
      "('Epoch: ', 710, ' Average loss at step ', 782, ': ', 11300.07294834347)\n",
      "('Epoch: ', 710, ' Average loss at step ', 787, ': ', 11.434323523184119)\n",
      "('Epoch: ', 710, ' Average loss at step ', 1000, ': ', 3.7111707339286806)\n",
      "('Epoch: ', 710, ' Average loss at step ', 2000, ': ', 3.7212944059371948)\n",
      "('Epoch: ', 710, ' Average loss at step ', 2813, ': ', 3.7968040076382641)\n",
      "Training time took 97.864532 seconds to run 1 epoch\n",
      "('Epoch: ', 711, ' Average loss at step ', 1000, ': ', 0.020037528812885286)\n",
      "('Epoch: ', 711, ' Average loss at step ', 2000, ': ', 0.018359591066837311)\n",
      "('Epoch: ', 711, ' Average loss at step ', 2813, ': ', 0.018049796740409775)\n",
      "Training time took 44.064642 seconds to run 1 epoch\n",
      "('Epoch: ', 712, ' Average loss at step ', 1000, ': ', 128.85069277954102)\n",
      "('Epoch: ', 712, ' Average loss at step ', 2000, ': ', 129.06108646392823)\n",
      "('Epoch: ', 712, ' Average loss at step ', 3000, ': ', 127.2105687866211)\n",
      "('Epoch: ', 712, ' Average loss at step ', 4000, ': ', 127.39289471435546)\n",
      "('Epoch: ', 712, ' Average loss at step ', 4373, ': ', 126.88172043010752)\n",
      "('Epoch: ', 712, ' Average loss at step ', 761, ': ', 9813.9783736379522)\n",
      "('Epoch: ', 712, ' Average loss at step ', 782, ': ', 11399.422188850433)\n",
      "('Epoch: ', 712, ' Average loss at step ', 787, ': ', 11.052358683132336)\n",
      "('Epoch: ', 712, ' Average loss at step ', 1000, ': ', 3.7247719807624815)\n",
      "('Epoch: ', 712, ' Average loss at step ', 2000, ': ', 3.7157187991142271)\n",
      "('Epoch: ', 712, ' Average loss at step ', 2813, ': ', 3.6864772764920013)\n",
      "Training time took 97.747606 seconds to run 1 epoch\n",
      "('Epoch: ', 713, ' Average loss at step ', 1000, ': ', 0.020179508745670319)\n",
      "('Epoch: ', 713, ' Average loss at step ', 2000, ': ', 0.018129547119140624)\n",
      "('Epoch: ', 713, ' Average loss at step ', 2813, ': ', 0.017841770877979071)\n",
      "Training time took 44.006216 seconds to run 1 epoch\n",
      "('Epoch: ', 714, ' Average loss at step ', 1000, ': ', 127.01570280456544)\n",
      "('Epoch: ', 714, ' Average loss at step ', 2000, ': ', 128.60301093292236)\n",
      "('Epoch: ', 714, ' Average loss at step ', 3000, ': ', 128.25190138244628)\n",
      "('Epoch: ', 714, ' Average loss at step ', 4000, ': ', 128.28544743347169)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 714, ' Average loss at step ', 4373, ': ', 129.52985086748677)\n",
      "('Epoch: ', 714, ' Average loss at step ', 761, ': ', 9804.2151855468746)\n",
      "('Epoch: ', 714, ' Average loss at step ', 782, ': ', 11485.352528434099)\n",
      "('Epoch: ', 714, ' Average loss at step ', 787, ': ', 11.34778601886662)\n",
      "('Epoch: ', 714, ' Average loss at step ', 1000, ': ', 3.6843492674827574)\n",
      "('Epoch: ', 714, ' Average loss at step ', 2000, ': ', 3.7068518223762514)\n",
      "('Epoch: ', 714, ' Average loss at step ', 2813, ': ', 3.8063922685942626)\n",
      "Training time took 97.72778 seconds to run 1 epoch\n",
      "('Epoch: ', 715, ' Average loss at step ', 1000, ': ', 0.019835048973560334)\n",
      "('Epoch: ', 715, ' Average loss at step ', 2000, ': ', 0.018215968549251556)\n",
      "('Epoch: ', 715, ' Average loss at step ', 2813, ': ', 0.017808463552902484)\n",
      "Training time took 44.023716 seconds to run 1 epoch\n",
      "('Epoch: ', 716, ' Average loss at step ', 1000, ': ', 127.38602339172363)\n",
      "('Epoch: ', 716, ' Average loss at step ', 2000, ': ', 126.64989174652099)\n",
      "('Epoch: ', 716, ' Average loss at step ', 3000, ': ', 127.49594117736817)\n",
      "('Epoch: ', 716, ' Average loss at step ', 4000, ': ', 128.48359286499024)\n",
      "('Epoch: ', 716, ' Average loss at step ', 4373, ': ', 129.49790626443843)\n",
      "('Epoch: ', 716, ' Average loss at step ', 761, ': ', 9776.828926166736)\n",
      "('Epoch: ', 716, ' Average loss at step ', 782, ': ', 11303.924777178698)\n",
      "('Epoch: ', 716, ' Average loss at step ', 787, ': ', 11.124121543408654)\n",
      "('Epoch: ', 716, ' Average loss at step ', 1000, ': ', 3.7775263981819154)\n",
      "('Epoch: ', 716, ' Average loss at step ', 2000, ': ', 3.7906645264625549)\n",
      "('Epoch: ', 716, ' Average loss at step ', 2813, ': ', 3.7254648020702041)\n",
      "Training time took 97.715239 seconds to run 1 epoch\n",
      "('Epoch: ', 717, ' Average loss at step ', 1000, ': ', 0.020101300358772278)\n",
      "('Epoch: ', 717, ' Average loss at step ', 2000, ': ', 0.017998533487319945)\n",
      "('Epoch: ', 717, ' Average loss at step ', 2813, ': ', 0.017986883156992532)\n",
      "Training time took 44.016425 seconds to run 1 epoch\n",
      "('Epoch: ', 718, ' Average loss at step ', 1000, ': ', 128.75151678466796)\n",
      "('Epoch: ', 718, ' Average loss at step ', 2000, ': ', 128.32702252197265)\n",
      "('Epoch: ', 718, ' Average loss at step ', 3000, ': ', 126.87788906478882)\n",
      "('Epoch: ', 718, ' Average loss at step ', 4000, ': ', 127.17427441406249)\n",
      "('Epoch: ', 718, ' Average loss at step ', 4373, ': ', 129.78031373793078)\n",
      "('Epoch: ', 718, ' Average loss at step ', 761, ': ', 9743.9579056589228)\n",
      "('Epoch: ', 718, ' Average loss at step ', 782, ': ', 11433.010802206707)\n",
      "('Epoch: ', 718, ' Average loss at step ', 787, ': ', 11.067841578379236)\n",
      "('Epoch: ', 718, ' Average loss at step ', 1000, ': ', 3.6993205628395081)\n",
      "('Epoch: ', 718, ' Average loss at step ', 2000, ': ', 3.772083863258362)\n",
      "('Epoch: ', 718, ' Average loss at step ', 2813, ': ', 3.55654313881409)\n",
      "Training time took 97.748484 seconds to run 1 epoch\n",
      "('Epoch: ', 719, ' Average loss at step ', 1000, ': ', 0.019800641238689423)\n",
      "('Epoch: ', 719, ' Average loss at step ', 2000, ': ', 0.018147752702236175)\n",
      "('Epoch: ', 719, ' Average loss at step ', 2813, ': ', 0.017821329347605774)\n",
      "Training time took 44.033351 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984122748499\n",
      "Hits @ 1:  0.936891260841\n",
      "Testing time took 73.979231 seconds.\n",
      "\n",
      "('Epoch: ', 720, ' Average loss at step ', 1000, ': ', 129.29793445587157)\n",
      "('Epoch: ', 720, ' Average loss at step ', 2000, ': ', 126.66163124084473)\n",
      "('Epoch: ', 720, ' Average loss at step ', 3000, ': ', 128.03750762939453)\n",
      "('Epoch: ', 720, ' Average loss at step ', 4000, ': ', 128.82765073394776)\n",
      "('Epoch: ', 720, ' Average loss at step ', 4373, ': ', 129.00737760400258)\n",
      "('Epoch: ', 720, ' Average loss at step ', 761, ': ', 9822.3211869089228)\n",
      "('Epoch: ', 720, ' Average loss at step ', 782, ': ', 11469.235223396487)\n",
      "('Epoch: ', 720, ' Average loss at step ', 787, ': ', 11.30045830869796)\n",
      "('Epoch: ', 720, ' Average loss at step ', 1000, ': ', 3.8065863776206972)\n",
      "('Epoch: ', 720, ' Average loss at step ', 2000, ': ', 3.7395868973731994)\n",
      "('Epoch: ', 720, ' Average loss at step ', 2813, ': ', 3.6048536406362)\n",
      "Training time took 97.835392 seconds to run 1 epoch\n",
      "('Epoch: ', 721, ' Average loss at step ', 1000, ': ', 0.01986408966779709)\n",
      "('Epoch: ', 721, ' Average loss at step ', 2000, ': ', 0.018074353873729705)\n",
      "('Epoch: ', 721, ' Average loss at step ', 2813, ': ', 0.017656720330562498)\n",
      "Training time took 44.032937 seconds to run 1 epoch\n",
      "('Epoch: ', 722, ' Average loss at step ', 1000, ': ', 129.32742394256593)\n",
      "('Epoch: ', 722, ' Average loss at step ', 2000, ': ', 128.58071308898926)\n",
      "('Epoch: ', 722, ' Average loss at step ', 3000, ': ', 127.62349182891846)\n",
      "('Epoch: ', 722, ' Average loss at step ', 4000, ': ', 126.28831591033935)\n",
      "('Epoch: ', 722, ' Average loss at step ', 4373, ': ', 129.82515954458586)\n",
      "('Epoch: ', 722, ' Average loss at step ', 761, ': ', 9864.2388601202711)\n",
      "('Epoch: ', 722, ' Average loss at step ', 782, ': ', 11352.317334046895)\n",
      "('Epoch: ', 722, ' Average loss at step ', 787, ': ', 11.194866036034115)\n",
      "('Epoch: ', 722, ' Average loss at step ', 1000, ': ', 3.7572031779289246)\n",
      "('Epoch: ', 722, ' Average loss at step ', 2000, ': ', 3.6424612860679626)\n",
      "('Epoch: ', 722, ' Average loss at step ', 2813, ': ', 3.6661394329493855)\n",
      "Training time took 97.778309 seconds to run 1 epoch\n",
      "('Epoch: ', 723, ' Average loss at step ', 1000, ': ', 0.0196667200922966)\n",
      "('Epoch: ', 723, ' Average loss at step ', 2000, ': ', 0.018100851833820344)\n",
      "('Epoch: ', 723, ' Average loss at step ', 2813, ': ', 0.017665702427549314)\n",
      "Training time took 44.034973 seconds to run 1 epoch\n",
      "('Epoch: ', 724, ' Average loss at step ', 1000, ': ', 125.92494078826904)\n",
      "('Epoch: ', 724, ' Average loss at step ', 2000, ': ', 128.20930317687987)\n",
      "('Epoch: ', 724, ' Average loss at step ', 3000, ': ', 126.78201892852783)\n",
      "('Epoch: ', 724, ' Average loss at step ', 4000, ': ', 130.0427939453125)\n",
      "('Epoch: ', 724, ' Average loss at step ', 4373, ': ', 128.79964381392284)\n",
      "('Epoch: ', 724, ' Average loss at step ', 761, ': ', 9856.9272608706833)\n",
      "('Epoch: ', 724, ' Average loss at step ', 782, ': ', 11469.342295159451)\n",
      "('Epoch: ', 724, ' Average loss at step ', 787, ': ', 10.977766659423596)\n",
      "('Epoch: ', 724, ' Average loss at step ', 1000, ': ', 3.6882174763679503)\n",
      "('Epoch: ', 724, ' Average loss at step ', 2000, ': ', 3.6720595722198488)\n",
      "('Epoch: ', 724, ' Average loss at step ', 2813, ': ', 3.8667130247125483)\n",
      "Training time took 97.825284 seconds to run 1 epoch\n",
      "('Epoch: ', 725, ' Average loss at step ', 1000, ': ', 0.019701100409030916)\n",
      "('Epoch: ', 725, ' Average loss at step ', 2000, ': ', 0.018031141340732575)\n",
      "('Epoch: ', 725, ' Average loss at step ', 2813, ': ', 0.017591627507374204)\n",
      "Training time took 44.030881 seconds to run 1 epoch\n",
      "('Epoch: ', 726, ' Average loss at step ', 1000, ': ', 128.73086441040039)\n",
      "('Epoch: ', 726, ' Average loss at step ', 2000, ': ', 127.20268251800537)\n",
      "('Epoch: ', 726, ' Average loss at step ', 3000, ': ', 127.04084030914306)\n",
      "('Epoch: ', 726, ' Average loss at step ', 4000, ': ', 128.03610372924805)\n",
      "('Epoch: ', 726, ' Average loss at step ', 4373, ': ', 126.7741935483871)\n",
      "('Epoch: ', 726, ' Average loss at step ', 761, ': ', 9863.6619969418171)\n",
      "('Epoch: ', 726, ' Average loss at step ', 782, ': ', 11449.648386858795)\n",
      "('Epoch: ', 726, ' Average loss at step ', 787, ': ', 10.923543799014492)\n",
      "('Epoch: ', 726, ' Average loss at step ', 1000, ': ', 3.70724773645401)\n",
      "('Epoch: ', 726, ' Average loss at step ', 2000, ': ', 3.6877508907318117)\n",
      "('Epoch: ', 726, ' Average loss at step ', 2813, ': ', 3.7941645366217704)\n",
      "Training time took 97.755515 seconds to run 1 epoch\n",
      "('Epoch: ', 727, ' Average loss at step ', 1000, ': ', 0.019331031739711763)\n",
      "('Epoch: ', 727, ' Average loss at step ', 2000, ': ', 0.017849010407924651)\n",
      "('Epoch: ', 727, ' Average loss at step ', 2813, ': ', 0.017780030082012045)\n",
      "Training time took 44.035466 seconds to run 1 epoch\n",
      "('Epoch: ', 728, ' Average loss at step ', 1000, ': ', 128.77248307800292)\n",
      "('Epoch: ', 728, ' Average loss at step ', 2000, ': ', 127.27923950195313)\n",
      "('Epoch: ', 728, ' Average loss at step ', 3000, ': ', 128.31880875396729)\n",
      "('Epoch: ', 728, ' Average loss at step ', 4000, ': ', 127.94370793151856)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 728, ' Average loss at step ', 4373, ': ', 127.23118279569893)\n",
      "('Epoch: ', 728, ' Average loss at step ', 761, ': ', 9814.5732164884867)\n",
      "('Epoch: ', 728, ' Average loss at step ', 782, ': ', 11470.528686679738)\n",
      "('Epoch: ', 728, ' Average loss at step ', 787, ': ', 11.001753589882499)\n",
      "('Epoch: ', 728, ' Average loss at step ', 1000, ': ', 3.7857349309921267)\n",
      "('Epoch: ', 728, ' Average loss at step ', 2000, ': ', 3.6464172945022582)\n",
      "('Epoch: ', 728, ' Average loss at step ', 2813, ': ', 3.7840329960649237)\n",
      "Training time took 97.693841 seconds to run 1 epoch\n",
      "('Epoch: ', 729, ' Average loss at step ', 1000, ': ', 0.019754652559757231)\n",
      "('Epoch: ', 729, ' Average loss at step ', 2000, ': ', 0.017862077355384826)\n",
      "('Epoch: ', 729, ' Average loss at step ', 2813, ': ', 0.017721068315905305)\n",
      "Training time took 44.019073 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.98418945964\n",
      "Hits @ 1:  0.935623749166\n",
      "Testing time took 73.446262 seconds.\n",
      "\n",
      "('Epoch: ', 730, ' Average loss at step ', 1000, ': ', 126.99293243408204)\n",
      "('Epoch: ', 730, ' Average loss at step ', 2000, ': ', 129.12526107025147)\n",
      "('Epoch: ', 730, ' Average loss at step ', 3000, ': ', 127.59059048461914)\n",
      "('Epoch: ', 730, ' Average loss at step ', 4000, ': ', 127.94035377502442)\n",
      "('Epoch: ', 730, ' Average loss at step ', 4373, ': ', 127.41935483870968)\n",
      "('Epoch: ', 730, ' Average loss at step ', 761, ': ', 9888.931832725124)\n",
      "('Epoch: ', 730, ' Average loss at step ', 782, ': ', 11477.602294609274)\n",
      "('Epoch: ', 730, ' Average loss at step ', 787, ': ', 10.985678599990962)\n",
      "('Epoch: ', 730, ' Average loss at step ', 1000, ': ', 3.7690609970092774)\n",
      "('Epoch: ', 730, ' Average loss at step ', 2000, ': ', 3.8271628527641295)\n",
      "('Epoch: ', 730, ' Average loss at step ', 2813, ': ', 3.8247719891552854)\n",
      "Training time took 97.833724 seconds to run 1 epoch\n",
      "('Epoch: ', 731, ' Average loss at step ', 1000, ': ', 0.019448611259460451)\n",
      "('Epoch: ', 731, ' Average loss at step ', 2000, ': ', 0.01795171195268631)\n",
      "('Epoch: ', 731, ' Average loss at step ', 2813, ': ', 0.017334095876792383)\n",
      "Training time took 44.046594 seconds to run 1 epoch\n",
      "('Epoch: ', 732, ' Average loss at step ', 1000, ': ', 127.23232612609863)\n",
      "('Epoch: ', 732, ' Average loss at step ', 2000, ': ', 127.72)\n",
      "('Epoch: ', 732, ' Average loss at step ', 3000, ': ', 129.12753202056885)\n",
      "('Epoch: ', 732, ' Average loss at step ', 4000, ': ', 127.77949118041992)\n",
      "('Epoch: ', 732, ' Average loss at step ', 4373, ': ', 132.22194618307134)\n",
      "('Epoch: ', 732, ' Average loss at step ', 761, ': ', 9970.2534687243005)\n",
      "('Epoch: ', 732, ' Average loss at step ', 782, ': ', 11549.986148067381)\n",
      "('Epoch: ', 732, ' Average loss at step ', 787, ': ', 10.887600353352592)\n",
      "('Epoch: ', 732, ' Average loss at step ', 1000, ': ', 3.6751445994377137)\n",
      "('Epoch: ', 732, ' Average loss at step ', 2000, ': ', 3.702145579814911)\n",
      "('Epoch: ', 732, ' Average loss at step ', 2813, ': ', 3.7037595498738032)\n",
      "Training time took 97.797984 seconds to run 1 epoch\n",
      "('Epoch: ', 733, ' Average loss at step ', 1000, ': ', 0.019464487493038179)\n",
      "('Epoch: ', 733, ' Average loss at step ', 2000, ': ', 0.017728555917739867)\n",
      "('Epoch: ', 733, ' Average loss at step ', 2813, ': ', 0.01757753834935832)\n",
      "Training time took 44.014535 seconds to run 1 epoch\n",
      "('Epoch: ', 734, ' Average loss at step ', 1000, ': ', 126.29532932281494)\n",
      "('Epoch: ', 734, ' Average loss at step ', 2000, ': ', 127.55672682189942)\n",
      "('Epoch: ', 734, ' Average loss at step ', 3000, ': ', 129.30624978637695)\n",
      "('Epoch: ', 734, ' Average loss at step ', 4000, ': ', 128.47338211822509)\n",
      "('Epoch: ', 734, ' Average loss at step ', 4373, ': ', 127.42637630175518)\n",
      "('Epoch: ', 734, ' Average loss at step ', 761, ': ', 9844.7308677271794)\n",
      "('Epoch: ', 734, ' Average loss at step ', 782, ': ', 11577.161325999319)\n",
      "('Epoch: ', 734, ' Average loss at step ', 787, ': ', 10.670590878746285)\n",
      "('Epoch: ', 734, ' Average loss at step ', 1000, ': ', 3.8086737947463991)\n",
      "('Epoch: ', 734, ' Average loss at step ', 2000, ': ', 3.8219598522186278)\n",
      "('Epoch: ', 734, ' Average loss at step ', 2813, ': ', 3.708376608458646)\n",
      "Training time took 97.733638 seconds to run 1 epoch\n",
      "('Epoch: ', 735, ' Average loss at step ', 1000, ': ', 0.019448650598526001)\n",
      "('Epoch: ', 735, ' Average loss at step ', 2000, ': ', 0.017840201914310454)\n",
      "('Epoch: ', 735, ' Average loss at step ', 2813, ': ', 0.017405711151108953)\n",
      "Training time took 44.038837 seconds to run 1 epoch\n",
      "('Epoch: ', 736, ' Average loss at step ', 1000, ': ', 127.05036714172363)\n",
      "('Epoch: ', 736, ' Average loss at step ', 2000, ': ', 128.47483254241942)\n",
      "('Epoch: ', 736, ' Average loss at step ', 3000, ': ', 126.74129070281982)\n",
      "('Epoch: ', 736, ' Average loss at step ', 4000, ': ', 127.71778392028808)\n",
      "('Epoch: ', 736, ' Average loss at step ', 4373, ': ', 130.78171822332567)\n",
      "('Epoch: ', 736, ' Average loss at step ', 761, ': ', 9970.2358353464224)\n",
      "('Epoch: ', 736, ' Average loss at step ', 782, ': ', 11453.982052381762)\n",
      "('Epoch: ', 736, ' Average loss at step ', 787, ': ', 10.912395529467945)\n",
      "('Epoch: ', 736, ' Average loss at step ', 1000, ': ', 3.6791962828636171)\n",
      "('Epoch: ', 736, ' Average loss at step ', 2000, ': ', 3.7282647471427919)\n",
      "('Epoch: ', 736, ' Average loss at step ', 2813, ': ', 3.5750399780978124)\n",
      "Training time took 97.850985 seconds to run 1 epoch\n",
      "('Epoch: ', 737, ' Average loss at step ', 1000, ': ', 0.019330926716327666)\n",
      "('Epoch: ', 737, ' Average loss at step ', 2000, ': ', 0.017672292292118072)\n",
      "('Epoch: ', 737, ' Average loss at step ', 2813, ': ', 0.017395794905465226)\n",
      "Training time took 44.025488 seconds to run 1 epoch\n",
      "('Epoch: ', 738, ' Average loss at step ', 1000, ': ', 126.51812351989746)\n",
      "('Epoch: ', 738, ' Average loss at step ', 2000, ': ', 126.16946606445312)\n",
      "('Epoch: ', 738, ' Average loss at step ', 3000, ': ', 126.79049687194824)\n",
      "('Epoch: ', 738, ' Average loss at step ', 4000, ': ', 130.34096593475343)\n",
      "('Epoch: ', 738, ' Average loss at step ', 4373, ': ', 134.73312459966189)\n",
      "('Epoch: ', 738, ' Average loss at step ', 761, ': ', 9923.6789872018908)\n",
      "('Epoch: ', 738, ' Average loss at step ', 782, ': ', 11580.402855788852)\n",
      "('Epoch: ', 738, ' Average loss at step ', 787, ': ', 11.031175336764969)\n",
      "('Epoch: ', 738, ' Average loss at step ', 1000, ': ', 3.6251181411743163)\n",
      "('Epoch: ', 738, ' Average loss at step ', 2000, ': ', 3.7374236593246462)\n",
      "('Epoch: ', 738, ' Average loss at step ', 2813, ': ', 3.6737636163316925)\n",
      "Training time took 97.819363 seconds to run 1 epoch\n",
      "('Epoch: ', 739, ' Average loss at step ', 1000, ': ', 0.019386849284172059)\n",
      "('Epoch: ', 739, ' Average loss at step ', 2000, ': ', 0.017680358886718751)\n",
      "('Epoch: ', 739, ' Average loss at step ', 2813, ': ', 0.017303730099659249)\n",
      "Training time took 44.048931 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984122748499\n",
      "Hits @ 1:  0.936757838559\n",
      "Testing time took 73.488755 seconds.\n",
      "\n",
      "('Epoch: ', 740, ' Average loss at step ', 1000, ': ', 128.81726285552978)\n",
      "('Epoch: ', 740, ' Average loss at step ', 2000, ': ', 129.36386302947997)\n",
      "('Epoch: ', 740, ' Average loss at step ', 3000, ': ', 128.13955580139159)\n",
      "('Epoch: ', 740, ' Average loss at step ', 4000, ': ', 127.11452194976806)\n",
      "('Epoch: ', 740, ' Average loss at step ', 4373, ': ', 128.49890932472803)\n",
      "('Epoch: ', 740, ' Average loss at step ', 761, ': ', 9919.5810212787837)\n",
      "('Epoch: ', 740, ' Average loss at step ', 782, ': ', 11568.326393195823)\n",
      "('Epoch: ', 740, ' Average loss at step ', 787, ': ', 11.044567220993624)\n",
      "('Epoch: ', 740, ' Average loss at step ', 1000, ': ', 3.735977014064789)\n",
      "('Epoch: ', 740, ' Average loss at step ', 2000, ': ', 3.6814486594200133)\n",
      "('Epoch: ', 740, ' Average loss at step ', 2813, ': ', 3.6377085047989643)\n",
      "Training time took 97.820937 seconds to run 1 epoch\n",
      "('Epoch: ', 741, ' Average loss at step ', 1000, ': ', 0.019496584832668303)\n",
      "('Epoch: ', 741, ' Average loss at step ', 2000, ': ', 0.017596660494804382)\n",
      "('Epoch: ', 741, ' Average loss at step ', 2813, ': ', 0.017191839922825105)\n",
      "Training time took 44.014723 seconds to run 1 epoch\n",
      "('Epoch: ', 742, ' Average loss at step ', 1000, ': ', 127.57089929199219)\n",
      "('Epoch: ', 742, ' Average loss at step ', 2000, ': ', 126.74026412963867)\n",
      "('Epoch: ', 742, ' Average loss at step ', 3000, ': ', 128.58547613525391)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 742, ' Average loss at step ', 4000, ': ', 129.9434584121704)\n",
      "('Epoch: ', 742, ' Average loss at step ', 4373, ': ', 126.29069125267768)\n",
      "('Epoch: ', 742, ' Average loss at step ', 761, ': ', 9896.4962312397201)\n",
      "('Epoch: ', 742, ' Average loss at step ', 782, ': ', 11520.169801836588)\n",
      "('Epoch: ', 742, ' Average loss at step ', 787, ': ', 10.849181337817631)\n",
      "('Epoch: ', 742, ' Average loss at step ', 1000, ': ', 3.6709267969131472)\n",
      "('Epoch: ', 742, ' Average loss at step ', 2000, ': ', 3.6256296925544738)\n",
      "('Epoch: ', 742, ' Average loss at step ', 2813, ': ', 3.7057460464280227)\n",
      "Training time took 97.646183 seconds to run 1 epoch\n",
      "('Epoch: ', 743, ' Average loss at step ', 1000, ': ', 0.019242795825004579)\n",
      "('Epoch: ', 743, ' Average loss at step ', 2000, ': ', 0.017502911686897278)\n",
      "('Epoch: ', 743, ' Average loss at step ', 2813, ': ', 0.017158103840691701)\n",
      "Training time took 44.002064 seconds to run 1 epoch\n",
      "('Epoch: ', 744, ' Average loss at step ', 1000, ': ', 127.51583155822753)\n",
      "('Epoch: ', 744, ' Average loss at step ', 2000, ': ', 128.80253684997558)\n",
      "('Epoch: ', 744, ' Average loss at step ', 3000, ': ', 127.85157439422608)\n",
      "('Epoch: ', 744, ' Average loss at step ', 4000, ': ', 126.87454125976562)\n",
      "('Epoch: ', 744, ' Average loss at step ', 4373, ': ', 126.591795890562)\n",
      "('Epoch: ', 744, ' Average loss at step ', 761, ': ', 9942.3769948858971)\n",
      "('Epoch: ', 744, ' Average loss at step ', 782, ': ', 11543.240081200984)\n",
      "('Epoch: ', 744, ' Average loss at step ', 787, ': ', 11.167014617046327)\n",
      "('Epoch: ', 744, ' Average loss at step ', 1000, ': ', 3.7142281804084778)\n",
      "('Epoch: ', 744, ' Average loss at step ', 2000, ': ', 3.8027398858070374)\n",
      "('Epoch: ', 744, ' Average loss at step ', 2813, ': ', 3.6551679625299762)\n",
      "Training time took 97.720467 seconds to run 1 epoch\n",
      "('Epoch: ', 745, ' Average loss at step ', 1000, ': ', 0.01929843443632126)\n",
      "('Epoch: ', 745, ' Average loss at step ', 2000, ': ', 0.017615696489810942)\n",
      "('Epoch: ', 745, ' Average loss at step ', 2813, ': ', 0.017258108102629337)\n",
      "Training time took 44.041438 seconds to run 1 epoch\n",
      "('Epoch: ', 746, ' Average loss at step ', 1000, ': ', 129.18490012359618)\n",
      "('Epoch: ', 746, ' Average loss at step ', 2000, ': ', 127.76253731536865)\n",
      "('Epoch: ', 746, ' Average loss at step ', 3000, ': ', 129.23109313964844)\n",
      "('Epoch: ', 746, ' Average loss at step ', 4000, ': ', 127.36303912353516)\n",
      "('Epoch: ', 746, ' Average loss at step ', 4373, ': ', 128.85677866781913)\n",
      "('Epoch: ', 746, ' Average loss at step ', 761, ': ', 9968.7520250822363)\n",
      "('Epoch: ', 746, ' Average loss at step ', 782, ': ', 11527.180433988877)\n",
      "('Epoch: ', 746, ' Average loss at step ', 787, ': ', 11.255883096738627)\n",
      "('Epoch: ', 746, ' Average loss at step ', 1000, ': ', 3.7091171526908875)\n",
      "('Epoch: ', 746, ' Average loss at step ', 2000, ': ', 3.6215919671058656)\n",
      "('Epoch: ', 746, ' Average loss at step ', 2813, ': ', 3.7712664316440452)\n",
      "Training time took 97.676383 seconds to run 1 epoch\n",
      "('Epoch: ', 747, ' Average loss at step ', 1000, ': ', 0.018906842052936555)\n",
      "('Epoch: ', 747, ' Average loss at step ', 2000, ': ', 0.017746743559837342)\n",
      "('Epoch: ', 747, ' Average loss at step ', 2813, ': ', 0.017229386738368442)\n",
      "Training time took 44.006327 seconds to run 1 epoch\n",
      "('Epoch: ', 748, ' Average loss at step ', 1000, ': ', 128.59091076660155)\n",
      "('Epoch: ', 748, ' Average loss at step ', 2000, ': ', 128.28752097320557)\n",
      "('Epoch: ', 748, ' Average loss at step ', 3000, ': ', 128.93529085540771)\n",
      "('Epoch: ', 748, ' Average loss at step ', 4000, ': ', 129.37309380340577)\n",
      "('Epoch: ', 748, ' Average loss at step ', 4373, ': ', 131.4349308013916)\n",
      "('Epoch: ', 748, ' Average loss at step ', 761, ': ', 9980.3843390213824)\n",
      "('Epoch: ', 748, ' Average loss at step ', 782, ': ', 11643.278375955306)\n",
      "('Epoch: ', 748, ' Average loss at step ', 787, ': ', 10.80293682877344)\n",
      "('Epoch: ', 748, ' Average loss at step ', 1000, ': ', 3.6902609543800353)\n",
      "('Epoch: ', 748, ' Average loss at step ', 2000, ': ', 3.630631428718567)\n",
      "('Epoch: ', 748, ' Average loss at step ', 2813, ': ', 3.7844666571452699)\n",
      "Training time took 97.753209 seconds to run 1 epoch\n",
      "('Epoch: ', 749, ' Average loss at step ', 1000, ': ', 0.019221373915672302)\n",
      "('Epoch: ', 749, ' Average loss at step ', 2000, ': ', 0.01740069478750229)\n",
      "('Epoch: ', 749, ' Average loss at step ', 2813, ': ', 0.017122597750184571)\n",
      "Training time took 44.029953 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.983922615077\n",
      "Hits @ 1:  0.937158105404\n",
      "Testing time took 73.472353 seconds.\n",
      "\n",
      "('Epoch: ', 750, ' Average loss at step ', 1000, ': ', 130.09694560241698)\n",
      "('Epoch: ', 750, ' Average loss at step ', 2000, ': ', 128.78911430358886)\n",
      "('Epoch: ', 750, ' Average loss at step ', 3000, ': ', 128.53662451934815)\n",
      "('Epoch: ', 750, ' Average loss at step ', 4000, ': ', 128.63959674835206)\n",
      "('Epoch: ', 750, ' Average loss at step ', 4373, ': ', 126.32504366802912)\n",
      "('Epoch: ', 750, ' Average loss at step ', 761, ': ', 9949.8982511821541)\n",
      "('Epoch: ', 750, ' Average loss at step ', 782, ': ', 11621.041391995439)\n",
      "('Epoch: ', 750, ' Average loss at step ', 787, ': ', 10.921801303785873)\n",
      "('Epoch: ', 750, ' Average loss at step ', 1000, ': ', 3.5854876461029055)\n",
      "('Epoch: ', 750, ' Average loss at step ', 2000, ': ', 3.7187772684097289)\n",
      "('Epoch: ', 750, ' Average loss at step ', 2813, ': ', 3.8717874223962792)\n",
      "Training time took 97.757392 seconds to run 1 epoch\n",
      "('Epoch: ', 751, ' Average loss at step ', 1000, ': ', 0.018888747096061708)\n",
      "('Epoch: ', 751, ' Average loss at step ', 2000, ': ', 0.0174563090801239)\n",
      "('Epoch: ', 751, ' Average loss at step ', 2813, ': ', 0.017094153268583889)\n",
      "Training time took 44.020671 seconds to run 1 epoch\n",
      "('Epoch: ', 752, ' Average loss at step ', 1000, ': ', 126.36132579803467)\n",
      "('Epoch: ', 752, ' Average loss at step ', 2000, ': ', 129.92207747650147)\n",
      "('Epoch: ', 752, ' Average loss at step ', 3000, ': ', 128.77619639587402)\n",
      "('Epoch: ', 752, ' Average loss at step ', 4000, ': ', 128.6132071533203)\n",
      "('Epoch: ', 752, ' Average loss at step ', 4373, ': ', 128.44399567060574)\n",
      "('Epoch: ', 752, ' Average loss at step ', 761, ': ', 10079.367407226562)\n",
      "('Epoch: ', 752, ' Average loss at step ', 782, ': ', 11570.375596440861)\n",
      "('Epoch: ', 752, ' Average loss at step ', 787, ': ', 10.771585065293252)\n",
      "('Epoch: ', 752, ' Average loss at step ', 1000, ': ', 3.6770835623741149)\n",
      "('Epoch: ', 752, ' Average loss at step ', 2000, ': ', 3.610988884449005)\n",
      "('Epoch: ', 752, ' Average loss at step ', 2813, ': ', 3.6867825474057878)\n",
      "Training time took 97.756561 seconds to run 1 epoch\n",
      "('Epoch: ', 753, ' Average loss at step ', 1000, ': ', 0.019042333900928497)\n",
      "('Epoch: ', 753, ' Average loss at step ', 2000, ': ', 0.017212548911571503)\n",
      "('Epoch: ', 753, ' Average loss at step ', 2813, ': ', 0.017183050953695926)\n",
      "Training time took 44.012041 seconds to run 1 epoch\n",
      "('Epoch: ', 754, ' Average loss at step ', 1000, ': ', 128.91376248931886)\n",
      "('Epoch: ', 754, ' Average loss at step ', 2000, ': ', 127.701179397583)\n",
      "('Epoch: ', 754, ' Average loss at step ', 3000, ': ', 126.78243063354492)\n",
      "('Epoch: ', 754, ' Average loss at step ', 4000, ': ', 129.17489794921875)\n",
      "('Epoch: ', 754, ' Average loss at step ', 4373, ': ', 128.20000529545609)\n",
      "('Epoch: ', 754, ' Average loss at step ', 761, ': ', 9983.4004606548115)\n",
      "('Epoch: ', 754, ' Average loss at step ', 782, ': ', 11693.410974636883)\n",
      "('Epoch: ', 754, ' Average loss at step ', 787, ': ', 10.779226072568626)\n",
      "('Epoch: ', 754, ' Average loss at step ', 1000, ': ', 3.7394112854003905)\n",
      "('Epoch: ', 754, ' Average loss at step ', 2000, ': ', 3.6992412853240966)\n",
      "('Epoch: ', 754, ' Average loss at step ', 2813, ': ', 3.6090090039915639)\n",
      "Training time took 97.733211 seconds to run 1 epoch\n",
      "('Epoch: ', 755, ' Average loss at step ', 1000, ': ', 0.018919484674930574)\n",
      "('Epoch: ', 755, ' Average loss at step ', 2000, ': ', 0.017425056159496306)\n",
      "('Epoch: ', 755, ' Average loss at step ', 2813, ': ', 0.01687355992829271)\n",
      "Training time took 44.018306 seconds to run 1 epoch\n",
      "('Epoch: ', 756, ' Average loss at step ', 1000, ': ', 129.48191589355469)\n",
      "('Epoch: ', 756, ' Average loss at step ', 2000, ': ', 128.69370333862304)\n",
      "('Epoch: ', 756, ' Average loss at step ', 3000, ': ', 127.33638005828857)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 756, ' Average loss at step ', 4000, ': ', 128.54752442169189)\n",
      "('Epoch: ', 756, ' Average loss at step ', 4373, ': ', 129.27209046066449)\n",
      "('Epoch: ', 756, ' Average loss at step ', 761, ': ', 9971.9403326737247)\n",
      "('Epoch: ', 756, ' Average loss at step ', 782, ': ', 11730.568686354634)\n",
      "('Epoch: ', 756, ' Average loss at step ', 787, ': ', 10.718940780969673)\n",
      "('Epoch: ', 756, ' Average loss at step ', 1000, ': ', 3.6739021563529968)\n",
      "('Epoch: ', 756, ' Average loss at step ', 2000, ': ', 3.7281303429603576)\n",
      "('Epoch: ', 756, ' Average loss at step ', 2813, ': ', 3.7485161056659493)\n",
      "Training time took 97.790738 seconds to run 1 epoch\n",
      "('Epoch: ', 757, ' Average loss at step ', 1000, ': ', 0.018759504556655884)\n",
      "('Epoch: ', 757, ' Average loss at step ', 2000, ': ', 0.017198545277118681)\n",
      "('Epoch: ', 757, ' Average loss at step ', 2813, ': ', 0.016919853652052105)\n",
      "Training time took 44.036632 seconds to run 1 epoch\n",
      "('Epoch: ', 758, ' Average loss at step ', 1000, ': ', 128.75125254821776)\n",
      "('Epoch: ', 758, ' Average loss at step ', 2000, ': ', 127.31371795654297)\n",
      "('Epoch: ', 758, ' Average loss at step ', 3000, ': ', 127.86693305969239)\n",
      "('Epoch: ', 758, ' Average loss at step ', 4000, ': ', 127.90579042816162)\n",
      "('Epoch: ', 758, ' Average loss at step ', 4373, ': ', 131.74200377925749)\n",
      "('Epoch: ', 758, ' Average loss at step ', 761, ': ', 10038.436729350842)\n",
      "('Epoch: ', 758, ' Average loss at step ', 782, ': ', 11660.444452224712)\n",
      "('Epoch: ', 758, ' Average loss at step ', 787, ': ', 10.740677594531887)\n",
      "('Epoch: ', 758, ' Average loss at step ', 1000, ': ', 3.7741328892707826)\n",
      "('Epoch: ', 758, ' Average loss at step ', 2000, ': ', 3.6343317732810974)\n",
      "('Epoch: ', 758, ' Average loss at step ', 2813, ': ', 3.6330011983223147)\n",
      "Training time took 98.153962 seconds to run 1 epoch\n",
      "('Epoch: ', 759, ' Average loss at step ', 1000, ': ', 0.019021775424480438)\n",
      "('Epoch: ', 759, ' Average loss at step ', 2000, ': ', 0.017320213615894319)\n",
      "('Epoch: ', 759, ' Average loss at step ', 2813, ': ', 0.016867151181098862)\n",
      "Training time took 44.13342 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.983789192795\n",
      "Hits @ 1:  0.937224816544\n",
      "Testing time took 73.446312 seconds.\n",
      "\n",
      "('Epoch: ', 760, ' Average loss at step ', 1000, ': ', 127.98638285827637)\n",
      "('Epoch: ', 760, ' Average loss at step ', 2000, ': ', 128.21124118041993)\n",
      "('Epoch: ', 760, ' Average loss at step ', 3000, ': ', 129.17810626220702)\n",
      "('Epoch: ', 760, ' Average loss at step ', 4000, ': ', 127.95832297515869)\n",
      "('Epoch: ', 760, ' Average loss at step ', 4373, ': ', 127.80668990842757)\n",
      "('Epoch: ', 760, ' Average loss at step ', 761, ': ', 9954.224840023644)\n",
      "('Epoch: ', 760, ' Average loss at step ', 782, ': ', 11672.859101787571)\n",
      "('Epoch: ', 760, ' Average loss at step ', 787, ': ', 10.540784286178706)\n",
      "('Epoch: ', 760, ' Average loss at step ', 1000, ': ', 3.6178768882751466)\n",
      "('Epoch: ', 760, ' Average loss at step ', 2000, ': ', 3.524839797973633)\n",
      "('Epoch: ', 760, ' Average loss at step ', 2813, ': ', 3.6882658098718801)\n",
      "Training time took 97.779704 seconds to run 1 epoch\n",
      "('Epoch: ', 761, ' Average loss at step ', 1000, ': ', 0.018832876086235045)\n",
      "('Epoch: ', 761, ' Average loss at step ', 2000, ': ', 0.017204850316047668)\n",
      "('Epoch: ', 761, ' Average loss at step ', 2813, ': ', 0.016691870069856125)\n",
      "Training time took 44.008735 seconds to run 1 epoch\n",
      "('Epoch: ', 762, ' Average loss at step ', 1000, ': ', 128.71197611999511)\n",
      "('Epoch: ', 762, ' Average loss at step ', 2000, ': ', 129.69)\n",
      "('Epoch: ', 762, ' Average loss at step ', 3000, ': ', 128.00033454895021)\n",
      "('Epoch: ', 762, ' Average loss at step ', 4000, ': ', 128.80182384490968)\n",
      "('Epoch: ', 762, ' Average loss at step ', 4373, ': ', 126.29779374727639)\n",
      "('Epoch: ', 762, ' Average loss at step ', 761, ': ', 10049.951867033305)\n",
      "('Epoch: ', 762, ' Average loss at step ', 782, ': ', 11663.757357979553)\n",
      "('Epoch: ', 762, ' Average loss at step ', 787, ': ', 10.77691999949875)\n",
      "('Epoch: ', 762, ' Average loss at step ', 1000, ': ', 3.6266341733932497)\n",
      "('Epoch: ', 762, ' Average loss at step ', 2000, ': ', 3.6573448743820189)\n",
      "('Epoch: ', 762, ' Average loss at step ', 2813, ': ', 3.6393229086410823)\n",
      "Training time took 97.797815 seconds to run 1 epoch\n",
      "('Epoch: ', 763, ' Average loss at step ', 1000, ': ', 0.018851203203201293)\n",
      "('Epoch: ', 763, ' Average loss at step ', 2000, ': ', 0.017036124587059023)\n",
      "('Epoch: ', 763, ' Average loss at step ', 2813, ': ', 0.016945840396317354)\n",
      "Training time took 44.054405 seconds to run 1 epoch\n",
      "('Epoch: ', 764, ' Average loss at step ', 1000, ': ', 126.97469925689697)\n",
      "('Epoch: ', 764, ' Average loss at step ', 2000, ': ', 129.14523622894288)\n",
      "('Epoch: ', 764, ' Average loss at step ', 3000, ': ', 127.31610758209229)\n",
      "('Epoch: ', 764, ' Average loss at step ', 4000, ': ', 129.16544929504394)\n",
      "('Epoch: ', 764, ' Average loss at step ', 4373, ': ', 131.74806373350083)\n",
      "('Epoch: ', 764, ' Average loss at step ', 761, ': ', 9971.6234150133641)\n",
      "('Epoch: ', 764, ' Average loss at step ', 782, ': ', 11719.413068431899)\n",
      "('Epoch: ', 764, ' Average loss at step ', 787, ': ', 10.447429164372025)\n",
      "('Epoch: ', 764, ' Average loss at step ', 1000, ': ', 3.6736971683502198)\n",
      "('Epoch: ', 764, ' Average loss at step ', 2000, ': ', 3.630057915210724)\n",
      "('Epoch: ', 764, ' Average loss at step ', 2813, ': ', 3.6829818645721586)\n",
      "Training time took 97.71163 seconds to run 1 epoch\n",
      "('Epoch: ', 765, ' Average loss at step ', 1000, ': ', 0.018630754590034486)\n",
      "('Epoch: ', 765, ' Average loss at step ', 2000, ': ', 0.017124125063419343)\n",
      "('Epoch: ', 765, ' Average loss at step ', 2813, ': ', 0.016761075760343393)\n",
      "Training time took 44.056193 seconds to run 1 epoch\n",
      "('Epoch: ', 766, ' Average loss at step ', 1000, ': ', 128.55670314788819)\n",
      "('Epoch: ', 766, ' Average loss at step ', 2000, ': ', 128.03214160919188)\n",
      "('Epoch: ', 766, ' Average loss at step ', 3000, ': ', 127.98845743560791)\n",
      "('Epoch: ', 766, ' Average loss at step ', 4000, ': ', 128.73700360107421)\n",
      "('Epoch: ', 766, ' Average loss at step ', 4373, ': ', 129.15321079377205)\n",
      "('Epoch: ', 766, ' Average loss at step ', 761, ': ', 10026.811003032484)\n",
      "('Epoch: ', 766, ' Average loss at step ', 782, ': ', 11556.512200154049)\n",
      "('Epoch: ', 766, ' Average loss at step ', 787, ': ', 10.74304404028196)\n",
      "('Epoch: ', 766, ' Average loss at step ', 1000, ': ', 3.6227659711837767)\n",
      "('Epoch: ', 766, ' Average loss at step ', 2000, ': ', 3.5748677101135256)\n",
      "('Epoch: ', 766, ' Average loss at step ', 2813, ': ', 3.5882717600009713)\n",
      "Training time took 97.808661 seconds to run 1 epoch\n",
      "('Epoch: ', 767, ' Average loss at step ', 1000, ': ', 0.018644938230514527)\n",
      "('Epoch: ', 767, ' Average loss at step ', 2000, ': ', 0.017099581837654115)\n",
      "('Epoch: ', 767, ' Average loss at step ', 2813, ': ', 0.016590435223039147)\n",
      "Training time took 44.025184 seconds to run 1 epoch\n",
      "('Epoch: ', 768, ' Average loss at step ', 1000, ': ', 128.52563463592529)\n",
      "('Epoch: ', 768, ' Average loss at step ', 2000, ': ', 129.08960620117188)\n",
      "('Epoch: ', 768, ' Average loss at step ', 3000, ': ', 129.81262706756593)\n",
      "('Epoch: ', 768, ' Average loss at step ', 4000, ': ', 128.77113271331788)\n",
      "('Epoch: ', 768, ' Average loss at step ', 4373, ': ', 127.5999953772432)\n",
      "('Epoch: ', 768, ' Average loss at step ', 761, ': ', 10059.703538111637)\n",
      "('Epoch: ', 768, ' Average loss at step ', 782, ': ', 11742.060728808219)\n",
      "('Epoch: ', 768, ' Average loss at step ', 787, ': ', 10.820770678629401)\n",
      "('Epoch: ', 768, ' Average loss at step ', 1000, ': ', 3.6547445931434632)\n",
      "('Epoch: ', 768, ' Average loss at step ', 2000, ': ', 3.4820660357475282)\n",
      "('Epoch: ', 768, ' Average loss at step ', 2813, ': ', 3.6431837310931954)\n",
      "Training time took 97.835523 seconds to run 1 epoch\n",
      "('Epoch: ', 769, ' Average loss at step ', 1000, ': ', 0.018742858827114104)\n",
      "('Epoch: ', 769, ' Average loss at step ', 2000, ': ', 0.016903821408748628)\n",
      "('Epoch: ', 769, ' Average loss at step ', 2813, ': ', 0.016573453698252222)\n",
      "Training time took 44.00131 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.984122748499\n",
      "Hits @ 1:  0.938225483656\n",
      "Testing time took 73.500677 seconds.\n",
      "\n",
      "('Epoch: ', 770, ' Average loss at step ', 1000, ': ', 129.4626280899048)\n",
      "('Epoch: ', 770, ' Average loss at step ', 2000, ': ', 126.65030072021484)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 770, ' Average loss at step ', 3000, ': ', 128.02976221466065)\n",
      "('Epoch: ', 770, ' Average loss at step ', 4000, ': ', 126.44)\n",
      "('Epoch: ', 770, ' Average loss at step ', 4373, ': ', 126.80419671663674)\n",
      "('Epoch: ', 770, ' Average loss at step ', 761, ': ', 10065.13609426398)\n",
      "('Epoch: ', 770, ' Average loss at step ', 782, ': ', 11790.843597451185)\n",
      "('Epoch: ', 770, ' Average loss at step ', 787, ': ', 10.616509368401447)\n",
      "('Epoch: ', 770, ' Average loss at step ', 1000, ': ', 3.7586204462051391)\n",
      "('Epoch: ', 770, ' Average loss at step ', 2000, ': ', 3.6478618669509886)\n",
      "('Epoch: ', 770, ' Average loss at step ', 2813, ': ', 3.812313281843815)\n",
      "Training time took 97.810103 seconds to run 1 epoch\n",
      "('Epoch: ', 771, ' Average loss at step ', 1000, ': ', 0.018840341687202455)\n",
      "('Epoch: ', 771, ' Average loss at step ', 2000, ': ', 0.017019389390945435)\n",
      "('Epoch: ', 771, ' Average loss at step ', 2813, ': ', 0.016638514810595018)\n",
      "Training time took 44.043476 seconds to run 1 epoch\n",
      "('Epoch: ', 772, ' Average loss at step ', 1000, ': ', 129.55870422363282)\n",
      "('Epoch: ', 772, ' Average loss at step ', 2000, ': ', 127.54283740234375)\n",
      "('Epoch: ', 772, ' Average loss at step ', 3000, ': ', 127.92785816192627)\n",
      "('Epoch: ', 772, ' Average loss at step ', 4000, ': ', 129.11282417297363)\n",
      "('Epoch: ', 772, ' Average loss at step ', 4373, ': ', 128.50191575737409)\n",
      "('Epoch: ', 772, ' Average loss at step ', 761, ': ', 10109.280482241982)\n",
      "('Epoch: ', 772, ' Average loss at step ', 782, ': ', 11796.116264704706)\n",
      "('Epoch: ', 772, ' Average loss at step ', 787, ': ', 10.756580657328055)\n",
      "('Epoch: ', 772, ' Average loss at step ', 1000, ': ', 3.5321317934989929)\n",
      "('Epoch: ', 772, ' Average loss at step ', 2000, ': ', 3.6381188802719118)\n",
      "('Epoch: ', 772, ' Average loss at step ', 2813, ': ', 3.8324044608130245)\n",
      "Training time took 97.863688 seconds to run 1 epoch\n",
      "('Epoch: ', 773, ' Average loss at step ', 1000, ': ', 0.018500176608562468)\n",
      "('Epoch: ', 773, ' Average loss at step ', 2000, ': ', 0.01704469358921051)\n",
      "('Epoch: ', 773, ' Average loss at step ', 2813, ': ', 0.016552919384293957)\n",
      "Training time took 44.02443 seconds to run 1 epoch\n",
      "('Epoch: ', 774, ' Average loss at step ', 1000, ': ', 130.49000000000001)\n",
      "('Epoch: ', 774, ' Average loss at step ', 2000, ': ', 125.76035697937012)\n",
      "('Epoch: ', 774, ' Average loss at step ', 3000, ': ', 127.28284113311767)\n",
      "('Epoch: ', 774, ' Average loss at step ', 4000, ': ', 128.88405475616455)\n",
      "('Epoch: ', 774, ' Average loss at step ', 4373, ': ', 127.9208195388958)\n",
      "('Epoch: ', 774, ' Average loss at step ', 761, ': ', 10065.142530581825)\n",
      "('Epoch: ', 774, ' Average loss at step ', 782, ': ', 11776.237763584348)\n",
      "('Epoch: ', 774, ' Average loss at step ', 787, ': ', 10.869412056969018)\n",
      "('Epoch: ', 774, ' Average loss at step ', 1000, ': ', 3.6943531789779662)\n",
      "('Epoch: ', 774, ' Average loss at step ', 2000, ': ', 3.6479580063819883)\n",
      "('Epoch: ', 774, ' Average loss at step ', 2813, ': ', 3.7125036023520486)\n",
      "Training time took 97.844754 seconds to run 1 epoch\n",
      "('Epoch: ', 775, ' Average loss at step ', 1000, ': ', 0.018614082157611848)\n",
      "('Epoch: ', 775, ' Average loss at step ', 2000, ': ', 0.016859801232814789)\n",
      "('Epoch: ', 775, ' Average loss at step ', 2813, ': ', 0.016566329768725803)\n",
      "Training time took 44.019309 seconds to run 1 epoch\n",
      "('Epoch: ', 776, ' Average loss at step ', 1000, ': ', 128.30386050415038)\n",
      "('Epoch: ', 776, ' Average loss at step ', 2000, ': ', 129.48017601013183)\n",
      "('Epoch: ', 776, ' Average loss at step ', 3000, ': ', 128.89886585235595)\n",
      "('Epoch: ', 776, ' Average loss at step ', 4000, ': ', 127.80954559326172)\n",
      "('Epoch: ', 776, ' Average loss at step ', 4373, ': ', 128.09504100840579)\n",
      "('Epoch: ', 776, ' Average loss at step ', 761, ': ', 10170.613562654195)\n",
      "('Epoch: ', 776, ' Average loss at step ', 782, ': ', 11788.878494243158)\n",
      "('Epoch: ', 776, ' Average loss at step ', 787, ': ', 10.49117027651566)\n",
      "('Epoch: ', 776, ' Average loss at step ', 1000, ': ', 3.6649824700355529)\n",
      "('Epoch: ', 776, ' Average loss at step ', 2000, ': ', 3.6164957351684572)\n",
      "('Epoch: ', 776, ' Average loss at step ', 2813, ': ', 3.6949999972517267)\n",
      "Training time took 97.845136 seconds to run 1 epoch\n",
      "('Epoch: ', 777, ' Average loss at step ', 1000, ': ', 0.018741167485713958)\n",
      "('Epoch: ', 777, ' Average loss at step ', 2000, ': ', 0.0169343381524086)\n",
      "('Epoch: ', 777, ' Average loss at step ', 2813, ': ', 0.016335958917739944)\n",
      "Training time took 44.033056 seconds to run 1 epoch\n",
      "('Epoch: ', 778, ' Average loss at step ', 1000, ': ', 129.88029967498778)\n",
      "('Epoch: ', 778, ' Average loss at step ', 2000, ': ', 128.12310564422609)\n",
      "('Epoch: ', 778, ' Average loss at step ', 3000, ': ', 127.36777487182617)\n",
      "('Epoch: ', 778, ' Average loss at step ', 4000, ': ', 127.34413578033447)\n",
      "('Epoch: ', 778, ' Average loss at step ', 4373, ': ', 127.50336165069253)\n",
      "('Epoch: ', 778, ' Average loss at step ', 761, ': ', 10076.307874177632)\n",
      "('Epoch: ', 778, ' Average loss at step ', 782, ': ', 11838.254577089669)\n",
      "('Epoch: ', 778, ' Average loss at step ', 787, ': ', 10.419223154470817)\n",
      "('Epoch: ', 778, ' Average loss at step ', 1000, ': ', 3.6685533375740049)\n",
      "('Epoch: ', 778, ' Average loss at step ', 2000, ': ', 3.5811512403488157)\n",
      "('Epoch: ', 778, ' Average loss at step ', 2813, ': ', 3.74969847155322)\n",
      "Training time took 97.747937 seconds to run 1 epoch\n",
      "('Epoch: ', 779, ' Average loss at step ', 1000, ': ', 0.018399234592914582)\n",
      "('Epoch: ', 779, ' Average loss at step ', 2000, ': ', 0.016717488467693328)\n",
      "('Epoch: ', 779, ' Average loss at step ', 2813, ': ', 0.016554271719725847)\n",
      "Training time took 44.060955 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.983989326217\n",
      "Hits @ 1:  0.939092728486\n",
      "Testing time took 73.471526 seconds.\n",
      "\n",
      "('Epoch: ', 780, ' Average loss at step ', 1000, ': ', 128.49024191284181)\n",
      "('Epoch: ', 780, ' Average loss at step ', 2000, ': ', 128.25333856201172)\n",
      "('Epoch: ', 780, ' Average loss at step ', 3000, ': ', 127.6821164932251)\n",
      "('Epoch: ', 780, ' Average loss at step ', 4000, ': ', 127.08326329803467)\n",
      "('Epoch: ', 780, ' Average loss at step ', 4373, ': ', 126.60925100182975)\n",
      "('Epoch: ', 780, ' Average loss at step ', 761, ': ', 10130.775173468339)\n",
      "('Epoch: ', 780, ' Average loss at step ', 782, ': ', 11785.66445262484)\n",
      "('Epoch: ', 780, ' Average loss at step ', 787, ': ', 10.76762356163588)\n",
      "('Epoch: ', 780, ' Average loss at step ', 1000, ': ', 3.6321657018661497)\n",
      "('Epoch: ', 780, ' Average loss at step ', 2000, ': ', 3.5451265468597413)\n",
      "('Epoch: ', 780, ' Average loss at step ', 2813, ': ', 3.6962695579810685)\n",
      "Training time took 97.918895 seconds to run 1 epoch\n",
      "('Epoch: ', 781, ' Average loss at step ', 1000, ': ', 0.018199279248714447)\n",
      "('Epoch: ', 781, ' Average loss at step ', 2000, ': ', 0.016944923579692839)\n",
      "('Epoch: ', 781, ' Average loss at step ', 2813, ': ', 0.016485969641525756)\n",
      "Training time took 44.042378 seconds to run 1 epoch\n",
      "('Epoch: ', 782, ' Average loss at step ', 1000, ': ', 129.39891825866698)\n",
      "('Epoch: ', 782, ' Average loss at step ', 2000, ': ', 126.69378065490723)\n",
      "('Epoch: ', 782, ' Average loss at step ', 3000, ': ', 127.02471650695801)\n",
      "('Epoch: ', 782, ' Average loss at step ', 4000, ': ', 128.8517998123169)\n",
      "('Epoch: ', 782, ' Average loss at step ', 4373, ': ', 129.98184107708676)\n",
      "('Epoch: ', 782, ' Average loss at step ', 761, ': ', 10098.4948255037)\n",
      "('Epoch: ', 782, ' Average loss at step ', 782, ': ', 11844.04863056178)\n",
      "('Epoch: ', 782, ' Average loss at step ', 787, ': ', 10.599012949994503)\n",
      "('Epoch: ', 782, ' Average loss at step ', 1000, ': ', 3.7258987498283385)\n",
      "('Epoch: ', 782, ' Average loss at step ', 2000, ': ', 3.7020725831985475)\n",
      "('Epoch: ', 782, ' Average loss at step ', 2813, ': ', 3.7192959656269093)\n",
      "Training time took 97.862662 seconds to run 1 epoch\n",
      "('Epoch: ', 783, ' Average loss at step ', 1000, ': ', 0.018398593604564667)\n",
      "('Epoch: ', 783, ' Average loss at step ', 2000, ': ', 0.016787016451358796)\n",
      "('Epoch: ', 783, ' Average loss at step ', 2813, ': ', 0.016230457742225948)\n",
      "Training time took 44.025775 seconds to run 1 epoch\n",
      "('Epoch: ', 784, ' Average loss at step ', 1000, ': ', 129.65442956542969)\n",
      "('Epoch: ', 784, ' Average loss at step ', 2000, ': ', 128.09426087951661)\n",
      "('Epoch: ', 784, ' Average loss at step ', 3000, ': ', 127.83236236572266)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 784, ' Average loss at step ', 4000, ': ', 128.80704315185548)\n",
      "('Epoch: ', 784, ' Average loss at step ', 4373, ': ', 128.84718168935467)\n",
      "('Epoch: ', 784, ' Average loss at step ', 761, ': ', 10189.064187782689)\n",
      "('Epoch: ', 784, ' Average loss at step ', 782, ': ', 11847.431501205385)\n",
      "('Epoch: ', 784, ' Average loss at step ', 787, ': ', 10.378141213312707)\n",
      "('Epoch: ', 784, ' Average loss at step ', 1000, ': ', 3.7515263538360597)\n",
      "('Epoch: ', 784, ' Average loss at step ', 2000, ': ', 3.5408287448883056)\n",
      "('Epoch: ', 784, ' Average loss at step ', 2813, ': ', 3.5876165246728604)\n",
      "Training time took 97.875625 seconds to run 1 epoch\n",
      "('Epoch: ', 785, ' Average loss at step ', 1000, ': ', 0.018180806815624236)\n",
      "('Epoch: ', 785, ' Average loss at step ', 2000, ': ', 0.016549276173114778)\n",
      "('Epoch: ', 785, ' Average loss at step ', 2813, ': ', 0.016428715122744367)\n",
      "Training time took 44.039434 seconds to run 1 epoch\n",
      "('Epoch: ', 786, ' Average loss at step ', 1000, ': ', 128.98618329620362)\n",
      "('Epoch: ', 786, ' Average loss at step ', 2000, ': ', 128.76653242492677)\n",
      "('Epoch: ', 786, ' Average loss at step ', 3000, ': ', 128.95229212188721)\n",
      "('Epoch: ', 786, ' Average loss at step ', 4000, ': ', 126.08653149414063)\n",
      "('Epoch: ', 786, ' Average loss at step ', 4373, ': ', 129.45378965972571)\n",
      "('Epoch: ', 786, ' Average loss at step ', 761, ': ', 10072.180744371915)\n",
      "('Epoch: ', 786, ' Average loss at step ', 782, ': ', 11829.272768535931)\n",
      "('Epoch: ', 786, ' Average loss at step ', 787, ': ', 10.848481093350864)\n",
      "('Epoch: ', 786, ' Average loss at step ', 1000, ': ', 3.6106657214164732)\n",
      "('Epoch: ', 786, ' Average loss at step ', 2000, ': ', 3.6076614179611206)\n",
      "('Epoch: ', 786, ' Average loss at step ', 2813, ': ', 3.6452453253891668)\n",
      "Training time took 97.864914 seconds to run 1 epoch\n",
      "('Epoch: ', 787, ' Average loss at step ', 1000, ': ', 0.018351073563098907)\n",
      "('Epoch: ', 787, ' Average loss at step ', 2000, ': ', 0.016676815032958984)\n",
      "('Epoch: ', 787, ' Average loss at step ', 2813, ': ', 0.016431166473867859)\n",
      "Training time took 44.041266 seconds to run 1 epoch\n",
      "('Epoch: ', 788, ' Average loss at step ', 1000, ': ', 126.94412705230712)\n",
      "('Epoch: ', 788, ' Average loss at step ', 2000, ': ', 128.64811099243164)\n",
      "('Epoch: ', 788, ' Average loss at step ', 3000, ': ', 126.5041389541626)\n",
      "('Epoch: ', 788, ' Average loss at step ', 4000, ': ', 127.78403575897217)\n",
      "('Epoch: ', 788, ' Average loss at step ', 4373, ': ', 126.85577499225576)\n",
      "('Epoch: ', 788, ' Average loss at step ', 761, ': ', 10091.960541735198)\n",
      "('Epoch: ', 788, ' Average loss at step ', 782, ': ', 11888.917409821142)\n",
      "('Epoch: ', 788, ' Average loss at step ', 787, ': ', 10.64620615689809)\n",
      "('Epoch: ', 788, ' Average loss at step ', 1000, ': ', 3.6517061185836792)\n",
      "('Epoch: ', 788, ' Average loss at step ', 2000, ': ', 3.6501595678329468)\n",
      "('Epoch: ', 788, ' Average loss at step ', 2813, ': ', 3.5603657643783269)\n",
      "Training time took 97.750953 seconds to run 1 epoch\n",
      "('Epoch: ', 789, ' Average loss at step ', 1000, ': ', 0.018202296495437621)\n",
      "('Epoch: ', 789, ' Average loss at step ', 2000, ': ', 0.016502773761749266)\n",
      "('Epoch: ', 789, ' Average loss at step ', 2813, ': ', 0.01641669818039598)\n",
      "Training time took 44.020186 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.983922615077\n",
      "Hits @ 1:  0.938092061374\n",
      "Testing time took 73.490284 seconds.\n",
      "\n",
      "('Epoch: ', 790, ' Average loss at step ', 1000, ': ', 128.13201425170899)\n",
      "('Epoch: ', 790, ' Average loss at step ', 2000, ': ', 127.64749966430664)\n",
      "('Epoch: ', 790, ' Average loss at step ', 3000, ': ', 129.25299094390869)\n",
      "('Epoch: ', 790, ' Average loss at step ', 4000, ': ', 125.25529409027099)\n",
      "('Epoch: ', 790, ' Average loss at step ', 4373, ': ', 129.5729285619592)\n",
      "('Epoch: ', 790, ' Average loss at step ', 761, ': ', 10148.669095651727)\n",
      "('Epoch: ', 790, ' Average loss at step ', 782, ': ', 11882.280261558699)\n",
      "('Epoch: ', 790, ' Average loss at step ', 787, ': ', 10.344633224356265)\n",
      "('Epoch: ', 790, ' Average loss at step ', 1000, ': ', 3.6900716800689697)\n",
      "('Epoch: ', 790, ' Average loss at step ', 2000, ': ', 3.6274516525268554)\n",
      "('Epoch: ', 790, ' Average loss at step ', 2813, ': ', 3.6817806777108477)\n",
      "Training time took 97.772939 seconds to run 1 epoch\n",
      "('Epoch: ', 791, ' Average loss at step ', 1000, ': ', 0.018105710923671723)\n",
      "('Epoch: ', 791, ' Average loss at step ', 2000, ': ', 0.016628559291362761)\n",
      "('Epoch: ', 791, ' Average loss at step ', 2813, ': ', 0.016284044740235277)\n",
      "Training time took 44.034616 seconds to run 1 epoch\n",
      "('Epoch: ', 792, ' Average loss at step ', 1000, ': ', 130.31805124664308)\n",
      "('Epoch: ', 792, ' Average loss at step ', 2000, ': ', 129.2212855834961)\n",
      "('Epoch: ', 792, ' Average loss at step ', 3000, ': ', 128.19908906555176)\n",
      "('Epoch: ', 792, ' Average loss at step ', 4000, ': ', 127.77253969573975)\n",
      "('Epoch: ', 792, ' Average loss at step ', 4373, ': ', 132.74193548387098)\n",
      "('Epoch: ', 792, ' Average loss at step ', 761, ': ', 10196.057425087376)\n",
      "('Epoch: ', 792, ' Average loss at step ', 782, ': ', 11836.00664900268)\n",
      "('Epoch: ', 792, ' Average loss at step ', 787, ': ', 10.82370705640953)\n",
      "('Epoch: ', 792, ' Average loss at step ', 1000, ': ', 3.7097308712005614)\n",
      "('Epoch: ', 792, ' Average loss at step ', 2000, ': ', 3.6278786144256592)\n",
      "('Epoch: ', 792, ' Average loss at step ', 2813, ': ', 3.5959603357784853)\n",
      "Training time took 97.746043 seconds to run 1 epoch\n",
      "('Epoch: ', 793, ' Average loss at step ', 1000, ': ', 0.018174699544906615)\n",
      "('Epoch: ', 793, ' Average loss at step ', 2000, ': ', 0.016482162892818449)\n",
      "('Epoch: ', 793, ' Average loss at step ', 2813, ': ', 0.016187180292430183)\n",
      "Training time took 44.004233 seconds to run 1 epoch\n",
      "('Epoch: ', 794, ' Average loss at step ', 1000, ': ', 129.73561643218994)\n",
      "('Epoch: ', 794, ' Average loss at step ', 2000, ': ', 127.65469059753418)\n",
      "('Epoch: ', 794, ' Average loss at step ', 3000, ': ', 128.89589640808106)\n",
      "('Epoch: ', 794, ' Average loss at step ', 4000, ': ', 125.51574628448486)\n",
      "('Epoch: ', 794, ' Average loss at step ', 4373, ': ', 126.88175929489957)\n",
      "('Epoch: ', 794, ' Average loss at step ', 761, ': ', 10223.992992521587)\n",
      "('Epoch: ', 794, ' Average loss at step ', 782, ': ', 11857.760276413452)\n",
      "('Epoch: ', 794, ' Average loss at step ', 787, ': ', 10.390570992428534)\n",
      "('Epoch: ', 794, ' Average loss at step ', 1000, ': ', 3.5662574515342711)\n",
      "('Epoch: ', 794, ' Average loss at step ', 2000, ': ', 3.5749537248611452)\n",
      "('Epoch: ', 794, ' Average loss at step ', 2813, ': ', 3.6027103709469874)\n",
      "Training time took 97.75616 seconds to run 1 epoch\n",
      "('Epoch: ', 795, ' Average loss at step ', 1000, ': ', 0.01812786740064621)\n",
      "('Epoch: ', 795, ' Average loss at step ', 2000, ': ', 0.01635693109035492)\n",
      "('Epoch: ', 795, ' Average loss at step ', 2813, ': ', 0.016176989806696698)\n",
      "Training time took 44.051977 seconds to run 1 epoch\n",
      "('Epoch: ', 796, ' Average loss at step ', 1000, ': ', 128.13174855041504)\n",
      "('Epoch: ', 796, ' Average loss at step ', 2000, ': ', 128.33925872039794)\n",
      "('Epoch: ', 796, ' Average loss at step ', 3000, ': ', 127.28172386169433)\n",
      "('Epoch: ', 796, ' Average loss at step ', 4000, ': ', 128.94746057891845)\n",
      "('Epoch: ', 796, ' Average loss at step ', 4373, ': ', 125.55700470298849)\n",
      "('Epoch: ', 796, ' Average loss at step ', 761, ': ', 10165.253904322573)\n",
      "('Epoch: ', 796, ' Average loss at step ', 782, ': ', 11932.311672235115)\n",
      "('Epoch: ', 796, ' Average loss at step ', 787, ': ', 10.446541971832742)\n",
      "('Epoch: ', 796, ' Average loss at step ', 1000, ': ', 3.5210731620788573)\n",
      "('Epoch: ', 796, ' Average loss at step ', 2000, ': ', 3.745558000564575)\n",
      "('Epoch: ', 796, ' Average loss at step ', 2813, ': ', 3.5575259888700663)\n",
      "Training time took 97.753783 seconds to run 1 epoch\n",
      "('Epoch: ', 797, ' Average loss at step ', 1000, ': ', 0.018030165612697602)\n",
      "('Epoch: ', 797, ' Average loss at step ', 2000, ': ', 0.016607539892196654)\n",
      "('Epoch: ', 797, ' Average loss at step ', 2813, ': ', 0.016051981249466319)\n",
      "Training time took 44.062641 seconds to run 1 epoch\n",
      "('Epoch: ', 798, ' Average loss at step ', 1000, ': ', 126.411898727417)\n",
      "('Epoch: ', 798, ' Average loss at step ', 2000, ': ', 128.8142402496338)\n",
      "('Epoch: ', 798, ' Average loss at step ', 3000, ': ', 129.73554779815674)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 798, ' Average loss at step ', 4000, ': ', 127.98091933441162)\n",
      "('Epoch: ', 798, ' Average loss at step ', 4373, ': ', 128.46774193548387)\n",
      "('Epoch: ', 798, ' Average loss at step ', 761, ': ', 10249.092370605469)\n",
      "('Epoch: ', 798, ' Average loss at step ', 782, ': ', 11838.752157565421)\n",
      "('Epoch: ', 798, ' Average loss at step ', 787, ': ', 10.570443854683834)\n",
      "('Epoch: ', 798, ' Average loss at step ', 1000, ': ', 3.5843036360740661)\n",
      "('Epoch: ', 798, ' Average loss at step ', 2000, ': ', 3.5995849461555482)\n",
      "('Epoch: ', 798, ' Average loss at step ', 2813, ': ', 3.6347274739166786)\n",
      "Training time took 97.821369 seconds to run 1 epoch\n",
      "('Epoch: ', 799, ' Average loss at step ', 1000, ': ', 0.017893794357776643)\n",
      "('Epoch: ', 799, ' Average loss at step ', 2000, ': ', 0.016540671050548555)\n",
      "('Epoch: ', 799, ' Average loss at step ', 2813, ': ', 0.016080645284629221)\n",
      "Training time took 44.024111 seconds to run 1 epoch\n",
      "Mean Rank:  1  of  28683\n",
      "Hits @ 10:  0.983589059373\n",
      "Hits @ 1:  0.938292194797\n",
      "Testing time took 73.504474 seconds.\n",
      "\n",
      "Training time took 62628.393806 seconds to run 400 epoch\n"
     ]
    }
   ],
   "source": [
    "start_time = dt.datetime.now()\n",
    "run(tfgraph, 800) \n",
    "end_time = dt.datetime.now()\n",
    "print(\"Training time took {} seconds to run {} epoch\".format((end_time-start_time).total_seconds(), totalEpoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "TextKE6(TRANS).ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
